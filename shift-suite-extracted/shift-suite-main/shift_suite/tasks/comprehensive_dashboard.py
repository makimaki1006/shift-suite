#!/usr/bin/env python3
"""
comprehensive_dashboard.py - çµ±åˆã‚·ãƒ•ãƒˆåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
æ™‚ç³»åˆ—åˆ†æãƒ»ç–²åŠ´åº¦ãƒ»å…¬å¹³æ€§ãƒ»å‹¤å‹™åŒºåˆ†å¯¾å¿œèƒ½åŠ›ã®åŒ…æ‹¬çš„åˆ†æã‚·ã‚¹ãƒ†ãƒ 
"""

import logging
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union
from datetime import datetime, timedelta, date
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px

log = logging.getLogger(__name__)

@dataclass
class FatigueMetrics:
    """ç–²åŠ´åº¦æŒ‡æ¨™"""
    consecutive_work_days: int = 0
    night_shift_frequency: float = 0.0
    rest_insufficiency: float = 0.0
    overtime_hours: float = 0.0
    fatigue_score: float = 0.0
    risk_level: str = "ä½"  # ä½/ä¸­/é«˜

@dataclass
class FairnessMetrics:
    """å…¬å¹³æ€§æŒ‡æ¨™"""
    work_hours_variance: float = 0.0
    night_shift_variance: float = 0.0
    holiday_work_variance: float = 0.0
    fairness_score: float = 1.0
    fairness_level: str = "è‰¯å¥½"  # è‰¯å¥½/æ™®é€š/è¦æ”¹å–„

@dataclass
class WorktypeCapability:
    """å‹¤å‹™åŒºåˆ†å¯¾å¿œèƒ½åŠ›"""
    total_worktypes: int = 0
    capable_worktypes: int = 0
    capability_ratio: float = 0.0
    multiskill_weight: float = 1.0
    capability_score: float = 0.0

@dataclass
class StaffAnalytics:
    """è·å“¡åˆ†æãƒ‡ãƒ¼ã‚¿"""
    staff_id: str
    name: str
    role: str
    employment_type: str
    fatigue_metrics: FatigueMetrics
    fairness_metrics: FairnessMetrics
    worktype_capability: WorktypeCapability
    monthly_trends: Dict[str, float]
    performance_score: float = 0.0

class TimeSeriesDataModel:
    """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(self, output_dir: Path):
        self.output_dir = Path(output_dir)
        self.monthly_trends = {}
        self.daily_patterns = {}
        self.staff_timeseries = {}
        self.worktype_evolution = {}
        self.data_range = None
        
    def load_historical_data(self, months_back: int = 6) -> bool:
        """éå»æ•°ã‹æœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            log.info(f"æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹: éå»{months_back}ã‹æœˆ")
            
            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
            data_files = {
                'shortage_time': list(self.output_dir.glob('**/shortage_time*.parquet')),
                'heat_data': list(self.output_dir.glob('**/heat_*.parquet')),
                'staff_data': list(self.output_dir.glob('**/intermediate_data*.parquet')),
                'need_data': list(self.output_dir.glob('**/need_per_date_slot*.parquet'))
            }
            
            found_files = sum(len(files) for files in data_files.values())
            log.info(f"ç™ºè¦‹ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {found_files}")
            
            if found_files == 0:
                log.warning("æ™‚ç³»åˆ—åˆ†æç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            # å„ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®å‡¦ç†
            self._process_shortage_trends(data_files['shortage_time'])
            self._process_staff_patterns(data_files['staff_data'])
            self._process_worktype_evolution(data_files['heat_data'])
            
            log.info("æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
            return True
            
        except Exception as e:
            log.error(f"æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _process_shortage_trends(self, files: List[Path]) -> None:
        """ä¸è¶³æ™‚é–“ãƒˆãƒ¬ãƒ³ãƒ‰ã®å‡¦ç†"""
        if not files:
            return
            
        for file_path in files:
            try:
                df = pd.read_parquet(file_path)
                
                # æ—¥ä»˜åˆ—ã®æŠ½å‡º
                date_columns = []
                for col in df.columns:
                    try:
                        pd.to_datetime(str(col))
                        date_columns.append(col)
                    except:
                        continue
                
                if date_columns:
                    # æœˆæ¬¡é›†è¨ˆ
                    monthly_data = {}
                    for col in date_columns:
                        try:
                            date_obj = pd.to_datetime(str(col))
                            month_key = date_obj.strftime("%Y-%m")
                            
                            if month_key not in monthly_data:
                                monthly_data[month_key] = 0
                            
                            monthly_data[month_key] += df[col].sum() * 0.5  # 30åˆ†â†’æ™‚é–“æ›ç®—
                        except:
                            continue
                    
                    self.monthly_trends['shortage'] = monthly_data
                    log.info(f"ä¸è¶³æ™‚é–“ãƒˆãƒ¬ãƒ³ãƒ‰å‡¦ç†å®Œäº†: {len(monthly_data)}ã‹æœˆåˆ†")
                    
            except Exception as e:
                log.warning(f"ä¸è¶³ãƒˆãƒ¬ãƒ³ãƒ‰å‡¦ç†ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
    
    def _process_staff_patterns(self, files: List[Path]) -> None:
        """è·å“¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‡¦ç†"""
        if not files:
            return
            
        for file_path in files:
            try:
                df = pd.read_parquet(file_path)
                
                if 'staff' in df.columns and 'ds' in df.columns:
                    # è·å“¡åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³é›†è¨ˆ
                    staff_patterns = df.groupby('staff').agg({
                        'ds': 'count',  # å‹¤å‹™æ—¥æ•°
                        'role': 'first',  # è·ç¨®
                        'employment': 'first' if 'employment' in df.columns else lambda x: 'unknown'
                    }).to_dict('index')
                    
                    self.staff_timeseries.update(staff_patterns)
                    log.info(f"è·å“¡ãƒ‘ã‚¿ãƒ¼ãƒ³å‡¦ç†å®Œäº†: {len(staff_patterns)}å")
                    
            except Exception as e:
                log.warning(f"è·å“¡ãƒ‘ã‚¿ãƒ¼ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
    
    def _process_worktype_evolution(self, files: List[Path]) -> None:
        """å‹¤å‹™åŒºåˆ†é€²åŒ–ã®å‡¦ç†"""
        if not files:
            return
            
        worktype_data = {}
        for file_path in files:
            try:
                if 'heat_' in file_path.name:
                    role = file_path.stem.replace('heat_', '')
                    df = pd.read_parquet(file_path)
                    
                    # å‹¤å‹™åŒºåˆ†åˆ¥é›†è¨ˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    worktype_data[role] = {
                        'total_slots': df.size,
                        'active_slots': (df > 0).sum().sum() if len(df.columns) > 0 else 0
                    }
                    
            except Exception as e:
                log.warning(f"å‹¤å‹™åŒºåˆ†é€²åŒ–å‡¦ç†ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
        
        self.worktype_evolution = worktype_data
        log.info(f"å‹¤å‹™åŒºåˆ†é€²åŒ–å‡¦ç†å®Œäº†: {len(worktype_data)}è·ç¨®")

class AdvancedAnalyticsEngine:
    """é«˜åº¦åˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, timeseries_model: TimeSeriesDataModel):
        self.timeseries_model = timeseries_model
        self.fatigue_weights = {
            'consecutive_days': 1.5,
            'night_frequency': 2.0,
            'rest_insufficiency': 2.5,
            'overtime': 1.2
        }
        self.fairness_weights = {
            'work_hours': 0.3,
            'night_shifts': 0.4,
            'holiday_work': 0.3
        }
    
    def calculate_fatigue_metrics(self, staff_data: Dict[str, Any]) -> FatigueMetrics:
        """ç–²åŠ´åº¦æŒ‡æ¨™ã®è¨ˆç®—"""
        try:
            # åŸºæœ¬å€¤ã®å–å¾—ï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰
            consecutive_days = staff_data.get('consecutive_work_days', 0)
            night_frequency = staff_data.get('night_shift_ratio', 0.0)
            rest_insufficiency = staff_data.get('insufficient_rest_ratio', 0.0)
            overtime_hours = staff_data.get('monthly_overtime', 0.0)
            
            # ç–²åŠ´ã‚¹ã‚³ã‚¢è¨ˆç®—
            fatigue_score = (
                consecutive_days * self.fatigue_weights['consecutive_days'] +
                night_frequency * self.fatigue_weights['night_frequency'] +
                rest_insufficiency * self.fatigue_weights['rest_insufficiency'] +
                overtime_hours * self.fatigue_weights['overtime']
            ) / 10.0  # æ­£è¦åŒ–
            
            # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¤å®š
            if fatigue_score >= 7.0:
                risk_level = "é«˜"
            elif fatigue_score >= 4.0:
                risk_level = "ä¸­"
            else:
                risk_level = "ä½"
            
            return FatigueMetrics(
                consecutive_work_days=consecutive_days,
                night_shift_frequency=night_frequency,
                rest_insufficiency=rest_insufficiency,
                overtime_hours=overtime_hours,
                fatigue_score=fatigue_score,
                risk_level=risk_level
            )
            
        except Exception as e:
            log.error(f"ç–²åŠ´åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return FatigueMetrics()
    
    def calculate_fairness_metrics(self, team_data: List[Dict[str, Any]]) -> Dict[str, FairnessMetrics]:
        """å…¬å¹³æ€§æŒ‡æ¨™ã®è¨ˆç®—"""
        fairness_results = {}
        
        try:
            if not team_data:
                return fairness_results
            
            # ãƒãƒ¼ãƒ å…¨ä½“ã®çµ±è¨ˆè¨ˆç®—
            work_hours = [member.get('monthly_hours', 0) for member in team_data]
            night_shifts = [member.get('monthly_night_shifts', 0) for member in team_data]
            holiday_work = [member.get('monthly_holiday_work', 0) for member in team_data]
            
            # åˆ†æ•£è¨ˆç®—
            work_hours_var = np.var(work_hours) if len(work_hours) > 1 else 0
            night_shifts_var = np.var(night_shifts) if len(night_shifts) > 1 else 0
            holiday_work_var = np.var(holiday_work) if len(holiday_work) > 1 else 0
            
            # å„è·å“¡ã®å…¬å¹³æ€§æŒ‡æ¨™
            for member in team_data:
                staff_id = member.get('staff_id', 'unknown')
                
                # å…¬å¹³æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
                fairness_score = 1.0 - (
                    work_hours_var * self.fairness_weights['work_hours'] +
                    night_shifts_var * self.fairness_weights['night_shifts'] +
                    holiday_work_var * self.fairness_weights['holiday_work']
                ) / 100.0  # æ­£è¦åŒ–
                
                fairness_score = max(0.0, min(1.0, fairness_score))
                
                # ãƒ¬ãƒ™ãƒ«åˆ¤å®š
                if fairness_score >= 0.8:
                    fairness_level = "è‰¯å¥½"
                elif fairness_score >= 0.6:
                    fairness_level = "æ™®é€š"
                else:
                    fairness_level = "è¦æ”¹å–„"
                
                fairness_results[staff_id] = FairnessMetrics(
                    work_hours_variance=work_hours_var,
                    night_shift_variance=night_shifts_var,
                    holiday_work_variance=holiday_work_var,
                    fairness_score=fairness_score,
                    fairness_level=fairness_level
                )
                
        except Exception as e:
            log.error(f"å…¬å¹³æ€§è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return fairness_results
    
    def calculate_worktype_capability(self, staff_data: Dict[str, Any], available_worktypes: List[str]) -> WorktypeCapability:
        """å‹¤å‹™åŒºåˆ†å¯¾å¿œèƒ½åŠ›ã®è¨ˆç®—"""
        try:
            capable_worktypes = staff_data.get('capable_worktypes', [])
            total_worktypes = len(available_worktypes)
            capable_count = len(capable_worktypes)
            
            capability_ratio = capable_count / total_worktypes if total_worktypes > 0 else 0
            
            # ãƒãƒ«ãƒã‚¹ã‚­ãƒ«é‡ã¿ï¼ˆå¯¾å¿œå¯èƒ½å‹¤å‹™åŒºåˆ†æ•°ã«å¿œã˜ã¦ï¼‰
            if capable_count >= total_worktypes * 0.8:
                multiskill_weight = 1.5
            elif capable_count >= total_worktypes * 0.6:
                multiskill_weight = 1.2
            else:
                multiskill_weight = 1.0
            
            capability_score = capability_ratio * multiskill_weight
            
            return WorktypeCapability(
                total_worktypes=total_worktypes,
                capable_worktypes=capable_count,
                capability_ratio=capability_ratio,
                multiskill_weight=multiskill_weight,
                capability_score=capability_score
            )
            
        except Exception as e:
            log.error(f"å‹¤å‹™åŒºåˆ†å¯¾å¿œèƒ½åŠ›è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return WorktypeCapability()

class IntegratedVisualizationSystem:
    """çµ±åˆå¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, analytics_engine: AdvancedAnalyticsEngine):
        self.analytics_engine = analytics_engine
        self.color_schemes = {
            'fatigue': ['#2ecc71', '#f39c12', '#e74c3c'],  # ç·‘ãƒ»ã‚ªãƒ¬ãƒ³ã‚¸ãƒ»èµ¤
            'fairness': ['#3498db', '#9b59b6', '#e67e22'],  # é’ãƒ»ç´«ãƒ»ã‚ªãƒ¬ãƒ³ã‚¸
            'capability': ['#1abc9c', '#34495e', '#e74c3c']  # ãƒ†ã‚£ãƒ¼ãƒ«ãƒ»ã‚°ãƒ¬ãƒ¼ãƒ»èµ¤
        }
    
    def _get_optimal_text_position(self, x_values: List[float], y_values: List[float]) -> str:
        """ãƒ‡ãƒ¼ã‚¿ç‚¹ã®å¯†åº¦ã«åŸºã¥ãæœ€é©ãªãƒ†ã‚­ã‚¹ãƒˆä½ç½®ã‚’æ±ºå®š"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ç‚¹ã®åˆ†æ•£ã‚’è¨ˆç®—
            x_range = max(x_values) - min(x_values) if len(x_values) > 1 else 1
            y_range = max(y_values) - min(y_values) if len(y_values) > 1 else 1
            
            # å¯†åº¦ãŒé«˜ã„å ´åˆã¯ä¸Šä¸‹ã«åˆ†æ•£
            if len(x_values) > 10:
                return "middle right"
            elif x_range < y_range:
                return "top center"
            else:
                return "middle right"
        except Exception:
            return "top center"
    
    def _create_smart_hover_text(self, name: str, metrics: Dict[str, float]) -> str:
        """ã‚¹ãƒãƒ¼ãƒˆãªãƒ›ãƒãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®ç”Ÿæˆ"""
        lines = [f"<b>{name}</b>"]
        for key, value in metrics.items():
            if isinstance(value, float):
                lines.append(f"{key}: {value:.2f}")
            else:
                lines.append(f"{key}: {value}")
        return "<br>".join(lines)
    
    def create_comprehensive_dashboard(self, staff_analytics: List[StaffAnalytics]) -> go.Figure:
        """çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ä½œæˆï¼ˆã‚µã‚¤ã‚ºæœ€é©åŒ–ç‰ˆï¼‰"""
        try:
            staff_count = len(staff_analytics)
            
            # ã‚°ãƒ©ãƒ•æ•°ã¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å‹•çš„æ±ºå®šï¼ˆã‚µã‚¤ã‚ºå„ªå…ˆï¼‰
            if staff_count <= 20:
                # å°‘æ•°ã®å ´åˆ: 2x2ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§å¤§ããè¡¨ç¤º
                fig = make_subplots(
                    rows=2, cols=2,
                    subplot_titles=[
                        "ç–²åŠ´åº¦vsæ€§èƒ½åˆ†æ", "å…¬å¹³æ€§ã‚¹ã‚³ã‚¢",
                        "å‹¤å‹™åŒºåˆ†å¯¾å¿œèƒ½åŠ›", "è·å“¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹"
                    ],
                    specs=[
                        [{"type": "scatter"}, {"type": "bar"}],
                        [{"type": "scatter"}, {"type": "bar"}]
                    ],
                    vertical_spacing=0.18,
                    horizontal_spacing=0.12
                )
                show_subplots = ['fatigue_vs_performance', 'fairness', 'capability', 'performance']
            else:
                # å¤šæ•°ã®å ´åˆ: 1x2ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§æœ€å¤§è¡¨ç¤º
                fig = make_subplots(
                    rows=1, cols=2,
                    subplot_titles=[
                        "ç–²åŠ´åº¦vsæ€§èƒ½åˆ†æ", "å…¬å¹³æ€§ã‚¹ã‚³ã‚¢"
                    ],
                    specs=[
                        [{"type": "scatter"}, {"type": "bar"}]
                    ],
                    horizontal_spacing=0.15
                )
                show_subplots = ['fatigue_vs_performance', 'fairness']
            
            # ãƒ‡ãƒ¼ã‚¿é‡ã«å¿œã˜ãŸè¡¨ç¤ºåˆ¶å¾¡
            show_text_labels = staff_count <= 10  # 10äººä»¥ä¸‹ã®å ´åˆã®ã¿ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
            use_abbreviated_names = staff_count > 10  # 10äººè¶…éã§åå‰ç•¥ç§°åŒ–
            
            if not staff_analytics:
                # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
                fig.add_annotation(
                    text="ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„",
                    xref="paper", yref="paper",
                    x=0.5, y=0.5, xanchor='center', yanchor='middle',
                    showarrow=False,
                    font=dict(size=16, color="#666")
                )
                return fig
            
            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
            fatigue_scores = [staff.fatigue_metrics.fatigue_score for staff in staff_analytics]
            performance_scores = [staff.performance_score for staff in staff_analytics]
            fairness_scores = [staff.fairness_metrics.fairness_score for staff in staff_analytics]
            capability_scores = [staff.worktype_capability.capability_score for staff in staff_analytics]
            capable_counts = [staff.worktype_capability.capable_worktypes for staff in staff_analytics]
            names = [staff.name for staff in staff_analytics]
            roles = [staff.role for staff in staff_analytics]
            
            # è¡¨ç¤ºåã®å‹•çš„å‡¦ç†ï¼ˆè·å“¡IDã§ã‚‚ãƒ›ãƒãƒ¼ã§å®Ÿåè¡¨ç¤ºï¼‰
            if use_abbreviated_names:
                display_names = [f"S{i+1}" for i in range(staff_count)]
            else:
                display_names = names
            
            # 1. ç–²åŠ´åº¦vsæ€§èƒ½åˆ†æï¼ˆå¿…é ˆï¼‰
            if 'fatigue_vs_performance' in show_subplots:
                scatter_mode = 'markers+text' if show_text_labels else 'markers'
                text_position = self._get_optimal_text_position(fatigue_scores, performance_scores) if show_text_labels else None
                
                fig.add_trace(
                    go.Scatter(
                        x=fatigue_scores,
                        y=performance_scores,
                        mode=scatter_mode,
                        text=display_names if show_text_labels else None,
                        textposition=text_position,
                        textfont=dict(size=10),
                        hovertext=[f"<b>{name}</b><br>è·ç¨®: {role}<br>ç–²åŠ´åº¦: {f:.1f}<br>æ€§èƒ½: {p:.1f}" 
                                  for name, role, f, p in zip(names, roles, fatigue_scores, performance_scores)],
                        hoverinfo='text',
                        marker=dict(
                            size=16 if not show_text_labels else 12,
                            color=fatigue_scores,
                            colorscale='RdYlGn',
                            reversescale=True,
                            showscale=False
                        ),
                        name="ç–²åŠ´åº¦vsæ€§èƒ½"
                    ),
                    row=1, col=1
                )
            
            # 2. å…¬å¹³æ€§åˆ†æï¼ˆå¿…é ˆï¼‰
            if 'fairness' in show_subplots:
                hover_text = [f"<b>{name}</b><br>è·ç¨®: {role}<br>å…¬å¹³æ€§: {score:.2f}" 
                             for name, role, score in zip(names, roles, fairness_scores)]
                
                col_pos = 2 if staff_count <= 20 else 2
                row_pos = 1
                
                fig.add_trace(
                    go.Bar(
                        x=display_names,
                        y=fairness_scores,
                        name="å…¬å¹³æ€§ã‚¹ã‚³ã‚¢",
                        marker_color=self.color_schemes['fairness'][0],
                        hovertext=hover_text,
                        hoverinfo='text'
                    ),
                    row=row_pos, col=col_pos
                )
            
            # 3. å‹¤å‹™åŒºåˆ†å¯¾å¿œèƒ½åŠ›ï¼ˆæ¡ä»¶ä»˜ãï¼‰
            if 'capability' in show_subplots:
                fig.add_trace(
                    go.Scatter(
                        x=capable_counts,
                        y=capability_scores,
                        mode='markers',
                        marker=dict(
                            size=18,
                            color=capability_scores,
                            colorscale='Viridis',
                            showscale=False
                        ),
                        hovertext=[f"<b>{name}</b><br>è·ç¨®: {role}<br>å¯¾å¿œå¯èƒ½: {count}ç¨®<br>ã‚¹ã‚³ã‚¢: {score:.2f}" 
                                  for name, role, count, score in zip(names, roles, capable_counts, capability_scores)],
                        hoverinfo='text',
                        name="å¯¾å¿œèƒ½åŠ›"
                    ),
                    row=2, col=1
                )
            
            # 4. è·å“¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆæ¡ä»¶ä»˜ãï¼‰
            if 'performance' in show_subplots:
                performance_hover = [f"<b>{name}</b><br>è·ç¨®: {role}<br>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: {score:.2f}" 
                                   for name, role, score in zip(names, roles, performance_scores)]
                
                fig.add_trace(
                    go.Bar(
                        x=display_names,
                        y=performance_scores,
                        name="ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
                        marker_color=self.color_schemes['capability'][0],
                        hovertext=performance_hover,
                        hoverinfo='text'
                    ),
                    row=2, col=2
                )
            
            
            # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ›´æ–°ï¼ˆã‚µã‚¤ã‚ºæœ€é©åŒ–ç‰ˆï¼‰
            layout_height = 1000 if staff_count <= 20 else 600  # ã‚°ãƒ©ãƒ•æ•°ã«å¿œã˜ãŸé«˜ã•
            
            fig.update_layout(
                title=dict(
                    text="ğŸ¥ çµ±åˆã‚·ãƒ•ãƒˆåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
                    font=dict(size=20),
                    x=0.5
                ),
                height=layout_height,
                showlegend=False,
                plot_bgcolor='rgba(248,249,250,0.8)',
                paper_bgcolor='white',
                font=dict(size=12),
                # å……å®Ÿã—ãŸãƒ›ãƒãƒ¼æƒ…å ±
                hoverlabel=dict(
                    bgcolor="rgba(255,255,255,0.95)",
                    font_size=13,
                    font_family="Arial",
                    bordercolor="#333"
                ),
                # ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–å¯¾å¿œ
                autosize=True,
                margin=dict(l=80, r=80, t=100, b=80)
            )
            
            # Xè»¸ãƒ©ãƒ™ãƒ«ã®å›è»¢è¨­å®šï¼ˆæ£’ã‚°ãƒ©ãƒ•ç”¨ï¼‰
            if staff_count > 8:
                if 'fairness' in show_subplots:
                    col_pos = 2 if staff_count <= 20 else 2
                    fig.update_xaxes(tickangle=45, row=1, col=col_pos)
                if 'performance' in show_subplots:
                    fig.update_xaxes(tickangle=45, row=2, col=2)
            
            # è»¸ãƒ©ãƒ™ãƒ«è¨­å®šï¼ˆå‹•çš„ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã«å¯¾å¿œï¼‰
            fig.update_xaxes(title_text="ç–²åŠ´ã‚¹ã‚³ã‚¢", title_font_size=14, row=1, col=1)
            fig.update_yaxes(title_text="ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", title_font_size=14, row=1, col=1)
            
            if 'fairness' in show_subplots:
                col_pos = 2 if staff_count <= 20 else 2
                fig.update_xaxes(title_text="è·å“¡" if not use_abbreviated_names else "è·å“¡ID", title_font_size=14, row=1, col=col_pos)
                fig.update_yaxes(title_text="å…¬å¹³æ€§ã‚¹ã‚³ã‚¢", title_font_size=14, row=1, col=col_pos)
            
            if 'capability' in show_subplots:
                fig.update_xaxes(title_text="å¯¾å¿œå¯èƒ½å‹¤å‹™åŒºåˆ†æ•°", title_font_size=14, row=2, col=1)
                fig.update_yaxes(title_text="å¯¾å¿œèƒ½åŠ›ã‚¹ã‚³ã‚¢", title_font_size=14, row=2, col=1)
            
            if 'performance' in show_subplots:
                fig.update_xaxes(title_text="è·å“¡" if not use_abbreviated_names else "è·å“¡ID", title_font_size=14, row=2, col=2)
                fig.update_yaxes(title_text="ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", title_font_size=14, row=2, col=2)
            
            log.info(f"çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆå®Œäº†: {staff_count}å, ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ={len(show_subplots)}ã‚°ãƒ©ãƒ•")
            return fig
            
        except Exception as e:
            log.error(f"çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return go.Figure().add_annotation(
                text=f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )
    
    def create_fatigue_heatmap(self, staff_analytics: List[StaffAnalytics]) -> go.Figure:
        """ç–²åŠ´åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ä½œæˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆé‡ãªã‚Šå¯¾ç­–ä»˜ãï¼‰"""
        if not staff_analytics:
            return go.Figure()
        
        try:
            # ãƒ‡ãƒ¼ã‚¿æº–å‚™
            staff_names = [staff.name for staff in staff_analytics]
            staff_count = len(staff_names)
            metrics = ['é€£ç¶šå‹¤å‹™æ—¥æ•°', 'å¤œå‹¤é »åº¦', 'ä¼‘æ¯ä¸è¶³', 'æ®‹æ¥­æ™‚é–“']
            
            # è·å“¡åã®å‹•çš„èª¿æ•´
            if staff_count > 15:
                display_names = [f"S{i+1}" for i in range(staff_count)]
            elif staff_count > 8:
                display_names = [name[:4] + '...' if len(name) > 5 else name for name in staff_names]
            else:
                display_names = staff_names
            
            heatmap_data = []
            for staff in staff_analytics:
                row = [
                    staff.fatigue_metrics.consecutive_work_days,
                    staff.fatigue_metrics.night_shift_frequency * 10,  # è¦–è¦šåŒ–ã®ãŸã‚ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
                    staff.fatigue_metrics.rest_insufficiency * 10,
                    staff.fatigue_metrics.overtime_hours / 10
                ]
                heatmap_data.append(row)
            
            # å……å®Ÿã—ãŸãƒ›ãƒãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®æº–å‚™
            hover_text = []
            for i, staff in enumerate(staff_analytics):
                row_hover = []
                hover_data = {
                    'é€£ç¶šå‹¤å‹™æ—¥æ•°': f"{staff.fatigue_metrics.consecutive_work_days}æ—¥",
                    'å¤œå‹¤é »åº¦': f"{staff.fatigue_metrics.night_shift_frequency:.2f}",
                    'ä¼‘æ¯ä¸è¶³': f"{staff.fatigue_metrics.rest_insufficiency:.2f}",
                    'æ®‹æ¥­æ™‚é–“': f"{staff.fatigue_metrics.overtime_hours:.1f}h"
                }
                for j, metric in enumerate(metrics):
                    hover_text_cell = (f"<b>{staff_names[i]}</b><br>"
                                     f"è·ç¨®: {staff.role}<br>"
                                     f"{metric}: {hover_data[metric]}<br>"
                                     f"ç–²åŠ´ã‚¹ã‚³ã‚¢: {staff.fatigue_metrics.fatigue_score:.1f}<br>"
                                     f"ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {staff.fatigue_metrics.risk_level}")
                    row_hover.append(hover_text_cell)
                hover_text.append(row_hover)
            
            fig = go.Figure(data=go.Heatmap(
                z=heatmap_data,
                x=metrics,
                y=display_names,
                colorscale='RdYlGn',
                reversescale=True,
                showscale=True,
                colorbar=dict(
                    title="ç–²åŠ´åº¦ãƒ¬ãƒ™ãƒ«",
                    titlefont=dict(size=12)
                ),
                hovertext=hover_text,
                hoverinfo='text'
            ))
            
            # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ã‚µã‚¤ã‚ºæœ€é©åŒ–
            heatmap_height = max(600, min(1200, staff_count * 30 + 150))
            
            fig.update_layout(
                title=dict(
                    text="ğŸ‘¥ è·å“¡åˆ¥ç–²åŠ´åº¦åˆ†æãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
                    font=dict(size=18),
                    x=0.5
                ),
                xaxis_title="ç–²åŠ´åº¦æŒ‡æ¨™",
                yaxis_title="è·å“¡" if staff_count <= 15 else "è·å“¡ID",
                height=heatmap_height,
                font=dict(size=12),
                # Yè»¸ãƒ©ãƒ™ãƒ«ã®èª¿æ•´ï¼ˆè·å“¡å/IDè¡¨ç¤ºã®æœ€é©åŒ–ï¼‰
                yaxis=dict(
                    tickfont=dict(size=10 if staff_count > 20 else 11),
                    automargin=True
                ),
                xaxis=dict(
                    tickfont=dict(size=12)
                ),
                # ãƒãƒ¼ã‚¸ãƒ³ã®èª¿æ•´
                margin=dict(l=120, r=60, t=100, b=60),
                # ãƒ›ãƒãƒ¼æƒ…å ±ã®æ”¹å–„
                hoverlabel=dict(
                    bgcolor="rgba(255,255,255,0.95)",
                    font_size=13,
                    font_family="Arial",
                    bordercolor="#333"
                )
            )
            
            return fig
            
        except Exception as e:
            log.error(f"ç–²åŠ´åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return go.Figure()

class ComprehensiveDashboard:
    """çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, output_dir: Path):
        self.output_dir = Path(output_dir)
        self.timeseries_model = TimeSeriesDataModel(output_dir)
        self.analytics_engine = AdvancedAnalyticsEngine(self.timeseries_model)
        self.visualization_system = IntegratedVisualizationSystem(self.analytics_engine)
        self.staff_analytics: List[StaffAnalytics] = []
        
    def initialize(self, months_back: int = 6) -> bool:
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰åˆæœŸåŒ–"""
        try:
            log.info("çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰åˆæœŸåŒ–é–‹å§‹")
            
            # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            if not self.timeseries_model.load_historical_data(months_back):
                log.warning("æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")
            
            # å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸåˆ†æç”Ÿæˆ
            if not self._generate_real_analytics():
                # å®Ÿãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã®ã¿ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                log.warning("å®Ÿãƒ‡ãƒ¼ã‚¿ãŒä¸ååˆ†ã®ãŸã‚ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
                self._generate_sample_analytics()
            
            log.info("çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰åˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            log.error(f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _generate_real_analytics(self) -> bool:
        """å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸåˆ†æãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
        try:
            log.info("å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®åˆ†æç”Ÿæˆé–‹å§‹")
            
            # å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢
            real_data_files = {
                'shortage_role': list(self.output_dir.glob('**/shortage_role*.parquet')),
                'shortage_employment': list(self.output_dir.glob('**/shortage_employment*.parquet')),
                'staff_data': list(self.output_dir.glob('**/intermediate_data*.parquet')),
                'fairness_data': list(self.output_dir.glob('**/fairness*.parquet')),
                'shortage_time': list(self.output_dir.glob('**/shortage_time*.parquet'))
            }
            
            # å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            required_files = ['shortage_role', 'staff_data']
            missing_files = [key for key in required_files 
                           if not real_data_files.get(key)]
            
            if missing_files:
                log.warning(f"å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³: {missing_files}")
                return False
            
            self.staff_analytics = []
            
            # è·ç¨®åˆ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è·å“¡æƒ…å ±ã‚’æ§‹ç¯‰
            try:
                shortage_role_file = real_data_files['shortage_role'][0]
                shortage_role_df = pd.read_parquet(shortage_role_file)
                log.info(f"è·ç¨®åˆ¥ä¸è¶³ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(shortage_role_df)}è¡Œ")
                
                # è·å“¡ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
                staff_file = real_data_files['staff_data'][0]
                staff_df = pd.read_parquet(staff_file)
                log.info(f"è·å“¡ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(staff_df)}è¡Œ")
                
                # é›‡ç”¨å½¢æ…‹åˆ¥ãƒ‡ãƒ¼ã‚¿
                employment_df = pd.DataFrame()
                if real_data_files.get('shortage_employment'):
                    employment_df = pd.read_parquet(real_data_files['shortage_employment'][0])
                    log.info(f"é›‡ç”¨å½¢æ…‹åˆ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(employment_df)}è¡Œ")
                
                # å…¬å¹³æ€§ãƒ‡ãƒ¼ã‚¿
                fairness_df = pd.DataFrame()
                if real_data_files.get('fairness_data'):
                    fairness_df = pd.read_parquet(real_data_files['fairness_data'][0])
                    log.info(f"å…¬å¹³æ€§ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(fairness_df)}è¡Œ")
                
                # è·ç¨®ã”ã¨ã®åˆ†æãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
                for _, role_row in shortage_role_df.iterrows():
                    if pd.isna(role_row.get('role')) or role_row.get('role') in ['å…¨ä½“', 'åˆè¨ˆ', 'ç·è¨ˆ']:
                        continue
                    
                    role_name = role_row.get('role', 'unknown')
                    
                    # è©²å½“è·ç¨®ã®è·å“¡æ•°ã‚’æ¨å®š
                    role_staff = staff_df[staff_df.get('role', '') == role_name] if 'role' in staff_df.columns else pd.DataFrame()
                    staff_count = len(role_staff) if not role_staff.empty else 1
                    
                    # è·ç¨®ãƒ¬ãƒ™ãƒ«ã®æŒ‡æ¨™ã‹ã‚‰å€‹äººãƒ¬ãƒ™ãƒ«ã‚’æ¨å®šç”Ÿæˆ
                    for i in range(min(staff_count, 5)):  # æœ€å¤§5åã¾ã§
                        staff_id = f"{role_name}_{i+1:03d}"
                        staff_name = f"{role_name}{i+1}"
                        
                        # ç–²åŠ´åº¦ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸è¶³æ™‚é–“ã‹ã‚‰æ¨å®šï¼‰
                        role_lack_h = role_row.get('lack_h', 0)
                        role_need_h = role_row.get('need_h', 1)
                        
                        # ä¸è¶³ç‡ã‹ã‚‰ç–²åŠ´åº¦ã‚’æ¨å®š
                        shortage_ratio = role_lack_h / role_need_h if role_need_h > 0 else 0
                        estimated_fatigue = min(shortage_ratio * 10, 10)  # 0-10ã‚¹ã‚±ãƒ¼ãƒ«
                        
                        fatigue_data = {
                            'consecutive_work_days': int(min(estimated_fatigue * 0.8, 7)),
                            'night_shift_ratio': min(shortage_ratio * 0.5, 0.4),
                            'insufficient_rest_ratio': min(shortage_ratio * 0.3, 0.3),
                            'monthly_overtime': min(role_lack_h * 2, 50)
                        }
                        
                        # å…¬å¹³æ€§ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒãƒ¼ãƒ å¹³å‡ã‚’ä½¿ç”¨ï¼‰
                        fairness_score = 0.8  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                        if not fairness_df.empty and 'fairness_score' in fairness_df.columns:
                            fairness_score = fairness_df['fairness_score'].mean()
                        
                        fairness_metrics = FairnessMetrics(
                            fairness_score=fairness_score,
                            fairness_level="è‰¯å¥½" if fairness_score >= 0.8 else "æ™®é€š" if fairness_score >= 0.6 else "è¦æ”¹å–„"
                        )
                        
                        # å‹¤å‹™åŒºåˆ†å¯¾å¿œèƒ½åŠ›ï¼ˆè·ç¨®ã«åŸºã¥ãæ¨å®šï¼‰
                        if 'çœ‹è­·å¸«' in role_name:
                            capable_worktypes = ['æ—¥å‹¤', 'å¤œå‹¤', 'æº–å¤œå‹¤']
                        elif 'åŒ»å¸«' in role_name:
                            capable_worktypes = ['æ—¥å‹¤', 'å¤œå‹¤']
                        elif 'è–¬å‰¤å¸«' in role_name:
                            capable_worktypes = ['æ—¥å‹¤']
                        else:
                            capable_worktypes = ['æ—¥å‹¤', 'å¤œå‹¤']
                        
                        capability_data = {
                            'capable_worktypes': capable_worktypes
                        }
                        available_worktypes = ['æ—¥å‹¤', 'å¤œå‹¤', 'æº–å¤œå‹¤', 'æ·±å¤œå‹¤']
                        
                        # é›‡ç”¨å½¢æ…‹ã®æ¨å®š
                        employment_type = "æ­£è¦"
                        if not employment_df.empty:
                            # é›‡ç”¨å½¢æ…‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
                            employment_types = employment_df.get('employment', ['æ­£è¦']).tolist()
                            employment_type = np.random.choice(employment_types) if employment_types else "æ­£è¦"
                        
                        # æœˆæ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ï¼ˆæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ï¼‰
                        monthly_trends = {}
                        if hasattr(self.timeseries_model, 'monthly_trends') and self.timeseries_model.monthly_trends:
                            shortage_trends = self.timeseries_model.monthly_trends.get('shortage', {})
                            # è·ç¨®æ¯”ç‡ã§é…åˆ†
                            total_shortage = sum(shortage_trends.values()) if shortage_trends else 0
                            role_ratio = role_lack_h / total_shortage if total_shortage > 0 else 0
                            
                            for month, value in shortage_trends.items():
                                monthly_trends[month] = value * role_ratio
                        else:
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                            monthly_trends = {'2024-07': role_lack_h}
                        
                        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ï¼ˆç–²åŠ´åº¦ã®é€†æ•°çš„é–¢ä¿‚ï¼‰
                        performance_score = max(0.1, 1.0 - (estimated_fatigue / 10) * 0.5)
                        
                        # StaffAnalyticsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
                        staff_analytics = StaffAnalytics(
                            staff_id=staff_id,
                            name=staff_name,
                            role=role_name,
                            employment_type=employment_type,
                            fatigue_metrics=self.analytics_engine.calculate_fatigue_metrics(fatigue_data),
                            fairness_metrics=fairness_metrics,
                            worktype_capability=self.analytics_engine.calculate_worktype_capability(
                                capability_data, available_worktypes
                            ),
                            monthly_trends=monthly_trends,
                            performance_score=performance_score
                        )
                        
                        self.staff_analytics.append(staff_analytics)
                
                log.info(f"å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰{len(self.staff_analytics)}åã®åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ")
                return len(self.staff_analytics) > 0
                
            except Exception as e:
                log.error(f"å®Ÿãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                return False
                
        except Exception as e:
            log.error(f"å®Ÿãƒ‡ãƒ¼ã‚¿åˆ†æç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _generate_sample_analytics(self) -> None:
        """ã‚µãƒ³ãƒ—ãƒ«åˆ†æãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆé–‹ç™ºç”¨ï¼‰"""
        sample_staff = [
            {"staff_id": "001", "name": "ç”°ä¸­çœ‹è­·å¸«", "role": "çœ‹è­·å¸«", "employment_type": "æ­£è¦"},
            {"staff_id": "002", "name": "ä½è—¤åŒ»å¸«", "role": "åŒ»å¸«", "employment_type": "æ­£è¦"},
            {"staff_id": "003", "name": "å±±ç”°è–¬å‰¤å¸«", "role": "è–¬å‰¤å¸«", "employment_type": "ãƒ‘ãƒ¼ãƒˆ"},
            {"staff_id": "004", "name": "éˆ´æœ¨çœ‹è­·å¸«", "role": "çœ‹è­·å¸«", "employment_type": "æ­£è¦"},
            {"staff_id": "005", "name": "é«˜æ©‹æŠ€å¸«", "role": "æŠ€å¸«", "employment_type": "å¥‘ç´„"},
        ]
        
        self.staff_analytics = []
        
        for staff_info in sample_staff:
            # ã‚µãƒ³ãƒ—ãƒ«ç–²åŠ´åº¦ãƒ‡ãƒ¼ã‚¿
            fatigue_data = {
                'consecutive_work_days': np.random.randint(0, 8),
                'night_shift_ratio': np.random.uniform(0, 0.4),
                'insufficient_rest_ratio': np.random.uniform(0, 0.3),
                'monthly_overtime': np.random.uniform(0, 40)
            }
            
            # ã‚µãƒ³ãƒ—ãƒ«å…¬å¹³æ€§ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒãƒ¼ãƒ å…¨ä½“ã§è¨ˆç®—ã™ã‚‹ãŸã‚ç°¡æ˜“ç‰ˆï¼‰
            fairness_metrics = FairnessMetrics(
                fairness_score=np.random.uniform(0.6, 1.0),
                fairness_level="è‰¯å¥½" if np.random.random() > 0.3 else "æ™®é€š"
            )
            
            # ã‚µãƒ³ãƒ—ãƒ«å‹¤å‹™åŒºåˆ†å¯¾å¿œèƒ½åŠ›ãƒ‡ãƒ¼ã‚¿
            capability_data = {
                'capable_worktypes': ['æ—¥å‹¤', 'å¤œå‹¤', 'æº–å¤œå‹¤'][:np.random.randint(1, 4)]
            }
            available_worktypes = ['æ—¥å‹¤', 'å¤œå‹¤', 'æº–å¤œå‹¤', 'æ·±å¤œå‹¤']
            
            staff_analytics = StaffAnalytics(
                staff_id=staff_info['staff_id'],
                name=staff_info['name'],
                role=staff_info['role'],
                employment_type=staff_info['employment_type'],
                fatigue_metrics=self.analytics_engine.calculate_fatigue_metrics(fatigue_data),
                fairness_metrics=fairness_metrics,
                worktype_capability=self.analytics_engine.calculate_worktype_capability(
                    capability_data, available_worktypes
                ),
                monthly_trends={
                    '2024-01': np.random.uniform(100, 200),
                    '2024-02': np.random.uniform(100, 200),
                    '2024-03': np.random.uniform(100, 200)
                },
                performance_score=np.random.uniform(0.7, 1.0)
            )
            
            self.staff_analytics.append(staff_analytics)
    
    def get_dashboard_figures(self) -> Dict[str, go.Figure]:
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å›³è¡¨ã®å–å¾—"""
        try:
            figures = {
                'comprehensive': self.visualization_system.create_comprehensive_dashboard(self.staff_analytics),
                'fatigue_heatmap': self.visualization_system.create_fatigue_heatmap(self.staff_analytics)
            }
            
            log.info("ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å›³è¡¨ç”Ÿæˆå®Œäº†")
            return figures
            
        except Exception as e:
            log.error(f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å›³è¡¨ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def export_analytics_data(self, filename: str = "comprehensive_analytics.json") -> Path:
        """åˆ†æãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            export_data = {
                'generation_time': datetime.now().isoformat(),
                'staff_count': len(self.staff_analytics),
                'staff_analytics': [asdict(staff) for staff in self.staff_analytics],
                'summary_metrics': self._calculate_summary_metrics()
            }
            
            export_path = self.output_dir / filename
            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            log.info(f"åˆ†æãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {export_path}")
            return export_path
            
        except Exception as e:
            log.error(f"åˆ†æãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _calculate_summary_metrics(self) -> Dict[str, Any]:
        """ã‚µãƒãƒªãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—"""
        if not self.staff_analytics:
            return {}
        
        fatigue_scores = [staff.fatigue_metrics.fatigue_score for staff in self.staff_analytics]
        fairness_scores = [staff.fairness_metrics.fairness_score for staff in self.staff_analytics]
        capability_scores = [staff.worktype_capability.capability_score for staff in self.staff_analytics]
        
        return {
            'average_fatigue_score': np.mean(fatigue_scores),
            'average_fairness_score': np.mean(fairness_scores),
            'average_capability_score': np.mean(capability_scores),
            'high_fatigue_count': sum(1 for score in fatigue_scores if score >= 7.0),
            'low_fairness_count': sum(1 for score in fairness_scores if score < 0.6),
            'multiskill_staff_count': sum(1 for staff in self.staff_analytics 
                                        if staff.worktype_capability.capable_worktypes >= 3)
        }

# ä¾¿åˆ©ãªé–¢æ•°
def create_comprehensive_dashboard(output_dir: Path, months_back: int = 6) -> ComprehensiveDashboard:
    """çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ä½œæˆ"""
    dashboard = ComprehensiveDashboard(output_dir)
    dashboard.initialize(months_back)
    return dashboard

def generate_dashboard_report(output_dir: Path, report_file: str = "dashboard_report.json") -> Path:
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    dashboard = create_comprehensive_dashboard(output_dir)
    return dashboard.export_analytics_data(report_file)