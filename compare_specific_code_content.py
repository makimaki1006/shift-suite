#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰¹å®šã‚³ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°æ¯”è¼ƒ
å®Œå…¨ã«ã‚³ãƒ”ãƒ¼ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã®æœ€çµ‚è¨¼æ˜
"""

from pathlib import Path
import difflib

def compare_specific_sections():
    """é‡è¦ãªã‚³ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°æ¯”è¼ƒ"""
    
    print("=" * 80)
    print("ğŸ”¬ ã‚³ãƒ¼ãƒ‰å†…å®¹ã®è©³ç´°æ¯”è¼ƒï¼ˆè¡Œå˜ä½ï¼‰")
    print("=" * 80)
    
    # Phase 3.1ã®é‡è¦ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è©³ç´°æ¯”è¼ƒ
    original_file = Path("shift_suite/tasks/lightweight_anomaly_detector.py")
    backup_file = Path("PHASE3_COMPLETE_BACKUP_20250802_100555/shift_suite/tasks/lightweight_anomaly_detector.py")
    
    print(f"\nğŸ“„ {original_file.name} ã®è©³ç´°æ¯”è¼ƒ:")
    
    with open(original_file, 'r', encoding='utf-8') as f:
        original_lines = f.readlines()
    
    with open(backup_file, 'r', encoding='utf-8') as f:
        backup_lines = f.readlines()
    
    # 1. è¡Œæ•°ã®æ¯”è¼ƒ
    print(f"\n  è¡Œæ•°æ¯”è¼ƒ:")
    print(f"    ã‚ªãƒªã‚¸ãƒŠãƒ«: {len(original_lines)} è¡Œ")
    print(f"    ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {len(backup_lines)} è¡Œ")
    print(f"    å·®åˆ†: {len(original_lines) - len(backup_lines)} è¡Œ")
    
    # 2. å·®åˆ†æ¤œå‡º
    diff = list(difflib.unified_diff(original_lines, backup_lines, 
                                     fromfile='ã‚ªãƒªã‚¸ãƒŠãƒ«', 
                                     tofile='ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—', 
                                     n=0))
    
    if not diff:
        print(f"\n  âœ… å®Œå…¨ä¸€è‡´: å·®åˆ†ãªã—")
    else:
        print(f"\n  âŒ å·®åˆ†æ¤œå‡º:")
        for line in diff[:20]:  # æœ€åˆã®20è¡Œã¾ã§è¡¨ç¤º
            print(f"    {line.rstrip()}")
    
    # 3. ç‰¹å®šã®é‡è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å­˜åœ¨ç¢ºèª
    print(f"\n  é‡è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å­˜åœ¨ç¢ºèª:")
    
    important_sections = [
        ("class LightweightAnomalyDetector:", "ã‚¯ãƒ©ã‚¹å®šç¾©"),
        ("def detect_anomalies(self, long_df: pd.DataFrame)", "ãƒ¡ã‚¤ãƒ³æ¤œçŸ¥ãƒ¡ã‚½ãƒƒãƒ‰"),
        ("éåº¦ãªåŠ´åƒæ™‚é–“æ¤œçŸ¥ï¼ˆO(n)ï¼‰", "åŠ´åƒæ™‚é–“æ¤œçŸ¥ã‚³ãƒ¡ãƒ³ãƒˆ"),
        ("severity = self._calculate_severity", "é‡è¦åº¦è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯"),
        ("return sorted(anomalies, key=lambda x:", "ã‚½ãƒ¼ãƒˆãƒ­ã‚¸ãƒƒã‚¯")
    ]
    
    for section, description in important_sections:
        original_found = any(section in line for line in original_lines)
        backup_found = any(section in line for line in backup_lines)
        
        if original_found and backup_found:
            # è©²å½“è¡Œã‚’æ¢ã—ã¦è¡¨ç¤º
            for i, line in enumerate(backup_lines):
                if section in line:
                    print(f"    âœ… {description} (è¡Œ {i+1}): {line.strip()[:60]}...")
                    break
        else:
            print(f"    âŒ {description}: {'åŸæœ¬ã«ãªã—' if not original_found else 'ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«ãªã—'}")
    
    # 4. Phase 3.2ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç¢ºèª
    print(f"\n" + "-" * 80)
    print(f"\nğŸ“„ fact_book_visualizer.py ã®è©³ç´°æ¯”è¼ƒ:")
    
    original_file2 = Path("shift_suite/tasks/fact_book_visualizer.py")
    backup_file2 = Path("PHASE3_COMPLETE_BACKUP_20250802_100555/shift_suite/tasks/fact_book_visualizer.py")
    
    with open(original_file2, 'r', encoding='utf-8') as f:
        original_lines2 = f.readlines()
    
    with open(backup_file2, 'r', encoding='utf-8') as f:
        backup_lines2 = f.readlines()
    
    print(f"\n  è¡Œæ•°æ¯”è¼ƒ:")
    print(f"    ã‚ªãƒªã‚¸ãƒŠãƒ«: {len(original_lines2)} è¡Œ")
    print(f"    ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {len(backup_lines2)} è¡Œ")
    
    # çµ±åˆæ©Ÿèƒ½ã®ç¢ºèª
    integration_checks = [
        "from .fact_extractor_prototype import FactExtractorPrototype",
        "from .lightweight_anomaly_detector import LightweightAnomalyDetector",
        "self.fact_extractor = FactExtractorPrototype()",
        "self.anomaly_detector = LightweightAnomalyDetector",
        "basic_facts = self.fact_extractor.extract_basic_facts(long_df)",
        "anomalies = self.anomaly_detector.detect_anomalies(long_df)"
    ]
    
    print(f"\n  Phase 2 & 3.1 çµ±åˆã‚³ãƒ¼ãƒ‰ã®ç¢ºèª:")
    for check in integration_checks:
        found = any(check in line for line in backup_lines2)
        status = "âœ…" if found else "âŒ"
        print(f"    {status} {check[:60]}...")
    
    # 5. ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­ã¨æœ«å°¾ã®ç¢ºèª
    print(f"\nğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­ã¨æœ«å°¾ã®ç¢ºèª:")
    
    print(f"\n  lightweight_anomaly_detector.py ã®å…ˆé ­3è¡Œ:")
    for i, line in enumerate(backup_lines[:3]):
        print(f"    {i+1}: {line.rstrip()}")
    
    print(f"\n  lightweight_anomaly_detector.py ã®æœ«å°¾3è¡Œ:")
    for i, line in enumerate(backup_lines[-3:]):
        print(f"    {len(backup_lines)-2+i}: {line.rstrip()}")
    
    # 6. æ–‡å­—æ•°ã®æ­£ç¢ºãªæ¯”è¼ƒ
    print(f"\nğŸ“Š æ–‡å­—æ•°ã®æ­£ç¢ºãªæ¯”è¼ƒ:")
    
    original_chars = sum(len(line) for line in original_lines)
    backup_chars = sum(len(line) for line in backup_lines)
    
    print(f"  ã‚ªãƒªã‚¸ãƒŠãƒ«: {original_chars:,} æ–‡å­—")
    print(f"  ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_chars:,} æ–‡å­—")
    print(f"  å·®åˆ†: {abs(original_chars - backup_chars)} æ–‡å­—")
    
    return len(diff) == 0

if __name__ == "__main__":
    is_identical = compare_specific_sections()
    
    print("\n" + "=" * 80)
    if is_identical:
        print("âœ… æœ€çµ‚çµè«–: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯1æ–‡å­—ã‚‚çœç•¥ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("   ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ãŒå®Œå…¨ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")
    else:
        print("âš ï¸ ä½•ã‚‰ã‹ã®å·®åˆ†ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")