#!/usr/bin/env python3
"""
åˆ¶ç´„å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ  - 46å€‹ã®åˆ¶ç´„ã‚’å…·ä½“çš„ã«ç†è§£ã§ãã‚‹å½¢ã§è¡¨ç¤º
"""

import json
import logging
from datetime import datetime
from typing import Dict, Any, List

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
log = logging.getLogger(__name__)

class ConstraintVisualizer:
    """åˆ¶ç´„å¯è¦–åŒ–å™¨"""
    
    def __init__(self):
        self.visualizer_name = "åˆ¶ç´„å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ "
        self.version = "1.0.0"
    
    def load_and_parse_constraints(self) -> Dict[str, Any]:
        """åˆ¶ç´„ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨è§£æ"""
        try:
            with open("batch_analysis_results.json", "r", encoding="utf-8") as f:
                batch_results = json.load(f)
            
            all_constraints = []
            file_constraint_map = {}
            
            for file_path, result in batch_results["individual_results"].items():
                if result.get("success"):
                    file_constraints = []
                    for constraint in result["constraints"]:
                        # åˆ¶ç´„ã‚’ç†è§£ã—ã‚„ã™ã„å½¢ã«å¤‰æ›
                        parsed_constraint = {
                            "file": file_path,
                            "id": constraint["id"], 
                            "category": constraint["category"],
                            "type": constraint["type"],
                            "constraint_text": constraint["constraint"],
                            "confidence": constraint["confidence"],
                            "priority": constraint["priority"],
                            "actionable": constraint["actionable"],
                            "recommendations": constraint["recommendations"],
                            "details": constraint.get("details", {})
                        }
                        all_constraints.append(parsed_constraint)
                        file_constraints.append(parsed_constraint)
                    
                    file_constraint_map[file_path] = file_constraints
            
            return {
                "all_constraints": all_constraints,
                "file_constraint_map": file_constraint_map,
                "total_constraints": len(all_constraints),
                "batch_summary": batch_results["batch_summary"]
            }
            
        except FileNotFoundError:
            return {"error": "batch_analysis_results.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
    
    def categorize_constraints_by_type(self, constraints_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ¶ç´„ã‚’ã‚¿ã‚¤ãƒ—åˆ¥ã«åˆ†é¡"""
        print("=== åˆ¶ç´„ã®ã‚¿ã‚¤ãƒ—åˆ¥åˆ†é¡ ===")
        
        if "error" in constraints_data:
            return constraints_data
        
        all_constraints = constraints_data["all_constraints"]
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†é¡
        categorized = {}
        for constraint in all_constraints:
            category = constraint["category"]
            if category not in categorized:
                categorized[category] = []
            categorized[category].append(constraint)
        
        # å„ã‚«ãƒ†ã‚´ãƒªã®è©³ç´°åˆ†æ
        category_analysis = {}
        for category, constraints in categorized.items():
            category_analysis[category] = {
                "count": len(constraints),
                "avg_confidence": sum(c["confidence"] for c in constraints) / len(constraints),
                "priority_distribution": {
                    "é«˜": len([c for c in constraints if c["priority"] == "é«˜"]),
                    "ä¸­": len([c for c in constraints if c["priority"] == "ä¸­"]),
                    "ä½": len([c for c in constraints if c["priority"] == "ä½"])
                },
                "unique_types": list(set(c["type"] for c in constraints)),
                "examples": constraints[:3]  # æœ€åˆã®3ã¤ã‚’ä¾‹ã¨ã—ã¦
            }
        
        # è¡¨ç¤º
        for category, analysis in category_analysis.items():
            print(f"\nğŸ“‚ {category} ({analysis['count']}å€‹)")
            print(f"   å¹³å‡ä¿¡é ¼åº¦: {analysis['avg_confidence']:.1%}")
            print(f"   å„ªå…ˆåº¦åˆ†å¸ƒ: é«˜{analysis['priority_distribution']['é«˜']} ä¸­{analysis['priority_distribution']['ä¸­']} ä½{analysis['priority_distribution']['ä½']}")
            print(f"   åˆ¶ç´„ã‚¿ã‚¤ãƒ—: {', '.join(analysis['unique_types'])}")
        
        return {
            "categorized_constraints": categorized,
            "category_analysis": category_analysis
        }
    
    def show_concrete_constraint_examples(self, constraints_data: Dict[str, Any]) -> None:
        """å…·ä½“çš„ãªåˆ¶ç´„ä¾‹ã®è¡¨ç¤º"""
        print("\n=== å…·ä½“çš„ãªåˆ¶ç´„ä¾‹ ===")
        
        if "error" in constraints_data:
            print("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼")
            return
        
        all_constraints = constraints_data["all_constraints"]
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ä»£è¡¨ä¾‹ã‚’è¡¨ç¤º
        categories = {}
        for constraint in all_constraints:
            category = constraint["category"]
            if category not in categories:
                categories[category] = []
            categories[category].append(constraint)
        
        for i, (category, constraints) in enumerate(categories.items(), 1):
            print(f"\n{i}. ã€{category}ã€‘ã®ä¾‹:")
            
            # å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ç•°ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾‹ã‚’3ã¤ã¾ã§è¡¨ç¤º
            shown_files = set()
            example_count = 0
            
            for constraint in constraints:
                if constraint["file"] not in shown_files and example_count < 3:
                    print(f"   ğŸ“„ {constraint['file']}:")
                    print(f"      åˆ¶ç´„: {constraint['constraint_text']}")
                    print(f"      å„ªå…ˆåº¦: {constraint['priority']} | ä¿¡é ¼åº¦: {constraint['confidence']:.1%}")
                    
                    if constraint["recommendations"]:
                        print(f"      æ¨å¥¨: {constraint['recommendations'][0]}")
                    
                    # è©³ç´°æƒ…å ±ãŒã‚ã‚Œã°è¡¨ç¤º
                    if constraint["details"]:
                        key_details = []
                        for key, value in constraint["details"].items():
                            if key in ["file_size", "utility_score", "shift_type", "processing_complexity"]:
                                key_details.append(f"{key}: {value}")
                        if key_details:
                            print(f"      è©³ç´°: {', '.join(key_details)}")
                    
                    print()
                    shown_files.add(constraint["file"])
                    example_count += 1
            
            if example_count < len(constraints):
                remaining = len(constraints) - example_count
                print(f"   ... ä»–{remaining}å€‹ã®åŒæ§˜åˆ¶ç´„")
    
    def analyze_constraint_patterns(self, constraints_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ¶ç´„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        print("\n=== åˆ¶ç´„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ ===")
        
        if "error" in constraints_data:
            return {"error": "ãƒ‡ãƒ¼ã‚¿ãªã—"}
        
        all_constraints = constraints_data["all_constraints"]
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        patterns = {
            "repetitive_patterns": {},  # ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³
            "file_specific_patterns": {},  # ãƒ•ã‚¡ã‚¤ãƒ«å›ºæœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
            "universal_patterns": [],  # å…¨ãƒ•ã‚¡ã‚¤ãƒ«å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³
            "confidence_patterns": {"high": 0, "medium": 0, "low": 0}
        }
        
        # ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        constraint_texts = {}
        for constraint in all_constraints:
            # åˆ¶ç´„æ–‡ã®åŸºæœ¬ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‚’é™¤å¤–ï¼‰
            pattern = constraint["constraint_text"]
            for file_name in constraints_data["file_constraint_map"].keys():
                pattern = pattern.replace(file_name.replace('.xlsx', ''), '[ãƒ•ã‚¡ã‚¤ãƒ«å]')
            
            if pattern not in constraint_texts:
                constraint_texts[pattern] = []
            constraint_texts[pattern].append(constraint)
        
        # ç¹°ã‚Šè¿”ã—ã®å¤šã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å®š
        for pattern, constraints in constraint_texts.items():
            if len(constraints) > 1:
                patterns["repetitive_patterns"][pattern] = {
                    "count": len(constraints),
                    "files": list(set(c["file"] for c in constraints)),
                    "category": constraints[0]["category"]
                }
        
        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        file_count = len(constraints_data["file_constraint_map"])
        for pattern, info in patterns["repetitive_patterns"].items():
            if info["count"] == file_count:
                patterns["universal_patterns"].append({
                    "pattern": pattern,
                    "category": info["category"]
                })
        
        # ä¿¡é ¼åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³
        for constraint in all_constraints:
            if constraint["confidence"] >= 0.9:
                patterns["confidence_patterns"]["high"] += 1
            elif constraint["confidence"] >= 0.7:
                patterns["confidence_patterns"]["medium"] += 1
            else:
                patterns["confidence_patterns"]["low"] += 1
        
        # çµæœè¡¨ç¤º
        print(f"ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {len(patterns['repetitive_patterns'])}")
        print(f"å…¨ãƒ•ã‚¡ã‚¤ãƒ«å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³: {len(patterns['universal_patterns'])}")
        print(f"ä¿¡é ¼åº¦åˆ†å¸ƒ: é«˜{patterns['confidence_patterns']['high']} ä¸­{patterns['confidence_patterns']['medium']} ä½{patterns['confidence_patterns']['low']}")
        
        # æœ€ã‚‚ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¡¨ç¤º
        print(f"\næœ€ã‚‚ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³:")
        sorted_patterns = sorted(patterns['repetitive_patterns'].items(), 
                               key=lambda x: x[1]['count'], reverse=True)
        
        for i, (pattern, info) in enumerate(sorted_patterns[:5], 1):
            print(f"  {i}. ã€Œ{pattern}ã€")
            print(f"     å‡ºç¾å›æ•°: {info['count']}å› | ã‚«ãƒ†ã‚´ãƒª: {info['category']}")
        
        return patterns
    
    def generate_constraint_reality_check(self, constraints_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ¶ç´„ã®ç¾å®Ÿæ€§ãƒã‚§ãƒƒã‚¯"""
        print("\n=== åˆ¶ç´„ã®ç¾å®Ÿæ€§ãƒã‚§ãƒƒã‚¯ ===")
        
        if "error" in constraints_data:
            return {"error": "ãƒ‡ãƒ¼ã‚¿ãªã—"}
        
        all_constraints = constraints_data["all_constraints"]
        
        reality_analysis = {
            "truly_useful_constraints": [],
            "obvious_constraints": [],
            "questionable_constraints": [],
            "file_management_constraints": [],
            "shift_analysis_constraints": []
        }
        
        for constraint in all_constraints:
            constraint_text = constraint["constraint_text"]
            category = constraint["category"]
            recommendations = constraint["recommendations"]
            
            # åˆ†é¡åŸºæº–
            if "åˆ†æå¯èƒ½ãªçŠ¶æ…‹" in constraint_text or "å­˜åœ¨" in constraint_text:
                reality_analysis["obvious_constraints"].append({
                    "constraint": constraint_text,
                    "reason": "ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ã¯å½“ç„¶ã®å‰ææ¡ä»¶"
                })
            
            elif "å®Ÿç”¨æ€§ã‚¹ã‚³ã‚¢" in constraint_text:
                reality_analysis["questionable_constraints"].append({
                    "constraint": constraint_text,
                    "reason": "ã‚¹ã‚³ã‚¢è‡ªä½“ãŒè¨ˆç®—çµæœã§ã€åˆ¶ç´„ã§ã¯ãªã„"
                })
            
            elif any("åˆ†æ" in rec or "ãƒ•ã‚¡ã‚¤ãƒ«" in rec for rec in recommendations):  
                reality_analysis["file_management_constraints"].append({
                    "constraint": constraint_text,
                    "benefit": "ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãƒ»ç®¡ç†ã®æ”¹å–„"
                })
            
            elif "ã‚·ãƒ•ãƒˆ" in constraint_text and "ç‰¹åŒ–" in constraint_text:
                reality_analysis["shift_analysis_constraints"].append({
                    "constraint": constraint_text,
                    "potential": "ã‚·ãƒ•ãƒˆåˆ†æã®æ–¹å‘æ€§ç¤ºå”†"
                })
            
            elif ("é«˜é€Ÿåˆ†æ" in str(recommendations) or 
                  "è©³ç´°åˆ†æ" in str(recommendations) or
                  "æ¯”è¼ƒåˆ†æ" in str(recommendations)):
                reality_analysis["truly_useful_constraints"].append({
                    "constraint": constraint_text,
                    "value": "å…·ä½“çš„ãªåˆ†ææˆ¦ç•¥ã®æç¤º"
                })
        
        # çµæœè¡¨ç¤º
        print(f"å®Ÿç”¨çš„åˆ¶ç´„: {len(reality_analysis['truly_useful_constraints'])}å€‹")
        print(f"å½“ç„¶ã®åˆ¶ç´„: {len(reality_analysis['obvious_constraints'])}å€‹")
        print(f"ç–‘å•ãªåˆ¶ç´„: {len(reality_analysis['questionable_constraints'])}å€‹")
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†åˆ¶ç´„: {len(reality_analysis['file_management_constraints'])}å€‹")
        print(f"ã‚·ãƒ•ãƒˆåˆ†æåˆ¶ç´„: {len(reality_analysis['shift_analysis_constraints'])}å€‹")
        
        # å®Ÿç”¨çš„åˆ¶ç´„ã®ä¾‹ã‚’è¡¨ç¤º
        if reality_analysis["truly_useful_constraints"]:
            print(f"\nå®Ÿç”¨çš„åˆ¶ç´„ã®ä¾‹:")
            for i, constraint in enumerate(reality_analysis["truly_useful_constraints"][:3], 1):
                print(f"  {i}. {constraint['constraint']}")
                print(f"     ä¾¡å€¤: {constraint['value']}")
        
        return reality_analysis

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 80)
    print("åˆ¶ç´„å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ  - 46å€‹ã®åˆ¶ç´„ã‚’å…·ä½“çš„ã«ç†è§£")
    print("=" * 80)
    
    try:
        visualizer = ConstraintVisualizer()
        
        # Phase 1: åˆ¶ç´„ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        constraints_data = visualizer.load_and_parse_constraints()
        
        if "error" in constraints_data:
            print(f"ã‚¨ãƒ©ãƒ¼: {constraints_data['error']}")
            return 1
        
        print(f"èª­ã¿è¾¼ã¿å®Œäº†: {constraints_data['total_constraints']}å€‹ã®åˆ¶ç´„")
        
        # Phase 2: ã‚¿ã‚¤ãƒ—åˆ¥åˆ†é¡
        categorized_data = visualizer.categorize_constraints_by_type(constraints_data)
        
        # Phase 3: å…·ä½“çš„ãªåˆ¶ç´„ä¾‹ã®è¡¨ç¤º
        visualizer.show_concrete_constraint_examples(constraints_data)
        
        # Phase 4: åˆ¶ç´„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
        patterns = visualizer.analyze_constraint_patterns(constraints_data)
        
        # Phase 5: åˆ¶ç´„ã®ç¾å®Ÿæ€§ãƒã‚§ãƒƒã‚¯
        reality_check = visualizer.generate_constraint_reality_check(constraints_data)
        
        # ç·åˆãƒ¬ãƒãƒ¼ãƒˆ
        visualization_report = {
            "analysis_metadata": {
                "timestamp": datetime.now().isoformat(),
                "total_constraints_analyzed": constraints_data['total_constraints'],
                "visualizer": visualizer.visualizer_name
            },
            "constraint_breakdown": constraints_data['batch_summary']['category_distribution'],
            "categorized_analysis": categorized_data.get('category_analysis', {}),
            "pattern_analysis": patterns,
            "reality_check": reality_check
        }
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        try:
            with open("constraint_visualization_report.json", "w", encoding="utf-8") as f:
                json.dump(visualization_report, f, ensure_ascii=False, indent=2)
            print(f"\n   [OK] åˆ¶ç´„å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: constraint_visualization_report.json")
        except Exception as e:
            print(f"   [WARNING] ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æœ€çµ‚ã‚µãƒãƒªãƒ¼
        print("\n" + "=" * 80)
        print("[CONSTRAINT SUMMARY] 46å€‹ã®åˆ¶ç´„ã®å®Ÿæ…‹")
        print("=" * 80)
        
        print(f"[BREAKDOWN] ã‚«ãƒ†ã‚´ãƒªåˆ¥å†…è¨³:")
        for category, count in constraints_data['batch_summary']['category_distribution'].items():
            print(f"  {category}: {count}å€‹")
        
        print(f"\n[REALITY CHECK] åˆ¶ç´„ã®ä¾¡å€¤è©•ä¾¡:")
        print(f"  å®Ÿç”¨çš„: {len(reality_check.get('truly_useful_constraints', []))}å€‹")
        print(f"  å½“ç„¶: {len(reality_check.get('obvious_constraints', []))}å€‹")
        print(f"  ç–‘å•: {len(reality_check.get('questionable_constraints', []))}å€‹")
        print(f"  ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†: {len(reality_check.get('file_management_constraints', []))}å€‹")
        print(f"  ã‚·ãƒ•ãƒˆåˆ†æ: {len(reality_check.get('shift_analysis_constraints', []))}å€‹")
        
        print(f"\n[PATTERN] ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(patterns.get('repetitive_patterns', {}))}ç¨®é¡")
        print(f"[UNIVERSAL] å…¨ãƒ•ã‚¡ã‚¤ãƒ«å…±é€š: {len(patterns.get('universal_patterns', []))}å€‹")
        
        print(f"\n[CONCLUSION] 46å€‹ã®åˆ¶ç´„ã®æ­£ä½“:")
        print(f"  - å¤šãã¯ã€Œãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã€ã€Œã‚µã‚¤ã‚ºãŒXXã€ç­‰ã®åŸºæœ¬æƒ…å ±")
        print(f"  - ã‚·ãƒ•ãƒˆåˆ¶ç´„ã¯ä¸»ã«ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã®æ¨æ¸¬")
        print(f"  - å®Ÿéš›ã®ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿å†…å®¹ã«åŸºã¥ãåˆ¶ç´„ã¯0å€‹")
        print(f"  - ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãƒ»ç®¡ç†ã®æ”¹å–„ã«ã¯æœ‰åŠ¹")
        
        return 0
        
    except Exception as e:
        print(f"\n[ERROR] åˆ¶ç´„å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    import sys
    sys.exit(main())