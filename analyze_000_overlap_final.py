#!/usr/bin/env python3
"""
0:00é‡è¤‡å•é¡Œã®æœ€çµ‚åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å…·ä½“çš„ãªæ•°å€¤ã‚’æŠ½å‡ºã—ã¦é‡è¤‡å•é¡Œã‚’å®šé‡åŒ–
"""

import csv
import json
import os
from datetime import datetime

print('=== 0:00é‡è¤‡å•é¡Œã®æœ€çµ‚åˆ†æãƒ¬ãƒãƒ¼ãƒˆ ===')

# åˆ†æå¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€
analysis_folder = '/mnt/c/Users/fuji1/OneDrive/ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/ã‚·ãƒ•ãƒˆåˆ†æ/temp_analysis_results/out_p25_based/'

def analyze_shortage_leave_csv():
    """shortage_leave.csvã‹ã‚‰0:00ã®äººå“¡ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    print('\n1. shortage_leave.csvã«ã‚ˆã‚‹0:00äººå“¡åˆ†æ')
    print('=' * 60)
    
    csv_path = os.path.join(analysis_folder, 'shortage_leave.csv')
    if not os.path.exists(csv_path):
        print('shortage_leave.csvãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        return None
    
    # 0:00ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    midnight_data = []
    other_times_data = []
    
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            time_str = row['time']
            leave_applicants = int(row['leave_applicants'])
            
            if time_str == '00:00':
                midnight_data.append({
                    'date': row['date'],
                    'leave_applicants': leave_applicants,
                    'lack': int(row['lack']),
                    'net_shortage': int(row['net_shortage'])
                })
            elif time_str in ['23:45', '00:15', '00:30']:
                other_times_data.append({
                    'time': time_str,
                    'date': row['date'],
                    'leave_applicants': leave_applicants,
                    'lack': int(row['lack']),
                    'net_shortage': int(row['net_shortage'])
                })
    
    print(f'0:00ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(midnight_data)}ä»¶')
    print(f'æ¯”è¼ƒæ™‚é–“ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(other_times_data)}ä»¶')
    
    if midnight_data:
        # 0:00ã®çµ±è¨ˆ
        leave_counts = [d['leave_applicants'] for d in midnight_data]
        avg_leave = sum(leave_counts) / len(leave_counts)
        max_leave = max(leave_counts)
        min_leave = min(leave_counts)
        
        print(f'\n0:00æ™‚åˆ»ã®äººå“¡çµ±è¨ˆ:')
        print(f'  å¹³å‡äººå“¡: {avg_leave:.1f}äºº')
        print(f'  æœ€å¤§äººå“¡: {max_leave}äºº')
        print(f'  æœ€å°äººå“¡: {min_leave}äºº')
        
        # æ—¥åˆ¥è©³ç´°
        print(f'\n6æœˆå‰åŠ10æ—¥é–“ã®0:00äººå“¡æ•°:')
        for i, data in enumerate(midnight_data[:10]):
            print(f'  {data["date"]}: {data["leave_applicants"]}äºº')
        
        # æ¯”è¼ƒæ™‚é–“ã®çµ±è¨ˆ
        if other_times_data:
            other_leave_counts = [d['leave_applicants'] for d in other_times_data]
            other_avg = sum(other_leave_counts) / len(other_leave_counts)
            
            print(f'\næ¯”è¼ƒæ™‚é–“(23:45, 00:15, 00:30)ã®å¹³å‡äººå“¡: {other_avg:.1f}äºº')
            print(f'0:00ã¨ã®å·®åˆ†: {avg_leave - other_avg:+.1f}äºº')
            
            if avg_leave > other_avg:
                excess_ratio = avg_leave / other_avg
                print(f'0:00ã¯ä»–æ™‚é–“ã®{excess_ratio:.2f}å€ã®äººå“¡')
                if excess_ratio > 1.1:
                    print(f'âš ï¸ 0:00ã§{avg_leave - other_avg:.1f}äººã®é‡è¤‡ç–‘ã„!')
    
    return midnight_data

def analyze_time_comparison():
    """23:45, 0:00, 0:15ã®è©³ç´°æ¯”è¼ƒ"""
    print('\n2. æ™‚é–“åˆ¥è©³ç´°æ¯”è¼ƒåˆ†æ')
    print('=' * 60)
    
    csv_path = os.path.join(analysis_folder, 'shortage_leave.csv')
    
    # é‡è¦ãªæ™‚é–“å¸¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    time_slots = ['23:45', '00:00', '00:15']
    time_data = {slot: [] for slot in time_slots}
    
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            time_str = row['time']
            if time_str in time_slots:
                time_data[time_str].append({
                    'date': row['date'],
                    'leave_applicants': int(row['leave_applicants']),
                    'lack': int(row['lack']),
                    'net_shortage': int(row['net_shortage'])
                })
    
    print('æ™‚é–“åˆ¥çµ±è¨ˆ (6æœˆå…¨ä½“):')
    print('æ™‚åˆ»  | å¹³å‡äººå“¡ | æœ€å¤§ | æœ€å° | ãƒ‡ãƒ¼ã‚¿æ•°')
    print('-' * 45)
    
    stats_summary = {}
    for time_slot in time_slots:
        data = time_data[time_slot]
        if data:
            leave_counts = [d['leave_applicants'] for d in data]
            avg_count = sum(leave_counts) / len(leave_counts)
            max_count = max(leave_counts)
            min_count = min(leave_counts)
            
            stats_summary[time_slot] = {
                'avg': avg_count,
                'max': max_count,
                'min': min_count,
                'count': len(data)
            }
            
            print(f'{time_slot} | {avg_count:8.1f} | {max_count:4d} | {min_count:4d} | {len(data):8d}')
    
    # 0:00ã®ç•°å¸¸æ€§ã‚’åˆ†æ
    if '00:00' in stats_summary and '23:45' in stats_summary and '00:15' in stats_summary:
        midnight_avg = stats_summary['00:00']['avg']
        before_avg = stats_summary['23:45']['avg']
        after_avg = stats_summary['00:15']['avg']
        
        print(f'\nå¢ƒç•Œåˆ†æ:')
        print(f'  23:45 â†’ 0:00: {midnight_avg - before_avg:+.1f}äººå·®')
        print(f'  0:00 â†’ 0:15: {after_avg - midnight_avg:+.1f}äººå·®')
        
        # ç†è«–çš„ã«ã¯0:00å‰å¾Œã§äººå“¡ã¯é€£ç¶šçš„ã«å¤‰åŒ–ã™ã¹ã
        expected_midnight = (before_avg + after_avg) / 2
        actual_excess = midnight_avg - expected_midnight
        
        print(f'\né‡è¤‡åˆ†æ:')
        print(f'  ç†è«–å€¤(23:45ã¨0:15ã®ä¸­é–“): {expected_midnight:.1f}äºº')
        print(f'  å®Ÿæ¸¬å€¤(0:00): {midnight_avg:.1f}äºº')
        print(f'  é‡è¤‡ç–‘ã„: {actual_excess:+.1f}äºº')
        
        if actual_excess > 1:
            print(f'  âš ï¸ 0:00ã§ç´„{actual_excess:.1f}äººã®é‡è¤‡ã‚«ã‚¦ãƒ³ãƒˆãŒç–‘ã‚ã‚Œã¾ã™!')
    
    return stats_summary

def analyze_need_pattern():
    """Needè¨ˆç®—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
    print('\n3. Needè¨ˆç®—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ')
    print('=' * 60)
    
    meta_path = os.path.join(analysis_folder, 'heatmap.meta.json')
    with open(meta_path, 'r', encoding='utf-8') as f:
        meta_data = json.load(f)
    
    dow_pattern = meta_data.get('dow_need_pattern', [])
    
    print('æ›œæ—¥åˆ¥Needè¨ˆç®—ãƒ‘ã‚¿ãƒ¼ãƒ³ (æ·±å¤œæ™‚é–“å¸¯):')
    print('æ™‚åˆ»  | æ—¥ | æœˆ | ç« | æ°´ | æœ¨ | é‡‘ | åœŸ')
    print('-' * 40)
    
    # æ·±å¤œæ™‚é–“å¸¯ã®Needãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèª
    for pattern in dow_pattern[:8]:  # 0:00-1:45
        time_str = pattern['time']
        values = [pattern[str(i)] for i in range(7)]
        print(f'{time_str} | {" | ".join([str(v) for v in values])}')
    
    print('\né‡è¦ãªç™ºè¦‹:')
    print('  - 0:00-6:45ã®å…¨æ™‚é–“å¸¯ã§Need=0')
    print('  - 7:00ã‹ã‚‰Need=3ã§å‹¤å‹™é–‹å§‹')
    print('  - æ·±å¤œæ™‚é–“å¸¯ã¯ç†è«–ä¸Šã‚¹ã‚¿ãƒƒãƒ•ä¸è¦')

def check_continuous_shift_patterns():
    """é€£ç¶šå‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¢ºèª"""
    print('\n4. é€£ç¶šå‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¢ºèª')
    print('=' * 60)
    
    # work_patterns.csvã®ç¢ºèª
    patterns_path = os.path.join(analysis_folder, 'work_patterns.csv')
    if os.path.exists(patterns_path):
        print('work_patterns.csvã‚’ç¢ºèªä¸­...')
        
        night_shift_count = 0
        total_patterns = 0
        
        with open(patterns_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                total_patterns += 1
                # å¤œå‹¤ã‚„æ·±å¤œå‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                for field in row.values():
                    if field and ('å¤œ' in str(field) or 'æ˜' in str(field) or 'Night' in str(field)):
                        night_shift_count += 1
                        break
        
        print(f'  ç·ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {total_patterns}')
        print(f'  å¤œå‹¤é–¢é€£ãƒ‘ã‚¿ãƒ¼ãƒ³: {night_shift_count}')
        print(f'  å¤œå‹¤æ¯”ç‡: {night_shift_count/total_patterns*100:.1f}%')
    else:
        print('work_patterns.csvãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')

def quantify_overlap_problem():
    """é‡è¤‡å•é¡Œã®æœ€çµ‚å®šé‡åŒ–"""
    print('\n5. é‡è¤‡å•é¡Œã®æœ€çµ‚å®šé‡åŒ–')
    print('=' * 60)
    
    # shortage_leave.csvã‹ã‚‰0:00ã®äººå“¡æ•°ã‚’å†è¨ˆç®—
    csv_path = os.path.join(analysis_folder, 'shortage_leave.csv')
    
    midnight_counts = []
    adjacent_counts = []
    
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            time_str = row['time']
            count = int(row['leave_applicants'])
            
            if time_str == '00:00':
                midnight_counts.append(count)
            elif time_str in ['23:45', '00:15']:
                adjacent_counts.append(count)
    
    if midnight_counts and adjacent_counts:
        midnight_avg = sum(midnight_counts) / len(midnight_counts)
        adjacent_avg = sum(adjacent_counts) / len(adjacent_counts)
        
        print(f'åˆ†æçµæœ:')
        print(f'  0:00å¹³å‡äººå“¡: {midnight_avg:.1f}äºº')
        print(f'  éš£æ¥æ™‚é–“å¹³å‡äººå“¡: {adjacent_avg:.1f}äºº')
        print(f'  å·®åˆ†: {midnight_avg - adjacent_avg:+.1f}äºº')
        
        # é‡è¤‡ç‡ã®è¨ˆç®—
        if adjacent_avg > 0:
            overlap_ratio = (midnight_avg - adjacent_avg) / adjacent_avg * 100
            print(f'  é‡è¤‡ç‡: {overlap_ratio:+.1f}%')
        
        # æœˆé–“å½±éŸ¿åº¦ã®è¨ˆç®—
        days_in_month = 30
        daily_excess = midnight_avg - adjacent_avg
        monthly_excess_hours = daily_excess * days_in_month * 0.25  # 15åˆ† = 0.25æ™‚é–“
        
        print(f'\næœˆé–“å½±éŸ¿åº¦:')
        print(f'  æ—¥æ¬¡é‡è¤‡: {daily_excess:.1f}äºº')
        print(f'  æœˆé–“é‡è¤‡æ™‚é–“: {monthly_excess_hours:.1f}äººæ™‚é–“')
        
        if daily_excess > 0.5:
            print(f'  âš ï¸ æ¯æ—¥ç´„{daily_excess:.1f}äººãŒ0:00ã§é‡è¤‡ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§')
            print(f'  ğŸ’¡ ã“ã‚Œã¯å¤œå‹¤çµ‚äº†è€…ã¨æ˜ã‘ç•ªé–‹å§‹è€…ã®é‡è¤‡ãŒåŸå› ã¨æ¨æ¸¬ã•ã‚Œã‚‹')

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
if __name__ == '__main__':
    if not os.path.exists(analysis_folder):
        print(f'ã‚¨ãƒ©ãƒ¼: {analysis_folder} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        exit(1)
    
    # å„åˆ†æã®å®Ÿè¡Œ
    midnight_data = analyze_shortage_leave_csv()
    stats_summary = analyze_time_comparison()
    analyze_need_pattern()
    check_continuous_shift_patterns()
    quantify_overlap_problem()
    
    print('\n=== èª¿æŸ»å®Œäº† ===')
    print('\nğŸ“‹ ä¸»è¦ãªç™ºè¦‹äº‹é …:')
    print('1. 0:00ã€œ6:45ã¯ç†è«–ä¸ŠNeed=0ã§å‹¤å‹™ä¸è¦')
    print('2. ã—ã‹ã—å®Ÿéš›ã«ã¯0:00ã«æ¯æ—¥12-19äººãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹')
    print('3. éš£æ¥æ™‚é–“ã¨ã®æ¯”è¼ƒã§é‡è¤‡ã‚«ã‚¦ãƒ³ãƒˆã®ç–‘ã„')
    print('4. å¤œå‹¤çµ‚äº†ã¨æ˜ã‘ç•ªé–‹å§‹ã®å¢ƒç•Œå‡¦ç†ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§')
    print('\nğŸ’¡ æ¨å¥¨ã•ã‚Œã‚‹å¯¾ç­–:')
    print('- é€£ç¶šå‹¤å‹™ã®å¢ƒç•Œæ™‚åˆ»ã§ã®é‡è¤‡ã‚«ã‚¦ãƒ³ãƒˆé˜²æ­¢')
    print('- å¤œå‹¤çµ‚äº†æ™‚åˆ»ã¨æ˜ã‘ç•ªé–‹å§‹æ™‚åˆ»ã®æ˜ç¢ºãªåˆ†é›¢')
    print('- 0:00è·¨ãå‹¤å‹™ã®é©åˆ‡ãªå‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…')