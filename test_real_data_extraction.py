#!/usr/bin/env python3
"""
å®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæ©Ÿèƒ½ã®æ¤œè¨¼ãƒ†ã‚¹ãƒˆ

ä¿®æ­£ç‰ˆAIComprehensiveReportGeneratorãŒå®Ÿéš›ã®Parquet/CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰
ãƒ‡ãƒ¼ã‚¿ã‚’æ­£ã—ãæŠ½å‡ºã—ã¦JSONã«åæ˜ ã—ã¦ã„ã‚‹ã‹ã‚’ãƒ†ã‚¹ãƒˆ
"""

import sys
import json
import logging
from pathlib import Path
from datetime import datetime

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
log = logging.getLogger(__name__)

def test_real_data_extraction():
    """å®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ"""
    log.info("ä¿®æ­£ç‰ˆå®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
    
    try:
        # å®Ÿéš›ã®åˆ†æçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
        test_output_dir = Path("temp_analysis_check")
        if not test_output_dir.exists():
            log.error("temp_analysis_check ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        from shift_suite.tasks.ai_comprehensive_report_generator import AIComprehensiveReportGenerator
        
        # AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨ã®åˆæœŸåŒ–
        generator = AIComprehensiveReportGenerator()
        
        # ãƒ†ã‚¹ãƒˆç”¨analysis_resultsã®æº–å‚™ï¼ˆæœ€å°é™ï¼‰
        test_analysis_results = {
            "basic_info": {
                "total_analysis_time": 120.5,
                "modules_executed": ["Shortage", "Fatigue", "Fairness", "Heatmap", "Cost"]
            }
        }
        
        test_analysis_params = {
            "slot_minutes": 30,
            "need_calculation_method": "p25_based",
            "statistical_method": "p25",
            "outlier_removal_enabled": True,
            "analysis_start_date": "2025-01-01",
            "analysis_end_date": "2025-03-31",
            "enabled_modules": ["Shortage", "Fatigue", "Fairness", "Cost", "Leave Analysis"]
        }
        
        log.info("å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’é–‹å§‹...")
        report = generator.generate_comprehensive_report(
            analysis_results=test_analysis_results,
            input_file_path="ãƒ‡ã‚¤_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿_ä¼‘æ—¥ç²¾ç·».xlsx",
            output_dir=str(test_output_dir / "out_p25_based"),
            analysis_params=test_analysis_params
        )
        
        # ãƒ¬ãƒãƒ¼ãƒˆã®æ¤œè¨¼
        if not report:
            log.error("âŒ ãƒ¬ãƒãƒ¼ãƒˆãŒç©ºã§ã™")
            return False
        
        log.info("=" * 60)
        log.info("å®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºçµæœã®æ¤œè¨¼")
        log.info("=" * 60)
        
        # KPIã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç¢ºèª
        kpis = report.get("key_performance_indicators", {})
        overall_perf = kpis.get("overall_performance", {})
        
        # ä¸è¶³æ™‚é–“ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        shortage_hours = overall_perf.get("total_shortage_hours", {}).get("value", 0)
        if shortage_hours > 0:
            log.info(f"âœ… å®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæˆåŠŸ - ç·ä¸è¶³æ™‚é–“: {shortage_hours:.1f} æ™‚é–“")
            severity = overall_perf.get("total_shortage_hours", {}).get("severity", "unknown")
            log.info(f"   é‡è¦åº¦: {severity}")
        else:
            log.warning("âš ï¸ ç·ä¸è¶³æ™‚é–“ãŒã¾ã 0.0ã§ã™")
        
        # ç–²åŠ´ã‚¹ã‚³ã‚¢ã®ç¢ºèª
        fatigue_score = overall_perf.get("avg_fatigue_score", {}).get("value", 0.5)
        if fatigue_score != 0.5:  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä»¥å¤–
            log.info(f"âœ… å®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæˆåŠŸ - å¹³å‡ç–²åŠ´ã‚¹ã‚³ã‚¢: {fatigue_score:.3f}")
            threshold_exceeded = overall_perf.get("avg_fatigue_score", {}).get("threshold_exceeded", False)
            log.info(f"   é–¾å€¤è¶…é: {threshold_exceeded}")
        else:
            log.warning("âš ï¸ ç–²åŠ´ã‚¹ã‚³ã‚¢ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®ã¾ã¾ã§ã™")
        
        # å…¬å¹³æ€§ã‚¹ã‚³ã‚¢ã®ç¢ºèª
        fairness_score = overall_perf.get("fairness_score", {}).get("value", 0.8)
        if fairness_score != 0.8:  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ä»¥å¤–
            log.info(f"âœ… å®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæˆåŠŸ - å…¬å¹³æ€§ã‚¹ã‚³ã‚¢: {fairness_score:.3f}")
            below_threshold = overall_perf.get("fairness_score", {}).get("below_threshold", False)
            log.info(f"   è¦æ”¹å–„: {below_threshold}")
        else:
            log.warning("âš ï¸ å…¬å¹³æ€§ã‚¹ã‚³ã‚¢ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®ã¾ã¾ã§ã™")
        
        # è©³ç´°åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ç¢ºèª
        detailed_modules = report.get("detailed_analysis_modules", {})
        
        # è·ç¨®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        role_performance = detailed_modules.get("role_performance", [])
        if role_performance:
            log.info(f"âœ… è·ç¨®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ: {len(role_performance)}è·ç¨®")
            for role in role_performance[:3]:  # æœ€åˆã®3è·ç¨®ã‚’ç¢ºèª
                role_id = role.get("role_id", "unknown")
                shortage = role.get("metrics", {}).get("shortage_hours", {}).get("value", 0)
                log.info(f"   - {role_id}: ä¸è¶³ {shortage:.1f}æ™‚é–“")
        else:
            log.warning("âš ï¸ è·ç¨®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãŒç©ºã§ã™")
        
        # ã‚¹ã‚¿ãƒƒãƒ•ç–²åŠ´åˆ†æ
        staff_fatigue = detailed_modules.get("staff_fatigue_analysis", [])
        if staff_fatigue:
            log.info(f"âœ… ã‚¹ã‚¿ãƒƒãƒ•ç–²åŠ´åˆ†æ: {len(staff_fatigue)}äººåˆ†")
            high_fatigue_staff = [s for s in staff_fatigue if s.get("fatigue_score", {}).get("value", 0) > 0.7]
            log.info(f"   - é«˜ç–²åŠ´ã‚¹ã‚¿ãƒƒãƒ•: {len(high_fatigue_staff)}äºº")
            
            # å®Ÿéš›ã®ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
            for staff in staff_fatigue[:3]:
                staff_id = staff.get("staff_id", "unknown")
                fatigue = staff.get("fatigue_score", {}).get("value", 0)
                status = staff.get("fatigue_score", {}).get("status", "unknown")
                log.info(f"   - {staff_id}: {fatigue:.3f} ({status})")
        else:
            log.warning("âš ï¸ ã‚¹ã‚¿ãƒƒãƒ•ç–²åŠ´åˆ†æãŒç©ºã§ã™")
        
        # ã‚¹ã‚¿ãƒƒãƒ•å…¬å¹³æ€§åˆ†æ
        staff_fairness = detailed_modules.get("staff_fairness_analysis", [])
        if staff_fairness:
            log.info(f"âœ… ã‚¹ã‚¿ãƒƒãƒ•å…¬å¹³æ€§åˆ†æ: {len(staff_fairness)}äººåˆ†")
            low_fairness_staff = [s for s in staff_fairness if s.get("fairness_score", {}).get("below_threshold", False)]
            log.info(f"   - å…¬å¹³æ€§è¦æ”¹å–„ã‚¹ã‚¿ãƒƒãƒ•: {len(low_fairness_staff)}äºº")
            
            # å®Ÿéš›ã®ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
            for staff in staff_fairness[:3]:
                staff_id = staff.get("staff_id", "unknown")
                fairness = staff.get("fairness_score", {}).get("value", 0)
                status = staff.get("fairness_score", {}).get("status", "unknown")
                log.info(f"   - {staff_id}: {fairness:.3f} ({status})")
        else:
            log.warning("âš ï¸ ã‚¹ã‚¿ãƒƒãƒ•å…¬å¹³æ€§åˆ†æãŒç©ºã§ã™")
        
        # æ™‚é–“æ åˆ†æ
        time_slot_analysis = detailed_modules.get("time_slot_analysis", [])
        if time_slot_analysis:
            log.info(f"âœ… æ™‚é–“æ åˆ†æ: {len(time_slot_analysis)}æ™‚é–“æ ")
            critical_slots = [t for t in time_slot_analysis if t.get("metrics", {}).get("shortage_excess_value", {}).get("severity") == "high"]
            log.info(f"   - é‡è¦æ™‚é–“æ : {len(critical_slots)}æ ")
            
            # å®Ÿéš›ã®æ™‚é–“æ ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
            for slot in time_slot_analysis[:3]:
                time_slot = slot.get("time_slot", "unknown")
                value = slot.get("metrics", {}).get("shortage_excess_value", {}).get("value", 0)
                severity = slot.get("metrics", {}).get("shortage_excess_value", {}).get("severity", "unknown")
                log.info(f"   - {time_slot}: {value:.1f} ({severity})")
        else:
            log.warning("âš ï¸ æ™‚é–“æ åˆ†æãŒç©ºã§ã™")
        
        # é‡è¦ãªè¦³æ¸¬çµæœ
        observations = report.get("summary_of_critical_observations", [])
        log.info(f"ğŸ“Š é‡è¦ãªè¦³æ¸¬çµæœ: {len(observations)}ä»¶")
        for obs in observations:
            category = obs.get('category', 'unknown')
            severity = obs.get('severity', 'unknown')
            description = obs.get('description', 'no description')[:100]
            log.info(f"   - {category} ({severity}): {description}...")
        
        # ã‚·ã‚¹ãƒ†ãƒ å•é¡Œé¡å‹
        problem_archetypes = report.get("systemic_problem_archetypes", [])
        log.info(f"ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ å•é¡Œé¡å‹: {len(problem_archetypes)}ä»¶")
        for arch in problem_archetypes:
            arch_id = arch.get('archetype_id', 'unknown')
            description = arch.get('description', 'no description')[:80]
            log.info(f"   - {arch_id}: {description}...")
        
        # ãƒ«ãƒ¼ãƒ«é•å
        rule_violations = report.get("rule_violation_summary", [])
        log.info(f"ğŸ“Š ãƒ«ãƒ¼ãƒ«é•å: {len(rule_violations)}ä»¶")
        for violation in rule_violations:
            rule_id = violation.get('rule_id', 'unknown')
            count = violation.get('violation_count_last_period', 0)
            log.info(f"   - {rule_id}: {count}ä»¶")
        
        # ç”Ÿæˆã•ã‚ŒãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        json_files = list(Path(".").glob("ai_comprehensive_report_*.json"))
        json_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)  # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…ˆé ­ã«
        
        if json_files:
            latest_json = json_files[0]
            log.info(f"âœ… æœ€æ–°JSONãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {latest_json.name}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
            file_size = latest_json.stat().st_size
            log.info(f"ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes")
            
            if file_size > 50000:  # 50KBä»¥ä¸Šãªã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã¨åˆ¤æ–­
                log.info("âœ… å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€å……å®Ÿã—ãŸãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
                
                # ä¸€éƒ¨ã®KPIã‚’å®Ÿéš›ã®JSONã‹ã‚‰å†ç¢ºèª
                with open(latest_json, 'r', encoding='utf-8') as f:
                    saved_report = json.load(f)
                
                saved_shortage = saved_report.get("key_performance_indicators", {}).get("overall_performance", {}).get("total_shortage_hours", {}).get("value", 0)
                saved_fatigue = saved_report.get("key_performance_indicators", {}).get("overall_performance", {}).get("avg_fatigue_score", {}).get("value", 0.5)
                
                log.info(f"ğŸ“Š ä¿å­˜ã•ã‚ŒãŸKPI - ä¸è¶³æ™‚é–“: {saved_shortage}, ç–²åŠ´: {saved_fatigue:.3f}")
                
                # è©³ç´°åˆ†æãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
                saved_modules = saved_report.get("detailed_analysis_modules", {})
                role_count = len(saved_modules.get("role_performance", []))
                fatigue_count = len(saved_modules.get("staff_fatigue_analysis", []))
                fairness_count = len(saved_modules.get("staff_fairness_analysis", []))
                
                log.info(f"ğŸ“Š ä¿å­˜ã•ã‚ŒãŸåˆ†æ - è·ç¨®: {role_count}, ç–²åŠ´: {fatigue_count}, å…¬å¹³æ€§: {fairness_count}")
                
                return True
            else:
                log.warning("âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå°ã•ã™ãã¾ã™ã€‚å®Ÿãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                return False
        else:
            log.error("âŒ JSONãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
    except Exception as e:
        log.error(f"âŒ å®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    log.info("=" * 80)
    log.info("ä¿®æ­£ç‰ˆAIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ©Ÿèƒ½ å®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ†ã‚¹ãƒˆé–‹å§‹")
    log.info("=" * 80)
    
    success = test_real_data_extraction()
    
    log.info("=" * 80)
    log.info("ãƒ†ã‚¹ãƒˆçµæœ")
    log.info("=" * 80)
    
    if success:
        log.info("ğŸ‰ ä¿®æ­£ç‰ˆå®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        log.info("âœ¨ å®Ÿéš›ã®Parquet/CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«æŠ½å‡ºã•ã‚Œã€JSONãƒ¬ãƒãƒ¼ãƒˆã«åæ˜ ã•ã‚Œã¦ã„ã¾ã™ã€‚")
        log.info("ğŸ“‹ ã“ã‚Œã§AIãŒåˆ†æã‚’è¡Œã†ãŸã‚ã®ã€Œææ–™ã€ãŒæä¾›ã•ã‚Œã¾ã™ã€‚")
        return True
    else:
        log.error("âŒ ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ã¾ã æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)