"""
é«˜åº¦ä¸è¶³åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
app.pyãŠã‚ˆã³dash_app.pyã‹ã‚‰å‘¼ã³å‡ºã™ãŸã‚ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
"""

import streamlit as st
import pandas as pd
from pathlib import Path
from typing import Optional, Dict, Any
import logging

# é«˜åº¦åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from comprehensive_enhanced_shortage_analysis_fixed import (
    ComprehensiveShortageAnalyzer,
    cache_manager
)

logger = logging.getLogger(__name__)


def display_advanced_shortage_tab(tab_container, data_dir: Path):
    """
    Streamlitç”¨ã®é«˜åº¦ä¸è¶³åˆ†æã‚¿ãƒ–ã‚’è¡¨ç¤º
    
    Args:
        tab_container: Streamlitã®ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒŠ
        data_dir: ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
    """
    with tab_container:
        st.header("ğŸ”¬ é«˜åº¦ä¸è¶³åˆ†æ")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            if st.button("ğŸ”„ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢", help="åˆ†æçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§å†è¨ˆç®—"):
                cache_manager.clear()
                st.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
        
        # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
        try:
            analyzer = ComprehensiveShortageAnalyzer(data_dir)
            
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            with st.spinner("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­..."):
                if not analyzer.load_all_data():
                    st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    return
            
            # åˆ†æãƒ¢ãƒ¼ãƒ‰é¸æŠ
            analysis_mode = st.selectbox(
                "åˆ†æãƒ¢ãƒ¼ãƒ‰é¸æŠ",
                ["åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆ", "æ ¹æœ¬åŸå› åˆ†æ", "ã‚³ã‚¹ãƒˆå½±éŸ¿åˆ†æ", 
                 "å°†æ¥äºˆæ¸¬", "æœ€é©é…ç½®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", "å€‹äººè² è·åˆ†æ", "çµ±è¨ˆåˆ†æ"]
            )
            
            # åˆ†æå®Ÿè¡Œ
            if st.button("ğŸš€ åˆ†æå®Ÿè¡Œ", type="primary"):
                with st.spinner(f"{analysis_mode}ã‚’å®Ÿè¡Œä¸­..."):
                    display_analysis_results(analyzer, analysis_mode)
                    
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            logger.error(f"Advanced shortage analysis error: {e}", exc_info=True)


def display_analysis_results(analyzer: ComprehensiveShortageAnalyzer, mode: str):
    """åˆ†æçµæœã‚’è¡¨ç¤º"""
    
    try:
        if mode == "åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆ":
            report = analyzer.generate_comprehensive_report()
            display_comprehensive_report(report)
            
        elif mode == "æ ¹æœ¬åŸå› åˆ†æ":
            results = analyzer.analyze_root_causes()
            display_root_cause_analysis(results)
            
        elif mode == "ã‚³ã‚¹ãƒˆå½±éŸ¿åˆ†æ":
            impact = analyzer.analyze_cost_impact()
            display_cost_impact(impact)
            
        elif mode == "å°†æ¥äºˆæ¸¬":
            col1, col2 = st.columns([3, 1])
            with col2:
                use_ml = st.checkbox("æ©Ÿæ¢°å­¦ç¿’ä½¿ç”¨", value=True)
            prediction = analyzer.predict_future_shortage(use_ml=use_ml)
            display_future_prediction(prediction)
            
        elif mode == "æœ€é©é…ç½®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³":
            simulation = analyzer.simulate_optimal_allocation()
            display_optimal_allocation(simulation)
            
        elif mode == "å€‹äººè² è·åˆ†æ":
            workload = analyzer.analyze_individual_workload()
            display_workload_analysis(workload)
            
        elif mode == "çµ±è¨ˆåˆ†æ":
            insights = analyzer.perform_advanced_statistical_analysis()
            display_statistical_insights(insights)
            
    except Exception as e:
        st.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        logger.error(f"Analysis execution error: {e}", exc_info=True)


def display_comprehensive_report(report: Dict):
    """åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º"""
    st.subheader("ğŸ“Š åŒ…æ‹¬çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    
    # ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
    if "executive_summary" in report:
        with st.expander("ğŸ“‹ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼", expanded=True):
            summary = report["executive_summary"]
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç·ä¸è¶³æ™‚é–“", f"{summary.get('total_shortage_hours', 0):.1f}h")
            with col2:
                st.metric("å½±éŸ¿ã‚³ã‚¹ãƒˆ", f"Â¥{summary.get('total_cost_impact', 0):,.0f}")
            with col3:
                st.metric("ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«", summary.get('overall_risk_level', 'N/A'))
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ª
    if "data_quality" in report:
        with st.expander("âœ… ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡"):
            quality = report["data_quality"]
            st.write(f"å®Œå…¨æ€§: {quality.get('completeness', 0):.1%}")
            st.write(f"ä¸€è²«æ€§: {quality.get('consistency', 0):.1%}")
            if quality.get('outliers_detected'):
                st.warning(f"å¤–ã‚Œå€¤æ¤œå‡º: {quality['outliers_detected']}ä»¶")
    
    # ãã®ä»–ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    for section in ["root_causes", "cost_impact", "future_prediction", 
                   "optimal_allocation", "workload_analysis", "statistical_insights"]:
        if section in report:
            display_section_details(section, report[section])


def display_root_cause_analysis(results: Dict):
    """æ ¹æœ¬åŸå› åˆ†æã®è¡¨ç¤º"""
    st.subheader("ğŸ” æ ¹æœ¬åŸå› åˆ†æ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("ç·ä¸è¶³æ™‚é–“", f"{results.get('total_shortage_hours', 0):.1f}h")
        
        # çµ±è¨ˆçš„è¦å› åˆ†è§£
        if "statistical_breakdown" in results:
            breakdown = results["statistical_breakdown"]
            st.write("**ä¸»è¦å› :**")
            for role, hours in breakdown.get("top_contributing_roles", {}).items():
                st.write(f"- {role}: {hours:.1f}h")
    
    with col2:
        # æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³
        if "time_patterns" in results:
            patterns = results["time_patterns"]
            st.write("**æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³:**")
            st.write(f"ãƒ”ãƒ¼ã‚¯æ™‚é–“: {', '.join(patterns.get('peak_hours', []))}")
            st.write(f"ãƒ”ãƒ¼ã‚¯æ›œæ—¥: {', '.join(patterns.get('peak_days', []))}")
    
    # æ¨å¥¨äº‹é …
    if "recommendations" in results:
        st.write("**æ¨å¥¨äº‹é …:**")
        for rec in results["recommendations"]:
            st.write(f"â€¢ {rec}")


def display_cost_impact(impact):
    """ã‚³ã‚¹ãƒˆå½±éŸ¿åˆ†æã®è¡¨ç¤º"""
    st.subheader("ğŸ’° ã‚³ã‚¹ãƒˆå½±éŸ¿åˆ†æ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ®‹æ¥­ã‚³ã‚¹ãƒˆ", f"Â¥{impact.overtime_cost:,.0f}")
    with col2:
        st.metric("æ´¾é£ã‚³ã‚¹ãƒˆ", f"Â¥{impact.dispatch_cost:,.0f}")
    with col3:
        st.metric("æ©Ÿä¼šæå¤±", f"Â¥{impact.opportunity_loss:,.0f}")
    with col4:
        st.metric("ç·å½±éŸ¿é¡", f"Â¥{impact.total_impact:,.0f}")
    
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«
    st.write(f"**é›¢è·ãƒªã‚¹ã‚¯:** {impact.turnover_risk}")
    
    # æœˆæ¬¡äºˆæ¸¬
    if impact.monthly_projection:
        st.write("**æœˆæ¬¡äºˆæ¸¬:**")
        projection_df = pd.DataFrame([impact.monthly_projection])
        st.dataframe(projection_df)


def display_future_prediction(prediction: Dict):
    """å°†æ¥äºˆæ¸¬ã®è¡¨ç¤º"""
    st.subheader("ğŸ”® å°†æ¥äºˆæ¸¬")
    
    # äºˆæ¸¬çµæœ
    st.write("**30æ—¥å¾Œäºˆæ¸¬:**")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        pred_value = prediction.get("prediction_30_days", {})
        st.metric("äºˆæ¸¬ä¸è¶³æ™‚é–“", f"{pred_value.get('predicted_shortage', 0):.1f}h")
    with col2:
        st.metric("ä¿¡é ¼åŒºé–“ä¸‹é™", f"{pred_value.get('confidence_interval', [0, 0])[0]:.1f}h")
    with col3:
        st.metric("ä¿¡é ¼åŒºé–“ä¸Šé™", f"{pred_value.get('confidence_interval', [0, 0])[1]:.1f}h")
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰
    if "trend_analysis" in prediction:
        trend = prediction["trend_analysis"]
        st.write(f"**ãƒˆãƒ¬ãƒ³ãƒ‰:** {trend.get('direction', 'N/A')}")
        st.write(f"**å­£ç¯€æ€§:** {trend.get('seasonality', 'N/A')}")
    
    # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½
    if "model_performance" in prediction:
        perf = prediction["model_performance"]
        st.write(f"**ãƒ¢ãƒ‡ãƒ«ç²¾åº¦ (RÂ²):** {perf.get('r2_score', 0):.3f}")


def display_optimal_allocation(simulation: Dict):
    """æœ€é©é…ç½®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®è¡¨ç¤º"""
    st.subheader("ğŸ¯ æœ€é©é…ç½®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    
    # æ”¹å–„æŒ‡æ¨™
    col1, col2, col3 = st.columns(3)
    
    with col1:
        current = simulation.get("current_shortage", 0)
        st.metric("ç¾åœ¨ã®ä¸è¶³", f"{current:.1f}h")
    with col2:
        optimized = simulation.get("optimized_shortage", 0)
        st.metric("æœ€é©åŒ–å¾Œ", f"{optimized:.1f}h", 
                 delta=f"{optimized - current:.1f}h")
    with col3:
        improvement = simulation.get("improvement_percentage", 0)
        st.metric("æ”¹å–„ç‡", f"{improvement:.1f}%")
    
    # æ¨å¥¨é…ç½®
    if "recommended_allocation" in simulation:
        st.write("**æ¨å¥¨é…ç½®:**")
        alloc_df = pd.DataFrame(simulation["recommended_allocation"])
        st.dataframe(alloc_df)
    
    # åˆ¶ç´„æ¡ä»¶
    if "constraints_satisfied" in simulation:
        satisfied = simulation["constraints_satisfied"]
        st.write(f"**åˆ¶ç´„æ¡ä»¶å……è¶³:** {'âœ…' if satisfied else 'âš ï¸'}")


def display_workload_analysis(workload):
    """å€‹äººè² è·åˆ†æã®è¡¨ç¤º"""
    st.subheader("ğŸ‘¥ å€‹äººè² è·åˆ†æ")
    
    if not workload:
        st.info("åˆ†æå¯¾è±¡ã®ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
    workload_df = pd.DataFrame([{
        'ã‚¹ã‚¿ãƒƒãƒ•': w.staff_name,
        'ç·å‹¤å‹™æ™‚é–“': w.total_hours,
        'å¹³å‡ã‚·ãƒ•ãƒˆé•·': w.average_shift_length,
        'ç–²åŠ´ã‚¹ã‚³ã‚¢': w.fatigue_score,
        'ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«': w.risk_level.value,
        'æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³': ', '.join(w.recommended_actions[:2]) if w.recommended_actions else 'ãªã—'
    } for w in workload])
    
    # ãƒã‚¤ãƒªã‚¹ã‚¯ã‚¹ã‚¿ãƒƒãƒ•
    high_risk = workload_df[workload_df['ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«'].isin(['å±é™º', 'é«˜'])]
    if not high_risk.empty:
        st.warning(f"âš ï¸ {len(high_risk)}åã®ã‚¹ã‚¿ãƒƒãƒ•ãŒé«˜ãƒªã‚¹ã‚¯çŠ¶æ…‹ã§ã™")
    
    # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    st.dataframe(workload_df, use_container_width=True)


def display_statistical_insights(insights):
    """çµ±è¨ˆåˆ†æã®è¡¨ç¤º"""
    st.subheader("ğŸ“ˆ é«˜åº¦çµ±è¨ˆåˆ†æ")
    
    # ç›¸é–¢åˆ†æ
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ç›¸é–¢åˆ†æ:**")
        st.write(f"éœ€è¦-ä¸è¶³ç›¸é–¢: {insights.correlation_analysis.demand_shortage:.2f}")
        st.write(f"ã‚¹ã‚¿ãƒƒãƒ•-ä¸è¶³ç›¸é–¢: {insights.correlation_analysis.staff_shortage:.2f}")
    
    with col2:
        st.write("**å›å¸°åˆ†æ:**")
        st.write(f"RÂ²ã‚¹ã‚³ã‚¢: {insights.regression_analysis.r2_score:.3f}")
        st.write(f"äºˆæ¸¬ç²¾åº¦: {(1 - insights.regression_analysis.mse / 100):.1%}")
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    if insights.clustering_results.cluster_sizes:
        st.write("**ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æ:**")
        cluster_df = pd.DataFrame({
            'ã‚¯ãƒ©ã‚¹ã‚¿': list(range(len(insights.clustering_results.cluster_sizes))),
            'ã‚µã‚¤ã‚º': insights.clustering_results.cluster_sizes
        })
        st.bar_chart(cluster_df.set_index('ã‚¯ãƒ©ã‚¹ã‚¿'))
    
    # æ™‚ç³»åˆ—åˆ†æ
    st.write("**æ™‚ç³»åˆ—åˆ†æ:**")
    st.write(f"ãƒˆãƒ¬ãƒ³ãƒ‰: {insights.time_series_analysis.trend}")
    st.write(f"äºˆæ¸¬å€¤: {insights.time_series_analysis.forecast_values[:3]}")


def display_section_details(section_name: str, section_data: Any):
    """æ±ç”¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¡¨ç¤º"""
    title_map = {
        "root_causes": "æ ¹æœ¬åŸå› ",
        "cost_impact": "ã‚³ã‚¹ãƒˆå½±éŸ¿",
        "future_prediction": "å°†æ¥äºˆæ¸¬",
        "optimal_allocation": "æœ€é©é…ç½®",
        "workload_analysis": "è² è·åˆ†æ",
        "statistical_insights": "çµ±è¨ˆæ´å¯Ÿ"
    }
    
    with st.expander(f"ğŸ“Œ {title_map.get(section_name, section_name)}"):
        if isinstance(section_data, dict):
            for key, value in section_data.items():
                if isinstance(value, (int, float)):
                    st.write(f"{key}: {value:.2f}")
                elif isinstance(value, list):
                    st.write(f"{key}: {', '.join(map(str, value[:5]))}")
                else:
                    st.write(f"{key}: {value}")
        else:
            st.write(section_data)


# Dashç”¨ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆå¿…è¦ã«å¿œã˜ã¦å®Ÿè£…ï¼‰
def get_advanced_analysis_for_dash(data_dir: Path, analysis_type: str = "comprehensive") -> Dict:
    """
    Dashç”¨ã®é«˜åº¦åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Args:
        data_dir: ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        analysis_type: åˆ†æã‚¿ã‚¤ãƒ—
        
    Returns:
        åˆ†æçµæœã®è¾æ›¸
    """
    try:
        analyzer = ComprehensiveShortageAnalyzer(data_dir)
        
        if not analyzer.load_all_data():
            return {"error": "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—"}
        
        if analysis_type == "comprehensive":
            return analyzer.generate_comprehensive_report()
        elif analysis_type == "root_causes":
            return analyzer.analyze_root_causes()
        elif analysis_type == "cost_impact":
            impact = analyzer.analyze_cost_impact()
            return impact.__dict__
        elif analysis_type == "prediction":
            return analyzer.predict_future_shortage(use_ml=True)
        elif analysis_type == "optimization":
            return analyzer.simulate_optimal_allocation()
        elif analysis_type == "workload":
            workload = analyzer.analyze_individual_workload()
            return {"workload": [w.__dict__ for w in workload]}
        elif analysis_type == "statistical":
            insights = analyzer.perform_advanced_statistical_analysis()
            return {
                "correlation": insights.correlation_analysis.__dict__,
                "regression": insights.regression_analysis.__dict__,
                "clustering": insights.clustering_results.__dict__,
                "time_series": insights.time_series_analysis.__dict__
            }
        else:
            return {"error": f"Unknown analysis type: {analysis_type}"}
            
    except Exception as e:
        logger.error(f"Dash analysis error: {e}", exc_info=True)
        return {"error": str(e)}