#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œå…¨æ€§ã®è©³ç´°åˆ†æ
"""

import json
from pathlib import Path

def analyze_backup_completeness():
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œå…¨æ€§ã®è©³ç´°åˆ†æ"""
    
    print("=" * 80)
    print("ğŸ” ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œå…¨æ€§ã®è©³ç´°åˆ†æ")
    print("=" * 80)
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    metadata_path = Path("PHASE3_COMPLETE_BACKUP_20250802_100555/backup_metadata.json")
    with open(metadata_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    # 1. ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
    categories = {
        "Phase 2å®Ÿè£…": [],
        "Phase 3.1å®Ÿè£…": [],
        "Phase 3.2å®Ÿè£…": [],
        "è¨­è¨ˆæ›¸ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ": [],
        "æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ": [],
        "ã‚·ã‚¹ãƒ†ãƒ åŸºç›¤": [],
        "ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³": []
    }
    
    for file_info in metadata["critical_files"]:
        path = file_info["path"]
        
        if "fact_extractor_prototype" in path:
            categories["Phase 2å®Ÿè£…"].append(file_info)
        elif "lightweight_anomaly_detector" in path:
            categories["Phase 3.1å®Ÿè£…"].append(file_info)
        elif "fact_book_visualizer" in path or "dash_fact_book_integration" in path:
            categories["Phase 3.2å®Ÿè£…"].append(file_info)
        elif ".md" in path and "PHASE" in path:
            categories["è¨­è¨ˆæ›¸ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"].append(file_info)
        elif "verify" in path or "check" in path or "test" in path:
            categories["æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"].append(file_info)
        elif "constants.py" in path or "__init__.py" in path or "requirements.txt" in path:
            categories["ã‚·ã‚¹ãƒ†ãƒ åŸºç›¤"].append(file_info)
        elif "app.py" in path or "dash_app.py" in path:
            categories["ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"].append(file_info)
    
    # 2. ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚µãƒãƒªãƒ¼
    print("\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çŠ¶æ³:")
    total_size = 0
    
    for category, files in categories.items():
        if files:
            category_size = sum(f["size_bytes"] for f in files)
            total_size += category_size
            print(f"\n{category}: {len(files)}ãƒ•ã‚¡ã‚¤ãƒ« ({category_size/1024:.1f} KB)")
            for f in files:
                status = "âœ…" if f["backup_status"] == "success" else "âŒ"
                print(f"  {status} {Path(f['path']).name} ({f['size_bytes']:,} bytes)")
    
    # 3. å®Œå…¨æ€§æ¤œè¨¼
    print(f"\nğŸ”’ å®Œå…¨æ€§ä¿è¨¼:")
    
    # ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼
    all_have_checksum = all(f.get("checksum") for f in metadata["critical_files"])
    print(f"  {'âœ…' if all_have_checksum else 'âŒ'} å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒã‚§ãƒƒã‚¯ã‚µãƒ ä»˜ä¸")
    
    # æˆåŠŸç‡
    success_count = len([f for f in metadata["critical_files"] if f["backup_status"] == "success"])
    total_count = len(metadata["critical_files"])
    success_rate = (success_count / total_count) * 100
    print(f"  {'âœ…' if success_rate == 100 else 'âŒ'} ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆåŠŸç‡: {success_rate:.1f}%")
    
    # 4. å¾©å…ƒå¯èƒ½æ€§æ¤œè¨¼
    print(f"\nğŸ”„ å¾©å…ƒå¯èƒ½æ€§:")
    
    # å¾©å…ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å­˜åœ¨
    restore_script = Path("PHASE3_COMPLETE_BACKUP_20250802_100555/restore_phase3.py")
    print(f"  {'âœ…' if restore_script.exists() else 'âŒ'} å¾©å…ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆå­˜åœ¨")
    
    # æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å­˜åœ¨
    verify_script = Path("PHASE3_COMPLETE_BACKUP_20250802_100555/verify_backup.py")
    print(f"  {'âœ…' if verify_script.exists() else 'âŒ'} æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆå­˜åœ¨")
    
    # ZIPã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®å­˜åœ¨
    zip_file = Path("PHASE3_COMPLETE_BACKUP_20250802_100555.zip")
    if zip_file.exists():
        zip_size_mb = zip_file.stat().st_size / (1024 * 1024)
        print(f"  âœ… ZIPã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å­˜åœ¨ ({zip_size_mb:.2f} MB)")
    else:
        print(f"  âŒ ZIPã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸åœ¨")
    
    # 5. Phaseå®Œå…¨æ€§ãƒãƒˆãƒªã‚¯ã‚¹
    print(f"\nğŸ“‹ Phaseå®Œå…¨æ€§ãƒãƒˆãƒªã‚¯ã‚¹:")
    
    phase_matrix = {
        "Phase 1": ["è¨­è¨ˆæ›¸", "èª¿æŸ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"],
        "Phase 2": ["å®Ÿè£…ã‚³ãƒ¼ãƒ‰", "çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ", "ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ"],
        "Phase 3.1": ["å®Ÿè£…ã‚³ãƒ¼ãƒ‰", "è¨­è¨ˆæ›¸", "æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ"],
        "Phase 3.2": ["å®Ÿè£…ã‚³ãƒ¼ãƒ‰", "çµ±åˆã‚¬ã‚¤ãƒ‰", "æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ"]
    }
    
    for phase, components in phase_matrix.items():
        print(f"\n  {phase}:")
        for component in components:
            # ç°¡æ˜“çš„ãªå­˜åœ¨ç¢ºèª
            exists = any(component.lower() in str(f["path"]).lower() for f in metadata["critical_files"])
            status = "âœ…" if exists else "âš ï¸"
            print(f"    {status} {component}")
    
    # 6. çµ±è¨ˆã‚µãƒãƒªãƒ¼
    print(f"\nğŸ“Š ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çµ±è¨ˆ:")
    print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_count}")
    print(f"  ç·ã‚µã‚¤ã‚º: {total_size / (1024*1024):.2f} MB")
    print(f"  å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {(total_size / total_count) / 1024:.1f} KB")
    print(f"  æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«: {max(metadata['critical_files'], key=lambda x: x['size_bytes'])['path']}")
    print(f"  æœ€å°ãƒ•ã‚¡ã‚¤ãƒ«: {min(metadata['critical_files'], key=lambda x: x['size_bytes'])['path']}")
    
    # æœ€çµ‚åˆ¤å®š
    is_complete = (
        success_rate == 100 and
        all_have_checksum and
        restore_script.exists() and
        verify_script.exists() and
        zip_file.exists()
    )
    
    print(f"\n{'ğŸ¯' if is_complete else 'âš ï¸'} ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œå…¨æ€§åˆ¤å®š: {'å®Œå…¨' if is_complete else 'ä¸å®Œå…¨'}")
    
    return is_complete

if __name__ == "__main__":
    analyze_backup_completeness()