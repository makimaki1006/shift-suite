"""
C2 ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£å‘ä¸Š - äº‹å‰å®‰å…¨ç¢ºèªã‚·ã‚¹ãƒ†ãƒ 
æ—¢å­˜æ©Ÿèƒ½ã¸ã®å½±éŸ¿ã‚’å¾¹åº•èª¿æŸ»ã—ã€ã‚¨ãƒ©ãƒ¼ãƒªã‚¹ã‚¯ã‚’æœ€å°åŒ–
"""

import os
import json
import ast
import re
import importlib.util
from datetime import datetime
from typing import Dict, List, Tuple, Any, Set
import traceback

class SystemSafetyAnalyzer:
    """ã‚·ã‚¹ãƒ†ãƒ å®‰å…¨æ€§åˆ†æå™¨"""
    
    def __init__(self):
        self.base_path = "/mnt/c/Users/fuji1/OneDrive/ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/ã‚·ãƒ•ãƒˆåˆ†æ"
        self.critical_files = [
            "app.py",
            "dash_app.py", 
            "shift_suite/__init__.py",
            "shift_suite/tasks/utils.py",
            "shift_suite/tasks/shortage.py",
            "shift_suite/tasks/fact_extractor_prototype.py",
            "shift_suite/tasks/lightweight_anomaly_detector.py"
        ]
        self.mobile_related_files = []
        self.dependency_map = {}
        self.safety_report = {}
        
    def analyze_system_safety(self):
        """ã‚·ã‚¹ãƒ†ãƒ å®‰å…¨æ€§ã®åŒ…æ‹¬åˆ†æ"""
        print("ğŸ” C2å®Ÿè£…å‰ã‚·ã‚¹ãƒ†ãƒ å®‰å…¨æ€§åˆ†æé–‹å§‹...")
        
        try:
            # 1. é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªãƒ»æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
            print("\nğŸ“‹ Step 1: é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æ–‡ãƒã‚§ãƒƒã‚¯...")
            syntax_results = self._check_critical_files_syntax()
            
            # 2. ãƒ¢ãƒã‚¤ãƒ«é–¢é€£æ—¢å­˜å®Ÿè£…ã®èª¿æŸ»
            print("\nğŸ“± Step 2: æ—¢å­˜ãƒ¢ãƒã‚¤ãƒ«å®Ÿè£…èª¿æŸ»...")
            mobile_analysis = self._analyze_existing_mobile_implementation()
            
            # 3. ä¾å­˜é–¢ä¿‚ãƒãƒƒãƒ”ãƒ³ã‚°
            print("\nğŸ”— Step 3: ä¾å­˜é–¢ä¿‚ãƒãƒƒãƒ”ãƒ³ã‚°...")
            dependency_analysis = self._analyze_dependencies()
            
            # 4. Phase 2/3.1çµ±åˆã®å®‰å…¨æ€§ç¢ºèª
            print("\nâš¡ Step 4: Phase 2/3.1çµ±åˆå®‰å…¨æ€§...")
            integration_safety = self._verify_phase_integration_safety()
            
            # 5. SLOT_HOURSè¨ˆç®—ã¸ã®å½±éŸ¿è©•ä¾¡
            print("\nğŸ§® Step 5: SLOT_HOURSè¨ˆç®—å½±éŸ¿è©•ä¾¡...")
            slot_hours_impact = self._assess_slot_hours_impact()
            
            # 6. ãƒªã‚¹ã‚¯è©•ä¾¡ãƒ»æ¨å¥¨äº‹é …
            print("\nâš ï¸ Step 6: ãƒªã‚¹ã‚¯è©•ä¾¡...")
            risk_assessment = self._perform_risk_assessment()
            
            # ç·åˆå®‰å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            self.safety_report = {
                'timestamp': datetime.now().isoformat(),
                'analysis_type': 'c2_pre_implementation_safety',
                'system_status': 'analyzed',
                'syntax_check': syntax_results,
                'mobile_implementation': mobile_analysis,
                'dependency_analysis': dependency_analysis,
                'integration_safety': integration_safety,
                'slot_hours_impact': slot_hours_impact,
                'risk_assessment': risk_assessment,
                'safety_score': self._calculate_safety_score(),
                'recommendations': self._generate_safety_recommendations()
            }
            
            return self.safety_report
            
        except Exception as e:
            error_report = {
                'timestamp': datetime.now().isoformat(),
                'analysis_type': 'c2_safety_analysis_error',
                'error': str(e),
                'traceback': traceback.format_exc(),
                'status': 'failed'
            }
            return error_report
    
    def _check_critical_files_syntax(self):
        """é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯"""
        results = {}
        
        for file_path in self.critical_files:
            full_path = os.path.join(self.base_path, file_path)
            
            if not os.path.exists(full_path):
                results[file_path] = {
                    'status': 'missing',
                    'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“'
                }
                continue
            
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
                ast.parse(content)
                
                # Phase 2/3.1é–¢é€£ã®é‡è¦é–¢æ•°ç¢ºèª
                critical_patterns = self._get_critical_patterns()
                pattern_matches = {}
                
                for pattern_name, pattern in critical_patterns.items():
                    matches = re.findall(pattern, content)
                    pattern_matches[pattern_name] = len(matches)
                
                results[file_path] = {
                    'status': 'ok',
                    'file_size': len(content),
                    'lines': len(content.split('\\n')),
                    'critical_patterns': pattern_matches,
                    'has_slot_hours': '* SLOT_HOURS' in content or 'SLOT_HOURS =' in content
                }
                
            except SyntaxError as e:
                results[file_path] = {
                    'status': 'syntax_error',
                    'error': str(e),
                    'line': e.lineno,
                    'column': e.offset
                }
            except Exception as e:
                results[file_path] = {
                    'status': 'error',
                    'error': str(e)
                }
        
        return results
    
    def _get_critical_patterns(self):
        """é‡è¦ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©"""
        return {
            'slot_hours_multiplication': r'\\* SLOT_HOURS',
            'slot_hours_definition': r'SLOT_HOURS\\s*=\\s*0\\.5',
            'parsed_slots_count': r'parsed_slots_count',
            'dash_callback': r'@app\\.callback',
            'import_statements': r'^import\\s+\\w+',
            'class_definitions': r'^class\\s+\\w+',
            'function_definitions': r'^def\\s+\\w+'
        }
    
    def _analyze_existing_mobile_implementation(self):
        """æ—¢å­˜ãƒ¢ãƒã‚¤ãƒ«å®Ÿè£…ã®åˆ†æ"""
        mobile_files = [
            "dash_app.py",
            "dash_components/visualization_engine.py",
            "improved_ui_components.py"
        ]
        
        analysis = {}
        
        for file_path in mobile_files:
            full_path = os.path.join(self.base_path, file_path)
            
            if not os.path.exists(full_path):
                analysis[file_path] = {'status': 'not_found'}
                continue
            
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ãƒ¢ãƒã‚¤ãƒ«é–¢é€£æ©Ÿèƒ½ã®æ¤œå‡º
                mobile_features = {
                    'responsive_breakpoints': len(re.findall(r'mobile.*768|768.*mobile', content, re.IGNORECASE)),
                    'viewport_meta': len(re.findall(r'viewport.*width=device-width', content)),
                    'media_queries': len(re.findall(r'@media.*max-width|@media.*min-width', content)),
                    'mobile_classes': len(re.findall(r'mobile-\\w+', content)),
                    'responsive_functions': len(re.findall(r'responsive.*function|create_responsive', content)),
                    'device_detection': len(re.findall(r'device.*type|viewport.*width', content))
                }
                
                analysis[file_path] = {
                    'status': 'analyzed',
                    'file_size': len(content),
                    'mobile_features': mobile_features,
                    'mobile_readiness': sum(mobile_features.values()) > 0
                }
                
            except Exception as e:
                analysis[file_path] = {
                    'status': 'error',
                    'error': str(e)
                }
        
        return analysis
    
    def _analyze_dependencies(self):
        """ä¾å­˜é–¢ä¿‚åˆ†æ"""
        analysis = {
            'import_map': {},
            'internal_dependencies': {},
            'external_dependencies': set(),
            'circular_dependencies': []
        }
        
        # ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆåˆ†æ
        for file_path in self.critical_files:
            full_path = os.path.join(self.base_path, file_path)
            
            if not os.path.exists(full_path):
                continue
            
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®æŠ½å‡º
                imports = self._extract_imports(content)
                analysis['import_map'][file_path] = imports
                
                # å†…éƒ¨ä¾å­˜é–¢ä¿‚ã®ç‰¹å®š
                internal_deps = [imp for imp in imports if 'shift_suite' in imp or imp.startswith('.')]
                analysis['internal_dependencies'][file_path] = internal_deps
                
                # å¤–éƒ¨ä¾å­˜é–¢ä¿‚ã®åé›†
                external_deps = [imp for imp in imports if not (imp.startswith('.') or 'shift_suite' in imp)]
                analysis['external_dependencies'].update(external_deps)
                
            except Exception as e:
                analysis['import_map'][file_path] = {'error': str(e)}
        
        # å¤–éƒ¨ä¾å­˜é–¢ä¿‚ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
        analysis['external_dependencies'] = sorted(list(analysis['external_dependencies']))
        
        return analysis
    
    def _extract_imports(self, content):
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã®æŠ½å‡º"""
        imports = []
        
        # é€šå¸¸ã®importæ–‡
        import_pattern = r'^\\s*import\\s+([\\w\\.]+)'
        imports.extend(re.findall(import_pattern, content, re.MULTILINE))
        
        # from importæ–‡
        from_pattern = r'^\\s*from\\s+([\\w\\.]+)\\s+import'
        imports.extend(re.findall(from_pattern, content, re.MULTILINE))
        
        return imports
    
    def _verify_phase_integration_safety(self):
        """Phase 2/3.1çµ±åˆã®å®‰å…¨æ€§ç¢ºèª"""
        safety_check = {
            'phase2_integration': {},
            'phase31_integration': {},
            'slot_hours_consistency': {},
            'calculation_chain': {}
        }
        
        # Phase 2çµ±åˆç¢ºèª
        phase2_file = os.path.join(self.base_path, "shift_suite/tasks/fact_extractor_prototype.py")
        if os.path.exists(phase2_file):
            with open(phase2_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            safety_check['phase2_integration'] = {
                'file_exists': True,
                'slot_hours_multiplications': len(re.findall(r'\\* SLOT_HOURS', content)),
                'parsed_slots_usage': len(re.findall(r'parsed_slots_count', content)),
                'has_proper_calculation': '* SLOT_HOURS' in content
            }
        
        # Phase 3.1çµ±åˆç¢ºèª
        phase31_file = os.path.join(self.base_path, "shift_suite/tasks/lightweight_anomaly_detector.py")
        if os.path.exists(phase31_file):
            with open(phase31_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            safety_check['phase31_integration'] = {
                'file_exists': True,
                'slot_hours_multiplications': len(re.findall(r'\\* SLOT_HOURS', content)),
                'parsed_slots_usage': len(re.findall(r'parsed_slots_count', content)),
                'has_proper_calculation': '* SLOT_HOURS' in content
            }
        
        return safety_check
    
    def _assess_slot_hours_impact(self):
        """SLOT_HOURSè¨ˆç®—ã¸ã®å½±éŸ¿è©•ä¾¡"""
        impact_assessment = {
            'current_implementation': {},
            'potential_risks': [],
            'mobile_specific_risks': [],
            'calculation_consistency': {}
        }
        
        # ç¾åœ¨ã®å®Ÿè£…çŠ¶æ³ç¢ºèª
        slot_hours_files = []
        for file_path in self.critical_files:
            full_path = os.path.join(self.base_path, file_path)
            if os.path.exists(full_path):
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if 'SLOT_HOURS' in content:
                    slot_hours_files.append({
                        'file': file_path,
                        'slot_hours_count': content.count('SLOT_HOURS'),
                        'multiplication_count': content.count('* SLOT_HOURS'),
                        'definition_present': 'SLOT_HOURS = 0.5' in content
                    })
        
        impact_assessment['current_implementation'] = {
            'affected_files': len(slot_hours_files),
            'files_detail': slot_hours_files
        }
        
        # æ½œåœ¨çš„ãƒªã‚¹ã‚¯ã®è©•ä¾¡
        if len(slot_hours_files) > 0:
            impact_assessment['potential_risks'] = [
                "ãƒ¢ãƒã‚¤ãƒ«ç”¨UIå¤‰æ›´ã«ã‚ˆã‚‹è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯æ„å›³ã—ãªã„å¤‰æ›´",
                "ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–å¯¾å¿œã§ã®ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›´",
                "JavaScript/CSSå¤‰æ›´ã«ã‚ˆã‚‹æ•°å€¤å‡¦ç†ã¸ã®å½±éŸ¿"
            ]
        else:
            impact_assessment['potential_risks'] = ["SLOT_HOURSä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
        
        return impact_assessment
    
    def _perform_risk_assessment(self):
        """ãƒªã‚¹ã‚¯è©•ä¾¡"""
        risks = {
            'critical_risks': [],
            'medium_risks': [],
            'low_risks': [],
            'mitigation_strategies': []
        }
        
        # æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
        syntax_errors = [f for f, result in self.safety_report.get('syntax_check', {}).items() 
                        if result.get('status') == 'syntax_error']
        
        if syntax_errors:
            risks['critical_risks'].append({
                'type': 'syntax_error',
                'description': f'æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {syntax_errors}',
                'impact': 'ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®å‹•ä½œåœæ­¢',
                'priority': 'immediate'
            })
        
        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«æ¬ æãƒã‚§ãƒƒã‚¯
        missing_files = [f for f, result in self.safety_report.get('syntax_check', {}).items() 
                        if result.get('status') == 'missing']
        
        if missing_files:
            risks['critical_risks'].append({
                'type': 'missing_files',
                'description': f'é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¬ æ: {missing_files}',
                'impact': 'æ©Ÿèƒ½åœæ­¢ãƒ»ã‚¨ãƒ©ãƒ¼å¤šç™º',
                'priority': 'immediate'
            })
        
        # ãƒ¢ãƒã‚¤ãƒ«å®Ÿè£…ã®ç«¶åˆãƒªã‚¹ã‚¯
        risks['medium_risks'].append({
            'type': 'mobile_implementation_conflict',
            'description': 'æ—¢å­˜ãƒ¢ãƒã‚¤ãƒ«å®Ÿè£…ã¨ã®ç«¶åˆå¯èƒ½æ€§',
            'impact': 'UI/UXä¸æ•´åˆãƒ»è¡¨ç¤ºã‚¨ãƒ©ãƒ¼',
            'priority': 'high'
        })
        
        # è»½æ¸›æˆ¦ç•¥
        risks['mitigation_strategies'] = [
            "æ®µéšçš„å®Ÿè£…ï¼ˆå°ã•ãªå¤‰æ›´ã‹ã‚‰é–‹å§‹ï¼‰",
            "å„æ®µéšã§ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ",
            "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆãƒ»ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æº–å‚™",
            "æ—¢å­˜æ©Ÿèƒ½ã®å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆå¿…é ˆ",
            "Phase 2/3.1è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ä¿è­·"
        ]
        
        return risks
    
    def _calculate_safety_score(self):
        """å®‰å…¨æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        score = 100
        
        # æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚‹æ¸›ç‚¹
        syntax_check = self.safety_report.get('syntax_check', {})
        for file_result in syntax_check.values():
            if file_result.get('status') == 'syntax_error':
                score -= 30
            elif file_result.get('status') == 'missing':
                score -= 20
            elif file_result.get('status') == 'error':
                score -= 10
        
        # ä¾å­˜é–¢ä¿‚å•é¡Œã«ã‚ˆã‚‹æ¸›ç‚¹
        dependency_issues = len(self.safety_report.get('dependency_analysis', {}).get('circular_dependencies', []))
        score -= dependency_issues * 5
        
        # ãƒªã‚¹ã‚¯è©•ä¾¡ã«ã‚ˆã‚‹æ¸›ç‚¹
        risk_assessment = self.safety_report.get('risk_assessment', {})
        critical_risks = len(risk_assessment.get('critical_risks', []))
        medium_risks = len(risk_assessment.get('medium_risks', []))
        
        score -= critical_risks * 15
        score -= medium_risks * 5
        
        return max(0, score)
    
    def _generate_safety_recommendations(self):
        """å®‰å…¨æ€§æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        # æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆ
        syntax_check = self.safety_report.get('syntax_check', {})
        syntax_errors = [f for f, result in syntax_check.items() if result.get('status') == 'syntax_error']
        
        if syntax_errors:
            recommendations.append({
                'priority': 'critical',
                'action': 'æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ä¿®æ­£',
                'description': f'ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£: {syntax_errors}',
                'before_c2': True
            })
        
        # åŸºæœ¬æ¨å¥¨äº‹é …
        recommendations.extend([
            {
                'priority': 'high',
                'action': 'ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ',
                'description': 'C2å®Ÿè£…å‰ã«ç¾åœ¨ã®å…¨ã‚·ã‚¹ãƒ†ãƒ ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ',
                'before_c2': True
            },
            {
                'priority': 'high', 
                'action': 'æ®µéšçš„å®Ÿè£…',
                'description': 'å°ã•ãªå¤‰æ›´ã‹ã‚‰é–‹å§‹ã—ã€å„æ®µéšã§å‹•ä½œç¢ºèª',
                'before_c2': False
            },
            {
                'priority': 'medium',
                'action': 'æ—¢å­˜ãƒ¢ãƒã‚¤ãƒ«æ©Ÿèƒ½èª¿æŸ»',
                'description': 'ç¾åœ¨ã®ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–æ©Ÿèƒ½ã¨ã®é‡è¤‡ãƒ»ç«¶åˆãƒã‚§ãƒƒã‚¯',
                'before_c2': True
            },
            {
                'priority': 'medium',
                'action': 'Phase 2/3.1ä¿è­·',
                'description': 'SLOT_HOURSè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã®ä¿è­·ãƒ»æ¤œè¨¼',
                'before_c2': False
            },
            {
                'priority': 'low',
                'action': 'åŒ…æ‹¬ãƒ†ã‚¹ãƒˆè¨ˆç”»',
                'description': 'å…¨æ©Ÿèƒ½ã®å›å¸°ãƒ†ã‚¹ãƒˆè¨ˆç”»ç­–å®š',
                'before_c2': True
            }
        ])
        
        return recommendations

def main():
    """å®‰å…¨æ€§åˆ†æãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ›¡ï¸ C2ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£å‘ä¸Š - äº‹å‰å®‰å…¨æ€§åˆ†æé–‹å§‹...")
    
    analyzer = SystemSafetyAnalyzer()
    report = analyzer.analyze_system_safety()
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    report_file = f"C2_safety_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    # çµæœè¡¨ç¤º
    if 'error' in report:
        print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {report['error']}")
        return report
    
    print(f"\\nğŸ“Š åˆ†æå®Œäº† - å®‰å…¨æ€§ã‚¹ã‚³ã‚¢: {report['safety_score']}/100")
    
    # é‡è¦ãªçµæœã®è¡¨ç¤º
    syntax_check = report.get('syntax_check', {})
    syntax_ok = sum(1 for result in syntax_check.values() if result.get('status') == 'ok')
    syntax_total = len(syntax_check)
    
    print(f"ğŸ“‹ æ§‹æ–‡ãƒã‚§ãƒƒã‚¯: {syntax_ok}/{syntax_total} ãƒ•ã‚¡ã‚¤ãƒ«æ­£å¸¸")
    
    # ãƒªã‚¹ã‚¯æ¦‚è¦
    risks = report.get('risk_assessment', {})
    critical_risks = len(risks.get('critical_risks', []))
    medium_risks = len(risks.get('medium_risks', []))
    
    if critical_risks > 0:
        print(f"ğŸš¨ é‡å¤§ãƒªã‚¹ã‚¯: {critical_risks}ä»¶ - C2å®Ÿè£…å‰ã«å¯¾å‡¦å¿…é ˆ")
    if medium_risks > 0:
        print(f"âš ï¸ ä¸­ãƒªã‚¹ã‚¯: {medium_risks}ä»¶ - æ…é‡ãªå®Ÿè£…ãŒå¿…è¦")
    
    # æ¨å¥¨äº‹é …
    recommendations = report.get('recommendations', [])
    before_c2_actions = [r for r in recommendations if r.get('before_c2')]
    
    print(f"\\nğŸ“‹ C2å®Ÿè£…å‰æ¨å¥¨äº‹é …: {len(before_c2_actions)}ä»¶")
    for rec in before_c2_actions[:3]:  # ä¸Šä½3ä»¶è¡¨ç¤º
        print(f"  â€¢ {rec['action']}: {rec['description']}")
    
    print(f"\\nğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
    
    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®æ¨å¥¨
    if report['safety_score'] >= 80:
        print("\\nâœ… å®‰å…¨æ€§è‰¯å¥½ - C2å®Ÿè£…è¨ˆç”»ç­–å®šã«é€²è¡Œå¯èƒ½")
    elif report['safety_score'] >= 60:
        print("\\nâš ï¸ æ³¨æ„è¦ - ãƒªã‚¹ã‚¯è»½æ¸›å¾Œã«C2å®Ÿè£…æ¨å¥¨")
    else:
        print("\\nğŸš¨ å±é™º - é‡å¤§å•é¡Œè§£æ±ºå¾Œã«C2å®Ÿè£…æ¤œè¨")
    
    return report

if __name__ == "__main__":
    result = main()