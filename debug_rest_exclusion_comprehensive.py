#!/usr/bin/env python3
"""
ç·åˆçš„ãªä¼‘æš‡é™¤å¤–ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã®å…¨æ®µéšã§ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ãŒã©ã®ã‚ˆã†ã«æ‰±ã‚ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼
"""

import pandas as pd
import sys
import os
import json
from pathlib import Path

# Add shift_suite to path
sys.path.insert(0, str(Path(__file__).parent))

def debug_excel_rest_data():
    """Excelãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥åˆ†æ"""
    print("=== 1. Excelãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿åˆ†æ ===")
    
    excel_file = "ã‚·ãƒ§ãƒ¼ãƒˆ_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿.xlsx"
    if not os.path.exists(excel_file):
        print(f"âŒ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {excel_file}")
        return None
        
    try:
        # Read the Excel file
        df = pd.read_excel(excel_file)
        print(f"ğŸ“Š Excel shape: {df.shape}")
        print(f"ğŸ“Š Columns: {list(df.columns)}")
        
        # Look for staff-related columns
        staff_columns = [col for col in df.columns if 'ã‚¹ã‚¿ãƒƒãƒ•' in col or 'staff' in col.lower()]
        print(f"ğŸ“Š Staff columns found: {staff_columns}")
        
        if staff_columns:
            staff_col = staff_columns[0]
            unique_values = df[staff_col].value_counts()
            print(f"\nğŸ“Š Unique values in {staff_col}:")
            print(unique_values.head(20))
            
            # Count rest patterns
            rest_patterns = ['Ã—', 'X', 'x', 'ä¼‘', 'ä¼‘ã¿', 'ä¼‘æš‡', 'OFF', 'off', 'Off', '-', 'âˆ’', 'â€•']
            rest_counts = {}
            
            for pattern in rest_patterns:
                if df[staff_col].dtype == 'object':
                    count = df[staff_col].str.contains(pattern, na=False).sum()
                else:
                    count = (df[staff_col] == pattern).sum()
                    
                if count > 0:
                    rest_counts[pattern] = count
                    
            print(f"\nâœ… ä¼‘æš‡ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºçµæœ: {rest_counts}")
            return df, staff_col, rest_counts
        else:
            print("âŒ ã‚¹ã‚¿ãƒƒãƒ•é–¢é€£ã®åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
            
    except Exception as e:
        print(f"âŒ Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def debug_intermediate_data():
    """intermediate_data.parquetã®ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ"""
    print("\n=== 2. intermediate_data.parquetåˆ†æ ===")
    
    # Check in current directory and temp directories
    possible_paths = [
        "analysis_results/out_p25_based/intermediate_data.parquet",
        "temp_analysis_results/out_p25_based/intermediate_data.parquet",
        "analysis_results_20/out_p25_based/intermediate_data.parquet",
        "/tmp/tmpdl5z1z7n/motogi_short/out_p25_based/intermediate_data.parquet"
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            print(f"ğŸ“‚ Found intermediate_data at: {path}")
            try:
                df = pd.read_parquet(path)
                print(f"ğŸ“Š Shape: {df.shape}")
                print(f"ğŸ“Š Columns: {list(df.columns)}")
                
                if 'staff' in df.columns:
                    print(f"ğŸ“Š Unique staff count: {df['staff'].nunique()}")
                    
                    # Check for rest patterns in staff names
                    rest_patterns = ['Ã—', 'X', 'x', 'ä¼‘', 'ä¼‘ã¿', 'ä¼‘æš‡', 'OFF', 'off', 'Off', '-', 'âˆ’', 'â€•']
                    rest_in_staff = {}
                    
                    for pattern in rest_patterns:
                        count = df['staff'].str.contains(pattern, na=False).sum()
                        if count > 0:
                            rest_in_staff[pattern] = count
                            
                    print(f"âœ… intermediate_dataå†…ã®ä¼‘æš‡ãƒ‘ã‚¿ãƒ¼ãƒ³: {rest_in_staff}")
                
                if 'parsed_slots_count' in df.columns:
                    zero_slots = (df['parsed_slots_count'] == 0).sum()
                    print(f"ğŸ“Š parsed_slots_count=0ã®ãƒ¬ã‚³ãƒ¼ãƒ‰: {zero_slots}")
                    
                    if zero_slots > 0:
                        print(f"ğŸ“Š Zero slots sample:")
                        zero_sample = df[df['parsed_slots_count'] == 0][['staff', 'parsed_slots_count']].head(10)
                        print(zero_sample)
                
                return df
                
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print(f"âš ï¸ Not found: {path}")
    
    print("âŒ intermediate_data.parquet ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return None

def debug_pre_aggregated_data():
    """pre_aggregated_data.parquetã®ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ"""
    print("\n=== 3. pre_aggregated_data.parquetåˆ†æ ===")
    
    possible_paths = [
        "analysis_results/out_p25_based/pre_aggregated_data.parquet",
        "temp_analysis_results/out_p25_based/pre_aggregated_data.parquet",
        "analysis_results_20/out_p25_based/pre_aggregated_data.parquet",
        "/tmp/tmpdl5z1z7n/motogi_short/out_p25_based/pre_aggregated_data.parquet"
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            print(f"ğŸ“‚ Found pre_aggregated_data at: {path}")
            try:
                df = pd.read_parquet(path)
                print(f"ğŸ“Š Shape: {df.shape}")
                print(f"ğŸ“Š Columns: {list(df.columns)}")
                
                if 'staff_count' in df.columns:
                    print(f"ğŸ“Š staff_count stats: min={df['staff_count'].min()}, max={df['staff_count'].max()}")
                    print(f"ğŸ“Š Zero staff_count records: {(df['staff_count'] == 0).sum()}")
                
                print(f"ğŸ“Š Sample data:")
                print(df.head(3))
                
                return df
                
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print(f"âš ï¸ Not found: {path}")
    
    print("âŒ pre_aggregated_data.parquet ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return None

def test_rest_exclusion_filter():
    """ç¾åœ¨ã®ä¼‘æš‡é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n=== 4. ä¼‘æš‡é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ãƒ†ã‚¹ãƒˆ ===")
    
    # Create test data with rest patterns
    test_data = pd.DataFrame({
        'staff': ['ç”°ä¸­å¤ªéƒ', 'Ã—', 'ä¼‘ã¿', 'OFF', 'ä½è—¤èŠ±å­', 'å±±ç”°æ¬¡éƒ', 'ä¼‘', 'x', 'æ­£ç¤¾å“¡A'],
        'parsed_slots_count': [8, 0, 0, 0, 6, 4, 0, 0, 8],
        'role': ['ä»‹è­·', 'ä»‹è­·', 'ä»‹è­·', 'çœ‹è­·å¸«', 'çœ‹è­·å¸«', 'ä»‹è­·', 'ä»‹è­·', 'ä»‹è­·', 'ä»‹è­·'],
        'date_lbl': ['2025-06-01'] * 9,
        'time': ['09:00'] * 9
    })
    
    print("ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿:")
    print(test_data)
    
    # Import the filter function
    try:
        sys.path.append('.')
        from dash_app import create_enhanced_rest_exclusion_filter
        
        print("\nğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å‰:")
        print(f"ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(test_data)}")
        
        filtered_data = create_enhanced_rest_exclusion_filter(test_data)
        
        print("\nâœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œ:")
        print(f"ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(filtered_data)}")
        print("æ®‹å­˜ãƒ‡ãƒ¼ã‚¿:")
        print(filtered_data[['staff', 'parsed_slots_count', 'role']])
        
        return filtered_data
        
    except Exception as e:
        print(f"âŒ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def analyze_data_flow():
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã®å…¨ä½“çš„ãªåˆ†æ"""
    print("\n=== 5. ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼åˆ†æã‚µãƒãƒªãƒ¼ ===")
    
    excel_result = debug_excel_rest_data()
    intermediate_result = debug_intermediate_data()
    pre_agg_result = debug_pre_aggregated_data()
    filter_result = test_rest_exclusion_filter()
    
    print("\nğŸ¯ çµè«–:")
    
    if excel_result:
        _, _, rest_counts = excel_result
        if rest_counts:
            print(f"âœ… 1. Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡º: {sum(rest_counts.values())}ä»¶")
        else:
            print("âš ï¸ 1. Excelãƒ•ã‚¡ã‚¤ãƒ«ã§ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    else:
        print("âŒ 1. Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—")
    
    if intermediate_result is not None:
        print("âœ… 2. intermediate_dataã®èª­ã¿è¾¼ã¿æˆåŠŸ")
    else:
        print("âŒ 2. intermediate_dataãŒè¦‹ã¤ã‹ã‚‰ãªã„")
    
    if pre_agg_result is not None:
        print("âœ… 3. pre_aggregated_dataã®èª­ã¿è¾¼ã¿æˆåŠŸ")
    else:
        print("âŒ 3. pre_aggregated_dataãŒè¦‹ã¤ã‹ã‚‰ãªã„")
    
    if filter_result is not None:
        print("âœ… 4. ä¼‘æš‡é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯å‹•ä½œã—ã¦ã„ã‚‹")
    else:
        print("âŒ 4. ä¼‘æš‡é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«å•é¡Œã‚ã‚Š")

def main():
    print("ğŸš€ ç·åˆçš„ãªä¼‘æš‡é™¤å¤–ãƒ‡ãƒãƒƒã‚°ã‚’é–‹å§‹ã—ã¾ã™\n")
    print("=" * 60)
    
    analyze_data_flow()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ æ¨å¥¨ã•ã‚Œã‚‹ä¿®æ­£ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
    print("1. io_excel.pyã§Excelèª­ã¿è¾¼ã¿æ™‚ã«ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–")
    print("2. ãƒ‡ãƒ¼ã‚¿åˆ†è§£å‡¦ç†ã§ä¸€è²«ã—ãŸä¼‘æš‡é™¤å¤–ãƒ­ã‚¸ãƒƒã‚¯ã‚’é©ç”¨")
    print("3. åˆ†æå‡¦ç†å‰ã«å¿…ãšä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°")
    print("4. é›†è¨ˆå‡¦ç†ã§ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ãŒæ··å…¥ã—ãªã„ã‚ˆã†ç¢ºèª")
    print("5. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§äºŒé‡ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’é¿ã‘ã‚‹")

if __name__ == "__main__":
    main()