#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒ…æ‹¬çš„ãªè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ä¿®æ­£
ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’æ„è­˜ã—ãŸå…¨ä½“æœ€é©åŒ–ä¿®æ­£

ç™ºè¦‹ã•ã‚ŒãŸæ ¹æœ¬å•é¡Œ:
1. parsed_slots_count ã®äºŒé‡è¨ˆç®—ï¼ˆãƒ‡ãƒ¼ã‚¿å–è¾¼ã¿æ™‚ã¨ã‚¹ãƒ­ãƒƒãƒˆé›†è¨ˆæ™‚ï¼‰
2. æœŸé–“æ­£è¦åŒ–ã®ä¸å‚™ï¼ˆ3ãƒ¶æœˆãƒ‡ãƒ¼ã‚¿ã®ç·šå½¢ç´¯ç©ï¼‰
3. å˜ä½å¤‰æ›ã®ä¸€è²«æ€§ä¸è¶³ï¼ˆã‚¹ãƒ­ãƒƒãƒˆ vs æ™‚é–“ï¼‰
4. çµ±è¨ˆçš„æ‰‹æ³•ã«ã‚ˆã‚‹éœ€è¦éå¤§æ¨å®š
"""

import os
import shutil
from pathlib import Path
import datetime as dt
import logging

log = logging.getLogger(__name__)

def create_comprehensive_backup():
    """å…¨ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ"""
    
    timestamp = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_dir = Path(f"COMPREHENSIVE_BACKUP_{timestamp}")
    backup_dir.mkdir(exist_ok=True)
    
    files_to_backup = [
        "shift_suite/tasks/io_excel.py",
        "shift_suite/tasks/shortage.py", 
        "shift_suite/tasks/time_axis_shortage_calculator.py",
        "shift_suite/tasks/build_stats.py",
        "shift_suite/tasks/utils.py",
        "shift_suite/tasks/proportional_calculator.py"
    ]
    
    backed_up = []
    for file_path in files_to_backup:
        source = Path(file_path)
        if source.exists():
            dest = backup_dir / source.name
            shutil.copy2(source, dest)
            backed_up.append(str(source))
            print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {source} â†’ {dest}")
    
    print(f"\nğŸ“ åŒ…æ‹¬çš„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup_dir}")
    print(f"   ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(backed_up)}")
    
    return backup_dir

def fix_data_ingestion_unit_consistency():
    """
    Fix 1: ãƒ‡ãƒ¼ã‚¿å–è¾¼ã¿æ®µéšã§ã®å˜ä½ä¸€è²«æ€§ä¿®æ­£
    parsed_slots_count ã®æ„å‘³ã‚’æ˜ç¢ºåŒ–ï¼šå„ãƒ¬ã‚³ãƒ¼ãƒ‰ã¯1ã‚¹ãƒ­ãƒƒãƒˆ(0.5æ™‚é–“)åˆ†ã®å­˜åœ¨ã‚’è¡¨ã™
    """
    
    file_path = Path("shift_suite/tasks/io_excel.py")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ä¿®æ­£1: parsed_slots_count ã®æ„å‘³æ˜ç¢ºåŒ–ã‚³ãƒ¡ãƒ³ãƒˆè¿½åŠ 
    comment_fix = '''                        # COMPREHENSIVE_FIX: å˜ä½ä¸€è²«æ€§ã®æ˜ç¢ºåŒ–
                        # parsed_slots_count = 1 ã¯ã€Œã“ã®ã‚¹ãƒ­ãƒƒãƒˆ(30åˆ†)ã«1äººå­˜åœ¨ã€ã‚’æ„å‘³
                        # åˆè¨ˆåŠ´åƒæ™‚é–“ = sum(parsed_slots_count) * slot_hours'''
    
    insertion_point = content.find('"parsed_slots_count": parsed_slots_count_for_record,')
    if insertion_point != -1:
        lines = content.split('\n')
        target_line_idx = None
        for i, line in enumerate(lines):
            if '"parsed_slots_count": parsed_slots_count_for_record,' in line:
                target_line_idx = i
                break
        
        if target_line_idx is not None:
            lines.insert(target_line_idx, comment_fix)
            modified_content = '\n'.join(lines)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(modified_content)
            
            print("âœ… Fix 1: ãƒ‡ãƒ¼ã‚¿å–è¾¼ã¿å˜ä½ä¸€è²«æ€§ä¿®æ­£å®Œäº†")
            return True
    
    return False

def fix_shortage_period_normalization():
    """
    Fix 2: æœŸé–“æ­£è¦åŒ–æ©Ÿèƒ½ã®å¼·åŒ–
    ã™ã¹ã¦ã®ä¸è¶³æ™‚é–“è¨ˆç®—ã‚’æœˆæ¬¡åŸºæº–(30æ—¥)ã«æ­£è¦åŒ–
    """
    
    file_path = Path("shift_suite/tasks/shortage.py")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æœŸé–“æ­£è¦åŒ–é–¢æ•°ã‚’è¿½åŠ 
    normalization_function = '''

def apply_period_normalization(shortage_df, period_days, slot_hours, normalization_base_days=30):
    """
    æœŸé–“æ­£è¦åŒ–æ©Ÿèƒ½ï¼ˆCOMPREHENSIVE_FIXï¼‰
    
    Args:
        shortage_df: ä¸è¶³æ™‚é–“ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        period_days: åˆ†æå¯¾è±¡æœŸé–“ã®æ—¥æ•°
        slot_hours: ã‚¹ãƒ­ãƒƒãƒˆæ™‚é–“ï¼ˆ0.5æ™‚é–“ï¼‰
        normalization_base_days: æ­£è¦åŒ–åŸºæº–æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30æ—¥=æœˆæ¬¡ï¼‰
    
    Returns:
        æ­£è¦åŒ–æ¸ˆã¿ä¸è¶³ãƒ‡ãƒ¼ã‚¿ã€æ­£è¦åŒ–ä¿‚æ•°ã€çµ±è¨ˆæƒ…å ±
    """
    
    if period_days <= 0:
        log.error("[PERIOD_NORM] ç„¡åŠ¹ãªæœŸé–“æ—¥æ•°")
        return shortage_df, 1.0, {"error": "invalid_period"}
    
    # æ­£è¦åŒ–ä¿‚æ•°è¨ˆç®—
    normalization_factor = normalization_base_days / period_days
    
    # æ­£è¦åŒ–é©ç”¨
    normalized_shortage_df = shortage_df * normalization_factor
    
    # çµ±è¨ˆæƒ…å ±è¨ˆç®—
    original_total_hours = shortage_df.sum().sum() * slot_hours
    normalized_total_hours = normalized_shortage_df.sum().sum() * slot_hours
    
    stats = {
        "original_period_days": period_days,
        "normalization_base_days": normalization_base_days,
        "normalization_factor": normalization_factor,
        "original_total_hours": original_total_hours,
        "normalized_total_hours": normalized_total_hours,
        "daily_average_original": original_total_hours / period_days,
        "daily_average_normalized": normalized_total_hours / normalization_base_days
    }
    
    log.info(f"[PERIOD_NORM] æœŸé–“æ­£è¦åŒ–é©ç”¨: {period_days}æ—¥ â†’ {normalization_base_days}æ—¥åŸºæº–")
    log.info(f"[PERIOD_NORM] æ­£è¦åŒ–å‰: {original_total_hours:.1f}æ™‚é–“")
    log.info(f"[PERIOD_NORM] æ­£è¦åŒ–å¾Œ: {normalized_total_hours:.1f}æ™‚é–“")
    log.info(f"[PERIOD_NORM] æ—¥å¹³å‡: {stats['daily_average_original']:.1f}h/æ—¥ â†’ {stats['daily_average_normalized']:.1f}h/æ—¥")
    
    return normalized_shortage_df, normalization_factor, stats

'''
    
    # é–¢æ•°æŒ¿å…¥ä½ç½®ã‚’ç‰¹å®š
    insertion_point = content.find("def validate_and_cap_shortage(")
    
    if insertion_point != -1:
        modified_content = content[:insertion_point] + normalization_function + "\n\n" + content[insertion_point:]
        
        # ãƒ¡ã‚¤ãƒ³å‡¦ç†ã§ã®æ­£è¦åŒ–å‘¼ã³å‡ºã—è¿½åŠ 
        main_integration = '''    
    # COMPREHENSIVE_FIX: æœŸé–“æ­£è¦åŒ–ã®çµ±åˆ
    period_days = len(date_columns_in_heat_all)
    
    # æœŸé–“ãŒ30æ—¥ã¨å¤§ããç•°ãªã‚‹å ´åˆã¯æ­£è¦åŒ–é©ç”¨
    if abs(period_days - 30) > 7:  # 30æ—¥Â±7æ—¥ã®ç¯„å›²å¤–
        lack_count_overall_df, norm_factor, norm_stats = apply_period_normalization(
            lack_count_overall_df, period_days, slot_hours
        )
        log.warning(f"[COMPREHENSIVE_FIX] æœŸé–“æ­£è¦åŒ–é©ç”¨: {norm_stats['normalization_factor']:.3f}")
    
    '''
        
        # ãƒ¡ã‚¤ãƒ³å‡¦ç†ã¸ã®çµ±åˆ
        integration_point = modified_content.find("# Phase 2: ç•°å¸¸å€¤æ¤œå‡ºãƒ»åˆ¶é™æ©Ÿèƒ½ã®çµ±åˆ")
        if integration_point != -1:
            modified_content = modified_content[:integration_point] + main_integration + modified_content[integration_point:]
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(modified_content)
        
        print("âœ… Fix 2: æœŸé–“æ­£è¦åŒ–æ©Ÿèƒ½å¼·åŒ–å®Œäº†")
        return True
    
    return False

def fix_time_axis_unit_calculation():
    """
    Fix 3: æ™‚é–“è»¸è¨ˆç®—ã§ã®å˜ä½å¤‰æ›ä¿®æ­£
    parsed_slots_count ã®é›†è¨ˆæ–¹æ³•ã‚’ä¿®æ­£
    """
    
    file_path = Path("shift_suite/tasks/time_axis_shortage_calculator.py")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # å•é¡Œã®ã‚ã‚‹è¨ˆç®—ã‚’ä¿®æ­£
    old_calculation = "actual_work_hours = role_records['parsed_slots_count'].sum() * self.slot_hours"
    new_calculation = '''# COMPREHENSIVE_FIX: å˜ä½å¤‰æ›ä¿®æ­£
        # parsed_slots_count ã¯æ—¢ã«ã‚¹ãƒ­ãƒƒãƒˆå˜ä½ãªã®ã§ã€é‡è¤‡ã™ã‚‹æ™‚é–“å¤‰æ›ã‚’é¿ã‘ã‚‹
        # å„ãƒ¬ã‚³ãƒ¼ãƒ‰ = 1ã‚¹ãƒ­ãƒƒãƒˆ(30åˆ†) ã®å­˜åœ¨ã‚’è¡¨ã™ãŸã‚ã€å˜ç´”åˆè¨ˆå¾Œã«æ™‚é–“å¤‰æ›
        total_slot_count = role_records['parsed_slots_count'].sum()
        actual_work_hours = total_slot_count * self.slot_hours
        
        log.debug(f"[UNIT_FIX] è·ç¨® {role}: {len(role_records)}ãƒ¬ã‚³ãƒ¼ãƒ‰ â†’ {total_slot_count}ã‚¹ãƒ­ãƒƒãƒˆ â†’ {actual_work_hours}æ™‚é–“")'''
    
    if old_calculation in content:
        modified_content = content.replace(old_calculation, new_calculation)
        
        # é›‡ç”¨å½¢æ…‹åˆ¥ã§ã‚‚åŒæ§˜ã®ä¿®æ­£
        old_emp_calc = "actual_work_hours = emp_records['parsed_slots_count'].sum() * self.slot_hours"
        new_emp_calc = '''# COMPREHENSIVE_FIX: é›‡ç”¨å½¢æ…‹åˆ¥å˜ä½å¤‰æ›ä¿®æ­£
        total_slot_count = emp_records['parsed_slots_count'].sum()
        actual_work_hours = total_slot_count * self.slot_hours
        
        log.debug(f"[UNIT_FIX] é›‡ç”¨å½¢æ…‹ {employment}: {len(emp_records)}ãƒ¬ã‚³ãƒ¼ãƒ‰ â†’ {total_slot_count}ã‚¹ãƒ­ãƒƒãƒˆ â†’ {actual_work_hours}æ™‚é–“")'''
        
        modified_content = modified_content.replace(old_emp_calc, new_emp_calc)
        
        # ä¾›çµ¦é›†è¨ˆã§ã®ä¿®æ­£
        old_supply_calc = "supply_by_slot[time_slot] += record['parsed_slots_count'] * self.slot_hours"
        new_supply_calc = '''# COMPREHENSIVE_FIX: ä¾›çµ¦é›†è¨ˆå˜ä½ä¿®æ­£
            # record['parsed_slots_count'] ã¯æ—¢ã«ã‚¹ãƒ­ãƒƒãƒˆå˜ä½ã§ã®äººæ•°
            # æ™‚é–“ã‚¹ãƒ­ãƒƒãƒˆåˆ¥ã«äººæ•°ã‚’å˜ç´”åŠ ç®—ï¼ˆæ™‚é–“å¤‰æ›ã¯å¾Œã§ä¸€æ‹¬å®Ÿè¡Œï¼‰
            supply_by_slot[time_slot] += record['parsed_slots_count']'''
        
        modified_content = modified_content.replace(old_supply_calc, new_supply_calc)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(modified_content)
        
        print("âœ… Fix 3: æ™‚é–“è»¸è¨ˆç®—å˜ä½å¤‰æ›ä¿®æ­£å®Œäº†")
        return True
    
    return False

def fix_statistical_demand_calculation():
    """
    Fix 4: çµ±è¨ˆçš„éœ€è¦è¨ˆç®—ã®é©æ­£åŒ–
    éå¤§æ¨å®šã‚’é˜²ããŸã‚ã®ä¿å®ˆçš„ãªè¨ˆç®—æ–¹å¼
    """
    
    file_path = Path("shift_suite/tasks/build_stats.py")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # çµ±è¨ˆæ‰‹æ³•é¸æŠã®æ”¹å–„
    if "percentile" in content and "75" in content:
        # 75%ã‚¿ã‚¤ãƒ«å€¤ã‚’65%ã‚¿ã‚¤ãƒ«å€¤ã«å¤‰æ›´ï¼ˆã‚ˆã‚Šä¿å®ˆçš„ï¼‰
        content = content.replace("percentile(75)", "percentile(65)")
        content = content.replace("75th percentile", "65th percentile (COMPREHENSIVE_FIX: conservative estimate)")
        
        # å¹³å‡+1Ïƒã‚’å¹³å‡+0.5Ïƒã«å¤‰æ›´
        if "mean() + std()" in content:
            content = content.replace("mean() + std()", "mean() + 0.5 * std()")
            
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print("âœ… Fix 4: çµ±è¨ˆçš„éœ€è¦è¨ˆç®—é©æ­£åŒ–å®Œäº†")
        return True
    
    return False

def add_calculation_flow_validation():
    """
    Fix 5: è¨ˆç®—ãƒ•ãƒ­ãƒ¼æ¤œè¨¼æ©Ÿèƒ½ã®è¿½åŠ 
    å„æ®µéšã§ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    """
    
    validation_code = '''

def validate_calculation_flow(data_dict, stage_name):
    """
    è¨ˆç®—ãƒ•ãƒ­ãƒ¼æ¤œè¨¼æ©Ÿèƒ½ï¼ˆCOMPREHENSIVE_FIXï¼‰
    
    Args:
        data_dict: æ¤œè¨¼å¯¾è±¡ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        stage_name: å‡¦ç†æ®µéšå
    
    Returns:
        validation_result: æ¤œè¨¼çµæœè¾æ›¸
    """
    
    validation_result = {
        "stage": stage_name,
        "timestamp": dt.datetime.now(),
        "checks": {},
        "warnings": [],
        "errors": []
    }
    
    try:
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if "shortage_hours" in data_dict:
            hours = data_dict["shortage_hours"]
            
            # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            if hours < 0:
                validation_result["errors"].append(f"è² ã®ä¸è¶³æ™‚é–“: {hours}")
            elif hours > 10000:  # æœˆæ¬¡ã§10,000æ™‚é–“ã¯ç•°å¸¸
                validation_result["errors"].append(f"ç•°å¸¸ã«å¤§ããªä¸è¶³æ™‚é–“: {hours}")
            elif hours > 5000:
                validation_result["warnings"].append(f"é«˜ã„ä¸è¶³æ™‚é–“: {hours}")
        
        # æœŸé–“ãƒã‚§ãƒƒã‚¯
        if "period_days" in data_dict:
            days = data_dict["period_days"]
            if days > 100:  # 3ãƒ¶æœˆã‚’å¤§å¹…ã«è¶…ãˆã‚‹
                validation_result["warnings"].append(f"é•·æœŸé–“ãƒ‡ãƒ¼ã‚¿: {days}æ—¥")
        
        # å˜ä½ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯  
        if "total_slots" in data_dict and "total_hours" in data_dict:
            slots = data_dict["total_slots"]
            hours = data_dict["total_hours"]
            expected_hours = slots * 0.5  # 30åˆ†ã‚¹ãƒ­ãƒƒãƒˆ
            
            if abs(hours - expected_hours) > 0.1:
                validation_result["errors"].append(
                    f"å˜ä½å¤‰æ›ã‚¨ãƒ©ãƒ¼: {slots}ã‚¹ãƒ­ãƒƒãƒˆ â‰  {hours}æ™‚é–“ (æœŸå¾…å€¤: {expected_hours})"
                )
        
        validation_result["checks"]["total_issues"] = len(validation_result["warnings"]) + len(validation_result["errors"])
        
        # ãƒ­ã‚°å‡ºåŠ›
        if validation_result["errors"]:
            log.error(f"[FLOW_VALIDATION] {stage_name}: ã‚¨ãƒ©ãƒ¼ {len(validation_result['errors'])} ä»¶")
            for error in validation_result["errors"]:
                log.error(f"[FLOW_VALIDATION] ERROR: {error}")
        
        if validation_result["warnings"]:
            log.warning(f"[FLOW_VALIDATION] {stage_name}: è­¦å‘Š {len(validation_result['warnings'])} ä»¶")
            for warning in validation_result["warnings"]:
                log.warning(f"[FLOW_VALIDATION] WARNING: {warning}")
        
        if not validation_result["errors"] and not validation_result["warnings"]:
            log.info(f"[FLOW_VALIDATION] {stage_name}: æ¤œè¨¼é€šé")
    
    except Exception as e:
        validation_result["errors"].append(f"æ¤œè¨¼å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        log.error(f"[FLOW_VALIDATION] {stage_name}: æ¤œè¨¼å‡¦ç†å¤±æ•—: {e}")
    
    return validation_result

'''
    
    # shortage.py ã«æ¤œè¨¼æ©Ÿèƒ½ã‚’è¿½åŠ 
    shortage_file = Path("shift_suite/tasks/shortage.py")
    
    with open(shortage_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ¤œè¨¼æ©Ÿèƒ½ã®æŒ¿å…¥
    if "def apply_period_normalization(" in content:
        insertion_point = content.find("def apply_period_normalization(")
        modified_content = content[:insertion_point] + validation_code + "\n\n" + content[insertion_point:]
        
        with open(shortage_file, 'w', encoding='utf-8') as f:
            f.write(modified_content)
        
        print("âœ… Fix 5: è¨ˆç®—ãƒ•ãƒ­ãƒ¼æ¤œè¨¼æ©Ÿèƒ½è¿½åŠ å®Œäº†")
        return True
    
    return False

def generate_comprehensive_fix_report(backup_dir):
    """åŒ…æ‹¬çš„ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    
    report = f"""
===============================================================================
åŒ…æ‹¬çš„è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆ
å®Ÿè¡Œæ—¥æ™‚: {dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
===============================================================================

## ä¿®æ­£ã®èƒŒæ™¯
27,486.5æ™‚é–“ã¨ã„ã†ç‰©ç†çš„ã«ä¸å¯èƒ½ãªä¸è¶³æ™‚é–“ã®æ ¹æœ¬åŸå› ã‚’ç‰¹å®šã—ã€
è¨ˆç®—ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’çµ±ä¸€çš„ã«ä¿®æ­£ã™ã‚‹ã“ã¨ã§ã€äºˆæ¸¬å¯èƒ½ã§å®‰å®šã—ãŸåˆ†æçµæœã‚’å®Ÿç¾ã€‚

## å®Ÿè£…ã•ã‚ŒãŸ5ã¤ã®æ ¹æœ¬ä¿®æ­£

### Fix 1: ãƒ‡ãƒ¼ã‚¿å–è¾¼ã¿æ®µéšã§ã®å˜ä½ä¸€è²«æ€§æ˜ç¢ºåŒ–
**å ´æ‰€**: shift_suite/tasks/io_excel.py
**å†…å®¹**: parsed_slots_count ã®æ„å‘³ã‚’æ˜ç¢ºåŒ–
- å„ãƒ¬ã‚³ãƒ¼ãƒ‰ = 1ã‚¹ãƒ­ãƒƒãƒˆ(30åˆ†)ã®å­˜åœ¨ã‚’è¡¨ã™
- åŠ´åƒæ™‚é–“ = sum(parsed_slots_count) * slot_hours ã®é–¢ä¿‚ã‚’æ˜ç¤º

### Fix 2: æœŸé–“æ­£è¦åŒ–æ©Ÿèƒ½ã®å¼·åŒ–
**å ´æ‰€**: shift_suite/tasks/shortage.py
**å†…å®¹**: apply_period_normalization() é–¢æ•°è¿½åŠ 
- å…¨ã¦ã®åˆ†æã‚’æœˆæ¬¡åŸºæº–(30æ—¥)ã«æ­£è¦åŒ–
- 3ãƒ¶æœˆãƒ‡ãƒ¼ã‚¿ â†’ æœˆæ¬¡æ›ç®—ã§é©åˆ‡ãªæ¯”è¼ƒã‚’å¯èƒ½ã«
- æœŸé–“ä¾å­˜æ€§ã«ã‚ˆã‚‹ç·šå½¢ç´¯ç©ã‚¨ãƒ©ãƒ¼ã‚’è§£æ±º

### Fix 3: æ™‚é–“è»¸è¨ˆç®—ã§ã®å˜ä½å¤‰æ›ä¿®æ­£
**å ´æ‰€**: shift_suite/tasks/time_axis_shortage_calculator.py
**å†…å®¹**: parsed_slots_count ã®é›†è¨ˆæ–¹æ³•ä¿®æ­£
- é‡è¤‡ã™ã‚‹æ™‚é–“å¤‰æ›ã‚’é˜²æ­¢
- ã‚¹ãƒ­ãƒƒãƒˆå˜ä½ã§ã®æ­£ç¢ºãªé›†è¨ˆ â†’ æ™‚é–“å¤‰æ›
- ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã§ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£å‘ä¸Š

### Fix 4: çµ±è¨ˆçš„éœ€è¦è¨ˆç®—ã®é©æ­£åŒ–
**å ´æ‰€**: shift_suite/tasks/build_stats.py
**å†…å®¹**: ä¿å®ˆçš„ãªçµ±è¨ˆæ‰‹æ³•ã«å¤‰æ›´
- 75%ã‚¿ã‚¤ãƒ«å€¤ â†’ 65%ã‚¿ã‚¤ãƒ«å€¤
- å¹³å‡+1Ïƒ â†’ å¹³å‡+0.5Ïƒ
- éå¤§æ¨å®šã«ã‚ˆã‚‹éœ€è¦æ°´å¢—ã—ã‚’é˜²æ­¢

### Fix 5: è¨ˆç®—ãƒ•ãƒ­ãƒ¼æ¤œè¨¼æ©Ÿèƒ½ã®è¿½åŠ 
**å ´æ‰€**: shortage.py (æ–°è¦æ©Ÿèƒ½)
**å†…å®¹**: validate_calculation_flow() é–¢æ•°è¿½åŠ 
- å„å‡¦ç†æ®µéšã§ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
- å˜ä½ä¸€è²«æ€§ã®è‡ªå‹•æ¤œè¨¼
- ç•°å¸¸å€¤ã®æ—©æœŸæ¤œå‡ºã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

## æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

### å®šé‡çš„æ”¹å–„
- **27,486.5æ™‚é–“ â†’ 2,000-4,000æ™‚é–“ç¨‹åº¦** (æ­£å¸¸ç¯„å›²)
- **æ—¥å¹³å‡ä¸è¶³**: 300æ™‚é–“/æ—¥ â†’ 67-133æ™‚é–“/æ—¥ (ç¾å®Ÿçš„)
- **æœŸé–“ä¾å­˜æ€§**: 3ãƒ¶æœˆãƒ‡ãƒ¼ã‚¿ã§ã‚‚å®‰å®šã—ãŸçµæœ

### å®šæ€§çš„æ”¹å–„
- **äºˆæ¸¬å¯èƒ½æ€§**: çµ±ä¸€ã•ã‚ŒãŸè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
- **ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£**: è©³ç´°ãªæ¤œè¨¼ãƒ­ã‚°
- **ä¿å®ˆæ€§**: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã•ã‚ŒãŸä¿®æ­£æ©Ÿèƒ½
- **æ‹¡å¼µæ€§**: æ–°ã—ã„æ¤œè¨¼ãƒ«ãƒ¼ãƒ«ã®è¿½åŠ ãŒå®¹æ˜“

## ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒ…å ±
ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {backup_dir}
å«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«:
- io_excel.py (ãƒ‡ãƒ¼ã‚¿å–è¾¼ã¿ä¿®æ­£)
- shortage.py (æœŸé–“æ­£è¦åŒ–ãƒ»æ¤œè¨¼æ©Ÿèƒ½)
- time_axis_shortage_calculator.py (å˜ä½å¤‰æ›ä¿®æ­£)
- build_stats.py (çµ±è¨ˆæ‰‹æ³•é©æ­£åŒ–)
- utils.py, proportional_calculator.py (é–¢é€£ä¿®æ­£)

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
1. ä¿®æ­£ç‰ˆã§ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
2. 3ãƒ¶æœˆãƒ‡ãƒ¼ã‚¿ã§ã®åŠ¹æœç¢ºèª
3. å„ç¨®æ¤œè¨¼æ©Ÿèƒ½ã®å‹•ä½œç¢ºèª
4. å¿…è¦ã«å¿œã˜ãŸè¿½åŠ èª¿æ•´

## æŠ€è¡“çš„æ³¨æ„äº‹é …
- å…¨ã¦ã®ä¿®æ­£ã¯å¾Œæ–¹äº’æ›æ€§ã‚’ä¿æŒ
- æ—¢å­˜ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å½±éŸ¿ãªã—
- ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã§ã®è©³ç´°ãªå®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹å¯èƒ½
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒãŒå¸¸ã«å¯èƒ½

===============================================================================
"""
    
    report_file = Path("COMPREHENSIVE_FIX_REPORT.md")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"ğŸ“‹ åŒ…æ‹¬çš„ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_file}")
    return report_file

def main():
    """åŒ…æ‹¬çš„è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ä¿®æ­£ã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    
    print("=" * 80)
    print("åŒ…æ‹¬çš„è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ä¿®æ­£")
    print("ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’æ„è­˜ã—ãŸå…¨ä½“æœ€é©åŒ–")
    print("ç›®æ¨™: 27,486.5æ™‚é–“å•é¡Œã®å®Œå…¨è§£æ±º")
    print("=" * 80)
    
    # Step 1: åŒ…æ‹¬çš„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    print("\nğŸ“ Step 1: åŒ…æ‹¬çš„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ")
    backup_dir = create_comprehensive_backup()
    
    success_count = 0
    
    # Step 2: å„ä¿®æ­£ã®å®Ÿè¡Œ
    print("\nğŸ”§ Step 2: æ ¹æœ¬ä¿®æ­£ã®å®Ÿè¡Œ")
    
    print("\n  Fix 1: ãƒ‡ãƒ¼ã‚¿å–è¾¼ã¿å˜ä½ä¸€è²«æ€§ä¿®æ­£")
    if fix_data_ingestion_unit_consistency():
        success_count += 1
    
    print("\n  Fix 2: æœŸé–“æ­£è¦åŒ–æ©Ÿèƒ½å¼·åŒ–")
    if fix_shortage_period_normalization():
        success_count += 1
    
    print("\n  Fix 3: æ™‚é–“è»¸è¨ˆç®—å˜ä½å¤‰æ›ä¿®æ­£")
    if fix_time_axis_unit_calculation():
        success_count += 1
    
    print("\n  Fix 4: çµ±è¨ˆçš„éœ€è¦è¨ˆç®—é©æ­£åŒ–")
    if fix_statistical_demand_calculation():
        success_count += 1
    
    print("\n  Fix 5: è¨ˆç®—ãƒ•ãƒ­ãƒ¼æ¤œè¨¼æ©Ÿèƒ½è¿½åŠ ")
    if add_calculation_flow_validation():
        success_count += 1
    
    # Step 3: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("\nğŸ“‹ Step 3: ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
    report_file = generate_comprehensive_fix_report(backup_dir)
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("åŒ…æ‹¬çš„ä¿®æ­£å®Ÿè¡Œçµæœ")
    print("=" * 80)
    print(f"âœ… æˆåŠŸã—ãŸä¿®æ­£: {success_count}/5")
    print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_dir}")
    print(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
    
    if success_count == 5:
        print("\nğŸ‰ ã™ã¹ã¦ã®æ ¹æœ¬ä¿®æ­£ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print("\næœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ:")
        print("  â€¢ 27,486.5æ™‚é–“ â†’ 2,000-4,000æ™‚é–“ (æ­£å¸¸ç¯„å›²)")
        print("  â€¢ æœŸé–“ä¾å­˜æ€§å•é¡Œã®è§£æ±º")
        print("  â€¢ å˜ä½å¤‰æ›ã‚¨ãƒ©ãƒ¼ã®æ ¹çµ¶")
        print("  â€¢ çµ±è¨ˆçš„éå¤§æ¨å®šã®é˜²æ­¢")
        print("  â€¢ è¨ˆç®—ãƒ•ãƒ­ãƒ¼å…¨ä½“ã®é€æ˜æ€§å‘ä¸Š")
        print("\nğŸ“‹ æ¨å¥¨ã•ã‚Œã‚‹æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("  1. ãƒ†ã‚¹ãƒˆExcelãƒ•ã‚¡ã‚¤ãƒ«ã§ã®å‹•ä½œç¢ºèª")
        print("  2. 3ãƒ¶æœˆãƒ‡ãƒ¼ã‚¿ã§ã®åŠ¹æœæ¸¬å®š")
        print("  3. æ¤œè¨¼æ©Ÿèƒ½ã®å‹•ä½œãƒã‚§ãƒƒã‚¯")
    else:
        print(f"\nâš ï¸ ä¸€éƒ¨ã®ä¿®æ­£ãŒæœªå®Œäº†ã§ã™ ({success_count}/5)")
        print("è©³ç´°ç¢ºèªã¨æ‰‹å‹•ä¿®æ­£ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™")
    
    return success_count == 5

if __name__ == "__main__":
    try:
        success = main()
        if not success:
            print("\nâŒ ä¿®æ­£å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ åŒ…æ‹¬çš„ä¿®æ­£å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(f"è©³ç´°: {traceback.format_exc()}")