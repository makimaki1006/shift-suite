#!/usr/bin/env python3
"""
çµ±ä¸€åˆ†æç®¡ç†ã‚·ã‚¹ãƒ†ãƒ æœ€çµ‚çµ±åˆæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å…¨ä½“æœ€é©åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æœ€çµ‚ç¢ºèªï¼š
1. å‹•çš„ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®å®‰å…¨æ€§ç¢ºèª
2. çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã¨AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆã®é€£æºç¢ºèª
3. ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®æ¤œè¨¼
4. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ã®ç¢ºèª
"""

import logging
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
log = logging.getLogger(__name__)

def test_unified_analysis_system():
    """çµ±ä¸€åˆ†æç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
    
    log.info("=" * 80)
    log.info("çµ±ä¸€åˆ†æç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  æœ€çµ‚çµ±åˆæ¤œè¨¼é–‹å§‹")
    log.info("=" * 80)
    
    try:
        # 1. çµ±ä¸€åˆ†æç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆç¢ºèª
        from shift_suite.tasks.unified_analysis_manager import (
            UnifiedAnalysisManager, 
            SafeDataConverter, 
            DynamicKeyManager,
            UnifiedAnalysisResult
        )
        log.info("âœ… çµ±ä¸€åˆ†æç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        
        # 2. AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆç¢ºèª
        try:
            from shift_suite.tasks.ai_comprehensive_report_generator import AIComprehensiveReportGenerator
            ai_available = True
            log.info("âœ… AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        except ImportError as e:
            ai_available = False
            log.warning(f"âš ï¸ AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼åˆ©ç”¨ä¸å¯: {e}")
        
        # 3. çµ±ä¸€åˆ†æç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        manager = UnifiedAnalysisManager()
        log.info("âœ… UnifiedAnalysisManageråˆæœŸåŒ–æˆåŠŸ")
        
        # 4. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã«è¿‘ã„å½¢å¼ï¼‰
        test_data = create_realistic_test_data()
        log.info(f"âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(test_data['long_df'])}è¡Œ")
        
        # 5. å„åˆ†æã‚¿ã‚¤ãƒ—ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        results = {}
        
        # 5.1 ä¸è¶³åˆ†æãƒ†ã‚¹ãƒˆ
        log.info("\n--- ä¸è¶³åˆ†æãƒ†ã‚¹ãƒˆ ---")
        shortage_result = manager.create_shortage_analysis(
            "test_file.xlsx", "default", test_data['role_shortage_df']
        )
        results['shortage'] = shortage_result
        log.info(f"âœ… ä¸è¶³åˆ†æå®Œäº†: {shortage_result.data_integrity}")
        log.info(f"   ç·ä¸è¶³æ™‚é–“: {shortage_result.core_metrics.get('total_shortage_hours', {}).get('value', 'N/A')}")
        
        # 5.2 ç–²åŠ´åˆ†æãƒ†ã‚¹ãƒˆ
        log.info("\n--- ç–²åŠ´åˆ†æãƒ†ã‚¹ãƒˆ ---")
        fatigue_result = manager.create_fatigue_analysis(
            "test_file.xlsx", "default", test_data['fatigue_df'], test_data['combined_df']
        )
        results['fatigue'] = fatigue_result
        log.info(f"âœ… ç–²åŠ´åˆ†æå®Œäº†: {fatigue_result.data_integrity}")
        log.info(f"   å¹³å‡ç–²åŠ´ã‚¹ã‚³ã‚¢: {fatigue_result.core_metrics.get('avg_fatigue_score', {}).get('value', 'N/A')}")
        
        # 5.3 å…¬å¹³æ€§åˆ†æãƒ†ã‚¹ãƒˆ
        log.info("\n--- å…¬å¹³æ€§åˆ†æãƒ†ã‚¹ãƒˆ ---")
        fairness_results = manager.create_fairness_analysis(
            "test_file.xlsx", "default", test_data['fairness_df']
        )
        results['fairness'] = fairness_results
        log.info(f"âœ… å…¬å¹³æ€§åˆ†æå®Œäº†: {len(fairness_results)}çµæœ")
        if fairness_results:
            avg_score = fairness_results[0].core_metrics.get('avg_fairness_score', {}).get('value', 'N/A')
            log.info(f"   å¹³å‡å…¬å¹³æ€§ã‚¹ã‚³ã‚¢: {avg_score}")
        
        # 6. AIäº’æ›çµæœã®å–å¾—ãƒ†ã‚¹ãƒˆ
        log.info("\n--- AIäº’æ›çµæœå–å¾—ãƒ†ã‚¹ãƒˆ ---")
        ai_compatible_results = manager.get_ai_compatible_results("test_file")
        log.info(f"âœ… AIäº’æ›çµæœå–å¾—å®Œäº†: {len(ai_compatible_results)}ç¨®é¡")
        
        for analysis_type, data in ai_compatible_results.items():
            integrity = data.get('data_integrity', 'unknown')
            log.info(f"   {analysis_type}: {integrity}")
        
        # 7. AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆã¨ã®é€£æºãƒ†ã‚¹ãƒˆï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if ai_available:
            log.info("\n--- AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆé€£æºãƒ†ã‚¹ãƒˆ ---")
            try:
                generator = AIComprehensiveReportGenerator()
                
                # çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã®çµæœã‚’ä½¿ç”¨ã—ã¦ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
                test_params = {
                    "slot_minutes": 30,
                    "need_calculation_method": "statistical_estimation",
                    "analysis_start_date": "2025-01-01",
                    "analysis_end_date": "2025-01-31"
                }
                
                # AIäº’æ›çµæœã‚’ç›´æ¥ä½¿ç”¨
                mece_report = generator.generate_mece_report(
                    ai_compatible_results, test_params
                )
                
                log.info("âœ… AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”ŸæˆæˆåŠŸ")
                log.info(f"   MECEæ§‹é€ : {len(mece_report)}ã‚»ã‚¯ã‚·ãƒ§ãƒ³")
                
                # MECEæ§‹é€ ã®ç¢ºèª
                expected_sections = [
                    "executive_summary", "shortage_analysis", "fatigue_analysis", 
                    "fairness_analysis", "operational_metrics", "risk_assessment"
                ]
                
                missing_sections = [s for s in expected_sections if s not in mece_report]
                if missing_sections:
                    log.warning(f"âš ï¸ ä¸è¶³ã‚»ã‚¯ã‚·ãƒ§ãƒ³: {missing_sections}")
                else:
                    log.info("âœ… MECEæ§‹é€ å®Œå…¨æ€§ç¢ºèª")
                
            except Exception as e:
                log.error(f"âŒ AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆé€£æºã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        
        # 8. ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
        log.info("\n--- ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ†ã‚¹ãƒˆ ---")
        test_error_handling(manager)
        
        # 9. ãƒ‡ãƒ¼ã‚¿å‹å®‰å…¨æ€§ãƒ†ã‚¹ãƒˆ
        log.info("\n--- ãƒ‡ãƒ¼ã‚¿å‹å®‰å…¨æ€§ãƒ†ã‚¹ãƒˆ ---")
        test_data_safety()
        
        # 10. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ
        log.info("\n--- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ†ã‚¹ãƒˆ ---")
        test_memory_efficiency(manager)
        
        # 11. å‹•çš„ã‚­ãƒ¼ç®¡ç†ãƒ†ã‚¹ãƒˆ
        log.info("\n--- å‹•çš„ã‚­ãƒ¼ç®¡ç†ãƒ†ã‚¹ãƒˆ ---")
        test_dynamic_key_management()
        
        log.info("\n" + "=" * 80)
        log.info("ğŸ‰ çµ±ä¸€åˆ†æç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  æœ€çµ‚çµ±åˆæ¤œè¨¼å®Œäº†")
        log.info("å…¨ä½“æœ€é©åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚‹çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        log.info("=" * 80)
        
        return True
        
    except Exception as e:
        log.error(f"âŒ çµ±åˆæ¤œè¨¼ä¸­ã«é‡å¤§ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False

def create_realistic_test_data():
    """å®Ÿãƒ‡ãƒ¼ã‚¿ã«è¿‘ã„ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
    np.random.seed(42)
    
    # é•·æœŸé–“ãƒ‡ãƒ¼ã‚¿ï¼ˆlong_dfç›¸å½“ï¼‰
    dates = pd.date_range('2025-01-01', '2025-01-31', freq='30T')
    staff_list = [f"ã‚¹ã‚¿ãƒƒãƒ•{i:02d}" for i in range(1, 21)]
    
    long_df = []
    for date in dates[:100]:  # ãƒ†ã‚¹ãƒˆç”¨ã«åˆ¶é™
        for staff in staff_list[:5]:  # ãƒ†ã‚¹ãƒˆç”¨ã«åˆ¶é™
            long_df.append({
                'ds': date,
                'staff': staff,
                'role': f'å½¹è·{np.random.randint(1, 4)}',
                'code': np.random.choice(['æ—¥å‹¤', 'å¤œå‹¤', 'é…ç•ª']),
                'parsed_slots_count': np.random.randint(0, 16)
            })
    
    long_df = pd.DataFrame(long_df)
    
    # ä¸è¶³åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿
    role_shortage_df = pd.DataFrame({
        'role': [f'å½¹è·{i}' for i in range(1, 6)],
        'lack_h': np.random.exponential(5, 5),  # ä¸è¶³æ™‚é–“
        'need_h': np.random.normal(40, 10, 5)   # å¿…è¦æ™‚é–“
    })
    
    # ç–²åŠ´åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿
    fatigue_df = pd.DataFrame({
        'staff': staff_list[:10],
        'fatigue_score': np.random.beta(2, 5, 10),  # 0-1ã®ç–²åŠ´ã‚¹ã‚³ã‚¢
        'work_hours': np.random.normal(8, 2, 10)
    })
    
    # çµ±åˆã‚¹ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿
    combined_df = pd.DataFrame({
        'staff': staff_list[:10],
        'final_score': np.random.normal(75, 15, 10),  # è©•ä¾¡ã‚¹ã‚³ã‚¢
        'performance': np.random.uniform(0.5, 1.0, 10)
    })
    
    # å…¬å¹³æ€§åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿
    fairness_df = pd.DataFrame({
        'staff': staff_list[:10],
        'night_ratio': np.random.beta(2, 8, 10),     # å¤œå‹¤æ¯”ç‡
        'total_shifts': np.random.poisson(20, 10),   # ç·ã‚·ãƒ•ãƒˆæ•°
        'fairness_score': np.random.beta(5, 2, 10)   # å…¬å¹³æ€§ã‚¹ã‚³ã‚¢
    })
    
    return {
        'long_df': long_df,
        'role_shortage_df': role_shortage_df,
        'fatigue_df': fatigue_df,
        'combined_df': combined_df,
        'fairness_df': fairness_df
    }

def test_error_handling(manager):
    """ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    
    # ç©ºãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ†ã‚¹ãƒˆ
    empty_df = pd.DataFrame()
    result = manager.create_shortage_analysis("empty_test.xlsx", "default", empty_df)
    assert result.data_integrity in ["valid", "error"]
    log.info("âœ… ç©ºãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ç¢ºèª")
    
    # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®ãƒ†ã‚¹ãƒˆ
    invalid_df = pd.DataFrame({
        'lack_h': ['invalid', None, float('inf'), -1],
        'role': ['å½¹è·A', 'å½¹è·B', 'å½¹è·C', 'å½¹è·D']
    })
    result = manager.create_shortage_analysis("invalid_test.xlsx", "default", invalid_df)
    log.info(f"âœ… ä¸æ­£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ç¢ºèª: {result.data_integrity}")
    
    # NaN/Infå€¤ã®ãƒ†ã‚¹ãƒˆ
    nan_df = pd.DataFrame({
        'lack_h': [1.0, np.nan, np.inf, -np.inf, 5.0],
        'role': ['A', 'B', 'C', 'D', 'E']
    })
    result = manager.create_shortage_analysis("nan_test.xlsx", "default", nan_df)
    log.info("âœ… NaN/Infå€¤å‡¦ç†ç¢ºèª")

def test_data_safety():
    """ãƒ‡ãƒ¼ã‚¿å‹å®‰å…¨æ€§ã®ãƒ†ã‚¹ãƒˆ"""
    from shift_suite.tasks.unified_analysis_manager import SafeDataConverter
    
    converter = SafeDataConverter()
    
    # å„ç¨®ãƒ‡ãƒ¼ã‚¿å‹ã®å®‰å…¨å¤‰æ›ãƒ†ã‚¹ãƒˆ
    test_cases = [
        (None, 0.0, "none_test"),
        ("123.45", 123.45, "string_number"),
        (float('inf'), 0.0, "infinity_test"),
        (float('nan'), 0.0, "nan_test"),
        ("invalid", 0.0, "invalid_string")
    ]
    
    for input_val, expected, field_name in test_cases:
        result = converter.safe_float(input_val, 0.0, field_name)
        assert isinstance(result, (int, float)), f"{field_name}ã§æ•°å€¤å‹ã§ãªã„çµæœ"
        assert not np.isinf(result), f"{field_name}ã§Infå€¤"
        assert not np.isnan(result), f"{field_name}ã§NaNå€¤"
    
    log.info("âœ… ãƒ‡ãƒ¼ã‚¿å‹å®‰å…¨æ€§ç¢ºèªå®Œäº†")

def test_memory_efficiency(manager):
    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    
    # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ
    large_df = pd.DataFrame({
        'lack_h': np.random.exponential(2, 1000),
        'role': [f'å½¹è·{i%50}' for i in range(1000)]
    })
    
    initial_count = len(manager.results_registry)
    
    # è¤‡æ•°ã®åˆ†æã‚’å®Ÿè¡Œ
    for i in range(5):
        manager.create_shortage_analysis(f"large_test_{i}.xlsx", "default", large_df)
    
    after_count = len(manager.results_registry)
    assert after_count > initial_count, "çµæœãŒç™»éŒ²ã•ã‚Œã¦ã„ãªã„"
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆï¼ˆ0æ™‚é–“ã§å…¨å‰Šé™¤ï¼‰
    manager.cleanup_old_results(max_age_hours=0)
    
    final_count = len(manager.results_registry)
    log.info(f"âœ… ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ç¢ºèª: {after_count} â†’ {final_count}")

def test_dynamic_key_management():
    """å‹•çš„ã‚­ãƒ¼ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    from shift_suite.tasks.unified_analysis_manager import DynamicKeyManager
    
    key_manager = DynamicKeyManager()
    
    # ã‚­ãƒ¼ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    key1 = key_manager.generate_analysis_key("test file.xlsx", "scenario1", "shortage")
    key2 = key_manager.generate_analysis_key("test file.xlsx", "scenario1", "shortage")
    
    assert key1 != key2, "åŒä¸€æ¡ä»¶ã§ç•°ãªã‚‹ã‚­ãƒ¼ãŒç”Ÿæˆã•ã‚Œãªã„"
    log.info("âœ… å‹•çš„ã‚­ãƒ¼ç”Ÿæˆç¢ºèª")
    
    # ã‚­ãƒ¼è§£æãƒ†ã‚¹ãƒˆ
    info = key_manager.extract_file_info(key1)
    assert info["file_name"] == "test_file", f"ãƒ•ã‚¡ã‚¤ãƒ«åè§£æã‚¨ãƒ©ãƒ¼: {info['file_name']}"
    assert info["scenario_key"] == "scenario1", f"ã‚·ãƒŠãƒªã‚ªã‚­ãƒ¼è§£æã‚¨ãƒ©ãƒ¼: {info['scenario_key']}"
    assert info["analysis_type"] == "shortage", f"åˆ†æã‚¿ã‚¤ãƒ—è§£æã‚¨ãƒ©ãƒ¼: {info['analysis_type']}"
    
    log.info("âœ… ã‚­ãƒ¼è§£ææ©Ÿèƒ½ç¢ºèª")

if __name__ == "__main__":
    success = test_unified_analysis_system()
    sys.exit(0 if success else 1)