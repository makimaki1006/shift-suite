#!/usr/bin/env python3
"""
è»¸5: åŒ»ç™‚ãƒ»ã‚±ã‚¢å“è³ª MECEäº‹å®ŸæŠ½å‡ºã‚¨ãƒ³ã‚¸ãƒ³

12è»¸åˆ†æãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®è»¸5ã‚’æ‹…å½“
éå»ã‚·ãƒ•ãƒˆå®Ÿç¸¾ã‹ã‚‰åŒ»ç™‚ãƒ»ã‚±ã‚¢å“è³ªå‘ä¸Šã«é–¢ã™ã‚‹åˆ¶ç´„ã‚’æŠ½å‡º

ä½œæˆæ—¥: 2025å¹´7æœˆ
"""

import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict, Counter
import json

log = logging.getLogger(__name__)

class MedicalCareQualityMECEFactExtractor:
    """è»¸5: åŒ»ç™‚ãƒ»ã‚±ã‚¢å“è³ªã®MECEäº‹å®ŸæŠ½å‡ºå™¨"""
    
    def __init__(self):
        self.axis_number = 5
        self.axis_name = "åŒ»ç™‚ãƒ»ã‚±ã‚¢å“è³ª"
        
    def extract_axis5_medical_care_quality_rules(self, long_df: pd.DataFrame, wt_df: pd.DataFrame = None) -> Dict[str, Any]:
        """
        è»¸5: åŒ»ç™‚ãƒ»ã‚±ã‚¢å“è³ªãƒ«ãƒ¼ãƒ«ã‚’MECEåˆ†è§£ã«ã‚ˆã‚ŠæŠ½å‡º
        
        Args:
            long_df: éå»ã®ã‚·ãƒ•ãƒˆå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿
            wt_df: å‹¤å‹™åŒºåˆ†ãƒã‚¹ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            Dict: æŠ½å‡ºçµæœï¼ˆhuman_readable, machine_readable, extraction_metadataï¼‰
        """
        log.info(f"ğŸ¯ è»¸5: {self.axis_name} MECEäº‹å®ŸæŠ½å‡ºã‚’é–‹å§‹")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
            if long_df.empty:
                raise ValueError("é•·æœŸãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            
            # è»¸5ã®MECEåˆ†è§£ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆ8ã¤ï¼‰
            mece_facts = {
                "åŒ»ç™‚å®‰å…¨åˆ¶ç´„": self._extract_medical_safety_constraints(long_df, wt_df),
                "ã‚±ã‚¢ç¶™ç¶šæ€§åˆ¶ç´„": self._extract_care_continuity_constraints(long_df, wt_df),
                "å°‚é–€æ€§é…ç½®åˆ¶ç´„": self._extract_expertise_placement_constraints(long_df, wt_df),
                "å“è³ªç›£ç£åˆ¶ç´„": self._extract_quality_supervision_constraints(long_df, wt_df),
                "åˆ©ç”¨è€…é©å¿œåˆ¶ç´„": self._extract_user_adaptation_constraints(long_df, wt_df),
                "åŒ»ç™‚é€£æºåˆ¶ç´„": self._extract_medical_coordination_constraints(long_df, wt_df),
                "ã‚±ã‚¢è¨˜éŒ²åˆ¶ç´„": self._extract_care_documentation_constraints(long_df, wt_df),
                "å“è³ªå‘ä¸Šåˆ¶ç´„": self._extract_quality_improvement_constraints(long_df, wt_df)
            }
            
            # äººé–“å¯èª­å½¢å¼ã®çµæœç”Ÿæˆ
            human_readable = self._generate_human_readable_results(mece_facts, long_df)
            
            # æ©Ÿæ¢°å¯èª­å½¢å¼ã®åˆ¶ç´„ç”Ÿæˆ
            machine_readable = self._generate_machine_readable_constraints(mece_facts, long_df)
            
            # æŠ½å‡ºãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            extraction_metadata = self._generate_extraction_metadata(long_df, wt_df, mece_facts)
            
            log.info(f"âœ… è»¸5: {self.axis_name} MECEäº‹å®ŸæŠ½å‡ºå®Œäº†")
            
            return {
                'human_readable': human_readable,
                'machine_readable': machine_readable,
                'extraction_metadata': extraction_metadata
            }
            
        except Exception as e:
            log.error(f"âŒ è»¸5: {self.axis_name} æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise e
    
    def _extract_medical_safety_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """åŒ»ç™‚å®‰å…¨åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # å¤œå‹¤å¸¯ã§ã®è¤‡æ•°é…ç½®ï¼ˆåŒ»ç™‚å®‰å…¨ï¼‰
            if 'code' in long_df.columns and 'ds' in long_df.columns:
                # å¤œå‹¤ã‚³ãƒ¼ãƒ‰ã‚’ç‰¹å®š
                night_shift_codes = ['å¤œå‹¤', 'ãƒŠã‚¤ãƒˆ', 'night', 'N', 'å¤œé–“']
                night_shifts = long_df[long_df['code'].str.contains('|'.join(night_shift_codes), case=False, na=False)]
                
                if not night_shifts.empty:
                    # å¤œå‹¤å¸¯ã§ã®é…ç½®äººæ•°åˆ†æ
                    night_staff_counts = night_shifts.groupby('ds')['staff'].nunique()
                    single_night_days = sum(night_staff_counts == 1)
                    total_night_days = len(night_staff_counts)
                    
                    if single_night_days > 0:
                        safety_risk_ratio = single_night_days / total_night_days
                        constraints.append(f"å¤œå‹¤å˜ç‹¬é…ç½®ãƒªã‚¹ã‚¯: {single_night_days}/{total_night_days}æ—¥ ({safety_risk_ratio:.1%}) - åŒ»ç™‚å®‰å…¨ã®ãŸã‚è¤‡æ•°é…ç½®æ¨å¥¨")
                    else:
                        constraints.append("å¤œå‹¤è¤‡æ•°é…ç½®ç¢ºä¿: åŒ»ç™‚å®‰å…¨åŸºæº–éµå®ˆ")
            
            # åŒ»ç™‚è³‡æ ¼è€…ã®é…ç½®ãƒ‘ã‚¿ãƒ¼ãƒ³
            if 'role' in long_df.columns:
                medical_roles = ['çœ‹è­·å¸«', 'å‡†çœ‹è­·å¸«', 'åŒ»å¸«', 'ãƒŠãƒ¼ã‚¹', 'nurse']
                medical_staff = long_df[long_df['role'].str.contains('|'.join(medical_roles), case=False, na=False)]
                
                if not medical_staff.empty:
                    # åŒ»ç™‚è³‡æ ¼è€…ã®é€£ç¶šå‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³
                    if 'ds' in medical_staff.columns and 'staff' in medical_staff.columns:
                        for staff_id in medical_staff['staff'].unique():
                            staff_shifts = medical_staff[medical_staff['staff'] == staff_id]['ds'].sort_values()
                            if len(staff_shifts) > 1:
                                # é€£ç¶šå‹¤å‹™æ—¥æ•°ã®è¨ˆç®—
                                consecutive_days = self._calculate_consecutive_workdays(staff_shifts)
                                if consecutive_days > 5:
                                    constraints.append(f"åŒ»ç™‚è³‡æ ¼è€…é€£ç¶šå‹¤å‹™: {staff_id} - {consecutive_days}æ—¥é€£ç¶š (ç–²åŠ´ã«ã‚ˆã‚‹åŒ»ç™‚å®‰å…¨ãƒªã‚¹ã‚¯)")
                
                # åŒ»ç™‚è³‡æ ¼è€…ã®é…ç½®é »åº¦
                total_shifts = len(long_df)
                medical_shifts = len(medical_staff)
                medical_coverage = medical_shifts / total_shifts if total_shifts > 0 else 0
                constraints.append(f"åŒ»ç™‚è³‡æ ¼è€…é…ç½®ç‡: {medical_coverage:.1%} - åŒ»ç™‚å®‰å…¨ç¢ºä¿ãƒ¬ãƒ™ãƒ«")
            
            # ç·Šæ€¥æ™‚å¯¾å¿œå¯èƒ½è€…ã®é…ç½®
            if 'employment' in long_df.columns and 'role' in long_df.columns:
                # æ­£è¦é›‡ç”¨Ã—åŒ»ç™‚è³‡æ ¼ã®çµ„ã¿åˆã‚ã›
                regular_medical = long_df[
                    (long_df['employment'].str.contains('æ­£ç¤¾å“¡|æ­£è¦|å¸¸å‹¤', case=False, na=False)) &
                    (long_df['role'].str.contains('çœ‹è­·å¸«|åŒ»å¸«|ãƒŠãƒ¼ã‚¹', case=False, na=False))
                ]
                
                if not regular_medical.empty and 'ds' in long_df.columns:
                    coverage_days = regular_medical['ds'].nunique()
                    total_days = long_df['ds'].nunique()
                    emergency_coverage = coverage_days / total_days if total_days > 0 else 0
                    
                    if emergency_coverage < 0.8:
                        constraints.append(f"ç·Šæ€¥å¯¾å¿œä½“åˆ¶ä¸è¶³: {emergency_coverage:.1%}ã‚«ãƒãƒ¬ãƒƒã‚¸ - æ­£è¦åŒ»ç™‚è³‡æ ¼è€…ã®é…ç½®å¼·åŒ–å¿…è¦")
                    else:
                        constraints.append(f"ç·Šæ€¥å¯¾å¿œä½“åˆ¶è‰¯å¥½: {emergency_coverage:.1%}ã‚«ãƒãƒ¬ãƒƒã‚¸")
                
        except Exception as e:
            log.warning(f"åŒ»ç™‚å®‰å…¨åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("åŒ»ç™‚å®‰å…¨åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["åŒ»ç™‚å®‰å…¨ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_care_continuity_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """ã‚±ã‚¢ç¶™ç¶šæ€§åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # åŒä¸€åˆ©ç”¨è€…æ‹…å½“ã®ç¶™ç¶šæ€§åˆ†æ
            if 'staff' in long_df.columns and 'ds' in long_df.columns:
                # ã‚¹ã‚¿ãƒƒãƒ•ã®å‹¤å‹™é »åº¦ã¨ç¶™ç¶šæ€§
                staff_frequency = long_df['staff'].value_counts()
                regular_staff = staff_frequency[staff_frequency >= 5]  # 5æ—¥ä»¥ä¸Šå‹¤å‹™ã‚’ç¶™ç¶šæ€§ã®åŸºæº–
                
                continuity_ratio = len(regular_staff) / len(staff_frequency) if len(staff_frequency) > 0 else 0
                constraints.append(f"ã‚±ã‚¢ç¶™ç¶šæ€§: {continuity_ratio:.1%}ã®ã‚¹ã‚¿ãƒƒãƒ•ãŒç¶™ç¶šå‹¤å‹™ (5æ—¥ä»¥ä¸Š)")
                
                # å‹¤å‹™é–“éš”ã®åˆ†æ
                for staff_id in regular_staff.index[:5]:  # ä¸Šä½5åã‚’åˆ†æ
                    staff_dates = pd.to_datetime(long_df[long_df['staff'] == staff_id]['ds']).sort_values()
                    if len(staff_dates) > 1:
                        intervals = staff_dates.diff().dt.days.dropna()
                        avg_interval = intervals.mean()
                        if avg_interval <= 2:
                            constraints.append(f"é«˜ç¶™ç¶šæ€§ã‚¹ã‚¿ãƒƒãƒ•: {staff_id} (å¹³å‡{avg_interval:.1f}æ—¥é–“éš”)")
            
            # ã‚·ãƒ•ãƒˆå¼•ãç¶™ããƒ‘ã‚¿ãƒ¼ãƒ³
            if 'code' in long_df.columns and 'ds' in long_df.columns and 'staff' in long_df.columns:
                # æ—¥å‹¤â†’å¤œå‹¤ã®å¼•ãç¶™ãåˆ†æ
                day_codes = ['æ—¥å‹¤', 'ãƒ‡ã‚¤', 'day', 'D', 'æ—¥ä¸­']
                night_codes = ['å¤œå‹¤', 'ãƒŠã‚¤ãƒˆ', 'night', 'N', 'å¤œé–“']
                
                day_shifts = long_df[long_df['code'].str.contains('|'.join(day_codes), case=False, na=False)]
                night_shifts = long_df[long_df['code'].str.contains('|'.join(night_codes), case=False, na=False)]
                
                if not day_shifts.empty and not night_shifts.empty:
                    # åŒæ—¥ã®å¼•ãç¶™ããƒ‘ã‚¿ãƒ¼ãƒ³
                    for date in day_shifts['ds'].dt.date.unique():
                        day_staff = set(day_shifts[day_shifts['ds'].dt.date == date]['staff'].unique())
                        night_staff = set(night_shifts[night_shifts['ds'].dt.date == date]['staff'].unique())
                        
                        if day_staff and night_staff:
                            overlap = len(day_staff.intersection(night_staff))
                            if overlap > 0:
                                constraints.append(f"å¼•ãç¶™ãé‡è¤‡: {date} - {overlap}åãŒæ—¥å‹¤ãƒ»å¤œå‹¤ä¸¡æ–¹æ‹…å½“ (ç¶™ç¶šæ€§å‘ä¸Š)")
                
                # é€±å˜ä½ã§ã®æ‹…å½“è€…å¤‰æ›´é »åº¦
                weekly_changes = self._analyze_weekly_staff_changes(long_df)
                if weekly_changes:
                    avg_changes = np.mean(weekly_changes)
                    constraints.append(f"é€±æ¬¡æ‹…å½“è€…å¤‰æ›´: å¹³å‡{avg_changes:.1f}å/é€± - ã‚±ã‚¢ç¶™ç¶šæ€§ã¸ã®å½±éŸ¿")
                
        except Exception as e:
            log.warning(f"ã‚±ã‚¢ç¶™ç¶šæ€§åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("ã‚±ã‚¢ç¶™ç¶šæ€§åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["ã‚±ã‚¢ç¶™ç¶šæ€§ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_expertise_placement_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """å°‚é–€æ€§é…ç½®åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # è·ç¨®åˆ¥å°‚é–€æ€§åˆ†æ
            if 'role' in long_df.columns:
                role_distribution = long_df['role'].value_counts()
                
                # å°‚é–€è·ç¨®ã®ç‰¹å®š
                specialized_roles = ['çœ‹è­·å¸«', 'å‡†çœ‹è­·å¸«', 'ç†å­¦ç™‚æ³•å£«', 'PT', 'OT', 'ä½œæ¥­ç™‚æ³•å£«', 'è¨€èªè´è¦šå£«', 'ST', 'åŒ»å¸«']
                specialized_count = 0
                
                for role in role_distribution.index:
                    for spec_role in specialized_roles:
                        if spec_role in role:
                            specialized_count += role_distribution[role]
                            break
                
                total_shifts = len(long_df)
                specialization_ratio = specialized_count / total_shifts if total_shifts > 0 else 0
                constraints.append(f"å°‚é–€è·é…ç½®ç‡: {specialization_ratio:.1%} - å°‚é–€ã‚±ã‚¢æä¾›ãƒ¬ãƒ™ãƒ«")
                
                # è·ç¨®å¤šæ§˜æ€§ã®åˆ†æ
                role_diversity = len(role_distribution) / total_shifts if total_shifts > 0 else 0
                if role_diversity > 0.1:
                    constraints.append(f"è·ç¨®å¤šæ§˜æ€§é«˜: {len(role_distribution)}è·ç¨® - å¤šè§’çš„ã‚±ã‚¢æä¾›å¯èƒ½")
                else:
                    constraints.append(f"è·ç¨®é›†ä¸­é…ç½®: {len(role_distribution)}è·ç¨® - å°‚é–€æ€§ã®é›†ç´„")
            
            # æ™‚é–“å¸¯åˆ¥å°‚é–€æ€§é…ç½®
            if 'role' in long_df.columns and 'ds' in long_df.columns:
                long_df['hour'] = pd.to_datetime(long_df['ds']).dt.hour
                
                # æ—¥ä¸­æ™‚é–“å¸¯ï¼ˆ9-17æ™‚ï¼‰ã§ã®å°‚é–€è·é…ç½®
                daytime_hours = range(9, 18)
                daytime_shifts = long_df[long_df['hour'].isin(daytime_hours)]
                
                if not daytime_shifts.empty:
                    daytime_roles = daytime_shifts['role'].value_counts()
                    specialized_daytime = sum(
                        count for role, count in daytime_roles.items()
                        if any(spec in role for spec in ['çœ‹è­·å¸«', 'PT', 'OT', 'ST', 'ç™‚æ³•å£«'])
                    )
                    daytime_specialization = specialized_daytime / len(daytime_shifts) if len(daytime_shifts) > 0 else 0
                    constraints.append(f"æ—¥ä¸­å°‚é–€è·é…ç½®: {daytime_specialization:.1%} - ãƒªãƒãƒ“ãƒªãƒ»æ²»ç™‚æ™‚é–“å¸¯ã®å°‚é–€æ€§")
                
                # å¤œé–“ãƒ»ä¼‘æ—¥ã§ã®åŸºæœ¬ã‚±ã‚¢ä½“åˆ¶
                nighttime_hours = list(range(0, 7)) + list(range(22, 24))
                nighttime_shifts = long_df[long_df['hour'].isin(nighttime_hours)]
                
                if not nighttime_shifts.empty:
                    basic_care_roles = ['ä»‹è­·å£«', 'ä»‹è­·ç¦ç¥‰å£«', 'ãƒ˜ãƒ«ãƒ‘ãƒ¼', 'çœ‹è­·å¸«']
                    nighttime_basic_care = sum(
                        nighttime_shifts['role'].str.contains(role, case=False, na=False).sum()
                        for role in basic_care_roles
                    )
                    nighttime_coverage = nighttime_basic_care / len(nighttime_shifts) if len(nighttime_shifts) > 0 else 0
                    constraints.append(f"å¤œé–“åŸºæœ¬ã‚±ã‚¢é…ç½®: {nighttime_coverage:.1%} - å®‰å…¨ãƒ»å¿«é©ãªå¤œé–“ã‚±ã‚¢")
            
            # çµŒé¨“å¹´æ•°ãƒ»é›‡ç”¨å½¢æ…‹ã¨å°‚é–€æ€§ã®é–¢ä¿‚
            if 'employment' in long_df.columns and 'role' in long_df.columns:
                # æ­£è¦é›‡ç”¨ã§ã®å°‚é–€è·æ¯”ç‡
                regular_staff = long_df[long_df['employment'].str.contains('æ­£ç¤¾å“¡|æ­£è¦|å¸¸å‹¤', case=False, na=False)]
                if not regular_staff.empty:
                    regular_specialized = sum(
                        regular_staff['role'].str.contains(role, case=False, na=False).sum()
                        for role in ['çœ‹è­·å¸«', 'ç™‚æ³•å£«', 'PT', 'OT', 'ST']
                    )
                    regular_specialization = regular_specialized / len(regular_staff) if len(regular_staff) > 0 else 0
                    constraints.append(f"æ­£è¦é›‡ç”¨å°‚é–€è·ç‡: {regular_specialization:.1%} - å°‚é–€æ€§ã®å®‰å®šç¢ºä¿")
                
        except Exception as e:
            log.warning(f"å°‚é–€æ€§é…ç½®åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("å°‚é–€æ€§é…ç½®åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["å°‚é–€æ€§é…ç½®ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_quality_supervision_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """å“è³ªç›£ç£åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # ç®¡ç†è€…ãƒ»ãƒªãƒ¼ãƒ€ãƒ¼ã®é…ç½®åˆ†æ
            if 'role' in long_df.columns:
                supervisor_roles = ['ä¸»ä»»', 'ãƒªãƒ¼ãƒ€ãƒ¼', 'ç®¡ç†è€…', 'å¸«é•·', 'ãƒãƒ¼ãƒ•', 'çµ±æ‹¬', 'supervisor', 'manager']
                supervisors = long_df[
                    long_df['role'].str.contains('|'.join(supervisor_roles), case=False, na=False)
                ]
                
                if not supervisors.empty:
                    # ç›£ç£è€…ã®å‹¤å‹™é »åº¦
                    if 'ds' in long_df.columns:
                        total_days = long_df['ds'].nunique()
                        supervisor_days = supervisors['ds'].nunique()
                        supervision_coverage = supervisor_days / total_days if total_days > 0 else 0
                        
                        constraints.append(f"ç›£ç£è€…é…ç½®ç‡: {supervision_coverage:.1%} - å“è³ªç®¡ç†ä½“åˆ¶")
                        
                        if supervision_coverage < 0.7:
                            constraints.append("ç›£ç£ä½“åˆ¶å¼·åŒ–å¿…è¦: å“è³ªç›£ç£ãŒä¸ååˆ†ãªæ—¥ãŒå­˜åœ¨")
                        else:
                            constraints.append("ç›£ç£ä½“åˆ¶è‰¯å¥½: ç¶™ç¶šçš„ãªå“è³ªç®¡ç†å®Ÿç¾")
                
                # ç›£ç£è€…ã¨ä¸€èˆ¬ã‚¹ã‚¿ãƒƒãƒ•ã®æ¯”ç‡
                total_staff_shifts = len(long_df)
                supervisor_shifts = len(supervisors)
                supervision_ratio = supervisor_shifts / total_staff_shifts if total_staff_shifts > 0 else 0
                
                if supervision_ratio < 0.1:
                    constraints.append(f"ç›£ç£è€…æ¯”ç‡ä½: {supervision_ratio:.1%} - ç›£ç£ä½“åˆ¶ã®å……å®ŸãŒå¿…è¦")
                elif supervision_ratio > 0.3:
                    constraints.append(f"ç›£ç£è€…æ¯”ç‡é«˜: {supervision_ratio:.1%} - ç®¡ç†ã‚³ã‚¹ãƒˆè¦æ¤œè¨")
                else:
                    constraints.append(f"ç›£ç£è€…æ¯”ç‡é©æ­£: {supervision_ratio:.1%}")
            
            # å“è³ªãƒã‚§ãƒƒã‚¯ä½“åˆ¶ï¼ˆã‚·ãƒ•ãƒˆé‡è¤‡ã«ã‚ˆã‚‹ç¢ºèªï¼‰
            if 'ds' in long_df.columns and 'staff' in long_df.columns:
                # åŒæ—¥è¤‡æ•°ã‚¹ã‚¿ãƒƒãƒ•ã§ã®ç›¸äº’ãƒã‚§ãƒƒã‚¯å¯èƒ½æ€§
                daily_staff_counts = long_df.groupby('ds')['staff'].nunique()
                multi_staff_days = sum(daily_staff_counts >= 2)
                total_days = len(daily_staff_counts)
                
                quality_check_coverage = multi_staff_days / total_days if total_days > 0 else 0
                constraints.append(f"ç›¸äº’ãƒã‚§ãƒƒã‚¯å¯èƒ½æ—¥: {quality_check_coverage:.1%} - å“è³ªç¢ºèªä½“åˆ¶")
                
                # 3åä»¥ä¸Šã§ã®é«˜å“è³ªãƒã‚§ãƒƒã‚¯
                high_quality_days = sum(daily_staff_counts >= 3)
                high_quality_coverage = high_quality_days / total_days if total_days > 0 else 0
                if high_quality_coverage > 0.5:
                    constraints.append(f"é«˜å“è³ªãƒã‚§ãƒƒã‚¯ä½“åˆ¶: {high_quality_coverage:.1%}ã®æ—¥ã§3åä»¥ä¸Šé…ç½®")
            
            # æ–°äººãƒ»ãƒ™ãƒ†ãƒ©ãƒ³æ··åœ¨ã«ã‚ˆã‚‹å“è³ªå‘ä¸Š
            if 'employment' in long_df.columns:
                # é›‡ç”¨å½¢æ…‹ã§ã®çµŒé¨“æ¨å®š
                veteran_types = ['æ­£ç¤¾å“¡', 'æ­£è¦', 'å¸¸å‹¤']
                newcomer_types = ['ãƒ‘ãƒ¼ãƒˆ', 'ã‚¢ãƒ«ãƒã‚¤ãƒˆ', 'éå¸¸å‹¤', 'æ´¾é£']
                
                veteran_shifts = sum(
                    long_df['employment'].str.contains(vet_type, case=False, na=False).sum()
                    for vet_type in veteran_types
                )
                newcomer_shifts = sum(
                    long_df['employment'].str.contains(new_type, case=False, na=False).sum()
                    for new_type in newcomer_types
                )
                
                if veteran_shifts > 0 and newcomer_shifts > 0:
                    veteran_ratio = veteran_shifts / (veteran_shifts + newcomer_shifts)
                    if 0.3 <= veteran_ratio <= 0.7:
                        constraints.append(f"ãƒ™ãƒ†ãƒ©ãƒ³ãƒ»æ–°äººãƒãƒ©ãƒ³ã‚¹è‰¯å¥½: ãƒ™ãƒ†ãƒ©ãƒ³{veteran_ratio:.1%} - æ•™è‚²ãƒ»å“è³ªå‘ä¸Šç’°å¢ƒ")
                    elif veteran_ratio < 0.3:
                        constraints.append(f"ãƒ™ãƒ†ãƒ©ãƒ³ä¸è¶³: {veteran_ratio:.1%} - å“è³ªæŒ‡å°ä½“åˆ¶ã®å¼·åŒ–å¿…è¦")
                    else:
                        constraints.append(f"ãƒ™ãƒ†ãƒ©ãƒ³éå¤š: {veteran_ratio:.1%} - æ–°äººè‚²æˆæ©Ÿä¼šã®ç¢ºä¿å¿…è¦")
                
        except Exception as e:
            log.warning(f"å“è³ªç›£ç£åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("å“è³ªç›£ç£åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["å“è³ªç›£ç£ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_user_adaptation_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """åˆ©ç”¨è€…é©å¿œåˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # æ‹…å½“è€…å¤‰æ›´é »åº¦ã«ã‚ˆã‚‹åˆ©ç”¨è€…ã¸ã®å½±éŸ¿
            if 'staff' in long_df.columns and 'ds' in long_df.columns:
                # é€±ã”ã¨ã®æ‹…å½“è€…å¤‰æ›´ãƒ‘ã‚¿ãƒ¼ãƒ³
                long_df['week'] = pd.to_datetime(long_df['ds']).dt.isocalendar().week
                weekly_staff_changes = []
                
                for week in long_df['week'].unique():
                    week_data = long_df[long_df['week'] == week]
                    unique_staff = week_data['staff'].nunique()
                    weekly_staff_changes.append(unique_staff)
                
                if weekly_staff_changes:
                    avg_weekly_changes = np.mean(weekly_staff_changes)
                    if avg_weekly_changes > 10:
                        constraints.append(f"æ‹…å½“è€…å¤‰æ›´é »åº¦é«˜: é€±å¹³å‡{avg_weekly_changes:.1f}å - åˆ©ç”¨è€…ã®é©å¿œè² æ‹…å¤§")
                    elif avg_weekly_changes < 5:
                        constraints.append(f"æ‹…å½“è€…å›ºå®šåº¦é«˜: é€±å¹³å‡{avg_weekly_changes:.1f}å - åˆ©ç”¨è€…ã®å®‰å¿ƒæ„Ÿå‘ä¸Š")
                    else:
                        constraints.append(f"æ‹…å½“è€…å¤‰æ›´é©åº¦: é€±å¹³å‡{avg_weekly_changes:.1f}å")
            
            # æ™‚é–“å¸¯åˆ¥ã‚±ã‚¢æä¾›ã®ä¸€è²«æ€§
            if 'ds' in long_df.columns and 'staff' in long_df.columns:
                long_df['hour'] = pd.to_datetime(long_df['ds']).dt.hour
                
                # æœãƒ»æ˜¼ãƒ»å¤•ãƒ»å¤œã®ä¸»è¦æ™‚é–“å¸¯ã§ã®æ‹…å½“è€…åˆ†æ
                time_periods = {
                    'æœ': [6, 7, 8, 9],
                    'æ˜¼': [11, 12, 13, 14],
                    'å¤•': [17, 18, 19, 20],
                    'å¤œ': [21, 22, 23, 0]
                }
                
                for period_name, hours in time_periods.items():
                    period_data = long_df[long_df['hour'].isin(hours)]
                    if not period_data.empty:
                        period_staff_consistency = period_data['staff'].value_counts()
                        most_frequent_staff = period_staff_consistency.iloc[0] if len(period_staff_consistency) > 0 else 0
                        total_period_shifts = len(period_data)
                        consistency_ratio = most_frequent_staff / total_period_shifts if total_period_shifts > 0 else 0
                        
                        if consistency_ratio > 0.5:
                            constraints.append(f"{period_name}æ™‚é–“å¸¯ä¸€è²«æ€§é«˜: {consistency_ratio:.1%} - åˆ©ç”¨è€…ã®ç”Ÿæ´»ãƒªã‚ºãƒ å®‰å®š")
                        else:
                            constraints.append(f"{period_name}æ™‚é–“å¸¯å¤‰å‹•å¤§: {consistency_ratio:.1%} - é©å¿œæ”¯æ´å¿…è¦")
            
            # åˆ©ç”¨è€…ç‰¹æ€§ã«å¿œã˜ãŸé…ç½®ï¼ˆæ¨å®šï¼‰
            if 'role' in long_df.columns:
                # èªçŸ¥ç—‡ã‚±ã‚¢å°‚é–€æ€§
                dementia_care_roles = ['èªçŸ¥ç—‡', 'ãƒ‡ã‚¤ã‚µãƒ¼ãƒ“ã‚¹', 'è¨ªå•', 'ã‚°ãƒ«ãƒ¼ãƒ—ãƒ›ãƒ¼ãƒ ']
                dementia_specialists = long_df[
                    long_df['role'].str.contains('|'.join(dementia_care_roles), case=False, na=False)
                ]
                
                if not dementia_specialists.empty:
                    dementia_care_ratio = len(dementia_specialists) / len(long_df)
                    constraints.append(f"èªçŸ¥ç—‡ã‚±ã‚¢å°‚é–€é…ç½®: {dementia_care_ratio:.1%} - ç‰¹æ€§ã«å¿œã˜ãŸã‚±ã‚¢æä¾›")
                
                # é‡åº¦ã‚±ã‚¢å¯¾å¿œ
                intensive_care_roles = ['çœ‹è­·å¸«', 'åŒ»å¸«', 'å‡†çœ‹è­·å¸«']
                intensive_care_staff = long_df[
                    long_df['role'].str.contains('|'.join(intensive_care_roles), case=False, na=False)
                ]
                
                if not intensive_care_staff.empty:
                    intensive_care_ratio = len(intensive_care_staff) / len(long_df)
                    constraints.append(f"é‡åº¦ã‚±ã‚¢å¯¾å¿œé…ç½®: {intensive_care_ratio:.1%} - åŒ»ç™‚ãƒ‹ãƒ¼ã‚ºã¸ã®å¯¾å¿œ")
                
        except Exception as e:
            log.warning(f"åˆ©ç”¨è€…é©å¿œåˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("åˆ©ç”¨è€…é©å¿œåˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["åˆ©ç”¨è€…é©å¿œã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_medical_coordination_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """åŒ»ç™‚é€£æºåˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # åŒ»ç™‚è·ç¨®é–“ã®é€£æºãƒ‘ã‚¿ãƒ¼ãƒ³
            if 'role' in long_df.columns and 'ds' in long_df.columns:
                medical_roles = ['çœ‹è­·å¸«', 'å‡†çœ‹è­·å¸«', 'åŒ»å¸«', 'è–¬å‰¤å¸«', 'ç†å­¦ç™‚æ³•å£«', 'ä½œæ¥­ç™‚æ³•å£«']
                
                # åŒæ—¥å‹¤å‹™ã§ã®åŒ»ç™‚è·ç¨®é€£æº
                daily_medical_teams = []
                for date in long_df['ds'].dt.date.unique():
                    daily_data = long_df[long_df['ds'].dt.date == date]
                    daily_medical_roles = []
                    
                    for role in medical_roles:
                        if daily_data['role'].str.contains(role, case=False, na=False).any():
                            daily_medical_roles.append(role)
                    
                    if len(daily_medical_roles) >= 2:
                        daily_medical_teams.append(len(daily_medical_roles))
                
                if daily_medical_teams:
                    avg_team_size = np.mean(daily_medical_teams)
                    coordination_days = len(daily_medical_teams)
                    total_days = long_df['ds'].dt.date.nunique()
                    coordination_ratio = coordination_days / total_days if total_days > 0 else 0
                    
                    constraints.append(f"åŒ»ç™‚ãƒãƒ¼ãƒ é€£æº: {coordination_ratio:.1%}ã®æ—¥ã§è¤‡æ•°åŒ»ç™‚è·é…ç½® (å¹³å‡{avg_team_size:.1f}è·ç¨®)")
                    
                    if coordination_ratio > 0.7:
                        constraints.append("åŒ»ç™‚é€£æºä½“åˆ¶å……å®Ÿ: åŒ…æ‹¬çš„ã‚±ã‚¢æä¾›å¯èƒ½")
                    else:
                        constraints.append("åŒ»ç™‚é€£æºå¼·åŒ–å¿…è¦: è·ç¨®é–“å”åƒã®å‘ä¸Šä½™åœ°")
            
            # çœ‹è­·å¸«ã¨ãƒªãƒãƒ“ãƒªå°‚é–€è·ã®å”åƒ
            if 'role' in long_df.columns and 'ds' in long_df.columns:
                nursing_staff = long_df[long_df['role'].str.contains('çœ‹è­·å¸«', case=False, na=False)]
                rehab_staff = long_df[long_df['role'].str.contains('ç†å­¦ç™‚æ³•å£«|ä½œæ¥­ç™‚æ³•å£«|PT|OT|ST', case=False, na=False)]
                
                if not nursing_staff.empty and not rehab_staff.empty:
                    # åŒæ—¥é…ç½®ã§ã®å”åƒæ©Ÿä¼š
                    nursing_dates = set(nursing_staff['ds'].dt.date)
                    rehab_dates = set(rehab_staff['ds'].dt.date)
                    collaboration_dates = nursing_dates.intersection(rehab_dates)
                    
                    collaboration_ratio = len(collaboration_dates) / len(nursing_dates.union(rehab_dates)) if nursing_dates.union(rehab_dates) else 0
                    constraints.append(f"çœ‹è­·ãƒ»ãƒªãƒãƒ“ãƒªå”åƒ: {collaboration_ratio:.1%} - ç·åˆçš„ã‚±ã‚¢è¨ˆç”»å®Ÿæ–½")
            
            # åŒ»ç™‚æƒ…å ±å…±æœ‰ã®ãŸã‚ã®ã‚·ãƒ•ãƒˆé‡è¤‡
            if 'ds' in long_df.columns and 'staff' in long_df.columns:
                # ã‚·ãƒ•ãƒˆé‡è¤‡æ™‚é–“ã§ã®æƒ…å ±å…±æœ‰æ©Ÿä¼š
                overlap_opportunities = 0
                total_shift_transitions = 0
                
                for date in long_df['ds'].dt.date.unique():
                    daily_shifts = long_df[long_df['ds'].dt.date == date]
                    if len(daily_shifts) > 1:
                        # æ™‚é–“å¸¯é‡è¤‡ã®æ¨å®š
                        morning_shift = daily_shifts[daily_shifts['ds'].dt.hour < 12]
                        afternoon_shift = daily_shifts[daily_shifts['ds'].dt.hour >= 12]
                        
                        if not morning_shift.empty and not afternoon_shift.empty:
                            total_shift_transitions += 1
                            
                            # ã‚¹ã‚¿ãƒƒãƒ•ã®é‡è¤‡ç¢ºèª
                            morning_staff = set(morning_shift['staff'])
                            afternoon_staff = set(afternoon_shift['staff'])
                            if morning_staff.intersection(afternoon_staff):
                                overlap_opportunities += 1
                
                if total_shift_transitions > 0:
                    overlap_ratio = overlap_opportunities / total_shift_transitions
                    constraints.append(f"ã‚·ãƒ•ãƒˆå¼•ãç¶™ãé‡è¤‡: {overlap_ratio:.1%} - åŒ»ç™‚æƒ…å ±å…±æœ‰æ©Ÿä¼š")
                
        except Exception as e:
            log.warning(f"åŒ»ç™‚é€£æºåˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("åŒ»ç™‚é€£æºåˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["åŒ»ç™‚é€£æºã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_care_documentation_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """ã‚±ã‚¢è¨˜éŒ²åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # è¨˜éŒ²ä½œæˆã«å¿…è¦ãªæ™‚é–“ç¢ºä¿ï¼ˆã‚·ãƒ•ãƒˆé•·åˆ†æï¼‰
            if 'ds' in long_df.columns:
                # å‹¤å‹™æ™‚é–“ã®æ¨å®šï¼ˆåŒä¸€æ—¥ã®æœ€å¤§ãƒ»æœ€å°æ™‚é–“å·®ï¼‰
                long_df['hour'] = pd.to_datetime(long_df['ds']).dt.hour
                
                daily_shift_spans = []
                for date in long_df['ds'].dt.date.unique():
                    daily_data = long_df[long_df['ds'].dt.date == date]
                    if len(daily_data) > 1:
                        min_hour = daily_data['hour'].min()
                        max_hour = daily_data['hour'].max()
                        span = max_hour - min_hour
                        daily_shift_spans.append(span)
                
                if daily_shift_spans:
                    avg_shift_span = np.mean(daily_shift_spans)
                    if avg_shift_span >= 8:
                        constraints.append(f"è¨˜éŒ²ä½œæˆæ™‚é–“ç¢ºä¿: å¹³å‡{avg_shift_span:.1f}æ™‚é–“å‹¤å‹™ - ååˆ†ãªè¨˜éŒ²æ™‚é–“")
                    else:
                        constraints.append(f"è¨˜éŒ²æ™‚é–“åˆ¶é™: å¹³å‡{avg_shift_span:.1f}æ™‚é–“å‹¤å‹™ - åŠ¹ç‡çš„è¨˜éŒ²ä½œæˆå¿…è¦")
            
            # è¨˜éŒ²è²¬ä»»è€…ã®é…ç½®
            if 'role' in long_df.columns:
                documentation_roles = ['çœ‹è­·å¸«', 'å‡†çœ‹è­·å¸«', 'ç®¡ç†è€…', 'ä¸»ä»»', 'ãƒªãƒ¼ãƒ€ãƒ¼']
                record_keepers = long_df[
                    long_df['role'].str.contains('|'.join(documentation_roles), case=False, na=False)
                ]
                
                if not record_keepers.empty:
                    record_coverage = len(record_keepers) / len(long_df)
                    constraints.append(f"è¨˜éŒ²è²¬ä»»è€…é…ç½®: {record_coverage:.1%} - ã‚±ã‚¢è¨˜éŒ²ã®å“è³ªç¢ºä¿")
                    
                    # è¨˜éŒ²è²¬ä»»è€…ã®å‹¤å‹™ç¶™ç¶šæ€§
                    if 'ds' in long_df.columns:
                        record_keeper_days = record_keepers['ds'].dt.date.nunique()
                        total_days = long_df['ds'].dt.date.nunique()
                        documentation_continuity = record_keeper_days / total_days if total_days > 0 else 0
                        
                        if documentation_continuity > 0.8:
                            constraints.append("è¨˜éŒ²ç¶™ç¶šæ€§è‰¯å¥½: ä¸€è²«ã—ãŸã‚±ã‚¢è¨˜éŒ²ç®¡ç†")
                        else:
                            constraints.append(f"è¨˜éŒ²ç¶™ç¶šæ€§è¦æ”¹å–„: {documentation_continuity:.1%}ã‚«ãƒãƒ¬ãƒƒã‚¸")
            
            # å¤šè·ç¨®è¨˜éŒ²ã®å¿…è¦æ€§
            if 'role' in long_df.columns and 'ds' in long_df.columns:
                # æ—¥åˆ¥ã®è·ç¨®å¤šæ§˜æ€§
                daily_role_diversity = []
                for date in long_df['ds'].dt.date.unique():
                    daily_data = long_df[long_df['ds'].dt.date == date]
                    unique_roles = daily_data['role'].nunique()
                    daily_role_diversity.append(unique_roles)
                
                if daily_role_diversity:
                    avg_role_diversity = np.mean(daily_role_diversity)
                    if avg_role_diversity >= 3:
                        constraints.append(f"å¤šè·ç¨®è¨˜éŒ²å¿…è¦: å¹³å‡{avg_role_diversity:.1f}è·ç¨®/æ—¥ - åŒ…æ‹¬çš„è¨˜éŒ²ä½œæˆ")
                    else:
                        constraints.append(f"è·ç¨®é›†ç´„è¨˜éŒ²: å¹³å‡{avg_role_diversity:.1f}è·ç¨®/æ—¥ - åŠ¹ç‡çš„è¨˜éŒ²ç®¡ç†")
                
        except Exception as e:
            log.warning(f"ã‚±ã‚¢è¨˜éŒ²åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("ã‚±ã‚¢è¨˜éŒ²åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["ã‚±ã‚¢è¨˜éŒ²ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_quality_improvement_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """å“è³ªå‘ä¸Šåˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # ç ”ä¿®ãƒ»æ•™è‚²æ©Ÿä¼šã®ç¢ºä¿ï¼ˆãƒ™ãƒ†ãƒ©ãƒ³ãƒ»æ–°äººæ··åœ¨åˆ†æï¼‰
            if 'employment' in long_df.columns and 'ds' in long_df.columns:
                # é›‡ç”¨å½¢æ…‹ã«ã‚ˆã‚‹çµŒé¨“æ¨å®š
                experienced_types = ['æ­£ç¤¾å“¡', 'æ­£è¦', 'å¸¸å‹¤']
                learning_types = ['ãƒ‘ãƒ¼ãƒˆ', 'ã‚¢ãƒ«ãƒã‚¤ãƒˆ', 'éå¸¸å‹¤']
                
                # åŒæ—¥é…ç½®ã§ã®æ•™è‚²æ©Ÿä¼š
                education_days = 0
                total_days = long_df['ds'].dt.date.nunique()
                
                for date in long_df['ds'].dt.date.unique():
                    daily_data = long_df[long_df['ds'].dt.date == date]
                    
                    has_experienced = daily_data['employment'].str.contains('|'.join(experienced_types), case=False, na=False).any()
                    has_learning = daily_data['employment'].str.contains('|'.join(learning_types), case=False, na=False).any()
                    
                    if has_experienced and has_learning:
                        education_days += 1
                
                education_ratio = education_days / total_days if total_days > 0 else 0
                constraints.append(f"æ•™è‚²æ©Ÿä¼šæä¾›: {education_ratio:.1%}ã®æ—¥ã§ãƒ™ãƒ†ãƒ©ãƒ³ãƒ»æ–°äººæ··åœ¨ - æŠ€èƒ½å‘ä¸Šç’°å¢ƒ")
                
                if education_ratio > 0.6:
                    constraints.append("ç¶™ç¶šçš„æ•™è‚²ä½“åˆ¶: å“è³ªå‘ä¸Šã®åŸºç›¤ç¢ºç«‹")
                else:
                    constraints.append("æ•™è‚²æ©Ÿä¼šæ‹¡å¤§å¿…è¦: æ··åœ¨é…ç½®ã®å¢—åŠ æ¤œè¨")
            
            # å“è³ªæ”¹å–„ã®ãŸã‚ã®æŒ¯ã‚Šè¿”ã‚Šæ™‚é–“
            if 'staff' in long_df.columns and 'ds' in long_df.columns:
                # åŒä¸€ã‚¹ã‚¿ãƒƒãƒ•ã®é€£ç¶šå‹¤å‹™ã§ã®æŒ¯ã‚Šè¿”ã‚Šæ©Ÿä¼š
                reflection_opportunities = 0
                
                for staff_id in long_df['staff'].unique():
                    staff_dates = pd.to_datetime(long_df[long_df['staff'] == staff_id]['ds']).sort_values()
                    if len(staff_dates) > 1:
                        consecutive_periods = self._find_consecutive_work_periods(staff_dates)
                        reflection_opportunities += len([p for p in consecutive_periods if p >= 3])  # 3æ—¥ä»¥ä¸Šé€£ç¶š
                
                total_staff = long_df['staff'].nunique()
                reflection_ratio = reflection_opportunities / total_staff if total_staff > 0 else 0
                constraints.append(f"æŒ¯ã‚Šè¿”ã‚Šæ©Ÿä¼š: {reflection_ratio:.1%}ã®ã‚¹ã‚¿ãƒƒãƒ•ã«é€£ç¶šå‹¤å‹™æœŸé–“ - ç¶™ç¶šçš„æ”¹å–„")
            
            # å“è³ªæŒ‡æ¨™ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ä½“åˆ¶
            if 'role' in long_df.columns:
                # å“è³ªç®¡ç†æ‹…å½“è€…ã®é…ç½®
                quality_roles = ['ä¸»ä»»', 'ãƒªãƒ¼ãƒ€ãƒ¼', 'å“è³ª', 'QC', 'ç®¡ç†è€…', 'çµ±æ‹¬']
                quality_staff = long_df[
                    long_df['role'].str.contains('|'.join(quality_roles), case=False, na=False)
                ]
                
                if not quality_staff.empty:
                    quality_monitoring_ratio = len(quality_staff) / len(long_df)
                    constraints.append(f"å“è³ªç›£è¦–ä½“åˆ¶: {quality_monitoring_ratio:.1%} - ç¶™ç¶šçš„å“è³ªæ”¹å–„")
                    
                    # å“è³ªç®¡ç†è€…ã®å®šæœŸé…ç½®
                    if 'ds' in long_df.columns:
                        quality_coverage_days = quality_staff['ds'].dt.date.nunique()
                        total_days = long_df['ds'].dt.date.nunique()
                        quality_coverage = quality_coverage_days / total_days if total_days > 0 else 0
                        
                        if quality_coverage > 0.5:
                            constraints.append("å®šæœŸå“è³ªç›£è¦–: ç¶™ç¶šçš„æ”¹å–„ä½“åˆ¶ç¢ºç«‹")
                        else:
                            constraints.append("å“è³ªç›£è¦–å¼·åŒ–å¿…è¦: å®šæœŸçš„ãªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ä½“åˆ¶æ§‹ç¯‰")
            
            # ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»æ”¹å–„ææ¡ˆã®ç’°å¢ƒ
            if 'role' in long_df.columns and 'employment' in long_df.columns:
                # å¤šæ§˜ãªèƒŒæ™¯ã‚’æŒã¤ã‚¹ã‚¿ãƒƒãƒ•ã®æ··åœ¨
                role_variety = long_df['role'].nunique()
                employment_variety = long_df['employment'].nunique()
                
                diversity_score = (role_variety + employment_variety) / len(long_df) * 100
                if diversity_score > 10:
                    constraints.append(f"å¤šæ§˜æ€§ç’°å¢ƒ: ã‚¹ã‚³ã‚¢{diversity_score:.1f} - ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³å‰µå‡ºå¯èƒ½")
                else:
                    constraints.append(f"å‡è³ªæ€§ç’°å¢ƒ: ã‚¹ã‚³ã‚¢{diversity_score:.1f} - å®‰å®šæ€§é‡è¦–")
                
        except Exception as e:
            log.warning(f"å“è³ªå‘ä¸Šåˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("å“è³ªå‘ä¸Šåˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["å“è³ªå‘ä¸Šã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _calculate_consecutive_workdays(self, dates: pd.Series) -> int:
        """é€£ç¶šå‹¤å‹™æ—¥æ•°ã®è¨ˆç®—"""
        if len(dates) <= 1:
            return len(dates)
        
        sorted_dates = sorted(dates)
        max_consecutive = 1
        current_consecutive = 1
        
        for i in range(1, len(sorted_dates)):
            if (sorted_dates[i] - sorted_dates[i-1]).days == 1:
                current_consecutive += 1
                max_consecutive = max(max_consecutive, current_consecutive)
            else:
                current_consecutive = 1
        
        return max_consecutive
    
    def _analyze_weekly_staff_changes(self, long_df: pd.DataFrame) -> List[int]:
        """é€±æ¬¡ã‚¹ã‚¿ãƒƒãƒ•å¤‰æ›´æ•°ã®åˆ†æ"""
        if 'ds' not in long_df.columns or 'staff' not in long_df.columns:
            return []
        
        long_df['week'] = pd.to_datetime(long_df['ds']).dt.isocalendar().week
        weekly_changes = []
        
        weeks = sorted(long_df['week'].unique())
        for i in range(1, len(weeks)):
            prev_week_staff = set(long_df[long_df['week'] == weeks[i-1]]['staff'])
            curr_week_staff = set(long_df[long_df['week'] == weeks[i]]['staff'])
            
            # æ–°è¦è¿½åŠ ã•ã‚ŒãŸã‚¹ã‚¿ãƒƒãƒ•æ•°
            new_staff = len(curr_week_staff - prev_week_staff)
            weekly_changes.append(new_staff)
        
        return weekly_changes
    
    def _find_consecutive_work_periods(self, dates: pd.Series) -> List[int]:
        """é€£ç¶šå‹¤å‹™æœŸé–“ã®ç™ºè¦‹"""
        if len(dates) <= 1:
            return [len(dates)]
        
        sorted_dates = sorted(dates)
        periods = []
        current_period = 1
        
        for i in range(1, len(sorted_dates)):
            if (sorted_dates[i] - sorted_dates[i-1]).days == 1:
                current_period += 1
            else:
                periods.append(current_period)
                current_period = 1
        
        periods.append(current_period)
        return periods
    
    def _generate_human_readable_results(self, mece_facts: Dict[str, List[str]], long_df: pd.DataFrame) -> Dict[str, Any]:
        """äººé–“å¯èª­å½¢å¼ã®çµæœç”Ÿæˆ"""
        
        # äº‹å®Ÿç·æ•°è¨ˆç®—
        total_facts = sum(len(facts) for facts in mece_facts.values())
        
        # å“è³ªé‡è¦åº¦åˆ¥åˆ†é¡
        high_importance = [fact for facts in mece_facts.values() for fact in facts if any(keyword in fact for keyword in ['å®‰å…¨', 'ç¶™ç¶š', 'å°‚é–€', 'ç›£ç£'])]
        medium_importance = [fact for facts in mece_facts.values() for fact in facts if any(keyword in fact for keyword in ['é€£æº', 'è¨˜éŒ²', 'é©å¿œ'])]
        improvement_focus = [fact for facts in mece_facts.values() for fact in facts if any(keyword in fact for keyword in ['å‘ä¸Š', 'æ”¹å–„', 'æ•™è‚²', 'å“è³ª'])]
        
        return {
            'æŠ½å‡ºäº‹å®Ÿã‚µãƒãƒªãƒ¼': {
                'ç·äº‹å®Ÿæ•°': total_facts,
                'åˆ†æè»¸': f'è»¸{self.axis_number}: {self.axis_name}',
                'åˆ†æå¯¾è±¡ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°': len(long_df),
                'MECEã‚«ãƒ†ã‚´ãƒªãƒ¼æ•°': len(mece_facts),
                **{category: len(facts) for category, facts in mece_facts.items()}
            },
            'MECEåˆ†è§£äº‹å®Ÿ': mece_facts,
            'å“è³ªé‡è¦åº¦åˆ¥åˆ†é¡': {
                'é«˜é‡è¦åº¦äº‹å®Ÿï¼ˆå®‰å…¨ãƒ»ç¶™ç¶šæ€§ï¼‰': high_importance,
                'ä¸­é‡è¦åº¦äº‹å®Ÿï¼ˆé€£æºãƒ»è¨˜éŒ²ï¼‰': medium_importance,
                'æ”¹å–„é‡ç‚¹äº‹å®Ÿï¼ˆå‘ä¸Šãƒ»æ•™è‚²ï¼‰': improvement_focus,
                'è¦æ¤œè¨¼äº‹å®Ÿ': [fact for facts in mece_facts.values() for fact in facts if 'ã‚¨ãƒ©ãƒ¼' in fact or 'æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ' in fact]
            }
        }
    
    def _generate_machine_readable_constraints(self, mece_facts: Dict[str, List[str]], long_df: pd.DataFrame) -> Dict[str, Any]:
        """æ©Ÿæ¢°å¯èª­å½¢å¼ã®åˆ¶ç´„ç”Ÿæˆ"""
        
        hard_constraints = []
        soft_constraints = []
        preferences = []
        
        # MECEã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥åˆ¶ç´„åˆ†é¡
        for category, facts in mece_facts.items():
            for i, fact in enumerate(facts):
                constraint_id = f"axis5_{category.lower().replace('åˆ¶ç´„', '')}_{i+1}"
                
                # åŒ»ç™‚ãƒ»ã‚±ã‚¢å“è³ªã®åˆ¶ç´„å¼·åº¦åˆ¤å®š
                if any(keyword in fact for keyword in ['å®‰å…¨', 'å¿…è¦', 'ç›£ç£', 'ç¶™ç¶šæ€§', 'å°‚é–€']):
                    hard_constraints.append({
                        'id': constraint_id,
                        'type': 'medical_care_quality',
                        'category': category,
                        'description': fact,
                        'priority': 'high',
                        'confidence': 0.9,
                        'quality_aspect': self._categorize_quality_aspect(fact)
                    })
                elif any(keyword in fact for keyword in ['æ”¹å–„', 'å‘ä¸Š', 'æœ€é©åŒ–', 'æ•™è‚²', 'é€£æº']):
                    soft_constraints.append({
                        'id': constraint_id,
                        'type': 'medical_care_quality',
                        'category': category,
                        'description': fact,
                        'priority': 'medium',
                        'confidence': 0.7,
                        'quality_aspect': self._categorize_quality_aspect(fact)
                    })
                else:
                    preferences.append({
                        'id': constraint_id,
                        'type': 'medical_care_quality',
                        'category': category,
                        'description': fact,
                        'priority': 'low',
                        'confidence': 0.5,
                        'quality_aspect': self._categorize_quality_aspect(fact)
                    })
        
        return {
            'hard_constraints': hard_constraints,
            'soft_constraints': soft_constraints,
            'preferences': preferences,
            'constraint_relationships': [
                {
                    'relationship_id': 'safety_supervision_dependency',
                    'type': 'requires',
                    'from_category': 'åŒ»ç™‚å®‰å…¨åˆ¶ç´„',
                    'to_category': 'å“è³ªç›£ç£åˆ¶ç´„',
                    'description': 'åŒ»ç™‚å®‰å…¨ã®ç¢ºä¿ã«ã¯å“è³ªç›£ç£ãŒå¿…è¦'
                },
                {
                    'relationship_id': 'continuity_expertise_synergy',
                    'type': 'enhances',
                    'from_category': 'ã‚±ã‚¢ç¶™ç¶šæ€§åˆ¶ç´„',
                    'to_category': 'å°‚é–€æ€§é…ç½®åˆ¶ç´„',
                    'description': 'ã‚±ã‚¢ç¶™ç¶šæ€§ã¨å°‚é–€æ€§é…ç½®ã®ç›¸ä¹—åŠ¹æœ'
                }
            ],
            'validation_rules': [
                {
                    'rule_id': 'axis5_medical_safety_check',
                    'description': 'åŒ»ç™‚å®‰å…¨åŸºæº–ãŒæº€ãŸã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª',
                    'validation_type': 'safety_compliance'
                },
                {
                    'rule_id': 'axis5_care_continuity_check',
                    'description': 'ã‚±ã‚¢ç¶™ç¶šæ€§ãŒé©åˆ‡ã«ä¿ãŸã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª',
                    'validation_type': 'continuity_maintenance'
                },
                {
                    'rule_id': 'axis5_quality_supervision_check',
                    'description': 'å“è³ªç›£ç£ä½“åˆ¶ãŒæ©Ÿèƒ½ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª',
                    'validation_type': 'quality_oversight'
                }
            ]
        }
    
    def _categorize_quality_aspect(self, fact: str) -> str:
        """å“è³ªå´é¢ã®åˆ†é¡"""
        if any(keyword in fact for keyword in ['å®‰å…¨', 'safety', 'åŒ»ç™‚å®‰å…¨']):
            return 'safety'
        elif any(keyword in fact for keyword in ['ç¶™ç¶š', 'ä¸€è²«', 'continuity']):
            return 'continuity'
        elif any(keyword in fact for keyword in ['å°‚é–€', 'æŠ€èƒ½', 'expertise']):
            return 'expertise'
        elif any(keyword in fact for keyword in ['ç›£ç£', 'ç®¡ç†', 'supervision']):
            return 'supervision'
        elif any(keyword in fact for keyword in ['é€£æº', 'å”åƒ', 'coordination']):
            return 'coordination'
        elif any(keyword in fact for keyword in ['è¨˜éŒ²', 'æ–‡æ›¸', 'documentation']):
            return 'documentation'
        elif any(keyword in fact for keyword in ['æ”¹å–„', 'å‘ä¸Š', 'improvement']):
            return 'improvement'
        else:
            return 'general'
    
    def _generate_extraction_metadata(self, long_df: pd.DataFrame, wt_df: pd.DataFrame, 
                                     mece_facts: Dict[str, List[str]]) -> Dict[str, Any]:
        """æŠ½å‡ºãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
        
        # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®è¨ˆç®—
        date_range = {}
        if 'ds' in long_df.columns:
            dates = pd.to_datetime(long_df['ds'])
            date_range = {
                'start_date': dates.min().isoformat(),
                'end_date': dates.max().isoformat(),
                'total_days': (dates.max() - dates.min()).days
            }
        
        # åŒ»ç™‚ãƒ»ã‚±ã‚¢å“è³ªæŒ‡æ¨™
        quality_indicators = {
            'medical_staff_ratio': len(long_df[long_df['role'].str.contains('çœ‹è­·å¸«|åŒ»å¸«', case=False, na=False)]) / len(long_df) if len(long_df) > 0 else 0,
            'specialized_care_coverage': len([f for facts in mece_facts.values() for f in facts if 'å°‚é–€' in f]) / sum(len(facts) for facts in mece_facts.values()) if sum(len(facts) for facts in mece_facts.values()) > 0 else 0,
            'safety_concern_ratio': len([f for facts in mece_facts.values() for f in facts if 'å®‰å…¨' in f or 'ãƒªã‚¹ã‚¯' in f]) / sum(len(facts) for facts in mece_facts.values()) if sum(len(facts) for facts in mece_facts.values()) > 0 else 0
        }
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ªæŒ‡æ¨™
        data_quality = {
            'completeness': 1.0 - (long_df.isnull().sum().sum() / (len(long_df) * len(long_df.columns))),
            'record_count': len(long_df),
            'unique_staff_count': long_df['staff'].nunique() if 'staff' in long_df.columns else 0,
            'unique_roles_count': long_df['role'].nunique() if 'role' in long_df.columns else 0,
            'quality_focus_ratio': len([f for facts in mece_facts.values() for f in facts if any(q in f for q in ['å“è³ª', 'å®‰å…¨', 'ç¶™ç¶š', 'å°‚é–€'])]) / sum(len(facts) for facts in mece_facts.values()) if sum(len(facts) for facts in mece_facts.values()) > 0 else 0
        }
        
        return {
            'extraction_timestamp': datetime.now().isoformat(),
            'axis_info': {
                'axis_number': self.axis_number,
                'axis_name': self.axis_name,
                'mece_categories': list(mece_facts.keys()),
                'focus_area': 'åŒ»ç™‚ãƒ»ã‚±ã‚¢å“è³ªå‘ä¸Šåˆ¶ç´„'
            },
            'data_period': date_range,
            'quality_indicators': quality_indicators,
            'data_quality': data_quality,
            'extraction_statistics': {
                'total_facts_extracted': sum(len(facts) for facts in mece_facts.values()),
                'safety_related_facts': len([f for facts in mece_facts.values() for f in facts if 'å®‰å…¨' in f]),
                'quality_improvement_facts': len([f for facts in mece_facts.values() for f in facts if 'æ”¹å–„' in f or 'å‘ä¸Š' in f]),
                'categories_with_facts': len([cat for cat, facts in mece_facts.items() if facts and not any('æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ' in f for f in facts)])
            }
        }