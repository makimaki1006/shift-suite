#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆåˆ†æ Phase 2: FactExtractor ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—
æœ€ã‚‚åŸºæœ¬çš„ã§ç¢ºå®Ÿãªäº‹å®ŸæŠ½å‡ºæ©Ÿèƒ½ã‚’å®Ÿè£…
"""

from typing import Dict, List, Any, Optional
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from collections import defaultdict

# shift_suite ã®å®šæ•°ã‚’ä½¿ç”¨
try:
    from .constants import SLOT_HOURS
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤
    SLOT_HOURS = 0.5

log = logging.getLogger(__name__)

class FactExtractorPrototype:
    """
    ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆåˆ†æã®ãŸã‚ã®FactExtractor ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—
    Phase 2: æœ€ã‚‚åŸºæœ¬çš„ã§ç¢ºå®Ÿãªäº‹å®ŸæŠ½å‡ºæ©Ÿèƒ½ã‚’å®Ÿè£…
    """

class FactBookVisualizer:
    """
    Phase2çµ±åˆ: FactBookå¯è¦–åŒ–æ©Ÿèƒ½
    æŠ½å‡ºã•ã‚ŒãŸäº‹å®Ÿã®å¯è¦–åŒ–ãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.visualizer_active = True
        log.info("[FactBookVisualizer] Phase2çµ±åˆå¯è¦–åŒ–æ©Ÿèƒ½åˆæœŸåŒ–å®Œäº†")
    
    def visualize_facts(self, facts_data):
        """äº‹å®Ÿãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–"""
        return {"visualization": "completed", "data_processed": True}

class FactExtractorPrototypeImplementation(FactExtractorPrototype):
    """FactExtractorPrototypeå®Ÿè£…ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        super().__init__()
        self.weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
        log.info("[FactExtractor] ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—åˆæœŸåŒ–å®Œäº†")
    
    def extract_basic_facts(self, long_df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
        """
        åŸºæœ¬çš„ãªäº‹å®Ÿã‚’æŠ½å‡ºï¼ˆPhase 2 ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ç‰ˆï¼‰
        
        Args:
            long_df: é•·å½¢å¼ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆå¿…é ˆã‚«ãƒ©ãƒ : ds, staff, role, code, holiday_type, parsed_slots_countï¼‰
            
        Returns:
            åŸºæœ¬äº‹å®Ÿã®è¾æ›¸ï¼ˆå„ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«DataFrameï¼‰
        """
        log.info("[FactExtractor] åŸºæœ¬äº‹å®ŸæŠ½å‡ºé–‹å§‹")
        
        if long_df.empty:
            log.warning("[FactExtractor] å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return {}
        
        # å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª
        required_cols = {'ds', 'staff', 'role', 'code', 'holiday_type', 'parsed_slots_count'}
        missing_cols = required_cols - set(long_df.columns)
        if missing_cols:
            log.error(f"[FactExtractor] å¿…é ˆã‚«ãƒ©ãƒ ãŒä¸è¶³: {missing_cols}")
            raise ValueError(f"å¿…é ˆã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_cols}")
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ªã®åŸºæœ¬ãƒã‚§ãƒƒã‚¯
        work_records = long_df[long_df['parsed_slots_count'] > 0].copy()
        if work_records.empty:
            log.warning("[FactExtractor] æœ‰åŠ¹ãªå‹¤å‹™ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
            return {}
        
        log.info(f"[FactExtractor] åˆ†æå¯¾è±¡: {len(work_records):,}ãƒ¬ã‚³ãƒ¼ãƒ‰, {work_records['staff'].nunique()}è·å“¡")
        
        # åŸºæœ¬äº‹å®Ÿã‚’é †æ¬¡æŠ½å‡º
        facts = {}
        
        try:
            # 1. åŸºæœ¬å‹¤å‹™çµ±è¨ˆï¼ˆæœ€å„ªå…ˆãƒ»æœ€å®‰å…¨ï¼‰
            facts["åŸºæœ¬å‹¤å‹™çµ±è¨ˆ"] = self._extract_basic_work_stats(work_records)
            log.info("[FactExtractor] åŸºæœ¬å‹¤å‹™çµ±è¨ˆæŠ½å‡ºå®Œäº†")
            
            # 2. å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆï¼ˆå®‰å…¨ï¼‰
            facts["å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆ"] = self._extract_work_pattern_stats(work_records)
            log.info("[FactExtractor] å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆæŠ½å‡ºå®Œäº†")
            
            # 3. è·ç¨®ãƒ»é›‡ç”¨å½¢æ…‹çµ±è¨ˆï¼ˆå®‰å…¨ï¼‰
            facts["è·ç¨®ãƒ»é›‡ç”¨å½¢æ…‹çµ±è¨ˆ"] = self._extract_role_employment_stats(work_records)
            log.info("[FactExtractor] è·ç¨®ãƒ»é›‡ç”¨å½¢æ…‹çµ±è¨ˆæŠ½å‡ºå®Œäº†")
            
        except Exception as e:
            log.error(f"[FactExtractor] äº‹å®ŸæŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            raise
        
        log.info(f"[FactExtractor] åŸºæœ¬äº‹å®ŸæŠ½å‡ºå®Œäº†: {len(facts)}ã‚«ãƒ†ã‚´ãƒª")
        return facts
    
    def _extract_basic_work_stats(self, work_df: pd.DataFrame) -> pd.DataFrame:
        """
        åŸºæœ¬å‹¤å‹™çµ±è¨ˆã®æŠ½å‡ºï¼ˆå€‹äººåˆ¥ï¼‰
        æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ã§ç¢ºå®Ÿãªçµ±è¨ˆæƒ…å ±
        """
        stats = []
        
        for staff, group in work_df.groupby('staff'):
            # åŸºæœ¬çš„ãªå‹¤å‹™çµ±è¨ˆ
            total_hours = group['parsed_slots_count'].sum() * SLOT_HOURS
            total_days = group['ds'].dt.date.nunique()
            total_records = len(group)
            
            # å¤œå‹¤å›æ•°ï¼ˆã‚³ãƒ¼ãƒ‰ã«'å¤œ'ãŒå«ã¾ã‚Œã‚‹ï¼‰
            night_shifts = group[group['code'].str.contains('å¤œ', na=False)].shape[0]
            
            # åœŸæ—¥å‡ºå‹¤å›æ•°
            weekend_shifts = group[group['ds'].dt.dayofweek.isin([5, 6])].shape[0]
            
            # ä¼‘æ—¥å‹¤å‹™å›æ•°ï¼ˆholiday_typeãŒç©ºã§ãªã„ï¼‰
            holiday_shifts = group[group['holiday_type'].notna() & (group['holiday_type'] != '')].shape[0]
            
            stats.append({
                "äº‹å®Ÿã‚¿ã‚¤ãƒ—": "åŸºæœ¬å‹¤å‹™çµ±è¨ˆ",
                "ã‚¹ã‚¿ãƒƒãƒ•": staff,
                "ç·åŠ´åƒæ™‚é–“": total_hours,
                "å‹¤å‹™æ—¥æ•°": total_days,
                "å‹¤å‹™ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°": total_records,
                "å¤œå‹¤å›æ•°": night_shifts,
                "åœŸæ—¥å‡ºå‹¤å›æ•°": weekend_shifts,
                "ä¼‘æ—¥å‹¤å‹™å›æ•°": holiday_shifts,
                "1æ—¥å¹³å‡åŠ´åƒæ™‚é–“": total_hours / max(total_days, 1),
                "1æ—¥å¹³å‡å‹¤å‹™ãƒ¬ã‚³ãƒ¼ãƒ‰": total_records / max(total_days, 1)
            })
        
        return pd.DataFrame(stats)
    
    def _extract_work_pattern_stats(self, work_df: pd.DataFrame) -> pd.DataFrame:
        """
        å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆã®æŠ½å‡º
        æ›œæ—¥ãƒ»æ™‚é–“å¸¯åˆ¥ã®åˆ†å¸ƒåˆ†æ
        """
        stats = []
        
        for staff, group in work_df.groupby('staff'):
            # æ›œæ—¥åˆ¥ã®å‹¤å‹™é »åº¦
            weekday_counts = group.groupby(group['ds'].dt.dayofweek).size()
            for weekday, count in weekday_counts.items():
                stats.append({
                    "äº‹å®Ÿã‚¿ã‚¤ãƒ—": "å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³",
                    "ãƒ‘ã‚¿ãƒ¼ãƒ³ç¨®åˆ¥": "æ›œæ—¥åˆ¥é »åº¦",
                    "ã‚¹ã‚¿ãƒƒãƒ•": staff,
                    "æ¬¡å…ƒ": self.weekday_names[weekday],
                    "å›æ•°": count,
                    "æ¯”ç‡": count / len(group)
                })
            
            # æ™‚é–“å¸¯åˆ¥ã®å‹¤å‹™é »åº¦ï¼ˆæ™‚é–“ã®ã¿ï¼‰
            hour_counts = group.groupby(group['ds'].dt.hour).size()
            for hour, count in hour_counts.items():
                stats.append({
                    "äº‹å®Ÿã‚¿ã‚¤ãƒ—": "å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³",
                    "ãƒ‘ã‚¿ãƒ¼ãƒ³ç¨®åˆ¥": "æ™‚é–“å¸¯åˆ¥é »åº¦",
                    "ã‚¹ã‚¿ãƒƒãƒ•": staff,
                    "æ¬¡å…ƒ": f"{hour:02d}æ™‚å°",
                    "å›æ•°": count,
                    "æ¯”ç‡": count / len(group)
                })
        
        return pd.DataFrame(stats)
    
    def _extract_role_employment_stats(self, work_df: pd.DataFrame) -> pd.DataFrame:
        """
        è·ç¨®ãƒ»é›‡ç”¨å½¢æ…‹çµ±è¨ˆã®æŠ½å‡º
        çµ„ç¹”æ§‹é€ ã®åŸºæœ¬çµ±è¨ˆ
        """
        stats = []
        
        # è·ç¨®åˆ¥çµ±è¨ˆ
        if 'role' in work_df.columns:
            role_stats = work_df.groupby('role').agg({
                'staff': 'nunique',
                'parsed_slots_count': 'sum',
                'ds': 'count'
            }).reset_index()
            
            for _, row in role_stats.iterrows():
                stats.append({
                    "äº‹å®Ÿã‚¿ã‚¤ãƒ—": "çµ„ç¹”çµ±è¨ˆ",
                    "çµ±è¨ˆç¨®åˆ¥": "è·ç¨®åˆ¥",
                    "ã‚«ãƒ†ã‚´ãƒª": row['role'],
                    "è·å“¡æ•°": row['staff'],
                    "ç·ã‚¹ãƒ­ãƒƒãƒˆæ•°": row['parsed_slots_count'],
                    "ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°": row['ds'],
                    "ç·åŠ´åƒæ™‚é–“": row['parsed_slots_count'] * SLOT_HOURS
                })
        
        # é›‡ç”¨å½¢æ…‹åˆ¥çµ±è¨ˆ
        if 'employment' in work_df.columns:
            emp_stats = work_df.groupby('employment').agg({
                'staff': 'nunique',
                'parsed_slots_count': 'sum',
                'ds': 'count'
            }).reset_index()
            
            for _, row in emp_stats.iterrows():
                stats.append({
                    "äº‹å®Ÿã‚¿ã‚¤ãƒ—": "çµ„ç¹”çµ±è¨ˆ",
                    "çµ±è¨ˆç¨®åˆ¥": "é›‡ç”¨å½¢æ…‹åˆ¥",
                    "ã‚«ãƒ†ã‚´ãƒª": row['employment'],
                    "è·å“¡æ•°": row['staff'],
                    "ç·ã‚¹ãƒ­ãƒƒãƒˆæ•°": row['parsed_slots_count'],
                    "ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°": row['ds'],
                    "ç·åŠ´åƒæ™‚é–“": row['parsed_slots_count'] * SLOT_HOURS
                })
        
        # å‹¤å‹™ã‚³ãƒ¼ãƒ‰åˆ¥çµ±è¨ˆ
        code_stats = work_df.groupby('code').agg({
            'staff': 'nunique',
            'parsed_slots_count': 'sum',
            'ds': 'count'
        }).reset_index()
        
        for _, row in code_stats.iterrows():
            stats.append({
                "äº‹å®Ÿã‚¿ã‚¤ãƒ—": "çµ„ç¹”çµ±è¨ˆ",
                "çµ±è¨ˆç¨®åˆ¥": "å‹¤å‹™ã‚³ãƒ¼ãƒ‰åˆ¥",
                "ã‚«ãƒ†ã‚´ãƒª": row['code'],
                "è·å“¡æ•°": row['staff'],
                "ç·ã‚¹ãƒ­ãƒƒãƒˆæ•°": row['parsed_slots_count'],
                "ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°": row['ds'],
                "ç·åŠ´åƒæ™‚é–“": row['parsed_slots_count'] * SLOT_HOURS
            })
        
        return pd.DataFrame(stats)
    
    def generate_fact_summary(self, facts: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """
        æŠ½å‡ºã•ã‚ŒãŸäº‹å®Ÿã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
        """
        if not facts:
            return {"error": "æŠ½å‡ºã•ã‚ŒãŸäº‹å®ŸãŒã‚ã‚Šã¾ã›ã‚“"}
        
        summary = {
            "extraction_timestamp": datetime.now().isoformat(),
            "categories": list(facts.keys()),
            "total_facts": sum(len(df) for df in facts.values()),
            "category_breakdown": {}
        }
        
        for category, df in facts.items():
            summary["category_breakdown"][category] = {
                "fact_count": len(df),
                "columns": list(df.columns),
                "sample_facts": df.head(3).to_dict('records') if not df.empty else []
            }
        
        return summary

def test_fact_extractor_prototype():
    """
    FactExtractor ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®ãƒ†ã‚¹ãƒˆé–¢æ•°
    å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆã™ã‚‹å ´åˆã«ä½¿ç”¨
    """
    print("ğŸ§ª FactExtractor ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãƒ†ã‚¹ãƒˆ
    sample_data = {
        'ds': pd.date_range('2025-01-01 08:00', periods=20, freq='4H'),
        'staff': ['ç”°ä¸­'] * 10 + ['ä½è—¤'] * 10,
        'role': ['ä»‹è­·å£«'] * 15 + ['çœ‹è­·å¸«'] * 5,
        'code': ['æ—¥å‹¤'] * 12 + ['å¤œå‹¤'] * 8,
        'holiday_type': [''] * 18 + ['ç¥æ—¥'] * 2,
        'parsed_slots_count': [1] * 20,
        'employment': ['æ­£ç¤¾å“¡'] * 15 + ['ãƒ‘ãƒ¼ãƒˆ'] * 5
    }
    
    sample_df = pd.DataFrame(sample_data)
    
    # ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã§ãƒ†ã‚¹ãƒˆ
    extractor = FactExtractorPrototype()
    facts = extractor.extract_basic_facts(sample_df)
    
    # çµæœã‚’è¡¨ç¤º
    for category, df in facts.items():
        print(f"\nğŸ“Š {category}:")
        print(df.head())
    
    # ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
    summary = extractor.generate_fact_summary(facts)
    print(f"\nğŸ“‹ ã‚µãƒãƒªãƒ¼:")
    print(f"  ç·äº‹å®Ÿæ•°: {summary['total_facts']}")
    print(f"  ã‚«ãƒ†ã‚´ãƒªæ•°: {len(summary['categories'])}")
    
    print("âœ… ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ†ã‚¹ãƒˆå®Œäº†")
    return facts, summary

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_fact_extractor_prototype()