#!/usr/bin/env python3
"""
å®¢è¦³çš„ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
ãƒ—ãƒ­ã®è¦³ç‚¹ã§å…¨ã‚·ã‚¹ãƒ†ãƒ ã®å‹•çš„ä¸€è²«æ€§ã‚’æ¤œè¨¼
"""

import pandas as pd
from pathlib import Path
import sys
import os
import numpy as np
from datetime import datetime, timedelta
import traceback

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, os.getcwd())

def objective_consistency_check():
    """å®¢è¦³çš„ãªä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯"""
    print("=== å®¢è¦³çš„ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ—ãƒ­è¦³ç‚¹ï¼‰ ===")
    
    # 1. ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒã¨åŸºæœ¬æ§‹æˆã®ç¢ºèª
    print("\nã€1. ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒç¢ºèªã€‘")
    current_dir = Path.cwd()
    print(f"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {current_dir}")
    
    # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    critical_files = {
        "Excelå…¥åŠ›": "ã‚·ãƒ§ãƒ¼ãƒˆ_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿.xlsx",
        "ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰": "dash_app.py", 
        "ãƒ‡ãƒ¼ã‚¿å‡¦ç†": "shift_suite/tasks/io_excel.py",
        "è¨­å®š": "shift_suite/tasks/utils.py"
    }
    
    file_status = {}
    for name, filepath in critical_files.items():
        path = Path(filepath)
        exists = path.exists()
        file_status[name] = {
            "exists": exists,
            "path": str(path),
            "size": path.stat().st_size if exists else 0
        }
        status = "âœ…" if exists else "âŒ"
        print(f"  {status} {name}: {filepath}")
    
    # 2. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®å‹•çš„æ¤œè¨¼
    print("\nã€2. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§å‹•çš„æ¤œè¨¼ã€‘")
    
    try:
        # shift_suiteãŒæ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã‚‹ã‹
        from shift_suite.tasks.io_excel import ingest_excel
        print("âœ… shift_suite.tasks.io_excel ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        
        excel_path = Path("ã‚·ãƒ§ãƒ¼ãƒˆ_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿.xlsx")
        if not excel_path.exists():
            print("âŒ å…¥åŠ›Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’å®Ÿè¡Œ
        excel_file = pd.ExcelFile(excel_path, engine="openpyxl")
        sheet_names = excel_file.sheet_names
        shift_sheets = [s for s in sheet_names if "å‹¤å‹™" not in s]
        
        print(f"âœ… Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {len(sheet_names)}ã‚·ãƒ¼ãƒˆ")
        print(f"  - å®Ÿç¸¾ã‚·ãƒ¼ãƒˆ: {shift_sheets}")
        
        # ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Ÿè¡Œ
        long_df, wt_df, unknown_codes = ingest_excel(
            excel_path,
            shift_sheets=shift_sheets,
            header_row=0,
            slot_minutes=30,
            year_month_cell_location="D1"
        )
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿å‡¦ç†æˆåŠŸ:")
        print(f"  - ç”Ÿæˆãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(long_df):,}")
        print(f"  - å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {len(wt_df)}")
        print(f"  - æœªçŸ¥ã‚³ãƒ¼ãƒ‰æ•°: {len(unknown_codes)}")
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return
    
    # 3. ãƒ‡ãƒ¼ã‚¿å“è³ªã®å®¢è¦³çš„è©•ä¾¡
    print("\nã€3. ãƒ‡ãƒ¼ã‚¿å“è³ªå®¢è¦³çš„è©•ä¾¡ã€‘")
    
    # åŸºæœ¬çµ±è¨ˆ
    total_records = len(long_df)
    working_records = len(long_df[long_df['holiday_type'] == 'é€šå¸¸å‹¤å‹™'])
    leave_records = total_records - working_records
    
    print(f"åŸºæœ¬çµ±è¨ˆ:")
    print(f"  - ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_records:,}")
    print(f"  - å‹¤å‹™ãƒ¬ã‚³ãƒ¼ãƒ‰: {working_records:,} ({working_records/total_records*100:.1f}%)")
    print(f"  - ä¼‘æš‡ãƒ¬ã‚³ãƒ¼ãƒ‰: {leave_records:,} ({leave_records/total_records*100:.1f}%)")
    
    # ãƒ‡ãƒ¼ã‚¿ã®å®Œæ•´æ€§ãƒã‚§ãƒƒã‚¯
    working_data = long_df[long_df['holiday_type'] == 'é€šå¸¸å‹¤å‹™'].copy()
    
    # æ—¥ä»˜ç¯„å›²ã®ä¸€è²«æ€§
    dates = pd.to_datetime(working_data['ds']).dt.date.unique()
    date_range = pd.date_range(start=dates.min(), end=dates.max(), freq='D')
    expected_days = len(date_range)
    actual_days = len(dates)
    
    print(f"\næ—¥ä»˜æ•´åˆæ€§:")
    print(f"  - æœŸå¾…æ—¥æ•°: {expected_days}æ—¥")
    print(f"  - å®Ÿéš›æ—¥æ•°: {actual_days}æ—¥")
    print(f"  - æ•´åˆæ€§: {'âœ…' if actual_days == expected_days else 'âŒ'}")
    
    # æ™‚é–“ã‚¹ãƒ­ãƒƒãƒˆã®ä¸€è²«æ€§
    working_data['time_slot'] = pd.to_datetime(working_data['ds']).dt.strftime('%H:%M')
    unique_slots = sorted(working_data['time_slot'].unique())
    expected_slots = [f"{h:02d}:{m:02d}" for h in range(24) for m in [0, 30]]
    
    print(f"\næ™‚é–“ã‚¹ãƒ­ãƒƒãƒˆæ•´åˆæ€§:")
    print(f"  - æœŸå¾…ã‚¹ãƒ­ãƒƒãƒˆæ•°: {len(expected_slots)}")
    print(f"  - å®Ÿéš›ã‚¹ãƒ­ãƒƒãƒˆæ•°: {len(unique_slots)}")
    print(f"  - æ•´åˆæ€§: {'âœ…' if len(unique_slots) <= len(expected_slots) else 'âŒ'}")
    
    # 4. å¤œå‹¤ãƒ»æ˜ç•ªã®æ•´åˆæ€§ç¢ºèª
    print("\nã€4. å¤œå‹¤ãƒ»æ˜ç•ªæ•´åˆæ€§ç¢ºèªã€‘")
    
    # æ˜ç•ªã‚³ãƒ¼ãƒ‰ã®å­˜åœ¨ç¢ºèª
    dawn_data = working_data[working_data['code'] == 'æ˜']
    print(f"æ˜ç•ªã€Œæ˜ã€ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(dawn_data)}")
    
    if len(dawn_data) > 0:
        dawn_data['hour'] = pd.to_datetime(dawn_data['ds']).dt.hour
        dawn_hours = dawn_data['hour'].value_counts().sort_index()
        print("æ˜ç•ªæ™‚é–“åˆ†å¸ƒ:")
        for hour, count in dawn_hours.items():
            print(f"  - {hour:02d}æ™‚å°: {count}ãƒ¬ã‚³ãƒ¼ãƒ‰")
        
        # å¤œå‹¤æ™‚é–“å¸¯ï¼ˆ0-5æ™‚ï¼‰ã§ã®æ˜ç•ªã‚«ãƒãƒ¼ç‡
        night_hours = [0, 1, 2, 3, 4, 5]
        night_dawn = dawn_data[dawn_data['hour'].isin(night_hours)]
        total_night_slots = len(night_hours) * actual_days  # 6æ™‚é–“ Ã— æ—¥æ•°
        dawn_coverage = len(night_dawn) / total_night_slots * 100 if total_night_slots > 0 else 0
        
        print(f"å¤œå‹¤æ™‚é–“å¸¯æ˜ç•ªã‚«ãƒãƒ¼ç‡: {dawn_coverage:.1f}%")
        print(f"æ•´åˆæ€§: {'âœ…' if dawn_coverage > 0 else 'âŒ'}")
    else:
        print("âŒ æ˜ç•ªãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
    
    # 5. è·ç¨®ãƒ»é›‡ç”¨å½¢æ…‹ã®ä¸€è²«æ€§
    print("\nã€5. è·ç¨®ãƒ»é›‡ç”¨å½¢æ…‹ä¸€è²«æ€§ã€‘")
    
    # è·ç¨®åˆ†æ
    roles = working_data['role'].value_counts()
    print(f"è·ç¨®æ•°: {len(roles)}")
    print("è·ç¨®åˆ†å¸ƒ:")
    for role, count in roles.items():
        percentage = count / len(working_data) * 100
        print(f"  - {role}: {count:,}ãƒ¬ã‚³ãƒ¼ãƒ‰ ({percentage:.1f}%)")
    
    # é›‡ç”¨å½¢æ…‹åˆ†æ
    employments = working_data['employment'].value_counts()
    print(f"\né›‡ç”¨å½¢æ…‹æ•°: {len(employments)}")
    print("é›‡ç”¨å½¢æ…‹åˆ†å¸ƒ:")
    for emp, count in employments.items():
        percentage = count / len(working_data) * 100
        print(f"  - {emp}: {count:,}ãƒ¬ã‚³ãƒ¼ãƒ‰ ({percentage:.1f}%)")
    
    # ã‚¯ãƒ­ã‚¹é›†è¨ˆã«ã‚ˆã‚‹æ•´åˆæ€§ç¢ºèª
    cross_table = pd.crosstab(working_data['role'], working_data['employment'], margins=True)
    print(f"\nè·ç¨®Ã—é›‡ç”¨å½¢æ…‹ã‚¯ãƒ­ã‚¹é›†è¨ˆ:")
    print(cross_table)
    
    # 6. è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã®ä¸€è²«æ€§æ¤œè¨¼
    print("\nã€6. è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ä¸€è²«æ€§æ¤œè¨¼ã€‘")
    
    # ã‚·ãƒŠãƒªã‚ªè¨ˆç®—ã®ä¸€è²«æ€§
    working_data['date'] = pd.to_datetime(working_data['ds']).dt.date
    daily_counts = working_data.groupby(['date', 'time_slot']).size().reset_index(name='count')
    
    # å„ã‚·ãƒŠãƒªã‚ªã§ã®ä¸€è²«æ€§ç¢ºèª
    scenarios = ['median', 'mean', '25th_percentile']
    scenario_results = {}
    
    for scenario in scenarios:
        if scenario == 'median':
            scenario_values = daily_counts.groupby('time_slot')['count'].median()
        elif scenario == 'mean':
            scenario_values = daily_counts.groupby('time_slot')['count'].mean()
        else:  # 25th_percentile
            scenario_values = daily_counts.groupby('time_slot')['count'].quantile(0.25)
        
        total_demand = scenario_values.sum() * 0.5  # 30åˆ†ã‚¹ãƒ­ãƒƒãƒˆ = 0.5æ™‚é–“
        scenario_results[scenario] = total_demand
        
        print(f"{scenario}ã‚·ãƒŠãƒªã‚ªç·éœ€è¦: {total_demand:.1f}æ™‚é–“")
    
    # 7. dash_app.py ã®æ•´åˆæ€§ç¢ºèª
    print("\nã€7. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ•´åˆæ€§ç¢ºèªã€‘")
    
    dash_path = Path("dash_app.py")
    if dash_path.exists():
        print("âœ… dash_app.py å­˜åœ¨ç¢ºèª")
        
        try:
            with open(dash_path, 'r', encoding='utf-8') as f:
                dash_content = f.read()
            
            # é‡è¦ãªé–¢æ•°ãƒ»å¤‰æ•°ã®å­˜åœ¨ç¢ºèª
            critical_elements = [
                'create_shortage_from_heat_all',
                'shortage',
                'excess', 
                'scenario',
                '@app.callback'
            ]
            
            element_status = {}
            for element in critical_elements:
                exists = element in dash_content
                element_status[element] = exists
                status = "âœ…" if exists else "âŒ"
                print(f"  {status} {element}")
            
            # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯æ•°ã®ç¢ºèª
            callback_count = dash_content.count('@app.callback')
            print(f"  - ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°æ•°: {callback_count}")
            
        except Exception as e:
            print(f"âŒ dash_app.py èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print("âŒ dash_app.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # 8. ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®æ•´åˆæ€§è©•ä¾¡
    print("\nã€8. ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“æ•´åˆæ€§è©•ä¾¡ã€‘")
    
    consistency_checks = {
        "ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨": all(fs["exists"] for fs in file_status.values()),
        "ãƒ‡ãƒ¼ã‚¿å‡¦ç†": total_records > 0,
        "æ—¥ä»˜æ•´åˆæ€§": actual_days == expected_days,
        "æ™‚é–“æ•´åˆæ€§": len(unique_slots) <= len(expected_slots),
        "æ˜ç•ªãƒ‡ãƒ¼ã‚¿": len(dawn_data) > 0,
        "è·ç¨®ãƒ‡ãƒ¼ã‚¿": len(roles) > 0,
        "é›‡ç”¨å½¢æ…‹ãƒ‡ãƒ¼ã‚¿": len(employments) > 0,
        "ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰": dash_path.exists()
    }
    
    print("æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯çµæœ:")
    passed_checks = 0
    total_checks = len(consistency_checks)
    
    for check_name, result in consistency_checks.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {status} {check_name}")
        if result:
            passed_checks += 1
    
    overall_score = passed_checks / total_checks * 100
    print(f"\nç·åˆæ•´åˆæ€§ã‚¹ã‚³ã‚¢: {passed_checks}/{total_checks} ({overall_score:.1f}%)")
    
    # 9. æ½œåœ¨çš„å•é¡Œã®ç‰¹å®š
    print("\nã€9. æ½œåœ¨çš„å•é¡Œç‰¹å®šã€‘")
    
    potential_issues = []
    
    # ãƒ‡ãƒ¼ã‚¿é‡ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    if total_records < 1000:
        potential_issues.append(f"ãƒ‡ãƒ¼ã‚¿é‡ãŒå°‘ãªã„å¯èƒ½æ€§ ({total_records:,}ãƒ¬ã‚³ãƒ¼ãƒ‰)")
    
    # å‹¤å‹™ãƒ»ä¼‘æš‡æ¯”ç‡ã®å¦¥å½“æ€§
    work_ratio = working_records / total_records * 100
    if work_ratio < 80:
        potential_issues.append(f"å‹¤å‹™æ¯”ç‡ãŒä½ã„å¯èƒ½æ€§ ({work_ratio:.1f}%)")
    
    # è·ç¨®ã®åã‚Šãƒã‚§ãƒƒã‚¯
    max_role_ratio = roles.max() / len(working_data) * 100
    if max_role_ratio > 50:
        potential_issues.append(f"ç‰¹å®šè·ç¨®ã¸ã®é›†ä¸­ (æœ€å¤§{max_role_ratio:.1f}%)")
    
    # ã‚·ãƒŠãƒªã‚ªé–“ã®å·®ç•°ãƒã‚§ãƒƒã‚¯
    scenario_range = max(scenario_results.values()) - min(scenario_results.values())
    if scenario_range > 100:  # 100æ™‚é–“ä»¥ä¸Šã®å·®
        potential_issues.append(f"ã‚·ãƒŠãƒªã‚ªé–“ã®å·®ç•°ãŒå¤§ãã„ ({scenario_range:.1f}æ™‚é–“)")
    
    if potential_issues:
        print("æ¤œå‡ºã•ã‚ŒãŸæ½œåœ¨çš„å•é¡Œ:")
        for issue in potential_issues:
            print(f"  âš ï¸ {issue}")
    else:
        print("âœ… é‡å¤§ãªæ½œåœ¨çš„å•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    
    # 10. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    print("\nã€10. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘")
    
    if overall_score >= 90:
        print("ğŸŸ¢ ã‚·ã‚¹ãƒ†ãƒ ã¯æ¦‚ã­å¥å…¨ã§ã™")
        print("æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        print("  - å®šæœŸçš„ãªç›£è¦–ç¶™ç¶š")
        print("  - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®æ¤œè¨")
    elif overall_score >= 70:
        print("ğŸŸ¡ è»½å¾®ãªå•é¡ŒãŒã‚ã‚Šã¾ã™")
        print("æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        print("  - å¤±æ•—é …ç›®ã®å€‹åˆ¥èª¿æŸ»")
        print("  - ãƒ‡ãƒ¼ã‚¿å“è³ªå‘ä¸Šã®æ¤œè¨")
    else:
        print("ğŸ”´ é‡å¤§ãªå•é¡ŒãŒã‚ã‚Šã¾ã™")
        print("æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        print("  - ç·Šæ€¥å¯¾å¿œãŒå¿…è¦")
        print("  - ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®è¦‹ç›´ã—")
    
    print("\n=== å®¢è¦³çš„ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯å®Œäº† ===")
    return {
        "overall_score": overall_score,
        "total_records": total_records,
        "working_records": working_records,
        "consistency_checks": consistency_checks,
        "potential_issues": potential_issues
    }

if __name__ == "__main__":
    result = objective_consistency_check()