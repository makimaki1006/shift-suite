#!/usr/bin/env python3
"""
app.py - Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆã‚»ãƒ¼ãƒ•ãƒ¢ãƒ¼ãƒ‰ï¼‰
scikit-learnä¾å­˜é–¢ä¿‚å•é¡Œã‚’å›é¿ã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³
"""

import streamlit as st
import pandas as pd
import numpy as np
import logging
from pathlib import Path
from datetime import datetime, timedelta
import json

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
log = logging.getLogger(__name__)

# å®‰å…¨ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆscikit-learnä¾å­˜ãªã—ï¼‰
try:
    from shift_suite.tasks.utils import safe_read_excel, log
    from shift_suite.tasks.io_excel import ingest_excel
    from shift_suite.tasks.heatmap import build_heatmap
    from shift_suite.tasks.shortage import shortage_and_brief
    from shift_suite.tasks.fairness import run_fairness
    from shift_suite.tasks.forecast import build_demand_series, forecast_need
    _HAS_BASIC_SUITE = True
except ImportError as e:
    log.error(f"Basic shift_suite imports failed: {e}")
    _HAS_BASIC_SUITE = False

# è¤‡åˆåˆ¶ç´„ç™ºè¦‹ã‚·ã‚¹ãƒ†ãƒ ï¼ˆè»½é‡ç‰ˆï¼‰
try:
    from shift_suite.tasks.shift_mind_reader_lite import ShiftMindReaderLite
    _HAS_CONSTRAINT_ANALYSIS = True
except ImportError:
    _HAS_CONSTRAINT_ANALYSIS = False

def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆã‚»ãƒ¼ãƒ•ãƒ¢ãƒ¼ãƒ‰ï¼‰"""
    st.set_page_config(
        page_title="ã‚·ãƒ•ãƒˆåˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆã‚»ãƒ¼ãƒ•ãƒ¢ãƒ¼ãƒ‰ï¼‰",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    
    st.title("ğŸ“Š ã‚·ãƒ•ãƒˆåˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆã‚»ãƒ¼ãƒ•ãƒ¢ãƒ¼ãƒ‰ï¼‰")
    
    # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹è¡¨ç¤º
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if _HAS_BASIC_SUITE:
            st.success("âœ… åŸºæœ¬æ©Ÿèƒ½åˆ©ç”¨å¯èƒ½")
        else:
            st.error("âŒ åŸºæœ¬æ©Ÿèƒ½åˆ©ç”¨ä¸å¯")
    
    with col2:
        if _HAS_CONSTRAINT_ANALYSIS:
            st.success("âœ… åˆ¶ç´„åˆ†æåˆ©ç”¨å¯èƒ½")
        else:
            st.warning("âš ï¸ åˆ¶ç´„åˆ†æã¯è»½é‡ç‰ˆã®ã¿")
    
    with col3:
        st.info("ğŸ”§ ã‚»ãƒ¼ãƒ•ãƒ¢ãƒ¼ãƒ‰å‹•ä½œä¸­")
    
    # ä¾å­˜é–¢ä¿‚å•é¡Œã®èª¬æ˜
    with st.expander("â„¹ï¸ ã‚»ãƒ¼ãƒ•ãƒ¢ãƒ¼ãƒ‰ã«ã¤ã„ã¦"):
        st.markdown("""
        **ã‚»ãƒ¼ãƒ•ãƒ¢ãƒ¼ãƒ‰**ã¯ã€scikit-learn DLLä¾å­˜é–¢ä¿‚å•é¡Œã‚’å›é¿ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚
        
        **åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½:**
        - âœ… åŸºæœ¬çš„ãªã‚·ãƒ•ãƒˆåˆ†æ
        - âœ… ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆ
        - âœ… ä¸è¶³åˆ†æ
        - âœ… å…¬å¹³æ€§åˆ†æ
        - âœ… éœ€è¦äºˆæ¸¬ï¼ˆåŸºæœ¬ç‰ˆï¼‰
        - âœ… è»½é‡ç‰ˆåˆ¶ç´„ç™ºè¦‹
        
        **åˆ¶é™ã•ã‚Œã¦ã„ã‚‹æ©Ÿèƒ½:**
        - âŒ é«˜åº¦ãªæ©Ÿæ¢°å­¦ç¿’åˆ†æ
        - âŒ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ
        - âŒ ç•°å¸¸æ¤œçŸ¥åˆ†æ
        - âŒ ã‚¹ã‚­ãƒ«ãƒãƒˆãƒªãƒƒã‚¯ã‚¹æ§‹ç¯‰
        """)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.header("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    uploaded_file = st.file_uploader(
        "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=['xlsx', 'xls'],
        help="ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    
    if uploaded_file is not None:
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
        st.info(f"ğŸ“„ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name}")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            if _HAS_BASIC_SUITE:
                # safe_read_excelã‚’ä½¿ç”¨ã—ã¦èª­ã¿è¾¼ã¿
                df = safe_read_excel(uploaded_file)
                st.success("âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ")
                
                # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦è¡¨ç¤º
                st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°", len(df))
                with col2:
                    st.metric("åˆ—æ•°", len(df.columns))
                with col3:
                    if 'staff' in df.columns:
                        st.metric("ã‚¹ã‚¿ãƒƒãƒ•æ•°", df['staff'].nunique())
                    else:
                        st.metric("ã‚¹ã‚¿ãƒƒãƒ•æ•°", "ä¸æ˜")
                with col4:
                    if 'ds' in df.columns:
                        date_range = f"{df['ds'].min().date()} - {df['ds'].max().date()}"
                        st.metric("æœŸé–“", "ç¢ºèª")
                        st.caption(date_range)
                    else:
                        st.metric("æœŸé–“", "ä¸æ˜")
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                st.subheader("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.dataframe(df.head(10), use_container_width=True)
                
                # åˆ¶ç´„åˆ†æå®Ÿè¡Œ
                if _HAS_CONSTRAINT_ANALYSIS and st.button("ğŸ” è»½é‡ç‰ˆåˆ¶ç´„åˆ†æã‚’å®Ÿè¡Œ"):
                    with st.spinner("åˆ¶ç´„åˆ†æã‚’å®Ÿè¡Œä¸­..."):
                        try:
                            mind_reader = ShiftMindReaderLite()
                            insights = mind_reader.get_simplified_insights(df)
                            
                            st.success("âœ… åˆ¶ç´„åˆ†æå®Œäº†")
                            
                            # çµæœè¡¨ç¤º
                            st.subheader("ğŸ“‹ ç™ºè¦‹ã•ã‚ŒãŸåˆ¶ç´„ãƒ‘ã‚¿ãƒ¼ãƒ³")
                            
                            if insights.get('key_findings'):
                                st.write("**ä¸»è¦ãªç™ºè¦‹:**")
                                for finding in insights['key_findings']:
                                    st.write(f"â€¢ {finding}")
                            
                            if insights.get('recommendations'):
                                st.write("**æ¨å¥¨äº‹é …:**")
                                for recommendation in insights['recommendations']:
                                    st.write(f"â€¢ {recommendation}")
                            
                            # çµæœã‚’JSONã§è¡¨ç¤ºï¼ˆè©³ç´°ï¼‰
                            with st.expander("è©³ç´°ãªåˆ†æçµæœ"):
                                st.json(insights)
                        
                        except Exception as e:
                            st.error(f"åˆ¶ç´„åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                            
            else:
                # åŸºæœ¬æ©Ÿèƒ½ãŒä½¿ãˆãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                df = pd.read_excel(uploaded_file)
                st.warning("âš ï¸ åŸºæœ¬æ©Ÿèƒ½åˆ¶é™ãƒ¢ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿")
                
                st.subheader("ğŸ“Š åŸºæœ¬ãƒ‡ãƒ¼ã‚¿æƒ…å ±")
                st.write(f"ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df)}")
                st.write(f"åˆ—æ•°: {len(df.columns)}")
                st.write("åˆ—å:", list(df.columns))
                
                st.dataframe(df.head(), use_container_width=True)
                
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            log.error(f"Data loading error: {e}")
    
    # ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­
    st.header("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­")
    
    if st.button("ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­å®Ÿè¡Œ"):
        with st.spinner("è¨ºæ–­ä¸­..."):
            diagnosis = {
                "timestamp": datetime.now().isoformat(),
                "basic_suite": _HAS_BASIC_SUITE,
                "constraint_analysis": _HAS_CONSTRAINT_ANALYSIS,
                "python_version": f"{__import__('sys').version}",
                "pandas_version": pd.__version__,
                "numpy_version": np.__version__
            }
            
            st.success("âœ… è¨ºæ–­å®Œäº†")
            st.json(diagnosis)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("""
    **ã‚·ãƒ•ãƒˆåˆ†æã‚·ã‚¹ãƒ†ãƒ  ã‚»ãƒ¼ãƒ•ãƒ¢ãƒ¼ãƒ‰**  
    - ä¾å­˜é–¢ä¿‚å•é¡Œã‚’å›é¿ã—ãŸè»½é‡ç‰ˆ
    - åŸºæœ¬çš„ãªåˆ†ææ©Ÿèƒ½ã‚’æä¾›  
    - åˆ¶ç´„ç™ºè¦‹ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¨¼ç‰ˆ
    """)

if __name__ == "__main__":
    main()