#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
A3.1 åŸºæœ¬ç›£è¦–ä½“åˆ¶
ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒãƒ»ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆã®çµ±åˆç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
import time
import json
import logging
from pathlib import Path
from datetime import datetime, timedelta
import subprocess
import psutil
from dataclasses import dataclass
from typing import Dict, List, Optional, Any

# ç›£è¦–è¨­å®š
@dataclass
class MonitoringConfig:
    """ç›£è¦–è¨­å®šã‚¯ãƒ©ã‚¹"""
    
    # ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–å¯¾è±¡
    critical_files: List[str]
    log_directories: List[str]
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¾å€¤
    max_cpu_percent: float = 80.0
    max_memory_percent: float = 85.0
    max_response_time: float = 10.0
    
    # ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
    alert_email: str = "admin@shift-suite.com"
    alert_threshold: int = 3  # é€£ç¶šã‚¨ãƒ©ãƒ¼æ•°
    
    # ç›£è¦–é–“éš”
    check_interval: int = 300  # 5åˆ†
    log_retention_days: int = 30

class SystemMonitor:
    """ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒç›£è¦–"""
    
    def __init__(self, config: MonitoringConfig):
        self.config = config
        self.setup_logging()
        self.last_check = datetime.now()
        self.error_count = 0
        
    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        log_dir = Path("logs/monitoring")
        log_dir.mkdir(parents=True, exist_ok=True)
        
        log_file = log_dir / f"system_monitor_{datetime.now().strftime('%Y%m%d')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def check_critical_files(self) -> Dict[str, Any]:
        """é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª"""
        
        critical_files = [
            "shift_suite/tasks/fact_extractor_prototype.py",
            "shift_suite/tasks/lightweight_anomaly_detector.py", 
            "shift_suite/tasks/fact_book_visualizer.py",
            "shift_suite/tasks/dash_fact_book_integration.py",
            "dash_app.py",
            "app.py"
        ]
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "files": {},
            "status": "healthy"
        }
        
        for file_path in critical_files:
            path = Path(file_path)
            if path.exists():
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç¢ºèª
                stat = path.stat()
                results["files"][file_path] = {
                    "exists": True,
                    "size": stat.st_size,
                    "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    "status": "ok"
                }
            else:
                results["files"][file_path] = {
                    "exists": False,
                    "status": "missing"
                }
                results["status"] = "warning"
                self.logger.warning(f"Critical file missing: {file_path}")
        
        return results
    
    def check_process_status(self) -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ³ç¢ºèª"""
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "processes": {},
            "system": {},
            "status": "healthy"
        }
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            results["system"] = {
                "cpu_percent": cpu_percent,
                "memory_percent": memory.percent,
                "memory_used_gb": memory.used / (1024**3),
                "memory_total_gb": memory.total / (1024**3),
                "disk_percent": disk.percent,
                "disk_free_gb": disk.free / (1024**3)
            }
            
            # CPU/ãƒ¡ãƒ¢ãƒªé–¾å€¤ãƒã‚§ãƒƒã‚¯
            if cpu_percent > self.config.max_cpu_percent:
                results["status"] = "warning"
                self.logger.warning(f"High CPU usage: {cpu_percent}%")
            
            if memory.percent > self.config.max_memory_percent:
                results["status"] = "warning"
                self.logger.warning(f"High memory usage: {memory.percent}%")
                
        except Exception as e:
            results["system"]["error"] = str(e)
            results["status"] = "error"
            self.logger.error(f"System monitoring error: {e}")
        
        return results
    
    def check_phase2_31_integration(self) -> Dict[str, Any]:
        """Phase 2/3.1çµ±åˆçŠ¶æ³ç¢ºèª"""
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "phase2": {},
            "phase31": {},
            "integration": {},
            "status": "healthy"
        }
        
        try:
            # Phase 2ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            phase2_file = Path("shift_suite/tasks/fact_extractor_prototype.py")
            if phase2_file.exists():
                with open(phase2_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                slot_hours_count = content.count('* SLOT_HOURS')
                wrong_comment = "parsed_slots_count is already in hours" in content
                
                results["phase2"] = {
                    "file_exists": True,
                    "slot_hours_multiplications": slot_hours_count,
                    "wrong_comments": wrong_comment,
                    "expected_multiplications": 4,
                    "status": "ok" if slot_hours_count >= 4 and not wrong_comment else "warning"
                }
                
                if slot_hours_count < 4 or wrong_comment:
                    results["status"] = "warning"
                    self.logger.warning(f"Phase 2 integrity issue: SLOT_HOURS={slot_hours_count}, wrong_comment={wrong_comment}")
            
            # Phase 3.1ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            phase31_file = Path("shift_suite/tasks/lightweight_anomaly_detector.py")
            if phase31_file.exists():
                with open(phase31_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                slot_hours_count = content.count('* SLOT_HOURS')
                wrong_comment = "parsed_slots_count is already in hours" in content
                
                results["phase31"] = {
                    "file_exists": True,
                    "slot_hours_multiplications": slot_hours_count,
                    "wrong_comments": wrong_comment,
                    "expected_multiplications": 1,
                    "status": "ok" if slot_hours_count >= 1 and not wrong_comment else "warning"
                }
                
                if slot_hours_count < 1 or wrong_comment:
                    results["status"] = "warning"
                    self.logger.warning(f"Phase 3.1 integrity issue: SLOT_HOURS={slot_hours_count}, wrong_comment={wrong_comment}")
            
            # çµ±åˆç¢ºèª
            factbook_file = Path("shift_suite/tasks/fact_book_visualizer.py")
            if factbook_file.exists():
                with open(factbook_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                phase2_integration = "FactExtractorPrototype" in content
                phase31_integration = "LightweightAnomalyDetector" in content
                
                results["integration"] = {
                    "factbook_exists": True,
                    "phase2_integration": phase2_integration,
                    "phase31_integration": phase31_integration,
                    "status": "ok" if phase2_integration and phase31_integration else "warning"
                }
                
                if not (phase2_integration and phase31_integration):
                    results["status"] = "warning"
                    self.logger.warning(f"Integration issue: Phase2={phase2_integration}, Phase3.1={phase31_integration}")
                    
        except Exception as e:
            results["error"] = str(e)
            results["status"] = "error"
            self.logger.error(f"Phase 2/3.1 integration check error: {e}")
        
        return results

class ErrorLogMonitor:
    """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç›£è¦–"""
    
    def __init__(self, config: MonitoringConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.last_position = {}
    
    def scan_logs(self) -> Dict[str, Any]:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ã‚­ãƒ£ãƒ³"""
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "logs_scanned": 0,
            "errors_found": 0,
            "warnings_found": 0,
            "critical_errors": [],
            "status": "healthy"
        }
        
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå€™è£œ
        log_paths = [
            "logs",
            ".",
            "shift_suite"
        ]
        
        error_patterns = [
            "ERROR",
            "CRITICAL", 
            "FATAL",
            "Exception",
            "Traceback",
            "Phase 2",
            "Phase 3.1",
            "SLOT_HOURS",
            "parsed_slots_count"
        ]
        
        for log_dir in log_paths:
            log_path = Path(log_dir)
            if not log_path.exists():
                continue
                
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
            for log_file in log_path.glob("*.log"):
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                        results["logs_scanned"] += 1
                        
                        for line_num, line in enumerate(lines, 1):
                            for pattern in error_patterns:
                                if pattern.lower() in line.lower():
                                    if "ERROR" in line.upper() or "CRITICAL" in line.upper():
                                        results["errors_found"] += 1
                                        results["critical_errors"].append({
                                            "file": str(log_file),
                                            "line": line_num,
                                            "content": line.strip(),
                                            "pattern": pattern
                                        })
                                    elif "WARNING" in line.upper():
                                        results["warnings_found"] += 1
                                        
                except Exception as e:
                    self.logger.error(f"Error reading log file {log_file}: {e}")
        
        # çŠ¶æ…‹åˆ¤å®š
        if results["errors_found"] > 0:
            results["status"] = "error"
        elif results["warnings_found"] > 5:
            results["status"] = "warning"
        
        return results

class PerformanceMonitor:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–"""
    
    def __init__(self, config: MonitoringConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
    
    def measure_response_times(self) -> Dict[str, Any]:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“æ¸¬å®š"""
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "tests": {},
            "average_response_time": 0.0,
            "status": "healthy"
        }
        
        # Pythonæ§‹æ–‡ãƒã‚§ãƒƒã‚¯ï¼ˆå¿œç­”æ€§ãƒ†ã‚¹ãƒˆï¼‰
        test_files = [
            "shift_suite/tasks/fact_extractor_prototype.py",
            "shift_suite/tasks/lightweight_anomaly_detector.py"
        ]
        
        total_time = 0.0
        test_count = 0
        
        for file_path in test_files:
            if Path(file_path).exists():
                try:
                    start_time = time.time()
                    result = subprocess.run(
                        [sys.executable, "-m", "py_compile", file_path],
                        capture_output=True,
                        timeout=self.config.max_response_time
                    )
                    end_time = time.time()
                    
                    response_time = end_time - start_time
                    total_time += response_time
                    test_count += 1
                    
                    results["tests"][file_path] = {
                        "response_time": response_time,
                        "syntax_ok": result.returncode == 0,
                        "status": "ok" if result.returncode == 0 and response_time < self.config.max_response_time else "warning"
                    }
                    
                    if response_time > self.config.max_response_time:
                        results["status"] = "warning"
                        self.logger.warning(f"Slow response: {file_path} took {response_time:.2f}s")
                        
                except subprocess.TimeoutExpired:
                    results["tests"][file_path] = {
                        "response_time": self.config.max_response_time,
                        "syntax_ok": False,
                        "status": "timeout"
                    }
                    results["status"] = "error"
                    self.logger.error(f"Timeout: {file_path}")
                    
                except Exception as e:
                    results["tests"][file_path] = {
                        "error": str(e),
                        "status": "error"
                    }
                    results["status"] = "error"
                    self.logger.error(f"Performance test error for {file_path}: {e}")
        
        if test_count > 0:
            results["average_response_time"] = total_time / test_count
        
        return results

class AlertSystem:
    """ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, config: MonitoringConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.alert_history = []
    
    def send_alert(self, alert_type: str, message: str, severity: str = "warning") -> bool:
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        
        alert = {
            "timestamp": datetime.now().isoformat(),
            "type": alert_type,
            "message": message,
            "severity": severity
        }
        
        self.alert_history.append(alert)
        
        # ãƒ­ã‚°å‡ºåŠ›
        if severity == "critical":
            self.logger.critical(f"ALERT [{alert_type}]: {message}")
        elif severity == "error":
            self.logger.error(f"ALERT [{alert_type}]: {message}")
        else:
            self.logger.warning(f"ALERT [{alert_type}]: {message}")
        
        # å®Ÿéš›ã®é€šçŸ¥ï¼ˆãƒ¡ãƒ¼ãƒ«ãƒ»Slackç­‰ï¼‰ã¯ã“ã“ã§å®Ÿè£…
        # ç¾åœ¨ã¯ãƒ­ã‚°å‡ºåŠ›ã®ã¿
        
        return True

class MonitoringCoordinator:
    """ç›£è¦–çµ±åˆç®¡ç†"""
    
    def __init__(self):
        self.config = MonitoringConfig(
            critical_files=[
                "shift_suite/tasks/fact_extractor_prototype.py",
                "shift_suite/tasks/lightweight_anomaly_detector.py",
                "dash_app.py"
            ],
            log_directories=["logs", "."]
        )
        
        self.system_monitor = SystemMonitor(self.config)
        self.error_monitor = ErrorLogMonitor(self.config)
        self.performance_monitor = PerformanceMonitor(self.config)
        self.alert_system = AlertSystem(self.config)
        
        # çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.results_dir = Path("logs/monitoring/results")
        self.results_dir.mkdir(parents=True, exist_ok=True)
    
    def run_comprehensive_check(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ç›£è¦–ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        
        print("ğŸ” A3.1 åŒ…æ‹¬çš„ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–å®Ÿè¡Œ")
        print("=" * 60)
        
        comprehensive_results = {
            "timestamp": datetime.now().isoformat(),
            "monitoring_version": "1.0",
            "checks": {},
            "overall_status": "healthy",
            "summary": {}
        }
        
        # 1. ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒç¢ºèª
        print("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒç¢ºèª...")
        system_results = self.system_monitor.check_critical_files()
        process_results = self.system_monitor.check_process_status()
        phase_results = self.system_monitor.check_phase2_31_integration()
        
        comprehensive_results["checks"]["system"] = {
            "files": system_results,
            "processes": process_results, 
            "phase_integration": phase_results
        }
        
        # 2. ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚¹ã‚­ãƒ£ãƒ³
        print("ğŸ“‹ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚¹ã‚­ãƒ£ãƒ³...")
        log_results = self.error_monitor.scan_logs()
        comprehensive_results["checks"]["logs"] = log_results
        
        # 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
        print("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š...")
        performance_results = self.performance_monitor.measure_response_times()
        comprehensive_results["checks"]["performance"] = performance_results
        
        # 4. ç·åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
        all_statuses = [
            system_results["status"],
            process_results["status"],
            phase_results["status"],
            log_results["status"],
            performance_results["status"]
        ]
        
        if "error" in all_statuses:
            comprehensive_results["overall_status"] = "error"
        elif "warning" in all_statuses:
            comprehensive_results["overall_status"] = "warning"
        else:
            comprehensive_results["overall_status"] = "healthy"
        
        # 5. ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        comprehensive_results["summary"] = {
            "files_checked": len(system_results["files"]),
            "files_healthy": sum(1 for f in system_results["files"].values() if f["status"] == "ok"),
            "logs_scanned": log_results["logs_scanned"],
            "errors_found": log_results["errors_found"],
            "warnings_found": log_results["warnings_found"],
            "average_response_time": performance_results["average_response_time"],
            "overall_health": comprehensive_results["overall_status"]
        }
        
        # 6. çµæœä¿å­˜
        result_file = self.results_dir / f"monitoring_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_results, f, indent=2, ensure_ascii=False)
        
        # 7. ã‚¢ãƒ©ãƒ¼ãƒˆåˆ¤å®šãƒ»é€ä¿¡
        if comprehensive_results["overall_status"] == "error":
            self.alert_system.send_alert(
                "system_health", 
                f"Critical system issues detected. Errors: {log_results['errors_found']}", 
                "critical"
            )
        elif comprehensive_results["overall_status"] == "warning":
            self.alert_system.send_alert(
                "system_health",
                f"System warnings detected. Warnings: {log_results['warnings_found']}",
                "warning"
            )
        
        return comprehensive_results
    
    def generate_monitoring_report(self, results: Dict[str, Any]) -> str:
        """ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        report = f"""
ğŸ” **ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ**
å®Ÿè¡Œæ—¥æ™‚: {results['timestamp']}
ç·åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {results['overall_status']}

ğŸ“Š **ç›£è¦–çµæœã‚µãƒãƒªãƒ¼**
- ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {results['summary']['files_healthy']}/{results['summary']['files_checked']} æ­£å¸¸
- ãƒ­ã‚°ã‚¹ã‚­ãƒ£ãƒ³: {results['summary']['logs_scanned']}ãƒ•ã‚¡ã‚¤ãƒ«
- ã‚¨ãƒ©ãƒ¼æ¤œå‡º: {results['summary']['errors_found']}ä»¶
- è­¦å‘Šæ¤œå‡º: {results['summary']['warnings_found']}ä»¶
- å¹³å‡å¿œç­”æ™‚é–“: {results['summary']['average_response_time']:.2f}ç§’

ğŸ¯ **Phase 2/3.1 çµ±åˆçŠ¶æ³**
Phase 2: {results['checks']['system']['phase_integration']['phase2'].get('status', 'unknown')}
Phase 3.1: {results['checks']['system']['phase_integration']['phase31'].get('status', 'unknown')}
çµ±åˆ: {results['checks']['system']['phase_integration']['integration'].get('status', 'unknown')}

ğŸ’¡ **æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**
"""
        
        if results['overall_status'] == "error":
            report += "ğŸš¨ å³åº§å¯¾å¿œãŒå¿…è¦ã§ã™ã€‚ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
        elif results['overall_status'] == "warning":
            report += "âš ï¸ æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚è­¦å‘Šå†…å®¹ã‚’ç¢ºèªã—ã€äºˆé˜²çš„å¯¾ç­–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
        else:
            report += "âœ… ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚ç¶™ç¶šç›£è¦–ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚"
        
        return report

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    
    print("ğŸš¨ A3.1 åŸºæœ¬ç›£è¦–ä½“åˆ¶ - é–‹å§‹")
    print("ğŸ¯ Phase 2/3.1ä¿®æ­£æˆæœã®å®‰å®šé‹ç”¨ç›£è¦–")
    print("=" * 80)
    
    try:
        # ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        coordinator = MonitoringCoordinator()
        
        # åŒ…æ‹¬çš„ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        results = coordinator.run_comprehensive_check()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»è¡¨ç¤º
        report = coordinator.generate_monitoring_report(results)
        print("\n" + "=" * 80)
        print("ğŸ“‹ ç›£è¦–çµæœãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 80)
        print(report)
        
        # æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ææ¡ˆ
        print("\nğŸš€ æ¬¡ã‚¹ãƒ†ãƒƒãƒ—:")
        if results['overall_status'] == "healthy":
            print("  1. A3.1.2 ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç›£è¦–ã®è©³ç´°è¨­å®š")
            print("  2. A3.1.3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®ç¶™ç¶šå®Ÿè¡Œ")
            print("  3. A3.1.4 ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®æœ¬æ ¼é‹ç”¨")
        else:
            print("  1. æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã®è©³ç´°èª¿æŸ»")
            print("  2. å¿…è¦ã«å¿œã˜ãŸä¿®æ­£ãƒ»å¯¾ç­–å®Ÿæ–½")
            print("  3. ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®å†å®Ÿè¡Œ")
        
        return results['overall_status'] == "healthy"
        
    except Exception as e:
        print(f"âŒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)