#!/usr/bin/env python3
"""
çµ±ä¸€åˆ†æç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  å…¨ä½“æœ€é©åŒ–ä¿®æ­£å®Ÿè¡Œ
Ultra-Thorough Thinkingã«åŸºã¥ãåŒ…æ‹¬çš„ä¿®æ­£
"""

import shutil
from pathlib import Path
from datetime import datetime

def create_comprehensive_backup():
    """åŒ…æ‹¬çš„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆ"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_dir = Path(f"comprehensive_backup_{timestamp}")
    backup_dir.mkdir(exist_ok=True)
    
    files_to_backup = [
        "app.py",
        "shift_suite/tasks/unified_analysis_manager.py",
        "shift_suite/tasks/shortage.py",
        "shift_suite/tasks/ai_comprehensive_report_generator.py"
    ]
    
    print("ğŸ—‚ï¸ åŒ…æ‹¬çš„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆä¸­...")
    for file_path in files_to_backup:
        if Path(file_path).exists():
            dest = backup_dir / Path(file_path).name
            shutil.copy2(file_path, dest)
            print(f"  âœ… {file_path} â†’ {dest}")
    
    print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup_dir}")
    return backup_dir

def fix_1_unified_system_debug_logging():
    """ä¿®æ­£1: çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ """
    print("\nğŸ”§ ä¿®æ­£1: çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ ")
    
    uam_path = Path("shift_suite/tasks/unified_analysis_manager.py")
    if not uam_path.exists():
        print("âŒ unified_analysis_manager.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    with open(uam_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # get_ai_compatible_resultsãƒ¡ã‚½ãƒƒãƒ‰ã«ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’è¿½åŠ 
    old_method_start = 'def get_ai_compatible_results(self, file_pattern: str = None) -> Dict[str, Any]:'
    if old_method_start in content:
        method_body_start = content.find(old_method_start)
        method_body = content[method_body_start:content.find('def ', method_body_start + 1)]
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ãŒæ—¢ã«è¿½åŠ ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if '[get_ai_compatible_results]' not in method_body:
            new_method_start = '''def get_ai_compatible_results(self, file_pattern: str = None) -> Dict[str, Any]:
        """AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”¨ã®çµæœè¾æ›¸ç”Ÿæˆ"""
        ai_results = {}
        
        # ğŸ”§ ä¿®æ­£: ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’è¿½åŠ 
        log.info(f"[get_ai_compatible_results] æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³: '{file_pattern}'")
        log.info(f"[get_ai_compatible_results] ãƒ¬ã‚¸ã‚¹ãƒˆãƒªå†…ã®ã‚­ãƒ¼æ•°: {len(self.results_registry)}")
        
        # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªå†…ã®ã‚­ãƒ¼ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        if self.results_registry:
            log.debug("[get_ai_compatible_results] ãƒ¬ã‚¸ã‚¹ãƒˆãƒªå†…ã®ã‚­ãƒ¼:")
            for key in list(self.results_registry.keys())[:5]:  # æœ€åˆã®5å€‹ã®ã¿
                log.debug(f"  - {key}")
        else:
            log.warning("[get_ai_compatible_results] âš ï¸ ãƒ¬ã‚¸ã‚¹ãƒˆãƒªãŒç©ºã§ã™ï¼")
        
        for key, result in self.results_registry.items():
            # ğŸ”§ ä¿®æ­£: ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã‚’æ”¹å–„
            if file_pattern is None:
                match = True
            else:
                # ãƒ•ã‚¡ã‚¤ãƒ«åã®éƒ¨åˆ†ä¸€è‡´ã‚’è¨±å¯
                from pathlib import Path
                clean_pattern = Path(file_pattern).stem  # æ‹¡å¼µå­ã‚’é™¤å»
                match = clean_pattern in key or file_pattern in key
                
            if match:
                log.debug(f"[get_ai_compatible_results] ãƒãƒƒãƒ: {key}")'''
            
            # æ—¢å­˜ã®ãƒ¡ã‚½ãƒƒãƒ‰æœ¬ä½“ã‚’ç½®æ›
            next_method_start = content.find('def ', method_body_start + 1)
            if next_method_start == -1:
                next_method_start = len(content)
            
            old_body = content[method_body_start:content.find('\n        for key, result in self.results_registry.items():')]
            new_content = content.replace(old_body, new_method_start)
            
            with open(uam_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            print("  âœ… get_ai_compatible_resultsã«ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
            return True
        else:
            print("  â„¹ï¸ ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã¯æ—¢ã«è¿½åŠ æ¸ˆã¿ã§ã™")
            return True
    else:
        print("  âŒ get_ai_compatible_resultsãƒ¡ã‚½ãƒƒãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False

def fix_2_file_name_consistency():
    """ä¿®æ­£2: ãƒ•ã‚¡ã‚¤ãƒ«åã®ä¸€è²«æ€§ç¢ºä¿"""
    print("\nğŸ”§ ä¿®æ­£2: ãƒ•ã‚¡ã‚¤ãƒ«åã®ä¸€è²«æ€§ç¢ºä¿ï¼ˆapp.pyï¼‰")
    
    app_path = Path("app.py")
    if not app_path.exists():
        print("âŒ app.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    with open(app_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # get_ai_compatible_resultså‘¼ã³å‡ºã—ç®‡æ‰€ã‚’ä¿®æ­£
    old_call = 'unified_results = st.session_state.unified_analysis_manager.get_ai_compatible_results(file_name)'
    if old_call in content:
        new_call = '''# ğŸ”§ ä¿®æ­£: ãƒ•ã‚¡ã‚¤ãƒ«åã®ã‚¹ãƒ†ãƒ ï¼ˆæ‹¡å¼µå­ãªã—ï¼‰ã‚’ä½¿ç”¨
                                file_stem = Path(file_name).stem
                                log.info(f"[AIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ] ãƒ•ã‚¡ã‚¤ãƒ«å: {file_name} â†’ ã‚¹ãƒ†ãƒ : {file_stem}")
                                
                                unified_results = st.session_state.unified_analysis_manager.get_ai_compatible_results(file_stem)
                                
                                # çµæœãŒç©ºã®å ´åˆã®è©³ç´°è¨ºæ–­
                                if not unified_results:
                                    log.warning(f"[AIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ] çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰çµæœãŒå–å¾—ã§ãã¾ã›ã‚“")
                                    log.warning(f"  æ¤œç´¢ã‚­ãƒ¼: {file_stem}")
                                    log.warning(f"  ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚µã‚¤ã‚º: {len(st.session_state.unified_analysis_manager.results_registry)}")'''
        
        new_content = content.replace(old_call, new_call)
        
        with open(app_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print("  âœ… ãƒ•ã‚¡ã‚¤ãƒ«åã®ä¸€è²«æ€§ä¿®æ­£ã‚’é©ç”¨ã—ã¾ã—ãŸ")
        return True
    else:
        print("  âŒ get_ai_compatible_resultså‘¼ã³å‡ºã—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False

def fix_3_shortage_slot_hours():
    """ä¿®æ­£3: shortage.pyã®å›ºå®šSLOT_HOURSä¿®æ­£"""
    print("\nğŸ”§ ä¿®æ­£3: shortage.pyã®å›ºå®šSLOT_HOURSä¿®æ­£")
    
    shortage_path = Path("shift_suite/tasks/shortage.py")
    if not shortage_path.exists():
        print("âŒ shortage.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    with open(shortage_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # SLOT_HOURSå®šæ•°ã®ä½¿ç”¨ã‚’æ¢ã™
    if 'SLOT_HOURS' in content:
        # SLOT_HOURSã®å®šç¾©ã‚’å‰Šé™¤ã¾ãŸã¯ç½®æ›
        lines = content.split('\n')
        new_lines = []
        
        for line in lines:
            if 'SLOT_HOURS' in line and '=' in line and 'slot_hours' not in line.lower():
                # å›ºå®šå®šæ•°ã®å®šç¾©ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
                new_lines.append(f"# {line}  # ğŸ”§ ä¿®æ­£: å‹•çš„ã‚¹ãƒ­ãƒƒãƒˆè¨ˆç®—ã«ç½®æ›")
            elif 'SLOT_HOURS' in line and 'slot_hours' not in line:
                # ä½¿ç”¨ç®‡æ‰€ã‚’å‹•çš„è¨ˆç®—ã«ç½®æ›
                new_line = line.replace('SLOT_HOURS', 'slot_hours')
                new_lines.append(f"{new_line}  # ğŸ”§ ä¿®æ­£: å‹•çš„å€¤ä½¿ç”¨")
            else:
                new_lines.append(line)
        
        new_content = '\n'.join(new_lines)
        
        with open(shortage_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print("  âœ… SLOT_HOURSå›ºå®šå€¤ã‚’å‹•çš„è¨ˆç®—ã«ä¿®æ­£ã—ã¾ã—ãŸ")
        return True
    else:
        print("  â„¹ï¸ SLOT_HOURSã¯æ—¢ã«ä¿®æ­£æ¸ˆã¿ã¾ãŸã¯ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return True

def fix_4_add_analysis_execution_validation():
    """ä¿®æ­£4: åˆ†æå®Ÿè¡Œçµæœã®æ¤œè¨¼è¿½åŠ """
    print("\nğŸ”§ ä¿®æ­£4: åˆ†æå®Ÿè¡Œçµæœã®æ¤œè¨¼è¿½åŠ ")
    
    # shortage_and_briefå®Ÿè¡Œå¾Œã®çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ç™»éŒ²éƒ¨åˆ†ã‚’ç¢ºèªãƒ»ä¿®æ­£
    app_path = Path("app.py")
    with open(app_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # shortage_and_briefå®Ÿè¡Œå¾Œã®å‡¦ç†ã‚’æ¢ã™
    shortage_exec_pattern = 'shortage_result_exec_run = shortage_and_brief('
    if shortage_exec_pattern in content:
        # çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç™»éŒ²ãŒé©åˆ‡ã«è¡Œã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        shortage_section_start = content.find(shortage_exec_pattern)
        shortage_section_end = content.find('try:', shortage_section_start + 500)  # æ¬¡ã®tryãƒ–ãƒ­ãƒƒã‚¯ã¾ã§
        
        if shortage_section_end == -1:
            shortage_section_end = shortage_section_start + 1000
        
        shortage_section = content[shortage_section_start:shortage_section_end]
        
        if 'create_shortage_analysis' not in shortage_section:
            print("  âš ï¸ shortage_and_briefå®Ÿè¡Œå¾Œã«çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ç™»éŒ²ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # ä¿®æ­£ç”¨ã®ã‚³ãƒ¼ãƒ‰ã‚’æŒ¿å…¥ä½ç½®ã‚’æ¢ã™
            insert_point = content.find('st.session_state.analysis_status["shortage"] = "success"')
            if insert_point != -1:
                insertion_code = '''
                    
                    # ğŸ”§ ä¿®æ­£: çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ä¸è¶³åˆ†æçµæœç™»éŒ²
                    if UNIFIED_ANALYSIS_AVAILABLE and hasattr(st.session_state, 'unified_analysis_manager'):
                        try:
                            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¸è¶³ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
                            shortage_role_file = scenario_out_dir / "shortage_role_summary.parquet"
                            if shortage_role_file.exists():
                                role_df = pd.read_parquet(shortage_role_file)
                                
                                # çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã«ç™»éŒ²
                                shortage_result = st.session_state.unified_analysis_manager.create_shortage_analysis(
                                    file_name, scenario_key, role_df
                                )
                                
                                log.info(f"âœ… çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ä¸è¶³åˆ†æçµæœç™»éŒ²å®Œäº†: {shortage_result.analysis_key}")
                            else:
                                log.warning("âš ï¸ shortage_role_summary.parquetãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        except Exception as e:
                            log.error(f"çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã¸ã®çµæœç™»éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
                '''
                
                new_content = content[:insert_point] + insertion_code + content[insert_point:]
                
                with open(app_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                
                print("  âœ… shortage_and_briefå®Ÿè¡Œå¾Œã®çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ç™»éŒ²ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                return True
        else:
            print("  â„¹ï¸ çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ç™»éŒ²ã¯æ—¢ã«å®Ÿè£…æ¸ˆã¿ã§ã™")
            return True
    
    return False

def fix_5_add_memory_cleanup():
    """ä¿®æ­£5: ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®è‡ªå‹•å®Ÿè¡Œ"""
    print("\nğŸ”§ ä¿®æ­£5: ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®è‡ªå‹•å®Ÿè¡Œ")
    
    app_path = Path("app.py")
    with open(app_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¾Œã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’è¿½åŠ 
    ai_report_end_pattern = 'log.info("AIå‘ã‘åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")'
    if ai_report_end_pattern in content:
        cleanup_code = '''
                        
                        # ğŸ”§ ä¿®æ­£: çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                        if UNIFIED_ANALYSIS_AVAILABLE and hasattr(st.session_state, 'unified_analysis_manager'):
                            try:
                                st.session_state.unified_analysis_manager.cleanup_old_results(max_age_hours=1)
                                log.info("âœ… çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
                            except Exception as e:
                                log.warning(f"ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")'''
        
        insert_point = content.find(ai_report_end_pattern) + len(ai_report_end_pattern)
        new_content = content[:insert_point] + cleanup_code + content[insert_point:]
        
        with open(app_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print("  âœ… ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®è‡ªå‹•å®Ÿè¡Œã‚’è¿½åŠ ã—ã¾ã—ãŸ")
        return True
    else:
        print("  â„¹ï¸ AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆç®‡æ‰€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False

def validate_fixes():
    """ä¿®æ­£å†…å®¹ã®æ¤œè¨¼"""
    print("\nâœ… ä¿®æ­£å†…å®¹ã®æ¤œè¨¼")
    
    # æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
    import ast
    
    files_to_validate = [
        "app.py",
        "shift_suite/tasks/unified_analysis_manager.py",
        "shift_suite/tasks/shortage.py"
    ]
    
    for file_path in files_to_validate:
        if Path(file_path).exists():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                ast.parse(content)
                print(f"  âœ… {file_path}: æ§‹æ–‡OK")
            except SyntaxError as e:
                print(f"  âŒ {file_path}: æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ - {e}")
                return False
            except Exception as e:
                print(f"  âš ï¸ {file_path}: æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ - {e}")
    
    return True

def main():
    """ãƒ¡ã‚¤ãƒ³ä¿®æ­£å‡¦ç†"""
    print("ğŸš€ çµ±ä¸€åˆ†æç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  å…¨ä½“æœ€é©åŒ–ä¿®æ­£å®Ÿè¡Œ")
    print("=" * 80)
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    backup_dir = create_comprehensive_backup()
    
    # ä¿®æ­£ã®å®Ÿè¡Œ
    fixes_applied = []
    
    if fix_1_unified_system_debug_logging():
        fixes_applied.append("çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ ")
    
    if fix_2_file_name_consistency():
        fixes_applied.append("ãƒ•ã‚¡ã‚¤ãƒ«åä¸€è²«æ€§ç¢ºä¿")
    
    if fix_3_shortage_slot_hours():
        fixes_applied.append("shortage.pyå›ºå®šå€¤ä¿®æ­£")
    
    if fix_4_add_analysis_execution_validation():
        fixes_applied.append("åˆ†æå®Ÿè¡Œçµæœæ¤œè¨¼è¿½åŠ ")
    
    if fix_5_add_memory_cleanup():
        fixes_applied.append("ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—è‡ªå‹•åŒ–")
    
    # æ¤œè¨¼
    if validate_fixes():
        print(f"\nğŸ‰ ä¿®æ­£å®Œäº†ï¼é©ç”¨ã•ã‚ŒãŸä¿®æ­£: {len(fixes_applied)}ä»¶")
        for i, fix in enumerate(fixes_applied, 1):
            print(f"  {i}. {fix}")
        
        print(f"\nğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_dir}")
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. streamlit run app.py ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•")
        print("2. ãƒ‡ã‚¤_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿_ä¼‘æ—¥ç²¾ç·».xlsx ã§å†ãƒ†ã‚¹ãƒˆ")
        print("3. ãƒ­ã‚°ï¼ˆshift_suite.logï¼‰ã§ä¿®æ­£åŠ¹æœã‚’ç¢ºèª")
        return True
    else:
        print("\nâŒ ä¿®æ­£ä¸­ã«æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        print(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒã—ã¦ãã ã•ã„: {backup_dir}")
        return False

if __name__ == "__main__":
    main()