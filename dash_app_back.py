# dash_app.py - Shift-Suiteé«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢ (app.pyæ©Ÿèƒ½å®Œå…¨å†ç¾ç‰ˆ)
import base64
import io
import json
import logging
import tempfile
import zipfile
import threading
import time
import weakref
import psutil
import os
from functools import lru_cache, wraps
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from collections import OrderedDict
import unicodedata

import dash
import dash_cytoscape as cyto
import numpy as np
import pandas as pd
import pyarrow.parquet as pq

import plotly.express as px
import plotly.graph_objects as go
from dash import dash_table, dcc, html
from dash.dependencies import Input, Output, State, ALL
from dash.exceptions import PreventUpdate
from flask import jsonify
import traceback
import gc
from shift_suite.tasks.utils import safe_read_excel, gen_labels
from shift_suite.tasks.shortage_factor_analyzer import ShortageFactorAnalyzer
from shift_suite.tasks import over_shortage_log
from shift_suite.tasks.daily_cost import calculate_daily_cost
from shift_suite.tasks import leave_analyzer
try:
    from shift_suite.tasks.analyzers.synergy_enhanced import (
        analyze_synergy, analyze_team_synergy, analyze_synergy_by_role, 
        analyze_all_roles_synergy, create_synergy_correlation_matrix, 
        create_synergy_correlation_matrix_optimized
    )
except ImportError:
    from shift_suite.tasks.analyzers.synergy import analyze_synergy
    analyze_team_synergy = None
    analyze_synergy_by_role = None
    analyze_all_roles_synergy = None
    create_synergy_correlation_matrix = None
    create_synergy_correlation_matrix_optimized = None
from shift_suite.tasks.analyzers.team_dynamics import analyze_team_dynamics
from shift_suite.tasks.blueprint_analyzer import create_blueprint_list
from shift_suite.tasks.integrated_creation_logic_viewer import (
    create_creation_logic_analysis_tab,
)
from shift_suite.tasks.quick_logic_analysis import (
    get_basic_shift_stats,
    get_quick_patterns,
    run_optimized_analysis,
    create_stats_cards,
    create_pattern_list,
    create_deep_analysis_display,
)
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

def create_shortage_from_heat_all(heat_all_df: pd.DataFrame) -> pd.DataFrame:
    """
    heat_ALLãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸è¶³ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹
    """
    if heat_all_df.empty:
        return pd.DataFrame()
    
    # æ—¥ä»˜åˆ—ã‚’ç‰¹å®šï¼ˆæ•°å€¤ã§ãªã„åˆ—ã¯é™¤å¤–ï¼‰
    date_columns = [col for col in heat_all_df.columns if col not in ['staff', 'role', 'code', 'sum', 'max', 'min', 'avg', 'need']]
    
    if not date_columns:
        return pd.DataFrame()
    
    # æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    time_index = heat_all_df.index
    
    # å„æ—¥ä»˜ãƒ»æ™‚é–“å¸¯ã®ä¸è¶³ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    shortage_data = {}
    for date_col in date_columns:
        if date_col in heat_all_df.columns:
            # å®Ÿéš›ã®äººæ•°ã‹ã‚‰å¿…è¦äººæ•°ã‚’å¼•ã„ã¦ä¸è¶³ã‚’è¨ˆç®—
            # æ­£ã®å€¤ã¯ä¸è¶³ã€è² ã®å€¤ã¯éå‰°
            actual_staff = heat_all_df[date_col].fillna(0)
            if 'need' in heat_all_df.columns:
                need = heat_all_df['need'].fillna(0)
                shortage = need - actual_staff
            else:
                # needãŒãªã„å ´åˆã¯ã€å¹³å‡å€¤ã‚’åŸºæº–ã¨ã™ã‚‹
                avg_staff = actual_staff.mean()
                shortage = avg_staff - actual_staff
            
            # ä¸è¶³ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹ï¼ˆæ­£ã®å€¤ã®ã¿ï¼‰
            shortage = shortage.clip(lower=0)
            shortage_data[date_col] = shortage
    
    if not shortage_data:
        return pd.DataFrame()
    
    shortage_df = pd.DataFrame(shortage_data, index=time_index)
    return shortage_df

def simple_synergy_analysis(long_df: pd.DataFrame, target_staff: str) -> pd.DataFrame:
    """
    ã‚·ãƒ³ãƒ—ãƒ«ãªã‚·ãƒŠã‚¸ãƒ¼åˆ†æï¼ˆshortage_dfã‚’ä½¿ã‚ãªã„ç‰ˆï¼‰
    å…±åƒé »åº¦ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ç›¸é–¢ã«åŸºã¥ãåˆ†æ
    """
    if long_df.empty or not target_staff:
        return pd.DataFrame()
    
    # å¯¾è±¡è·å“¡ã®å‹¤å‹™è¨˜éŒ²
    target_work = long_df[long_df['staff'] == target_staff]
    if target_work.empty:
        return pd.DataFrame()
    
    # ä»–ã®è·å“¡ã¨ã®å…±åƒåˆ†æ
    synergy_scores = []
    other_staff = long_df[long_df['staff'] != target_staff]['staff'].unique()
    
    for coworker in other_staff:
        coworker_work = long_df[long_df['staff'] == coworker]
        if coworker_work.empty:
            continue
        
        # å…±åƒã—ãŸæ—¥æ™‚ã‚’ç‰¹å®š
        target_slots = set(target_work['ds'])
        coworker_slots = set(coworker_work['ds'])
        together_slots = target_slots & coworker_slots
        
        if len(together_slots) < 2:  # æœ€ä½é™ã®å…±åƒå›æ•°
            continue
        
        # å…±åƒé »åº¦ã®è¨ˆç®—
        total_target_slots = len(target_slots)
        together_ratio = len(together_slots) / total_target_slots if total_target_slots > 0 else 0
        
        # ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆå…±åƒé »åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
        # ã‚ˆã‚Šå¤šãä¸€ç·’ã«åƒã = ã‚ˆã‚Šè‰¯ã„ç›¸æ€§ã¨ä»®å®š
        synergy_score = together_ratio * 100  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸
        
        synergy_scores.append({
            "ç›¸æ‰‹ã®è·å“¡": coworker,
            "ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢": synergy_score,
            "å…±åƒã‚¹ãƒ­ãƒƒãƒˆæ•°": len(together_slots)
        })
    
    if not synergy_scores:
        return pd.DataFrame()
    
    result_df = pd.DataFrame(synergy_scores).sort_values("ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢", ascending=False).reset_index(drop=True)
    return result_df

# ãƒ­ã‚¬ãƒ¼è¨­å®š
LOG_LEVEL = logging.DEBUG
log_stream = io.StringIO()

logging.basicConfig(
    level=LOG_LEVEL,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.StreamHandler(stream=log_stream)
    ],
    force=True
)
log = logging.getLogger(__name__)

# Analysis logger configuration
analysis_logger = logging.getLogger('analysis')
analysis_logger.setLevel(logging.INFO)
analysis_logger.propagate = False
try:
    file_handler = logging.FileHandler('analysis_log.log', mode='a', encoding='utf-8')
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - [%(module)s.%(funcName)s] - %(message)s')
    file_handler.setFormatter(formatter)
    if not analysis_logger.handlers:
        analysis_logger.addHandler(file_handler)
except Exception as e:
    logging.error(f"\u5206\u6790\u30ed\u30b0\u30d5\u30a1\u30a4\u30eb\u306e\u8a2d\u5b9a\u306b\u5931\u6557\u3057\u307e\u3057\u305f: {e}")

# Dashã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
app = dash.Dash(__name__, suppress_callback_exceptions=True)
server = app.server
app.title = "Shift-Suite é«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢"

# Flask error handlers
@server.errorhandler(Exception)
def handle_exception(e):
    """Catch all unhandled exceptions."""
    log.exception("Unhandled exception in request:")
    error_info = {
        "error": str(e),
        "type": type(e).__name__,
        "traceback": traceback.format_exc(),
    }
    return jsonify(error_info), 200


@server.errorhandler(500)
def handle_500(e):
    log.error("500 error occurred")
    return jsonify({"error": "Internal server error", "message": str(e)}), 200

# === ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ç®¡ç†ï¼ˆå®‰å®šæ€§å‘ä¸Šç‰ˆï¼‰ ===
# ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªLRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å®Ÿè£…
class ThreadSafeLRUCache:
    """ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªLRUã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Ÿè£…"""
    def __init__(self, maxsize: int = 50):
        self._cache = OrderedDict()
        self._lock = threading.RLock()
        self._maxsize = maxsize
        self._hits = 0
        self._misses = 0
        
    def get(self, key: str, default=None):
        with self._lock:
            if key in self._cache:
                # LRU: æœ€è¿‘ä½¿ç”¨ã—ãŸã‚‚ã®ã‚’æœ«å°¾ã«ç§»å‹•
                self._cache.move_to_end(key)
                self._hits += 1
                return self._cache[key]
            self._misses += 1
            return default
            
    def set(self, key: str, value: Any):
        with self._lock:
            if key in self._cache:
                del self._cache[key]
            self._cache[key] = value
            # ã‚µã‚¤ã‚ºåˆ¶é™ã‚’è¶…ãˆãŸã‚‰æœ€ã‚‚å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
            if len(self._cache) > self._maxsize:
                oldest_key = next(iter(self._cache))
                del self._cache[oldest_key]
                log.debug(f"Cache evicted: {oldest_key}")
                
    def clear(self):
        with self._lock:
            self._cache.clear()
            self._hits = 0
            self._misses = 0
            
    def get_stats(self):
        with self._lock:
            total = self._hits + self._misses
            hit_rate = self._hits / total if total > 0 else 0
            return {
                "size": len(self._cache),
                "hits": self._hits,
                "misses": self._misses,
                "hit_rate": hit_rate
            }
            
    def __contains__(self, key):
        with self._lock:
            return key in self._cache
            
    def keys(self):
        with self._lock:
            return list(self._cache.keys())

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ­ãƒƒã‚¯
DATA_CACHE = ThreadSafeLRUCache(maxsize=50)

# ã‚·ãƒŠã‚¸ãƒ¼åˆ†æçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
SYNERGY_CACHE = ThreadSafeLRUCache(maxsize=10)

def get_synergy_cache_key(long_df: pd.DataFrame, shortage_df: pd.DataFrame) -> str:
    """ã‚·ãƒŠã‚¸ãƒ¼åˆ†æçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
    try:
        # ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã¨ã™ã‚‹
        import hashlib
        long_hash = hashlib.md5(str(long_df.shape).encode() + str(long_df.columns.tolist()).encode()).hexdigest()[:8]
        shortage_hash = hashlib.md5(str(shortage_df.shape).encode() + str(shortage_df.columns.tolist()).encode()).hexdigest()[:8]
        return f"synergy_{long_hash}_{shortage_hash}"
    except:
        return "synergy_default"

def clear_synergy_cache():
    """ã‚·ãƒŠã‚¸ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
    global SYNERGY_CACHE
    SYNERGY_CACHE.clear()
    log.info("ã‚·ãƒŠã‚¸ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
LOADING_STATUS = {}  # èª­ã¿è¾¼ã¿ä¸­ã®ã‚­ãƒ¼ã‚’è¿½è·¡
LOADING_LOCK = threading.Lock()
# Path to the currently selected scenario directory.
CURRENT_SCENARIO_DIR: Path | None = None
# Temporary directory object for uploaded scenarios
TEMP_DIR_OBJ: tempfile.TemporaryDirectory | None = None

# ``LOGIC_ANALYSIS_CACHE`` stores results keyed by dataframe hash
LOGIC_ANALYSIS_CACHE: dict[int, dict[str, object]] = {}

def get_cached_analysis(df_hash: int):
    """Return cached analysis results for the given hash."""
    return LOGIC_ANALYSIS_CACHE.get(df_hash)


def cache_analysis(df_hash: int, results: dict) -> None:
    """Cache analysis results keeping at most 3 entries."""
    if len(LOGIC_ANALYSIS_CACHE) >= 3:
        oldest_key = next(iter(LOGIC_ANALYSIS_CACHE))
        del LOGIC_ANALYSIS_CACHE[oldest_key]
    LOGIC_ANALYSIS_CACHE[df_hash] = results

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
def safe_filename(name: str) -> str:
    """Normalize and sanitize strings for file keys"""
    name = unicodedata.normalize("NFKC", name)
    for ch in ["/", "\\", ":", "*", "?", "\"", "<", ">", "|", "ãƒ»", "ï¼", "ï¼¼"]:
        name = name.replace(ch, "_")
    return name


def calculate_role_dynamic_need(df_heat: pd.DataFrame, date_cols: List[str], heat_key: str) -> pd.DataFrame:
    """
    è·ç¨®åˆ¥ãƒ»é›‡ç”¨å½¢æ…‹åˆ¥ã®å‹•çš„needå€¤ã‚’æ­£ç¢ºã«è¨ˆç®—ã™ã‚‹å…±é€šé–¢æ•°
    
    Args:
        df_heat: è·ç¨®åˆ¥ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿
        date_cols: æ—¥ä»˜åˆ—ã®ãƒªã‚¹ãƒˆ
        heat_key: ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚­ãƒ¼ï¼ˆãƒ­ã‚°ç”¨ï¼‰
    
    Returns:
        è¨ˆç®—ã•ã‚ŒãŸå‹•çš„needå€¤ã®DataFrame
    """
    log.info(f"[ROLE_DYNAMIC_NEED] Calculating for {heat_key}")
    
    # â˜…â˜…â˜… ä¿®æ­£ï¼šè©³ç´°Needå€¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ä½¿ç”¨ â˜…â˜…â˜…
    # è·ç¨®åˆ¥ã¾ãŸã¯é›‡ç”¨å½¢æ…‹åˆ¥ã®è©³ç´°Needå€¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    detailed_need_key = None
    if heat_key.startswith('heat_emp_'):
        # é›‡ç”¨å½¢æ…‹åˆ¥
        emp_name = heat_key.replace('heat_emp_', '').replace('heat_', '')
        detailed_need_key = f"need_per_date_slot_emp_{emp_name}"
    elif heat_key.startswith('heat_') and heat_key not in ['heat_all', 'heat_ALL']:
        # è·ç¨®åˆ¥
        role_name = heat_key.replace('heat_', '')
        detailed_need_key = f"need_per_date_slot_role_{role_name}"
    
    # è©³ç´°Needå€¤ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ç›´æ¥ä½¿ç”¨
    if detailed_need_key:
        detailed_need_df = data_get(detailed_need_key, pd.DataFrame())
        if not detailed_need_df.empty:
            log.info(f"[ROLE_DYNAMIC_NEED] {heat_key}: Using detailed need file {detailed_need_key}")
            
            # æ—¥ä»˜åˆ—ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            available_date_cols = [col for col in date_cols if col in detailed_need_df.columns]
            if available_date_cols:
                filtered_need_df = detailed_need_df[available_date_cols].copy()
                filtered_need_df = filtered_need_df.reindex(index=df_heat.index, fill_value=0)
                log.info(f"[ROLE_DYNAMIC_NEED] {heat_key}: Successfully using detailed need values")
                return filtered_need_df
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®ãƒ­ã‚¸ãƒƒã‚¯
    log.warning(f"[ROLE_DYNAMIC_NEED] {heat_key}: Detailed need file not found, using fallback logic")
    
    # Step 1: need_per_date_slotã‹ã‚‰å…¨ä½“ã®å‹•çš„needå€¤ã‚’å–å¾—
    need_per_date_df = data_get('need_per_date_slot', pd.DataFrame())
    
    if need_per_date_df.empty or len(date_cols) == 0:
        log.warning(f"[ROLE_DYNAMIC_NEED] {heat_key}: Fallback to baseline need (no global data)")
        return pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                           index=df_heat.index, columns=date_cols)
    
    # Step 2: å…¨è·ç¨®ã®åŸºæº–needå€¤ã®åˆè¨ˆã‚’è¨ˆç®—
    # heat_ALLï¼ˆå…¨ä½“ï¼‰ã¨é›‡ç”¨å½¢æ…‹åˆ¥ï¼ˆheat_emp_ï¼‰ã‚’é™¤å¤–ã—ã¦å€‹åˆ¥è·ç¨®ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
    all_role_keys = [k for k in DATA_CACHE.keys() 
                    if k.startswith('heat_') 
                    and k not in ['heat_all', 'heat_ALL']
                    and not k.startswith('heat_emp_')]
    total_baseline_need = 0.0
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®å‡ºåŠ›
    all_heat_keys = [k for k in DATA_CACHE.keys() if k.startswith('heat_')]
    log.info(f"[ROLE_DYNAMIC_NEED] All heat keys: {all_heat_keys}")
    log.info(f"[ROLE_DYNAMIC_NEED] Filtered role keys: {all_role_keys}")
    
    for role_key in all_role_keys:
        role_heat = data_get(role_key, pd.DataFrame())
        if not role_heat.empty and 'need' in role_heat.columns:
            role_baseline = role_heat['need'].sum()
            total_baseline_need += role_baseline
            log.debug(f"[ROLE_DYNAMIC_NEED] {role_key}: baseline_need={role_baseline:.2f}")
    
    if total_baseline_need <= 0:
        log.warning(f"[ROLE_DYNAMIC_NEED] {heat_key}: Fallback to baseline need (no total baseline)")
        return pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                           index=df_heat.index, columns=date_cols)
    
    # Step 3: å½“å‰è·ç¨®ã®æ¯”ç‡ã‚’è¨ˆç®—
    current_role_total_baseline = df_heat['need'].sum() if 'need' in df_heat.columns else len(df_heat)
    role_ratio = current_role_total_baseline / total_baseline_need
    
    log.info(f"[ROLE_DYNAMIC_NEED] {heat_key}: role_ratio={role_ratio:.4f}, baseline_need={current_role_total_baseline}, total_baseline={total_baseline_need}")
    
    # Step 4: å…¨ä½“ã®å‹•çš„needå€¤ã«è·ç¨®æ¯”ç‡ã‚’é©ç”¨
    need_df = pd.DataFrame(index=df_heat.index, columns=date_cols)
    need_per_date_df.columns = [str(col) for col in need_per_date_df.columns]
    
    for date_col in date_cols:
        date_str = str(date_col)
        if date_str in need_per_date_df.columns:
            overall_need_series = need_per_date_df[date_str]
            
            # æ™‚é–“å¸¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆã‚ã›ã‚‹
            if len(overall_need_series) == len(df_heat):
                role_need_series = overall_need_series * role_ratio
                need_df[date_col] = role_need_series.values
            else:
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸ä¸€è‡´ã®å ´åˆã¯å¹³å‡å€¤ã‚’ä½¿ç”¨
                avg_need = overall_need_series.mean() * role_ratio
                need_df[date_col] = avg_need
        else:
            # è©²å½“æ—¥ä»˜ãŒãªã„å ´åˆã¯åŸºæº–å€¤ã‚’ä½¿ç”¨
            need_df[date_col] = df_heat['need'].values
    
    need_df = need_df.fillna(0)
    total_calculated_need = need_df.sum().sum()
    log.info(f"[ROLE_DYNAMIC_NEED] {heat_key}: Successfully calculated, total_need={total_calculated_need:.2f}")
    
    return need_df

def date_with_weekday(date_str: str) -> str:
    """æ—¥ä»˜æ–‡å­—åˆ—ã«æ›œæ—¥ã‚’è¿½åŠ """
    try:  # noqa: E722
        date = pd.to_datetime(date_str)
        weekdays = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
        return f"{date.strftime('%m/%d')}({weekdays[date.weekday()]})"
    except Exception:
        return str(date_str)


@lru_cache(maxsize=8)
def safe_read_parquet(filepath: Path) -> pd.DataFrame:
    """Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã¿çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    try:
        if not filepath.exists():
            log.debug(f"File does not exist: {filepath}")
            return pd.DataFrame()
        
        if filepath.stat().st_size == 0:
            log.warning(f"Empty file detected: {filepath}")
            return pd.DataFrame()
            
        df = pd.read_parquet(filepath)
        log.debug(f"Successfully loaded {filepath}: shape={df.shape}")
        return df
    except FileNotFoundError:
        log.debug(f"File not found: {filepath}")
        return pd.DataFrame()
    except pd.errors.EmptyDataError:
        log.warning(f"Empty data in file: {filepath}")
        return pd.DataFrame()
    except Exception as e:
        log.warning(f"Failed to read {filepath}: {type(e).__name__}: {e}")
        return pd.DataFrame()


@lru_cache(maxsize=8)
def safe_read_csv(filepath: Path) -> pd.DataFrame:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã¿çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    try:
        return pd.read_csv(filepath)  # type: ignore
    except Exception as e:
        log.warning(f"Failed to read {filepath}: {e}")
        return pd.DataFrame()


def clear_data_cache() -> None:
    """Clear cached data when the scenario changes with resource monitoring."""
    memory_before = get_memory_usage()
    log.info(f"Data cache clear started. Memory before: {memory_before['rss_mb']:.1f}MB")
    
    DATA_CACHE.clear()
    safe_read_parquet.cache_clear()
    safe_read_csv.cache_clear()
    
    # ç©æ¥µçš„ãªã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
    gc.collect()
    
    memory_after = get_memory_usage()
    memory_freed = memory_before['rss_mb'] - memory_after['rss_mb']
    log.info(f"Data cache cleared. Memory after: {memory_after['rss_mb']:.1f}MB (freed: {memory_freed:.1f}MB)")


# === ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–æ©Ÿèƒ½ï¼ˆå®‰å®šæ€§å‘ä¸Šã®ãŸã‚è¿½åŠ ï¼‰ ===
def get_memory_usage() -> Dict[str, float]:
    """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—"""
    try:
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        return {
            "rss_mb": memory_info.rss / 1024 / 1024,  # å®Ÿéš›ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
            "vms_mb": memory_info.vms / 1024 / 1024,  # ä»®æƒ³ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
            "percent": process.memory_percent(),       # ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã«å¯¾ã™ã‚‹å‰²åˆ
        }
    except Exception as e:
        log.warning(f"Memory usage monitoring failed: {e}")
        return {"rss_mb": 0, "vms_mb": 0, "percent": 0}

def check_memory_pressure() -> bool:
    """ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯"""
    memory_info = get_memory_usage()
    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡80%ä»¥ä¸Šã§è­¦å‘Š
    return memory_info["percent"] > 80

def emergency_cleanup():
    """ç·Šæ€¥ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    log.warning("ç·Šæ€¥ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œã—ã¾ã™")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
    DATA_CACHE.clear()
    safe_read_parquet.cache_clear()
    safe_read_csv.cache_clear()
    
    # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
    gc.collect()
    
    memory_after = get_memory_usage()
    log.info(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¾Œãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_after['rss_mb']:.1f}MB ({memory_after['percent']:.1f}%)")

# æ–°ã—ã„å®‰å®šæ€§å‘ä¸Šç‰ˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ©ãƒƒãƒ‘ãƒ¼
def safe_callback_enhanced(func):
    """Enhanced safe callback with resource monitoring and better error handling."""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        memory_start = get_memory_usage()
        
        try:
            # ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ãƒã‚§ãƒƒã‚¯
            if check_memory_pressure():
                log.warning(f"High memory usage before {func.__name__}: {memory_start['percent']:.1f}%")
                emergency_cleanup()
            
            # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªå®Ÿè¡Œ
            if gc.get_count()[0] > 700:
                gc.collect()
                
            # å®Ÿéš›ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
            result = func(*args, **kwargs)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°
            execution_time = time.time() - start_time
            memory_end = get_memory_usage()
            memory_delta = memory_end['rss_mb'] - memory_start['rss_mb']
            
            if execution_time > 5:  # 5ç§’ä»¥ä¸Šã®å‡¦ç†ã‚’è­¦å‘Š
                log.warning(f"Slow callback {func.__name__}: {execution_time:.2f}s, memory delta: {memory_delta:+.1f}MB")
            elif execution_time > 1:  # 1ç§’ä»¥ä¸Šã‚’æƒ…å ±ãƒ­ã‚°
                log.info(f"Callback {func.__name__}: {execution_time:.2f}s, memory delta: {memory_delta:+.1f}MB")
                
            return result
            
        except PreventUpdate:
            # PreventUpdateã¯æ­£å¸¸ãªãƒ•ãƒ­ãƒ¼ãªã®ã§å†ç™ºç”Ÿ
            raise
        except FileNotFoundError as e:
            log.error(f"File not found: {e}")
            return html.Div([
                html.H4("Error: File not found", style={'color': 'red'}),
                html.P(str(e)),
                html.P("Please check if the file was uploaded correctly.")
            ])
        except pd.errors.EmptyDataError:
            log.error("Empty dataframe")
            return html.Div([
                html.H4("Error: Data is empty", style={'color': 'orange'}),
                html.P("The data file may be empty or corrupted.")
            ])
        except MemoryError as e:
            log.error(f"Memory error: {e}")
            emergency_cleanup()
            return html.Div([
                html.H4("Memory Error", style={'color': 'red'}),
                html.P("Memory shortage occurred. Cache has been cleared."),
                html.P("Please refresh the browser or try with smaller dataset.")
            ])
        except TimeoutError as e:
            log.error(f"Timeout: {e}")
            return html.Div([
                html.H4("Processing Timeout", style={'color': 'orange'}),
                html.P("Processing is taking too long. Please reduce data size or wait.")
            ])
        except Exception as e:
            log.exception(f"Unexpected error in {func.__name__}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if check_memory_pressure():
                emergency_cleanup()
                
            return html.Div([
                html.H4(f"Error occurred ({func.__name__})", style={'color': 'red'}),
                html.Details([
                    html.Summary("Show error details"),
                    html.Pre(str(e), style={'background': '#f0f0f0', 'padding': '10px', 'overflow': 'auto'})
                ]),
                html.P("Please refresh the browser if the problem persists.")
            ])
    return wrapper

# çµ±ä¸€ã•ã‚ŒãŸsafe_callbacké–¢æ•°ï¼ˆEnhancedç‰ˆã‚’ä½¿ç”¨ï¼‰
safe_callback = safe_callback_enhanced


def data_get(key: str, default=None):
    """Load a data asset lazily from the current scenario directory with enhanced stability."""
    log.debug(f"data_get('{key}'): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¤œç´¢ä¸­...")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ï¼ˆThreadSafeLRUCacheã‚’ä½¿ç”¨ï¼‰
    cached_value = DATA_CACHE.get(key)
    if cached_value is not None:
        log.debug(f"data_get('{key}'): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ")
        return cached_value

    log.debug(f"data_get('{key}'): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã€‚ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚’é–‹å§‹...")

    if CURRENT_SCENARIO_DIR is None:
        log.warning(f"CURRENT_SCENARIO_DIRãŒæœªè¨­å®šã®ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚key={key}")
        default_value = default if default is not None else pd.DataFrame()
        DATA_CACHE.set(key, default_value)
        return default_value

    search_dirs = [CURRENT_SCENARIO_DIR, CURRENT_SCENARIO_DIR.parent]
    log.debug(f"Searching {search_dirs} for key {key}")

    # Special file names
    special = {
        "long_df": ["intermediate_data.parquet"],
        "daily_cost": ["daily_cost.parquet", "daily_cost.xlsx"],
        "shortage_time": ["shortage_time_CORRECTED.parquet"],
        "need_per_date_slot": ["need_per_date_slot.parquet"],
    }
    
    # â˜…â˜…â˜… è·ç¨®åˆ¥ãƒ»é›‡ç”¨å½¢æ…‹åˆ¥è©³ç´°Needå€¤ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢å¯¾å¿œ â˜…â˜…â˜…
    if key.startswith("need_per_date_slot_role_") or key.startswith("need_per_date_slot_emp_"):
        filenames = [f"{key}.parquet"]
    else:
        filenames = special.get(key, [f"{key}.parquet", f"{key}.csv", f"{key}.xlsx"])

    # Special handling for need_per_date_slot
    if key == "need_per_date_slot":
        for directory in search_dirs:
            fp = directory / "need_per_date_slot.parquet"
            if fp.exists():
                try:
                    log.debug(f"Loading need_per_date_slot from {fp}")
                    
                    # è¤‡æ•°ã®æ–¹æ³•ã§datetimeå•é¡Œã‚’å›é¿
                    df = None
                    
                    # æ–¹æ³•1: PyArrowãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã—ã¦èª­ã¿è¾¼ã¿ã€ã‚«ãƒ©ãƒ åã‚’æ‰‹å‹•å‡¦ç†
                    try:
                        table = pq.read_table(fp)
                        # ã‚«ãƒ©ãƒ åã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                        new_columns = [str(col) for col in table.column_names]
                        
                        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ï¼ˆindexå‡¦ç†ï¼‰
                        df = table.to_pandas()
                        df.columns = new_columns
                        
                        log.debug(f"Method 1 success: PyArrow table conversion")
                        
                    except Exception as e1:
                        log.debug(f"Method 1 failed: {e1}")
                        
                        # æ–¹æ³•2: pandasç›´æ¥èª­ã¿è¾¼ã¿ï¼ˆtypes_mapperãªã—ï¼‰
                        try:
                            df = pd.read_parquet(fp, engine='pyarrow', 
                                               use_nullable_dtypes=False)
                            df.columns = [str(col) for col in df.columns]
                            log.debug(f"Method 2 success: Direct pandas read")
                            
                        except Exception as e2:
                            log.debug(f"Method 2 failed: {e2}")
                            
                            # æ–¹æ³•3: æœ€å¾Œã®æ‰‹æ®µ - ãƒ•ã‚¡ã‚¤ãƒ«å†ä½œæˆ
                            try:
                                # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’åˆ¥ã®æ–¹æ³•ã§èª­ã¿è¾¼ã¿
                                temp_table = pq.read_table(fp)
                                temp_df = temp_table.to_pandas(types_mapper=pd.ArrowDtype)
                                temp_df.columns = [str(col) for col in temp_df.columns]
                                
                                # ä¸€æ™‚çš„ã«CSVçµŒç”±ã§å¤‰æ›
                                temp_csv = fp.with_suffix('.temp.csv')
                                temp_df.to_csv(temp_csv)
                                df = pd.read_csv(temp_csv, index_col=0)
                                temp_csv.unlink()  # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                                
                                log.debug(f"Method 3 success: CSV conversion")
                                
                            except Exception as e3:
                                log.error(f"All methods failed: {e1}, {e2}, {e3}")
                                raise e3
                    
                    if df is not None:
                        DATA_CACHE.set(key, df)
                        log.info(f"Successfully loaded need_per_date_slot: {df.shape}")
                        return df
                    else:
                        raise ValueError("Failed to load parquet file with any method")
                except Exception as e:
                    log.warning(f"Failed to load {fp}: {e}")
                    continue
        log.warning("need_per_date_slot.parquet not found")
        empty_df = pd.DataFrame()
        DATA_CACHE.set(key, empty_df)
        return empty_df

    for name in filenames:
        for directory in search_dirs:
            fp = directory / name
            log.debug(f"Checking {fp}")
            if fp.suffix == ".parquet" and fp.exists():
                df = safe_read_parquet(fp)
                if not df.empty:
                    DATA_CACHE.set(key, df)
                    log.debug(f"Loaded {fp} into cache for {key}")
                    return df
                break
            if fp.suffix == ".csv" and fp.exists():
                df = safe_read_csv(fp)
                if not df.empty:
                    DATA_CACHE.set(key, df)
                    log.debug(f"Loaded {fp} into cache for {key}")
                    return df
                break
            if fp.suffix == ".xlsx" and fp.exists():
                df = safe_read_excel(fp)
                if not df.empty:
                    DATA_CACHE.set(key, df)
                    log.debug(f"Loaded {fp} into cache for {key}")
                    return df
                break

    if key == "summary_report":
        files = sorted(CURRENT_SCENARIO_DIR.glob("OverShortage_SummaryReport_*.md"))
        if files:
            text = files[-1].read_text(encoding="utf-8")
            DATA_CACHE.set(key, text)
            log.debug(f"Loaded summary report {files[-1]}")
            return text
    if key in {"roles", "employments"}:
        roles, employments = load_shortage_meta(CURRENT_SCENARIO_DIR)
        DATA_CACHE.set("roles", roles)
        DATA_CACHE.set("employments", employments)
        return DATA_CACHE.get(key, default)

    if key == "shortage_events":
        df_events = over_shortage_log.list_events(CURRENT_SCENARIO_DIR)
        DATA_CACHE.set(key, df_events)
        DATA_CACHE.set("shortage_log_path", str(Path(CURRENT_SCENARIO_DIR) / "over_shortage_log.csv"))
        return DATA_CACHE.get(key, default)

    log.debug(f"ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼ '{key}' ã«å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    DATA_CACHE.set(key, default)
    return default


def _valid_df(df: pd.DataFrame) -> bool:
    """Return True if ``df`` is a non-empty :class:`~pandas.DataFrame`."""
    return isinstance(df, pd.DataFrame) and not df.empty


def calc_ratio_from_heatmap(df: pd.DataFrame) -> pd.DataFrame:
    """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸è¶³ç‡ã‚’è¨ˆç®—ï¼ˆçµ±åˆã‚·ã‚¹ãƒ†ãƒ å¯¾å¿œï¼‰"""
    if df.empty:
        return pd.DataFrame()

    date_cols = [c for c in df.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    if not date_cols:
        return pd.DataFrame()

    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ : need_per_date_slotã‚’å„ªå…ˆä½¿ç”¨
    need_per_date_df = data_get('need_per_date_slot')
    
    if not need_per_date_df.empty:
        # need_per_date_slotã‹ã‚‰need_dfã‚’ä½œæˆ
        log.info(f"Using need_per_date_slot for accurate need calculation: {need_per_date_df.shape}")
        
        # æ—¥ä»˜åˆ—ã®äº¤é›†åˆã‚’å–å¾—
        available_dates = [col for col in date_cols if str(col) in need_per_date_df.columns]
        
        if available_dates:
            need_df = need_per_date_df[[str(col) for col in available_dates]].copy()
            need_df.columns = available_dates  # å…ƒã®åˆ—åã«æˆ»ã™
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¸€è‡´ã•ã›ã‚‹
            common_index = df.index.intersection(need_df.index)
            need_df = need_df.loc[common_index]
        else:
            log.warning("No matching dates in need_per_date_slot, falling back to average need")
            need_df = pd.DataFrame(0.0, index=df.index, columns=date_cols)
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®average needä½¿ç”¨
        if "need" in df.columns:
            log.warning("need_per_date_slot not available, using average need values")
            need_series = df["need"].fillna(0)
            need_df = pd.DataFrame(
                np.repeat(need_series.values[:, np.newaxis], len(date_cols), axis=1),
                index=need_series.index,
                columns=date_cols
            )
        else:
            need_df = pd.DataFrame(0.0, index=df.index, columns=date_cols)
    staff_df = df[date_cols].fillna(0)
    
    # ä¿®æ­£: æ—¥æ›œæ—¥ã®éå‰°è¡¨ç¤ºã‚’é˜²ããŸã‚ã€è¨ˆç®—ã‚’å¼·åŒ–
    # need_dfãŒ0ã®å ´åˆã®é©åˆ‡ãªå‡¦ç†
    valid_need_mask = need_df > 0
    ratio_df = pd.DataFrame(0.0, index=need_df.index, columns=need_df.columns)
    
    # éœ€è¦ãŒã‚ã‚‹å ´åˆã®ã¿ä¸è¶³ç‡ã‚’è¨ˆç®—
    ratio_df = ratio_df.where(~valid_need_mask, 
                             ((need_df - staff_df) / need_df).clip(lower=0))
    
    # æœ€çµ‚çš„ã«NaNå€¤ã‚’0ã§åŸ‹ã‚ã‚‹ï¼ˆæ—¥æ›œæ—¥å¯¾ç­–ï¼‰
    ratio_df = ratio_df.fillna(0)
    
    return ratio_df


def load_shortage_meta(data_dir: Path) -> Tuple[List[str], List[str]]:
    """è·ç¨®ã¨é›‡ç”¨å½¢æ…‹ã®ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    roles = []
    employments = []
    meta_fp = data_dir / "shortage.meta.json"
    if meta_fp.exists():
        try:
            with open(meta_fp, 'r', encoding='utf-8') as f:
                meta = json.load(f)
            roles = meta.get("roles", [])
            employments = meta.get("employments", [])
        except Exception as e:
            log.debug(f"Failed to load shortage meta: {e}")
    return roles, employments



def load_and_sum_heatmaps(data_dir: Path, keys: List[str]) -> pd.DataFrame:
    """Load multiple heatmap files and aggregate them."""
    dfs = []
    for key in keys:
        df = data_get(key)
        if df is None and data_dir:
            fp = Path(data_dir) / f"{key}.parquet"
            if fp.exists():
                df = safe_read_parquet(fp)
                if not df.empty:
                    DATA_CACHE.set(key, df)
        if isinstance(df, pd.DataFrame) and not df.empty:
            dfs.append(df)

    if not dfs:
        return pd.DataFrame()

    total = dfs[0].copy()
    for df in dfs[1:]:
        total = total.add(df, fill_value=0)

    if {"need", "staff"}.issubset(total.columns):
        total["lack"] = (total["need"] - total["staff"]).clip(lower=0)
    if {"staff", "upper"}.issubset(total.columns):
        total["excess"] = (total["staff"] - total["upper"]).clip(lower=0)

    return total


def generate_heatmap_figure(df_heat: pd.DataFrame, title: str) -> go.Figure:
    """æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã™ã‚‹"""
    if df_heat is None or df_heat.empty:
        return go.Figure().update_layout(title_text=f"{title}: ãƒ‡ãƒ¼ã‚¿ãªã—", height=300)

    date_cols = [c for c in df_heat.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    if not date_cols:
        return go.Figure().update_layout(title_text=f"{title}: è¡¨ç¤ºå¯èƒ½ãªæ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãªã—", height=300)

    display_df = df_heat[date_cols]
    time_labels = gen_labels(30)
    display_df = display_df.reindex(time_labels, fill_value=0)
    
    # ä¿®æ­£ç‚¹1: NaNå€¤ã‚’æ˜ç¤ºçš„ã«0ã§åŸ‹ã‚ã‚‹
    display_df = display_df.fillna(0)
    
    display_df_renamed = display_df.copy()
    display_df_renamed.columns = [date_with_weekday(c) for c in display_df.columns]

    # ä¿®æ­£ç‚¹2: text_autoã‚’è¿½åŠ ã—ã¦ã€0å€¤ã‚‚è¡¨ç¤ºã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
    fig = px.imshow(
        display_df_renamed,
        aspect='auto',
        color_continuous_scale=px.colors.sequential.Viridis,
        title=title,
        labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'},
        text_auto=True  # ã‚»ãƒ«ã«å€¤ã‚’è¡¨ç¤º
    )
    
    # ä¿®æ­£ç‚¹3: 0å€¤ã®è¡¨ç¤ºã‚¹ã‚¿ã‚¤ãƒ«ã‚’èª¿æ•´
    fig.update_traces(
        texttemplate='%{text}',
        textfont={"size": 10}
    )
    fig.update_xaxes(tickvals=list(range(len(display_df.columns))))
    return fig


def create_knowledge_network_graph(network_data: Dict) -> cyto.Cytoscape:
    """Return an interactive network graph of implicit knowledge."""
    nodes = [
        {"data": {"id": n["id"], "label": n["label"]}}
        for n in network_data.get("nodes", [])
    ]
    edges = [
        {
            "data": {
                "source": e.get("from"),
                "target": e.get("to"),
                "label": e.get("label", ""),
            }
        }
        for e in network_data.get("edges", [])
    ]

    return cyto.Cytoscape(
        id="knowledge-network-graph",
        elements=nodes + edges,
        style={"width": "100%", "height": "500px"},
        layout={"name": "cose"},
        stylesheet=[
            {"selector": "node", "style": {"content": "data(label)", "font-size": "10px"}},
            {
                "selector": "edge",
                "style": {
                    "label": "data(label)",
                    "font-size": "8px",
                    "curve-style": "bezier",
                },
            },
        ],
    )

# --- UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç”Ÿæˆé–¢æ•° ---
def create_metric_card(label: str, value: str, color: str = "#1f77b4") -> html.Div:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆ"""
    return html.Div([
        html.Div(label, style={  # type: ignore
            'fontSize': '14px',
            'color': '#666',
            'marginBottom': '5px'
        }),
        html.Div(value, style={  # type: ignore
            'fontSize': '24px',
            'fontWeight': 'bold',
            'color': color
        })
    ], style={
        'padding': '15px',
        'backgroundColor': 'white',
        'borderRadius': '8px',
        'boxShadow': '0 2px 4px rgba(0,0,0,0.1)',
        'textAlign': 'center',
        'minHeight': '80px'
    })


def create_overview_tab() -> html.Div:
    """æ¦‚è¦ã‚¿ãƒ–ã‚’ä½œæˆ"""
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame())
    df_fairness = data_get('fairness_before', pd.DataFrame())
    df_staff = data_get('staff_stats', pd.DataFrame())
    df_alerts = data_get('stats_alerts', pd.DataFrame())

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ï¼ˆé‡è¤‡ã‚«ã‚¦ãƒ³ãƒˆã‚’å›é¿ï¼‰
    # ç·ä¸è¶³æ™‚é–“ã®æ­£ã—ã„è¨ˆç®—
    lack_h = 0
    if not df_shortage_role.empty and 'lack_h' in df_shortage_role.columns:
        # ã€Œå…¨ä½“ã€ã€Œåˆè¨ˆã€ã€Œç·è¨ˆã€ã®è¡ŒãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        total_rows = df_shortage_role[df_shortage_role['role'].isin(['å…¨ä½“', 'åˆè¨ˆ', 'ç·è¨ˆ'])]
        if not total_rows.empty:
            lack_h = total_rows['lack_h'].iloc[0]
        else:
            # shortage_timeã‹ã‚‰ç›´æ¥è¨ˆç®—ã™ã‚‹æ–¹ãŒæ­£ç¢º
            shortage_time_df = data_get('shortage_time', pd.DataFrame())
            if not shortage_time_df.empty:
                # å„ã‚»ãƒ«ã®å€¤ã‚’åˆè¨ˆï¼ˆ30åˆ†å˜ä½ãªã®ã§0.5æ™‚é–“ï¼‰
                try:
                    shortage_values = shortage_time_df.select_dtypes(include=[np.number]).values
                    if shortage_values.size > 0:
                        total_slots = np.nansum(shortage_values)
                        if np.isfinite(total_slots):
                            lack_h = float(total_slots * 0.5)
                        else:
                            log.warning("shortage_timeè¨ˆç®—ã§ç„¡é™å€¤ã¾ãŸã¯NaNãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                            lack_h = df_shortage_role['lack_h'].sum()
                    else:
                        log.debug("shortage_time_dfã«æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                        lack_h = df_shortage_role['lack_h'].sum()
                except Exception as e:
                    log.debug(f"shortage_timeè¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼: {e}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šè·ç¨®åˆ¥ã®åˆè¨ˆï¼ˆé‡è¤‡ã®å¯èƒ½æ€§ã‚ã‚Šï¼‰
                    lack_h = df_shortage_role['lack_h'].sum()
            else:
                # æœ€çµ‚çš„ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                lack_h = df_shortage_role['lack_h'].sum()
    
    # ã‚³ã‚¹ãƒˆè¨ˆç®—ã‚‚åŒæ§˜ã«ä¿®æ­£
    excess_cost = 0
    lack_temp_cost = 0
    lack_penalty_cost = 0
    
    if not df_shortage_role.empty:
        # åˆè¨ˆè¡ŒãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        total_rows = df_shortage_role[df_shortage_role['role'].isin(['å…¨ä½“', 'åˆè¨ˆ', 'ç·è¨ˆ'])]
        if not total_rows.empty:
            excess_cost = total_rows['estimated_excess_cost'].iloc[0] if 'estimated_excess_cost' in total_rows.columns else 0
            lack_temp_cost = total_rows['estimated_lack_cost_if_temporary_staff'].iloc[0] if 'estimated_lack_cost_if_temporary_staff' in total_rows.columns else 0
            lack_penalty_cost = total_rows['estimated_lack_penalty_cost'].iloc[0] if 'estimated_lack_penalty_cost' in total_rows.columns else 0
        else:
            # åˆè¨ˆè¡ŒãŒãªã„å ´åˆã¯ã€é‡è¤‡ã‚’è€ƒæ…®ã›ãšã«åˆè¨ˆ
            excess_cost = df_shortage_role['estimated_excess_cost'].sum() if 'estimated_excess_cost' in df_shortage_role.columns else 0
            lack_temp_cost = df_shortage_role['estimated_lack_cost_if_temporary_staff'].sum() if 'estimated_lack_cost_if_temporary_staff' in df_shortage_role.columns else 0
            lack_penalty_cost = df_shortage_role['estimated_lack_penalty_cost'].sum() if 'estimated_lack_penalty_cost' in df_shortage_role.columns else 0

    # JainæŒ‡æ•°ã®å®‰å…¨ãªå–å¾—
    jain_index = "N/A"
    try:
        if not df_fairness.empty and 'metric' in df_fairness.columns:
            jain_row = df_fairness[df_fairness['metric'] == 'jain_index']
            if not jain_row.empty and 'value' in jain_row.columns:
                value = jain_row['value'].iloc[0]
                if pd.notna(value):
                    jain_index = f"{float(value):.3f}"
    except (ValueError, TypeError, IndexError) as e:
        log.debug(f"JainæŒ‡æ•°ã®è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼: {e}")
        jain_index = "ã‚¨ãƒ©ãƒ¼"

    # åŸºæœ¬çµ±è¨ˆã®å®‰å…¨ãªè¨ˆç®—
    staff_count = len(df_staff) if not df_staff.empty else 0
    avg_night_ratio = 0
    try:
        if not df_staff.empty and 'night_ratio' in df_staff.columns:
            night_ratios = df_staff['night_ratio'].dropna()
            avg_night_ratio = float(night_ratios.mean()) if len(night_ratios) > 0 else 0
    except (ValueError, TypeError) as e:
        log.debug(f"å¤œå‹¤æ¯”ç‡ã®è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼: {e}")
        avg_night_ratio = 0
    
    alerts_count = len(df_alerts) if not df_alerts.empty else 0

    return html.Div([
        html.Div(id='overview-insights', style={  # type: ignore
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("åˆ†ææ¦‚è¦", style={'marginBottom': '20px'}),  # type: ignore
        # ğŸ“Š é‡è¦æŒ‡æ¨™ã‚’å¤§ããè¡¨ç¤ºï¼ˆæœ€å„ªå…ˆï¼‰
        html.Div([  # type: ignore
            html.Div([
                html.Div([
                    html.H2(f"{lack_h:.1f}", style={
                        'margin': '0', 'color': '#d32f2f' if lack_h > 100 else '#2e7d32', 
                        'fontSize': '3rem', 'fontWeight': 'bold'
                    }),
                    html.P("ç·ä¸è¶³æ™‚é–“(h)", style={'margin': '5px 0', 'fontSize': '1.1rem', 'color': '#666'})
                ], style={
                    'textAlign': 'center', 'padding': '20px', 'backgroundColor': 'white',
                    'borderRadius': '12px', 'boxShadow': '0 4px 8px rgba(0,0,0,0.12)',
                    'border': f"3px solid {'#d32f2f' if lack_h > 100 else '#2e7d32'}"
                }),
            ], style={'width': '24%', 'display': 'inline-block', 'padding': '5px'}),
            
            html.Div([
                html.Div([
                    html.H3(f"{excess_cost:,.0f}", style={
                        'margin': '0', 'color': '#ff9800', 'fontSize': '2rem', 'fontWeight': 'bold'
                    }),
                    html.P("ç·éå‰°ã‚³ã‚¹ãƒˆ(Â¥)", style={'margin': '5px 0', 'fontSize': '1rem', 'color': '#666'})
                ], style={
                    'textAlign': 'center', 'padding': '15px', 'backgroundColor': 'white',
                    'borderRadius': '8px', 'boxShadow': '0 2px 4px rgba(0,0,0,0.1)',
                    'border': '2px solid #ff9800'
                }),
            ], style={'width': '24%', 'display': 'inline-block', 'padding': '5px'}),
            
            html.Div([
                html.Div([
                    html.H3(f"{lack_temp_cost:,.0f}", style={
                        'margin': '0', 'color': '#f44336', 'fontSize': '2rem', 'fontWeight': 'bold'
                    }),
                    html.P("ä¸è¶³ã‚³ã‚¹ãƒˆ(æ´¾é£)(Â¥)", style={'margin': '5px 0', 'fontSize': '1rem', 'color': '#666'})
                ], style={
                    'textAlign': 'center', 'padding': '15px', 'backgroundColor': 'white',
                    'borderRadius': '8px', 'boxShadow': '0 2px 4px rgba(0,0,0,0.1)',
                    'border': '2px solid #f44336'
                }),
            ], style={'width': '24%', 'display': 'inline-block', 'padding': '5px'}),
            
            html.Div([
                html.Div([
                    html.H3(str(alerts_count), style={
                        'margin': '0', 'color': '#ff7f0e' if alerts_count > 0 else '#1f77b4', 
                        'fontSize': '2rem', 'fontWeight': 'bold'
                    }),
                    html.P("ã‚¢ãƒ©ãƒ¼ãƒˆæ•°", style={'margin': '5px 0', 'fontSize': '1rem', 'color': '#666'})
                ], style={
                    'textAlign': 'center', 'padding': '15px', 'backgroundColor': 'white',
                    'borderRadius': '8px', 'boxShadow': '0 2px 4px rgba(0,0,0,0.1)',
                    'border': f"2px solid {'#ff7f0e' if alerts_count > 0 else '#1f77b4'}"
                }),
            ], style={'width': '24%', 'display': 'inline-block', 'padding': '5px'}),
        ], style={'marginBottom': '20px'}),
        
        # ğŸ“ˆ è©³ç´°æŒ‡æ¨™ã‚’å°ã•ãè¡¨ç¤ºï¼ˆè£œåŠ©æƒ…å ±ï¼‰
        html.Div([  # type: ignore
            html.Div([
                create_metric_card("å¤œå‹¤ JainæŒ‡æ•°", jain_index),
            ], style={'width': '20%', 'display': 'inline-block', 'padding': '3px'}),
            html.Div([
                create_metric_card("ç·ã‚¹ã‚¿ãƒƒãƒ•æ•°", str(staff_count)),
            ], style={'width': '20%', 'display': 'inline-block', 'padding': '3px'}),
            html.Div([
                create_metric_card("å¹³å‡å¤œå‹¤æ¯”ç‡", f"{avg_night_ratio:.3f}"),
            ], style={'width': '20%', 'display': 'inline-block', 'padding': '3px'}),
            html.Div([
                create_metric_card("ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£(Â¥)", f"{lack_penalty_cost:,.0f}"),
            ], style={'width': '20%', 'display': 'inline-block', 'padding': '3px'}),
            html.Div([
                html.Div([
                    html.P(f"ç·ä¸è¶³ç‡: {(lack_h / (lack_h + 100)) * 100:.1f}%" if lack_h > 0 else "ç·ä¸è¶³ç‡: 0%", 
                           style={'margin': '0', 'fontSize': '0.9rem', 'textAlign': 'center'})
                ], style={
                    'padding': '10px', 'backgroundColor': 'white', 'borderRadius': '8px',
                    'boxShadow': '0 2px 4px rgba(0,0,0,0.1)', 'minHeight': '60px', 'display': 'flex',
                    'alignItems': 'center', 'justifyContent': 'center'
                }),
            ], style={'width': '20%', 'display': 'inline-block', 'padding': '3px'}),
        ], style={'marginBottom': '30px'}),
    ])


def create_heatmap_tab() -> html.Div:
    """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚¿ãƒ–ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚ä¸Šä¸‹2ã¤ã®æ¯”è¼ƒã‚¨ãƒªã‚¢ã‚’æŒã¡ã¾ã™ã€‚"""
    roles = data_get('roles', [])
    employments = data_get('employments', [])

    # æ¯”è¼ƒã‚¨ãƒªã‚¢ã‚’1ã¤ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    def create_comparison_area(area_id: int):
        return html.Div([  # type: ignore
            html.H4(f"æ¯”è¼ƒã‚¨ãƒªã‚¢ {area_id}", style={'marginTop': '20px', 'borderTop': '2px solid #ddd', 'paddingTop': '20px'}),  # type: ignore

            # --- å„ã‚¨ãƒªã‚¢ã«è·ç¨®ã¨é›‡ç”¨å½¢æ…‹ã®ä¸¡æ–¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’è¨­ç½® ---
            html.Div([  # type: ignore
                html.Div([  # type: ignore
                    html.Label("è·ç¨®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"),  # type: ignore
                    dcc.Dropdown(
                        id={'type': 'heatmap-filter-role', 'index': area_id},
                        options=[{'label': 'ã™ã¹ã¦', 'value': 'all'}] + [{'label': r, 'value': r} for r in roles],
                        value='all',
                        clearable=False
                    )
                ], style={'width': '48%', 'display': 'inline-block', 'marginRight': '4%'}),

                html.Div([  # type: ignore
                    html.Label("é›‡ç”¨å½¢æ…‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"),  # type: ignore
                    dcc.Dropdown(
                        id={'type': 'heatmap-filter-employment', 'index': area_id},
                        options=[{'label': 'ã™ã¹ã¦', 'value': 'all'}] + [{'label': e, 'value': e} for e in employments],
                        value='all',
                        clearable=False
                    )
                ], style={'width': '48%', 'display': 'inline-block'}),
            ], style={'marginBottom': '10px'}),

            # --- ã‚°ãƒ©ãƒ•æç”»é ˜åŸŸ ---
            dcc.Loading(
                id={'type': 'loading-heatmap', 'index': area_id},
                children=html.Div(id={'type': 'graph-output-heatmap', 'index': area_id})
            )
        ], style={'padding': '10px', 'backgroundColor': '#f9f9f9', 'borderRadius': '5px', 'marginBottom': '10px'})

    return html.Div([
        html.H3("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æ¯”è¼ƒåˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
        html.P("ä¸Šä¸‹ã®ã‚¨ãƒªã‚¢ã§ãã‚Œãã‚Œã€Œè·ç¨®ã€ã¨ã€Œé›‡ç”¨å½¢æ…‹ã€ã®çµ„ã¿åˆã‚ã›ã‚’é¸æŠã—ã€ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚"),  # type: ignore
        create_comparison_area(1),
        create_comparison_area(2)
    ])


def create_shortage_tab() -> html.Div:
    """ä¸è¶³åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame())
    df_shortage_emp = data_get('shortage_employment_summary', pd.DataFrame())

    content = [html.Div(id='shortage-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("ä¸è¶³åˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
        html.Div(  # type: ignore
            dcc.Markdown(
                "\n".join(
                    [
                        "### è¨ˆç®—ã«ä½¿ç”¨ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
                        f"- Needç®—å‡ºæ–¹æ³•: {data_get('need_method', 'N/A')}",
                        f"- Upperç®—å‡ºæ–¹æ³•: {data_get('upper_method', 'N/A')}",
                        f"- ç›´æ¥é›‡ç”¨å˜ä¾¡: Â¥{data_get('wage_direct', 0):,.0f}/h",
                        f"- æ´¾é£å˜ä¾¡: Â¥{data_get('wage_temp', 0):,.0f}/h",
                        f"- æ¡ç”¨ã‚³ã‚¹ãƒˆ: Â¥{data_get('hiring_cost', 0):,}/äºº",
                        f"- ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£: Â¥{data_get('penalty_cost', 0):,.0f}/h",
                    ]
                )
            ),
            style={
                'backgroundColor': '#e9f2fa',
                'padding': '10px',
                'borderRadius': '8px',
                'border': '1px solid #cce5ff',
                'marginBottom': '20px'
            },
        )]

    # è·ç¨®åˆ¥ä¸è¶³åˆ†æ
    if not df_shortage_role.empty:
        content.append(html.H4("è·ç¨®åˆ¥ä¸è¶³æ™‚é–“"))  # type: ignore

        # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆé‡è¤‡ã‚«ã‚¦ãƒ³ãƒˆã‚’å›é¿ï¼‰
        total_lack = 0
        if 'lack_h' in df_shortage_role.columns:
            # ã€Œå…¨ä½“ã€ã€Œåˆè¨ˆã€ã€Œç·è¨ˆã€ã®è¡ŒãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
            total_rows = df_shortage_role[df_shortage_role['role'].isin(['å…¨ä½“', 'åˆè¨ˆ', 'ç·è¨ˆ'])]
            if not total_rows.empty:
                total_lack = total_rows['lack_h'].iloc[0]
            else:
                # ğŸ”§ ä¿®æ­£: é›‡ç”¨å½¢æ…‹ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã—ã¦ã‹ã‚‰åˆè¨ˆè¨ˆç®—
                role_only_df = df_shortage_role[~df_shortage_role['role'].str.startswith('emp_', na=False)]
                if not role_only_df.empty:
                    total_lack = role_only_df['lack_h'].sum()
                else:
                    # shortage_timeã‹ã‚‰ç›´æ¥è¨ˆç®—
                    shortage_time_df = data_get('shortage_time', pd.DataFrame())
                    if not shortage_time_df.empty:
                        try:
                            shortage_values = shortage_time_df.select_dtypes(include=[np.number]).values
                            total_lack = float(np.nansum(shortage_values) * 0.5)
                        except:
                            total_lack = df_shortage_role['lack_h'].sum()
                    else:
                        total_lack = df_shortage_role['lack_h'].sum()
        if total_lack > 0:
            top_roles = df_shortage_role.nlargest(3, 'lack_h')[['role', 'lack_h']]
            metrics = [
                html.Div([
                    create_metric_card("ç·ä¸è¶³æ™‚é–“", f"{total_lack:.1f}h")
                ], style={'width': '25%', 'display': 'inline-block', 'padding': '5px'})
            ]
            for i, row in enumerate(top_roles.itertuples(index=False)):
                metrics.append(
                    html.Div([
                        create_metric_card(f"ä¸è¶³Top{i+1}", f"{row.role}: {row.lack_h:.1f}h")  # type: ignore
                    ], style={'width': '25%', 'display': 'inline-block', 'padding': '5px'})
                )
            content.append(html.Div(metrics, style={'marginBottom': '20px'}))

        # è·ç¨®åˆ¥ä¸è¶³æ™‚é–“ã‚°ãƒ©ãƒ•
        fig_role_lack = px.bar(
            df_shortage_role,
            x='role',
            y='lack_h',
            title='è·ç¨®åˆ¥ä¸è¶³æ™‚é–“',
            labels={'role': 'è·ç¨®', 'lack_h': 'ä¸è¶³æ™‚é–“(h)'},
            color_discrete_sequence=['#FFA500']
        )
        content.append(dcc.Graph(figure=fig_role_lack))

        # è·ç¨®åˆ¥éå‰°æ™‚é–“ã‚°ãƒ©ãƒ•
        if 'excess_h' in df_shortage_role.columns:
            fig_role_excess = px.bar(
                df_shortage_role,
                x='role',
                y='excess_h',
                title='è·ç¨®åˆ¥éå‰°æ™‚é–“',
                labels={'role': 'è·ç¨®', 'excess_h': 'éå‰°æ™‚é–“(h)'},
                color_discrete_sequence=['#00BFFF']
            )
            content.append(dcc.Graph(figure=fig_role_excess))

    # é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³åˆ†æ
    if not df_shortage_emp.empty:
        content.append(html.H4("é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³æ™‚é–“", style={'marginTop': '30px'}))  # type: ignore

        fig_emp_lack = px.bar(
            df_shortage_emp,
            x='employment',
            y='lack_h',
            title='é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³æ™‚é–“',
            labels={'employment': 'é›‡ç”¨å½¢æ…‹', 'lack_h': 'ä¸è¶³æ™‚é–“(h)'},
            color_discrete_sequence=['#2ca02c']
        )
        content.append(dcc.Graph(figure=fig_emp_lack))

    # ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    content.append(html.Div([
        html.H4("ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", style={'marginTop': '30px'}),  # type: ignore
        html.P("å„æ™‚é–“å¸¯ã§å¿…è¦äººæ•°ã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„ã®å‰²åˆã§äººå“¡ãŒä¸è¶³ã—ã¦ã„ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚"),  # type: ignore
        html.Div([  # type: ignore
            html.Label("è¡¨ç¤ºç¯„å›²"),  # type: ignore
            dcc.Dropdown(
                id='shortage-heatmap-scope',
                options=[
                    {'label': 'å…¨ä½“', 'value': 'overall'},
                    {'label': 'è·ç¨®åˆ¥', 'value': 'role'},
                    {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'employment'}
                ],
                value='overall',
                style={'width': '200px'}
            ),
        ], style={'marginBottom': '10px'}),
        html.Div(id='shortage-heatmap-detail-container'),
        html.Div(id='shortage-ratio-heatmap')
    ]))

    # Factor Analysis section
    content.append(html.Hr())
    content.append(html.H4('è¦å› åˆ†æ (AI)', style={'marginTop': '30px'}))  # type: ignore
    content.append(html.Button('è¦å› åˆ†æãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’', id='factor-train-button', n_clicks=0))  # type: ignore
    content.append(html.Div(id='factor-output'))  # type: ignore

    # Over/Short Log section
    events_df = data_get('shortage_events', pd.DataFrame())
    if not events_df.empty:
        content.append(html.Hr())  # type: ignore
        content.append(html.H4('éä¸è¶³æ‰‹å‹•ãƒ­ã‚°', style={'marginTop': '30px'}))  # type: ignore
        content.append(dash_table.DataTable(
            id='over-shortage-table',
            data=events_df.to_dict('records'),
            columns=[{'name': c, 'id': c, 'presentation': 'input'} for c in events_df.columns],
            editable=True,
        ))
        content.append(dcc.RadioItems(
            id='log-save-mode',
            options=[{'label': 'è¿½è¨˜', 'value': 'append'}, {'label': 'ä¸Šæ›¸ã', 'value': 'overwrite'}],
            value='è¿½è¨˜',
            inline=True,
            style={'marginTop': '10px'}
        ))
        content.append(html.Button('ãƒ­ã‚°ã‚’ä¿å­˜', id='save-log-button', n_clicks=0, style={'marginTop': '10px'}))  # type: ignore
        content.append(html.Div(id='save-log-msg'))  # type: ignore

    return html.Div(content)


def create_optimization_tab() -> html.Div:
    """æœ€é©åŒ–åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    return html.Div([  # type: ignore
        html.Div(id='optimization-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("æœ€é©åŒ–åˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
        html.Div([  # type: ignore
            html.Label("è¡¨ç¤ºç¯„å›²"),  # type: ignore
            dcc.Dropdown(
                id='opt-scope',
                options=[
                    {'label': 'å…¨ä½“', 'value': 'overall'},
                    {'label': 'è·ç¨®åˆ¥', 'value': 'role'},
                    {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'employment'}
                ],
                value='overall',
                clearable=False
            ),
        ], style={'width': '30%', 'marginBottom': '20px'}),
        html.Div(id='opt-detail-container'),  # type: ignore
        html.Div(id='optimization-content')  # type: ignore
    ])


def create_leave_analysis_tab() -> html.Div:
    """ä¼‘æš‡åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='leave-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("ä¼‘æš‡åˆ†æ", style={'marginBottom': '20px'})]  # type: ignore

    df_staff_balance = data_get('staff_balance_daily', pd.DataFrame())
    df_daily_summary = data_get('daily_summary', pd.DataFrame())
    df_concentration = data_get('concentration_requested', pd.DataFrame())
    df_ratio_breakdown = data_get('leave_ratio_breakdown', pd.DataFrame())

    if not df_staff_balance.empty:
        fig_balance = px.line(
            df_staff_balance,
            x='date',
            y=['total_staff', 'leave_applicants_count', 'non_leave_staff'],
            title='å‹¤å‹™äºˆå®šäººæ•°ã¨å…¨ä¼‘æš‡å–å¾—è€…æ•°ã®æ¨ç§»',
            labels={'value': 'äººæ•°', 'variable': 'é …ç›®', 'date': 'æ—¥ä»˜'},
            markers=True
        )
        fig_balance.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_balance))
        content.append(dash_table.DataTable(
            data=df_staff_balance.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_staff_balance.columns]
        ))

    if not df_daily_summary.empty:
        fig_breakdown = px.bar(
            df_daily_summary,
            x='date',
            y='total_leave_days',
            color='leave_type',
            barmode='stack',
            title='æ—¥åˆ¥ ä¼‘æš‡å–å¾—è€…æ•°ï¼ˆå†…è¨³ï¼‰',
            labels={'date': 'æ—¥ä»˜', 'total_leave_days': 'ä¼‘æš‡å–å¾—è€…æ•°', 'leave_type': 'ä¼‘æš‡ã‚¿ã‚¤ãƒ—'}
        )
        fig_breakdown.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_breakdown))

    if not df_ratio_breakdown.empty:
        fig_ratio_break = px.bar(
            df_ratio_breakdown,
            x='dayofweek',
            y='leave_ratio',
            color='leave_type',
            facet_col='month_period',
            category_orders={
                'dayofweek': ['æœˆæ›œæ—¥', 'ç«æ›œæ—¥', 'æ°´æ›œæ—¥', 'æœ¨æ›œæ—¥', 'é‡‘æ›œæ—¥', 'åœŸæ›œæ—¥', 'æ—¥æ›œæ—¥'],
                'month_period': ['æœˆåˆ(1-10æ—¥)', 'æœˆä¸­(11-20æ—¥)', 'æœˆæœ«(21-æœ«æ—¥)'],
            },
            labels={'dayofweek': 'æ›œæ—¥', 'leave_ratio': 'å‰²åˆ', 'leave_type': 'ä¼‘æš‡ã‚¿ã‚¤ãƒ—', 'month_period': 'æœˆæœŸé–“'},
            title='æ›œæ—¥ãƒ»æœˆæœŸé–“åˆ¥ä¼‘æš‡å–å¾—ç‡'
        )
        content.append(dcc.Graph(figure=fig_ratio_break))

    if not df_concentration.empty:
        fig_conc = go.Figure()
        fig_conc.add_trace(go.Scatter(
            x=df_concentration['date'],
            y=df_concentration['leave_applicants_count'],
            mode='lines+markers',
            name='ä¼‘æš‡ç”³è«‹è€…æ•°',
            line=dict(shape='spline', smoothing=0.5),
            marker=dict(size=6)
        ))
        if 'is_concentrated' in df_concentration.columns:
            concentrated = df_concentration[df_concentration['is_concentrated']]
            if not concentrated.empty:
                fig_conc.add_trace(go.Scatter(
                    x=concentrated['date'],
                    y=concentrated['leave_applicants_count'],
                    mode='markers',
                    marker=dict(color='red', size=12, symbol='diamond'),
                    name='é–¾å€¤è¶…éæ—¥',
                    hovertemplate='<b>%{x|%Y-%m-%d}</b><br>ç”³è«‹è€…æ•°: %{y}äºº<extra></extra>'
                ))

        fig_conc.update_layout(
            title='å¸Œæœ›ä¼‘ ç”³è«‹è€…æ•°ã®æ¨ç§»ã¨é›†ä¸­æ—¥',
            xaxis_title='æ—¥ä»˜',
            yaxis_title='ç”³è«‹è€…æ•°'
        )
        fig_conc.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_conc))

    return html.Div(content)


def create_cost_analysis_tab() -> html.Div:
    """ã‚³ã‚¹ãƒˆåˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    return html.Div([
        html.Div(id='cost-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("äººä»¶è²»åˆ†æ", style={'marginBottom': '20px'}),

        html.H4("å‹•çš„ã‚³ã‚¹ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", style={'marginTop': '30px'}),
        dcc.RadioItems(
            id='cost-by-radio',
            options=[
                {'label': 'è·ç¨®åˆ¥', 'value': 'role'},
                {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'employment'},
                {'label': 'ã‚¹ã‚¿ãƒƒãƒ•åˆ¥', 'value': 'staff'},
            ],
            value='role',
            inline=True,
            style={'marginBottom': '10px'},
        ),
        html.Div(id='wage-input-container'),

        dcc.Loading(
            id="loading-cost-analysis",
            type="circle",
            children=html.Div(id='cost-analysis-content')
        )
    ])


def create_hire_plan_tab() -> html.Div:
    """æ¡ç”¨è¨ˆç”»ã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='hire-plan-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("æ¡ç”¨è¨ˆç”»", style={'marginBottom': '20px'})]  # type: ignore

    df_hire = data_get('hire_plan', pd.DataFrame())
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame())
    
    if not df_hire.empty:
        content.append(html.H4("å¿…è¦FTEï¼ˆè·ç¨®åˆ¥ï¼‰"))  # type: ignore

        # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«ç¿»è¨³
        df_hire_display = df_hire.copy()
        column_translations = {
            'role': 'è·ç¨®',
            'hire_fte': 'å¿…è¦FTE',
            'shortage_hours': 'ä¸è¶³æ™‚é–“',
            'current_fte': 'ç¾åœ¨FTE',
            'target_fte': 'ç›®æ¨™FTE',
            'priority': 'å„ªå…ˆåº¦',
            'cost_per_fte': 'FTEå˜ä¾¡',
            'total_cost': 'ç·ã‚³ã‚¹ãƒˆ'
        }
        df_hire_display.rename(columns=column_translations, inplace=True)

        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        content.append(dash_table.DataTable(
            data=df_hire_display.to_dict('records'),
            columns=[{'name': col, 'id': col} for col in df_hire_display.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'}
        ))

        # ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆå…ƒã®åˆ—åã‚’ä½¿ç”¨ï¼‰
        if 'role' in df_hire.columns and 'hire_fte' in df_hire.columns:
            fig_hire = px.bar(
                df_hire,
                x='role',
                y='hire_fte',
                title='è·ç¨®åˆ¥å¿…è¦FTE',
                labels={'role': 'è·ç¨®', 'hire_fte': 'å¿…è¦FTE'},
                color_discrete_sequence=['#1f77b4']
            )
            content.append(dcc.Graph(figure=fig_hire))

        # æ¡ç”¨æˆ¦ç•¥ææ¡ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
        content.append(html.Div([
            html.H4("æ¡ç”¨æˆ¦ç•¥ã®ææ¡ˆ", style={'marginTop': '30px'}),
            html.P("åˆ†æçµæœã«åŸºã¥ãæ¡ç”¨å„ªå…ˆåº¦ã¨æˆ¦ç•¥çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼š"),
            html.Ul([
                html.Li("æœ€ã‚‚ä¸è¶³ã®æ·±åˆ»ãªè·ç¨®ã‹ã‚‰å„ªå…ˆçš„ã«æ¡ç”¨ã‚’æ¤œè¨"),
                html.Li("å­£ç¯€æ€§ã‚’è€ƒæ…®ã—ãŸæ¡ç”¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®æœ€é©åŒ–"),
                html.Li("æ—¢å­˜è·å“¡ã®è² è·è»½æ¸›åŠ¹æœã®äºˆæ¸¬"),
                html.Li("ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®é«˜ã„æ¡ç”¨ãƒãƒ£ãƒãƒ«ã®æ´»ç”¨")
            ])
        ], style={'padding': '20px', 'backgroundColor': '#f8f9fa', 'borderRadius': '8px', 'marginTop': '20px'}))

    # æœ€é©æ¡ç”¨è¨ˆç”»
    df_optimal = data_get('optimal_hire_plan', pd.DataFrame())
    if not df_optimal.empty:
        content.append(html.H4("æœ€é©æ¡ç”¨è¨ˆç”»", style={'marginTop': '30px'}))  # type: ignore
        content.append(html.P("åˆ†æã®çµæœã€ä»¥ä¸‹ã®å…·ä½“çš„ãªæ¡ç”¨è¨ˆç”»ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"))
        
        # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«ç¿»è¨³
        df_optimal_display = df_optimal.copy()
        df_optimal_display.rename(columns=column_translations, inplace=True)
        
        content.append(dash_table.DataTable(
            data=df_optimal_display.to_dict('records'),
            columns=[{'name': col, 'id': col} for col in df_optimal_display.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'}
        ))

    return html.Div(content)


def create_fatigue_tab() -> html.Div:
    """ç–²åŠ´åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    explanation = """
    #### ç–²åŠ´åˆ†æã®è©•ä¾¡æ–¹æ³•
    ã‚¹ã‚¿ãƒƒãƒ•ã®ç–²åŠ´ã‚¹ã‚³ã‚¢ã¯ã€ä»¥ä¸‹ã®è¦ç´ ã‚’ç·åˆçš„ã«è©•ä¾¡ã—ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚å„è¦ç´ ã¯ã€å…¨ã‚¹ã‚¿ãƒƒãƒ•å†…ã§ã®ç›¸å¯¾çš„ãªä½ç½®ï¼ˆåå·®ï¼‰ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢åŒ–ã•ã‚Œã€é‡ã¿ä»˜ã‘ã•ã‚Œã¦åˆè¨ˆã•ã‚Œã¾ã™ã€‚
    - **å‹¤å‹™é–‹å§‹æ™‚åˆ»ã®ã°ã‚‰ã¤ã:** å‡ºå‹¤æ™‚åˆ»ãŒä¸è¦å‰‡ã§ã‚ã‚‹ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **æ¥­å‹™ã®å¤šæ§˜æ€§:** æ‹…å½“ã™ã‚‹æ¥­å‹™ï¼ˆå‹¤å‹™ã‚³ãƒ¼ãƒ‰ï¼‰ã®ç¨®é¡ãŒå¤šã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **åŠ´åƒæ™‚é–“ã®ã°ã‚‰ã¤ã:** æ—¥ã€…ã®åŠ´åƒæ™‚é–“ãŒä¸è¦å‰‡ã§ã‚ã‚‹ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **çŸ­ã„ä¼‘æ¯æœŸé–“:** å‹¤å‹™é–“ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«ãŒçŸ­ã„é »åº¦ãŒé«˜ã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **é€£å‹¤:** 3é€£å‹¤ä»¥ä¸Šã®é€£ç¶šå‹¤å‹™ãŒå¤šã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **å¤œå‹¤æ¯”ç‡:** å…¨å‹¤å‹™ã«å ã‚ã‚‹å¤œå‹¤ã®å‰²åˆãŒé«˜ã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚

    *ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€ã“ã‚Œã‚‰ã®è¦ç´ ã¯å‡ç­‰ãªé‡ã¿ï¼ˆå„1.0ï¼‰ã§è©•ä¾¡ã•ã‚Œã¾ã™ã€‚*
    """
    content = [
        html.Div(  # type: ignore
            dcc.Markdown(explanation),
            style={
                'padding': '15px',
                'backgroundColor': '#e9f2fa',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #cce5ff',
            },
        ),
        html.H3("ç–²åŠ´åˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
    ]
    df_fatigue = data_get('fatigue_score', pd.DataFrame())

    if not df_fatigue.empty:
        # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«ç¿»è¨³
        df_fatigue_display = df_fatigue.reset_index().rename(columns={'index': 'staff'})
        column_translations = {
            'staff': 'è·å“¡å',
            'fatigue_score': 'ç–²åŠ´ã‚¹ã‚³ã‚¢',
            'work_start_variance': 'å‹¤å‹™é–‹å§‹æ™‚åˆ»ã®ã°ã‚‰ã¤ã',
            'work_diversity': 'æ¥­å‹™ã®å¤šæ§˜æ€§',
            'work_duration_variance': 'åŠ´åƒæ™‚é–“ã®ã°ã‚‰ã¤ã',
            'short_rest_frequency': 'çŸ­ã„ä¼‘æ¯æœŸé–“ã®é »åº¦',
            'consecutive_work_days': 'é€£å‹¤å›æ•°',
            'night_shift_ratio': 'å¤œå‹¤æ¯”ç‡'
        }
        df_fatigue_display.rename(columns=column_translations, inplace=True)

        # 1. å¾“æ¥ã®æ£’ã‚°ãƒ©ãƒ•
        fig_bar = px.bar(
            df_fatigue_display,
            x='è·å“¡å',
            y='ç–²åŠ´ã‚¹ã‚³ã‚¢',
            title='ã‚¹ã‚¿ãƒƒãƒ•åˆ¥ç–²åŠ´ã‚¹ã‚³ã‚¢',
            labels={'è·å“¡å': 'è·å“¡å', 'ç–²åŠ´ã‚¹ã‚³ã‚¢': 'ç–²åŠ´ã‚¹ã‚³ã‚¢'},
            color='ç–²åŠ´ã‚¹ã‚³ã‚¢',
            color_continuous_scale='Reds'
        )
        content.append(dcc.Graph(figure=fig_bar))

        # 2. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆç–²åŠ´è¦å› ã®è©³ç´°åˆ†æï¼‰
        fatigue_factors = ['å‹¤å‹™é–‹å§‹æ™‚åˆ»ã®ã°ã‚‰ã¤ã', 'æ¥­å‹™ã®å¤šæ§˜æ€§', 'åŠ´åƒæ™‚é–“ã®ã°ã‚‰ã¤ã', 
                         'çŸ­ã„ä¼‘æ¯æœŸé–“ã®é »åº¦', 'é€£å‹¤å›æ•°', 'å¤œå‹¤æ¯”ç‡']
        available_factors = [col for col in fatigue_factors if col in df_fatigue_display.columns]
        
        if len(df_fatigue_display) > 1 and available_factors:
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ï¼ˆ0-1ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
            factor_data = df_fatigue_display[available_factors].copy()
            for col in available_factors:
                if factor_data[col].max() != factor_data[col].min():
                    factor_data[col] = (factor_data[col] - factor_data[col].min()) / (factor_data[col].max() - factor_data[col].min())
            
            fig_heatmap = px.imshow(
                factor_data.T,
                x=df_fatigue_display['è·å“¡å'],
                y=available_factors,
                title='ç–²åŠ´è¦å› ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆè·å“¡åˆ¥è©³ç´°åˆ†æï¼‰',
                color_continuous_scale='Reds',
                aspect='auto'
            )
            fig_heatmap.update_layout(xaxis_title="è·å“¡å", yaxis_title="ç–²åŠ´è¦å› ")
            content.append(dcc.Graph(figure=fig_heatmap))

        # 3. æ•£å¸ƒå›³ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆç–²åŠ´è¦å› é–“ã®ç›¸é–¢ï¼‰
        if len(available_factors) >= 2:
            # 2ã¤ã®ä¸»è¦è¦å› ã®æ•£å¸ƒå›³
            fig_scatter = px.scatter(
                df_fatigue_display,
                x=available_factors[0],
                y=available_factors[1] if len(available_factors) > 1 else available_factors[0],
                size='ç–²åŠ´ã‚¹ã‚³ã‚¢',
                hover_name='è·å“¡å',
                title=f'{available_factors[0]} vs {available_factors[1] if len(available_factors) > 1 else available_factors[0]}',
                color='ç–²åŠ´ã‚¹ã‚³ã‚¢',
                color_continuous_scale='Reds'
            )
            content.append(dcc.Graph(figure=fig_scatter))

        # 4. ç–²åŠ´è¦å› ã®ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹
        if len(available_factors) >= 2:
            corr_matrix = df_fatigue_display[available_factors].corr()
            fig_corr = px.imshow(
                corr_matrix,
                text_auto=True,
                aspect="auto",
                title="ç–²åŠ´è¦å› é–“ã®ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹",
                color_continuous_scale='RdBu_r'
            )
            fig_corr.update_layout(
                xaxis_title="ç–²åŠ´è¦å› ",
                yaxis_title="ç–²åŠ´è¦å› "
            )
            content.append(dcc.Graph(figure=fig_corr))

        # 5. ç–²åŠ´ã‚¹ã‚³ã‚¢åˆ†å¸ƒã¨ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
        fig_box = px.box(
            df_fatigue_display,
            y='ç–²åŠ´ã‚¹ã‚³ã‚¢',
            title='ç–²åŠ´ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒï¼ˆãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆï¼‰',
            points="all"  # å…¨ãƒ‡ãƒ¼ã‚¿ç‚¹ã‚’è¡¨ç¤º
        )
        content.append(dcc.Graph(figure=fig_box))

        # 6. ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼ˆä¸Šä½3åã®è©³ç´°æ¯”è¼ƒï¼‰
        if len(df_fatigue_display) >= 3 and available_factors:
            top3 = df_fatigue_display.nlargest(3, 'ç–²åŠ´ã‚¹ã‚³ã‚¢')
            fig_radar = go.Figure()
            
            for _, row in top3.iterrows():
                factor_values = [row[factor] for factor in available_factors]
                # æ­£è¦åŒ–ï¼ˆ0-1ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
                max_val = max(factor_values) if max(factor_values) > 0 else 1
                min_val = min(factor_values)
                normalized_values = [(val - min_val) / (max_val - min_val) if max_val != min_val else 0.5 for val in factor_values]
                
                fig_radar.add_trace(go.Scatterpolar(
                    r=normalized_values,
                    theta=available_factors,
                    fill='toself',
                    name=row['è·å“¡å'],
                    opacity=0.7
                ))
            
            fig_radar.update_layout(
                polar=dict(
                    radialaxis=dict(visible=True, range=[0, 1])
                ),
                title="ç–²åŠ´åº¦ä¸Šä½3åã®è¦å› æ¯”è¼ƒï¼ˆãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼‰",
                showlegend=True
            )
            content.append(dcc.Graph(figure=fig_radar))

        # 7. ç–²åŠ´åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        if 'ç–²åŠ´ã‚¹ã‚³ã‚¢' in df_fatigue_display.columns:
            ranking = df_fatigue_display.sort_values('ç–²åŠ´ã‚¹ã‚³ã‚¢', ascending=False)[['è·å“¡å', 'ç–²åŠ´ã‚¹ã‚³ã‚¢']]
            ranking.index = range(1, len(ranking) + 1)
            ranking.index.name = 'é †ä½'
            ranking = ranking.reset_index()
            content.append(html.H4('ç–²åŠ´åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°'))
            content.append(dash_table.DataTable(
                data=ranking.to_dict('records'),
                columns=[{'name': i, 'id': i} for i in ranking.columns],
                style_cell={'textAlign': 'left'},
                style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},
                style_data_conditional=[
                    {
                        'if': {'row_index': 0},
                        'backgroundColor': '#ffebee',
                        'color': 'black',
                    },
                    {
                        'if': {'row_index': 1},
                        'backgroundColor': '#fff3e0',
                        'color': 'black',
                    },
                    {
                        'if': {'row_index': 2},
                        'backgroundColor': '#fff8e1',
                        'color': 'black',
                    }
                ]
            ))

        # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        content.append(html.H4("è©³ç´°ãƒ‡ãƒ¼ã‚¿", style={'marginTop': '30px'}))
        content.append(dash_table.DataTable(
            data=df_fatigue_display.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_fatigue_display.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},
            sort_action="native"
        ))
    else:
        content.append(html.P("ç–²åŠ´åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))  # type: ignore

    return html.Div(content)


def create_forecast_tab() -> html.Div:
    """éœ€è¦äºˆæ¸¬ã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='forecast-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("éœ€è¦äºˆæ¸¬", style={'marginBottom': '20px'})]  # type: ignore
    df_fc = data_get('forecast', pd.DataFrame())
    df_actual = data_get('demand_series', pd.DataFrame())

    if not df_fc.empty:
        fig = go.Figure()
        if {'ds', 'yhat'}.issubset(df_fc.columns):
            fig.add_trace(go.Scatter(x=df_fc['ds'], y=df_fc['yhat'], mode='lines+markers', name='äºˆæ¸¬'))
        if not df_actual.empty and {'ds', 'y'}.issubset(df_actual.columns):
            fig.add_trace(go.Scatter(x=df_actual['ds'], y=df_actual['y'], mode='lines', name='å®Ÿç¸¾', line=dict(dash='dash')))
        fig.update_layout(title='éœ€è¦äºˆæ¸¬ã¨å®Ÿç¸¾', xaxis_title='æ—¥ä»˜', yaxis_title='éœ€è¦')
        content.append(dcc.Graph(figure=fig))
        content.append(dash_table.DataTable(
            data=df_fc.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_fc.columns]
        ))
    else:
        content.append(html.P("éœ€è¦äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))  # type: ignore

    return html.Div(content)


def create_fairness_tab() -> html.Div:
    """å…¬å¹³æ€§ã‚¿ãƒ–ã‚’ä½œæˆ"""
    explanation = """
    #### å…¬å¹³æ€§åˆ†æã®è©•ä¾¡æ–¹æ³•
    ã‚¹ã‚¿ãƒƒãƒ•é–“ã®ã€Œä¸å…¬å¹³æ„Ÿã€ã¯ã€å„å€‹äººã®åƒãæ–¹ãŒå…¨ä½“ã®å¹³å‡ã‹ã‚‰ã©ã‚Œã ã‘ä¹–é›¢ã—ã¦ã„ã‚‹ã‹ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢åŒ–ã•ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®è¦ç´ ã®ä¹–é›¢åº¦ã‚’å‡ç­‰ã«è©•ä¾¡ã—ã€ãã®å¹³å‡å€¤ã‚’ã€Œä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢ã€ã¨ã—ã¦ã„ã¾ã™ã€‚
    - **å¤œå‹¤æ¯”ç‡ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€å¤œå‹¤ã®å‰²åˆãŒæ¥µç«¯ã«å¤šã„ã€ã¾ãŸã¯å°‘ãªã„ã€‚
    - **ç·åŠ´åƒæ™‚é–“ï¼ˆã‚¹ãƒ­ãƒƒãƒˆæ•°ï¼‰ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€ç·åŠ´åƒæ™‚é–“ãŒæ¥µç«¯ã«å¤šã„ã€ã¾ãŸã¯å°‘ãªã„ã€‚
    - **é€£ä¼‘å–å¾—é »åº¦ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€é€£ä¼‘ã®å–å¾—ã—ã‚„ã™ã•ã«å·®ãŒã‚ã‚‹ã€‚

    *ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©ã€ã“ã‚Œã‚‰ã®è¦ç´ ã«ãŠã„ã¦å¹³å‡ã‹ã‚‰ã®ä¹–é›¢ãŒå¤§ãã„ï¼ˆï¼ä¸å…¬å¹³æ„Ÿã‚’æ„Ÿã˜ã‚„ã™ã„å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚*
    """
    content = [
        html.Div(  # type: ignore
            dcc.Markdown(explanation),
            style={
                'padding': '15px',
                'backgroundColor': '#f0f0f0',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #ddd',
            },
        ),
        html.H3("å…¬å¹³æ€§ (ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢)", style={'marginBottom': '20px'}),  # type: ignore
    ]
    df_fair = data_get('fairness_after', pd.DataFrame())

    if not df_fair.empty:
        # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«ç¿»è¨³
        df_fair_display = df_fair.copy()
        column_translations = {
            'staff': 'è·å“¡å',
            'unfairness_score': 'ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢',
            'fairness_score': 'å…¬å¹³æ€§ã‚¹ã‚³ã‚¢',
            'night_ratio': 'å¤œå‹¤æ¯”ç‡',
            'dev_night_ratio': 'å¤œå‹¤æ¯”ç‡ã®ä¹–é›¢',
            'dev_work_slots': 'ç·åŠ´åƒæ™‚é–“ã®ä¹–é›¢',
            'dev_consecutive': 'é€£ä¼‘å–å¾—é »åº¦ã®ä¹–é›¢',
            'work_slots': 'ç·åŠ´åƒæ™‚é–“',
            'consecutive_holidays': 'é€£ä¼‘å–å¾—å›æ•°'
        }
        df_fair_display.rename(columns=column_translations, inplace=True)

        metric_col = (
            'ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢'
            if 'ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢' in df_fair_display.columns
            else ('å…¬å¹³æ€§ã‚¹ã‚³ã‚¢' if 'å…¬å¹³æ€§ã‚¹ã‚³ã‚¢' in df_fair_display.columns else 'å¤œå‹¤æ¯”ç‡')
        )

        # 1. å¾“æ¥ã®æ£’ã‚°ãƒ©ãƒ•ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        fig_bar = px.bar(
            df_fair_display,
            x='è·å“¡å',
            y=metric_col,
            labels={'è·å“¡å': 'è·å“¡å', metric_col: 'ã‚¹ã‚³ã‚¢'},
            color=metric_col,
            color_continuous_scale='RdYlBu_r',
            title='è·å“¡åˆ¥ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢'
        )
        avg_val = df_fair_display[metric_col].mean()
        fig_bar.add_hline(y=avg_val, line_dash='dash', line_color='red', annotation_text="å¹³å‡å€¤")
        content.append(dcc.Graph(figure=fig_bar))

        # 2. å…¬å¹³æ€§è¦å› ã®æ•£å¸ƒå›³ãƒãƒˆãƒªãƒƒã‚¯ã‚¹
        fairness_factors = ['å¤œå‹¤æ¯”ç‡ã®ä¹–é›¢', 'ç·åŠ´åƒæ™‚é–“ã®ä¹–é›¢', 'é€£ä¼‘å–å¾—é »åº¦ã®ä¹–é›¢']
        available_factors = [col for col in fairness_factors if col in df_fair_display.columns]
        
        if len(available_factors) >= 2:
            # æ•£å¸ƒå›³: 2ã¤ã®ä¸»è¦è¦å› ã®é–¢ä¿‚
            fig_scatter = px.scatter(
                df_fair_display,
                x=available_factors[0],
                y=available_factors[1],
                size=metric_col,
                hover_name='è·å“¡å',
                title=f'{available_factors[0]} vs {available_factors[1]}',
                color=metric_col,
                color_continuous_scale='RdYlBu_r'
            )
            content.append(dcc.Graph(figure=fig_scatter))

        # 3. å…¬å¹³æ€§è¦å› ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        if available_factors:
            factor_data = df_fair_display[available_factors].copy()
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
            for col in available_factors:
                if factor_data[col].max() != factor_data[col].min():
                    factor_data[col] = (factor_data[col] - factor_data[col].min()) / (factor_data[col].max() - factor_data[col].min())
            
            fig_heatmap = px.imshow(
                factor_data.T,
                x=df_fair_display['è·å“¡å'],
                y=available_factors,
                title='å…¬å¹³æ€§è¦å› ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆè·å“¡åˆ¥è©³ç´°åˆ†æï¼‰',
                color_continuous_scale='RdYlBu_r',
                aspect='auto'
            )
            fig_heatmap.update_layout(xaxis_title="è·å“¡å", yaxis_title="å…¬å¹³æ€§è¦å› ")
            content.append(dcc.Graph(figure=fig_heatmap))

        # 4. åˆ†å¸ƒå›³ã¨ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
        fig_hist = px.histogram(
            df_fair_display,
            x=metric_col,
            nbins=20,
            title="å…¬å¹³æ€§ã‚¹ã‚³ã‚¢åˆ†å¸ƒ",
            labels={metric_col: 'ã‚¹ã‚³ã‚¢'}
        )
        fig_hist.update_layout(yaxis_title="äººæ•°")
        fig_hist.add_vline(x=avg_val, line_dash='dash', line_color='red', annotation_text="å¹³å‡å€¤")
        content.append(dcc.Graph(figure=fig_hist))

        # 5. ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼ˆä¸å…¬å¹³æ„Ÿä¸Šä½3åï¼‰
        if len(df_fair_display) >= 3 and available_factors:
            top3 = df_fair_display.nlargest(3, metric_col)
            fig_radar = go.Figure()
            
            for _, row in top3.iterrows():
                factor_values = [abs(row[factor]) for factor in available_factors]  # çµ¶å¯¾å€¤ã§æ¯”è¼ƒ
                # æ­£è¦åŒ–
                max_val = max(factor_values) if max(factor_values) > 0 else 1
                normalized_values = [val/max_val for val in factor_values]
                
                fig_radar.add_trace(go.Scatterpolar(
                    r=normalized_values,
                    theta=available_factors,
                    fill='toself',
                    name=row['è·å“¡å']
                ))
            
            fig_radar.update_layout(
                polar=dict(
                    radialaxis=dict(visible=True, range=[0, 1])
                ),
                title="ä¸å…¬å¹³æ„Ÿä¸Šä½3åã®è¦å› æ¯”è¼ƒï¼ˆãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼‰"
            )
            content.append(dcc.Graph(figure=fig_radar))

        # 6. ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
        if 'ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢' in df_fair_display.columns:
            ranking = df_fair_display.sort_values('ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢', ascending=False)[['è·å“¡å', 'ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢']]
            ranking.index = range(1, len(ranking) + 1)
            ranking.index.name = 'é †ä½'
            ranking = ranking.reset_index()
            content.append(html.H4('ä¸å…¬å¹³æ„Ÿãƒ©ãƒ³ã‚­ãƒ³ã‚°'))  # type: ignore
            content.append(dash_table.DataTable(
                data=ranking.to_dict('records'),
                columns=[{'name': i, 'id': i} for i in ranking.columns],
                style_cell={'textAlign': 'left'},
                style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'}
            ))

        # è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        content.append(html.H4("è©³ç´°ãƒ‡ãƒ¼ã‚¿", style={'marginTop': '30px'}))
        content.append(dash_table.DataTable(
            data=df_fair_display.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_fair_display.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},
            sort_action="native"
        ))
    else:
        content.append(html.P("å…¬å¹³æ€§ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

    return html.Div(content)


def create_gap_analysis_tab() -> html.Div:
    """åŸºæº–ä¹–é›¢åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='gap-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("åŸºæº–ä¹–é›¢åˆ†æ", style={'marginBottom': '20px'})]  # type: ignore
    df_summary = data_get('gap_summary', pd.DataFrame())
    df_heat = data_get('gap_heatmap', pd.DataFrame())

    if not df_summary.empty:
        content.append(dash_table.DataTable(
            data=df_summary.to_dict('records'),
            columns=[{'name': c, 'id': c} for c in df_summary.columns]
        ))
    if not df_heat.empty:
        fig = px.imshow(
            df_heat,
            aspect='auto',
            color_continuous_scale='RdBu_r',
            labels={'x': 'æ™‚é–“å¸¯', 'y': 'è·ç¨®', 'color': 'ä¹–é›¢'}
        )
        content.append(dcc.Graph(figure=fig))
    if df_summary.empty and df_heat.empty:
        content.append(html.P("åŸºæº–ä¹–é›¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))  # type: ignore

    return html.Div(content)


def create_summary_report_tab() -> html.Div:
    """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='summary-report-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ", style={'marginBottom': '20px'})]  # type: ignore
    report_text = data_get('summary_report')
    if report_text:
        content.append(dcc.Markdown(report_text))
    else:
        content.append(html.P("ãƒ¬ãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))
    return html.Div(content)


def create_ppt_report_tab() -> html.Div:
    """PowerPointãƒ¬ãƒãƒ¼ãƒˆã‚¿ãƒ–ã‚’ä½œæˆ"""
    return html.Div([  # type: ignore
        html.Div(id='ppt-report-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("PowerPointãƒ¬ãƒãƒ¼ãƒˆ", style={'marginBottom': '20px'}),  # type: ignore
        html.P("ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦PowerPointãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"),  # type: ignore
        html.Button('PPTãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ', id='ppt-generate', n_clicks=0)  # type: ignore
    ])


def create_individual_analysis_tab() -> html.Div:
    """è·å“¡å€‹åˆ¥åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    long_df = data_get('long_df', pd.DataFrame())

    if long_df.empty:
        return html.Div("åˆ†æã®å…ƒã¨ãªã‚‹å‹¤å‹™ãƒ‡ãƒ¼ã‚¿ (long_df) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    staff_list = sorted(long_df['staff'].unique())

    return html.Div([
        html.H3("è·å“¡å€‹åˆ¥åˆ†æ", style={'marginBottom': '20px'}),
        html.P("åˆ†æã—ãŸã„è·å“¡ã‚’ä»¥ä¸‹ã‹ã‚‰é¸æŠã—ã¦ãã ã•ã„ã€‚"),
        dcc.Dropdown(
            id='individual-staff-dropdown',
            options=[{'label': staff, 'value': staff} for staff in staff_list],
            value=staff_list[0] if staff_list else None,
            clearable=False,
            style={'width': '50%', 'marginBottom': '20px'}
        ),
        
        # ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚¿ã‚¤ãƒ—é¸æŠ
        html.Div([
            html.Label("ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚¿ã‚¤ãƒ—:", style={'fontWeight': 'bold', 'marginBottom': '10px'}),
            dcc.RadioItems(
                id='synergy-analysis-type',
                options=[
                    {'label': 'åŸºæœ¬åˆ†æï¼ˆå…¨è·å“¡å¯¾è±¡ï¼‰', 'value': 'basic'},
                    {'label': 'åŒè·ç¨®é™å®šåˆ†æ', 'value': 'same_role'},
                    {'label': 'å…¨è·ç¨®è©³ç´°åˆ†æ', 'value': 'all_roles'},
                    {'label': 'ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆå…¨ä½“ï¼‰', 'value': 'correlation_matrix'}
                ],
                value='basic',
                inline=True,
                style={'marginBottom': '20px'}
            ),
            html.Div([
                html.Button("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢", id='clear-synergy-cache-btn', className='btn btn-warning btn-sm', style={'marginRight': '10px'}),
                html.Small("â€»ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã¯è¨ˆç®—ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ˆã‚Šé«˜é€ŸåŒ–ã•ã‚Œã¾ã™", style={'color': '#666'})
            ])
        ], style={'marginBottom': '20px', 'padding': '10px', 'backgroundColor': '#f8f9fa', 'borderRadius': '5px'}),
        html.Div(id='individual-analysis-content')
    ])


def create_team_analysis_tab() -> html.Div:
    """ãƒãƒ¼ãƒ åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty:
        return html.Div("åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    filterable_cols = ['role', 'code', 'employment']

    return html.Div([
        html.H3("ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ»ãƒãƒ¼ãƒ åˆ†æ"),
        html.Div([
            html.P("ãƒãƒ¼ãƒ åˆ†æã§ã¯ã€ç‰¹å®šã®æ¡ä»¶ã«è©²å½“ã™ã‚‹ã‚¹ã‚¿ãƒƒãƒ•ã‚°ãƒ«ãƒ¼ãƒ—ã®ç‰¹æ€§ã‚’åˆ†æã—ã¾ã™ã€‚"),
            html.Ul([
                html.Li("ãƒãƒ¼ãƒ æ§‹æˆ: é¸æŠã—ãŸæ¡ä»¶ã«è©²å½“ã™ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ã®ä¸€è¦§ã¨è©³ç´°"),
                html.Li("ãƒãƒ¼ãƒ ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹: ãƒ¡ãƒ³ãƒãƒ¼é–“ã®ç›¸æ€§ã‚„å”åƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"),
                html.Li("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™: ãƒãƒ¼ãƒ å…¨ä½“ã®åŠ¹ç‡æ€§æŒ‡æ¨™ã¨æ”¹å–„ææ¡ˆ"),
                html.Li("æ™‚é–“å¸¯ã‚«ãƒãƒ¼ç‡: ãƒãƒ¼ãƒ ãŒã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹æ™‚é–“å¸¯ã®åˆ†å¸ƒ")
            ])
        ], style={
            'backgroundColor': '#f0f8ff',
            'padding': '15px',
            'borderRadius': '5px',
            'marginBottom': '20px'
        }),
        html.P("åˆ†æã—ãŸã„ãƒãƒ¼ãƒ ã®æ¡ä»¶ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼š"),
        html.Div([
            dcc.Dropdown(
                id='team-criteria-key-dropdown',
                options=[{'label': col, 'value': col} for col in filterable_cols],
                value='code',
                style={'width': '200px', 'display': 'inline-block'}
            ),
            dcc.Dropdown(
                id='team-criteria-value-dropdown',
                style={
                    'width': '300px',
                    'display': 'inline-block',
                    'marginLeft': '10px'
                }
            )
        ]),
        dcc.Loading(
            id="loading-team-analysis",
            children=html.Div([
                html.Div(id='team-analysis-content'),
                html.Div(id='team-analysis-explanation', style={'marginTop': '20px'})
            ])
        )
    ])


def create_blueprint_analysis_tab() -> html.Div:
    """Return layout for blueprint analysis with facts and implicit knowledge."""
    return html.Div([
        html.H3("ã‚·ãƒ•ãƒˆä½œæˆãƒ—ãƒ­ã‚»ã‚¹ã®\u300cæš—é»™çŸ¥\u300dåˆ†æ", style={'marginBottom': '20px'}),
        html.P(
            "éå»ã®ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€å®¢è¦³çš„äº‹å®Ÿã¨æš—é»™ã®ãƒ«ãƒ¼ãƒ«ã‚’åˆ†æã—ã¾ã™ã€‚",
            style={'marginBottom': '10px'}
        ),

        # åˆ†æã‚¿ã‚¤ãƒ—ã®é¸æŠ
        html.Div([
            dcc.RadioItems(
                id='blueprint-analysis-type',
                options=[
                    {'label': 'æš—é»™çŸ¥ã®ã¿', 'value': 'implicit'},
                    {'label': 'å®¢è¦³çš„äº‹å®Ÿã®ã¿', 'value': 'facts'},
                    {'label': 'çµ±åˆåˆ†æï¼ˆæš—é»™çŸ¥ï¼‹äº‹å®Ÿï¼‰', 'value': 'integrated'}
                ],
                value='integrated',
                inline=True,
                style={'marginBottom': '10px'}
            )
        ]),

        html.Details([
            html.Summary('ğŸ“Š åˆ†æã®è¦³ç‚¹ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§è©³ç´°ï¼‰', style={'cursor': 'pointer', 'fontWeight': 'bold'}),
            html.Div([
                html.H5("æš—é»™çŸ¥ã®6ã¤ã®è¦³ç‚¹"),
                html.Ul([
                    html.Li("ğŸ¤ ã‚¹ã‚­ãƒ«ç›¸æ€§: èª°ã¨èª°ã‚’çµ„ã¾ã›ã‚‹ã¨ä¸Šæ‰‹ãã„ãã‹ã€é€†ã«é¿ã‘ã¦ã„ã‚‹ã‹"),
                    html.Li("âš–ï¸ è² è·åˆ†æ•£æˆ¦ç•¥: ç¹å¿™æ™‚é–“å¸¯ã«ã©ã‚“ãªæˆ¦ç•¥ã§äººã‚’é…ç½®ã—ã¦ã„ã‚‹ã‹"),
                    html.Li("ğŸ‘¤ å€‹äººé…æ…®: ç‰¹å®šè·å“¡ã®å€‹äººäº‹æƒ…ã¸ã®é…æ…®ãƒ‘ã‚¿ãƒ¼ãƒ³"),
                    html.Li("ğŸ”„ ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: å…¬å¹³æ€§ã‚’ä¿ã¤ãŸã‚ã®è¤‡é›‘ãªãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ«"),
                    html.Li("ğŸš¨ ãƒªã‚¹ã‚¯å›é¿: ãƒˆãƒ©ãƒ–ãƒ«é˜²æ­¢ã®ãŸã‚ã®æš—é»™ã®é…ç½®ãƒ«ãƒ¼ãƒ«"),
                    html.Li("ğŸ“… æ™‚ç³»åˆ—æˆ¦ç•¥: æœˆåˆãƒ»æœˆæœ«ã€æ›œæ—¥ã«ã‚ˆã‚‹é…ç½®æˆ¦ç•¥ã®å¤‰åŒ–"),
                ]),
                html.H5("å®¢è¦³çš„äº‹å®Ÿã®è¦³ç‚¹", style={'marginTop': '10px'}),
                html.Ul([
                    html.Li("ğŸ“… æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³: ç‰¹å®šã®æ›œæ—¥ã®ã¿å‹¤å‹™ã€æ›œæ—¥ã®åã‚Š"),
                    html.Li("ğŸ·ï¸ ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³: ç‰¹å®šã®å‹¤å‹™ã‚³ãƒ¼ãƒ‰ã®ã¿ä½¿ç”¨ã€å›é¿"),
                    html.Li("â° æ™‚é–“å¸¯ãƒ‘ã‚¿ãƒ¼ãƒ³: æ—©æœãƒ»æ·±å¤œå‹¤å‹™ã€å›ºå®šæ™‚é–“å¸¯"),
                    html.Li("ğŸ‘¥ ãƒšã‚¢é–¢ä¿‚: é »ç¹ã«ä¸€ç·’ã«åƒã/åƒã‹ãªã„ãƒšã‚¢"),
                    html.Li("ğŸ“Š çµ±è¨ˆçš„äº‹å®Ÿ: å‹¤å‹™é »åº¦ã€å¹³å‡å‹¤å‹™æ™‚é–“"),
                ])
            ], style={'padding': '10px', 'backgroundColor': '#f0f0f0', 'borderRadius': '5px', 'marginTop': '10px'})
        ], style={'marginBottom': '20px'}),

        html.Button(
            "ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆã‚’ç”Ÿæˆ",
            id="generate-blueprint-button",
            n_clicks=0,
            style={
                "marginTop": "10px",
                "marginBottom": "20px",
                "padding": "10px 30px",
                "fontSize": "16px",
                "backgroundColor": "#1f77b4",
                "color": "white",
                "border": "none",
                "borderRadius": "5px",
                "cursor": "pointer"
            },
        ),
        dcc.Loading(
            id="loading-blueprint",
            type="default",
            children=html.Div([
                dcc.Tabs(id='blueprint-result-tabs', children=[
                    dcc.Tab(label='æš—é»™çŸ¥åˆ†æ', value='implicit_analysis', children=[
                        html.Div([
                            html.Div([
                                html.H4("å…¨ä½“åˆ†æãƒ“ãƒ¥ãƒ¼ï¼šã‚·ãƒ•ãƒˆå…¨ä½“ã®å‚¾å‘ã¨æš—é»™çŸ¥"),
                                dcc.Graph(id='tradeoff-scatter-plot'),
                                html.H5("ç™ºè¦‹ã•ã‚ŒãŸæš—é»™çŸ¥ãƒ«ãƒ¼ãƒ«ä¸€è¦§"),
                                html.P("ãƒ«ãƒ¼ãƒ«ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€é–¢é€£ã™ã‚‹ã‚¹ã‚¿ãƒƒãƒ•ã®å€‹åˆ¥åˆ†æã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"),
                                dash_table.DataTable(id='rules-data-table', row_selectable='single'),
                            ], style={'width': '50%', 'display': 'inline-block', 'verticalAlign': 'top'}),
                            html.Div([
                                html.H4("ã‚¹ã‚¿ãƒƒãƒ•å€‹åˆ¥ãƒ“ãƒ¥ãƒ¼ï¼šå€‹äººã®åƒãæ–¹ã¨ä¾¡å€¤è¦³"),
                                dcc.Dropdown(id='staff-selector-dropdown'),
                                dcc.Graph(id='staff-radar-chart'),
                                html.H5("ã“ã®ã‚¹ã‚¿ãƒƒãƒ•ã«é–¢é€£ã™ã‚‹æš—é»™çŸ¥"),
                                html.Div(id='staff-related-rules-list'),
                            ], style={'width': '49%', 'display': 'inline-block', 'verticalAlign': 'top', 'paddingLeft': '1%'}),
                        ])
                    ]),
                    dcc.Tab(label='å®¢è¦³çš„äº‹å®Ÿ', value='facts_analysis', children=[
                        html.Div([
                            html.H4("ç™ºè¦‹ã•ã‚ŒãŸå®¢è¦³çš„äº‹å®Ÿ"),
                            html.Div([
                                html.Label("äº‹å®Ÿã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼:"),
                                dcc.Dropdown(
                                    id='fact-category-filter',
                                    options=[
                                        {'label': 'å…¨ã¦è¡¨ç¤º', 'value': 'all'},
                                        {'label': 'å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³äº‹å®Ÿ', 'value': 'å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³äº‹å®Ÿ'},
                                        {'label': 'æ›œæ—¥äº‹å®Ÿ', 'value': 'æ›œæ—¥äº‹å®Ÿ'},
                                        {'label': 'ã‚³ãƒ¼ãƒ‰äº‹å®Ÿ', 'value': 'ã‚³ãƒ¼ãƒ‰äº‹å®Ÿ'},
                                        {'label': 'æ™‚é–“å¸¯äº‹å®Ÿ', 'value': 'æ™‚é–“å¸¯äº‹å®Ÿ'},
                                        {'label': 'ãƒšã‚¢äº‹å®Ÿ', 'value': 'ãƒšã‚¢äº‹å®Ÿ'},
                                        {'label': 'çµ±è¨ˆçš„äº‹å®Ÿ', 'value': 'çµ±è¨ˆçš„äº‹å®Ÿ'}
                                    ],
                                    value='all',
                                    clearable=False
                                )
                            ], style={'width': '300px', 'marginBottom': '20px'}),
                            dash_table.DataTable(
                                id='facts-data-table',
                                columns=[
                                    {'name': 'ã‚¹ã‚¿ãƒƒãƒ•', 'id': 'ã‚¹ã‚¿ãƒƒãƒ•'},
                                    {'name': 'ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'id': 'ã‚«ãƒ†ã‚´ãƒªãƒ¼'},
                                    {'name': 'äº‹å®Ÿã‚¿ã‚¤ãƒ—', 'id': 'äº‹å®Ÿã‚¿ã‚¤ãƒ—'},
                                    {'name': 'è©³ç´°', 'id': 'è©³ç´°'},
                                    {'name': 'ç¢ºä¿¡åº¦', 'id': 'ç¢ºä¿¡åº¦', 'type': 'numeric', 'format': {'specifier': '.2f'}}
                                ],
                                style_data_conditional=[
                                    {
                                        'if': {
                                            'column_id': 'ç¢ºä¿¡åº¦',
                                            'filter_query': '{ç¢ºä¿¡åº¦} >= 0.8'
                                        },
                                        'backgroundColor': '#3D9970',
                                        'color': 'white',
                                    },
                                    {
                                        'if': {
                                            'column_id': 'ç¢ºä¿¡åº¦',
                                            'filter_query': '{ç¢ºä¿¡åº¦} < 0.5'
                                        },
                                        'backgroundColor': '#FFDC00',
                                    }
                                ],
                                sort_action='native',
                                filter_action='native',
                                page_size=20
                            ),
                            html.Div(id='facts-summary', style={'marginTop': '20px'})
                        ])
                    ]),
                    dcc.Tab(label='çµ±åˆåˆ†æ', value='integrated_analysis', children=[
                        html.Div([
                            html.H4("äº‹å®Ÿã¨æš—é»™çŸ¥ã®é–¢é€£"),
                            html.P("å®¢è¦³çš„äº‹å®ŸãŒã©ã®ã‚ˆã†ãªæš—é»™çŸ¥ã«ã¤ãªãŒã£ã¦ã„ã‚‹ã‹ã‚’åˆ†æã—ã¾ã™ã€‚"),
                            html.Div(id='integrated-analysis-content')
                        ])
                    ])
                ], value='implicit_analysis'),
            ], id='blueprint-analysis-content')
        ),
    ])

# --- ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
app.layout = html.Div([
    dcc.Store(id='kpi-data-store', storage_type='memory'),
    dcc.Store(id='data-loaded', storage_type='memory'),
    dcc.Store(id='full-analysis-store', storage_type='memory'),
    dcc.Store(id='creation-logic-results-store', storage_type='memory'),
    dcc.Store(id='logic-analysis-progress', storage_type='memory'),
    dcc.Store(id='blueprint-results-store', storage_type='memory'),
    dcc.Interval(id='logic-analysis-interval', interval=500, disabled=True),

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    html.Div([  # type: ignore
        html.H1("ğŸ—‚ï¸ Shift-Suite é«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢", style={
            'textAlign': 'center',
            'color': 'white',
            'margin': '0',
            'padding': '20px'
        })
    ], style={
        'backgroundColor': '#2c3e50',
        'boxShadow': '0 2px 4px rgba(0,0,0,0.1)'
    }),

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢
    html.Div([  # type: ignore
        dcc.Upload(
            id='upload-data',
            children=html.Div([
                'åˆ†æçµæœã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ— ã¾ãŸã¯ ',
                html.A('ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠ', style={'textDecoration': 'underline'})
            ]),
            style={
                'width': '100%',
                'height': '100px',
                'lineHeight': '100px',
                'borderWidth': '2px',
                'borderStyle': 'dashed',
                'borderRadius': '10px',
                'textAlign': 'center',
                'margin': '20px 0',
                'backgroundColor': '#f8f9fa',
                'cursor': 'pointer'
            },
            multiple=False
        ),
    ], style={'padding': '0 20px'}),

    html.Div([  # type: ignore
        html.H3("åˆ†æã‚·ãƒŠãƒªã‚ªé¸æŠ", style={'textAlign': 'center'}),
        dcc.Dropdown(
            id='scenario-dropdown',
            placeholder="ã¾ãšåˆ†æçµæœã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            style={'width': '60%', 'margin': 'auto'}
        )
    ], id='scenario-selector-div', style={'display': 'none'}),

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    html.Div(id='main-content', style={'padding': '20px'}),  # type: ignore

    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ãƒ“ãƒ¥ãƒ¼ã‚¢
    html.Details([
        html.Summary('ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ã‚’è¡¨ç¤º/éè¡¨ç¤º'),
        dcc.Textarea(id='log-viewer', style={'width': '100%', 'height': 300}, readOnly=True)
    ], style={'padding': '0 20px'}),
    dcc.Interval(id='log-interval', interval=1000),

], style={'backgroundColor': '#f5f5f5', 'minHeight': '100vh'})

# --- ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•° ---
@app.callback(
    Output('data-loaded', 'data'),
    Output('scenario-dropdown', 'options'),
    Output('scenario-dropdown', 'value'),
    Output('scenario-selector-div', 'style'),
    Input('upload-data', 'contents'),
    State('upload-data', 'filename')
)
@safe_callback
def process_upload(contents, filename):
    """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚·ãƒŠãƒªã‚ªã‚’æ¤œå‡º"""
    if contents is None:
        raise PreventUpdate

    global TEMP_DIR_OBJ

    log.info(f"Received upload: {filename}")

    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    if TEMP_DIR_OBJ:
        TEMP_DIR_OBJ.cleanup()

    TEMP_DIR_OBJ = tempfile.TemporaryDirectory(prefix="shift_suite_dash_")
    temp_dir_path = Path(TEMP_DIR_OBJ.name)
    log.debug(f"Created temp dir {temp_dir_path}")

    # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)

    try:
        with zipfile.ZipFile(io.BytesIO(decoded)) as zf:
            zf.extractall(temp_dir_path)
        log.info(f"Extracted ZIP to {temp_dir_path}")

        scenarios = [d.name for d in temp_dir_path.iterdir() if d.is_dir() and d.name.startswith('out_')]
        if not scenarios:
            return {'error': 'åˆ†æã‚·ãƒŠãƒªã‚ªã®ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}, [], None, {'display': 'none'}

        log.debug(f"Found scenarios: {scenarios}")

        # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ç”¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        scenario_name_map = {
            'out_median_based': 'ä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹',
            'out_mean_based': 'å¹³å‡å€¤ãƒ™ãƒ¼ã‚¹',
            'out_p25_based': '25ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹',
        }

        scenario_options = [
            {'label': scenario_name_map.get(s, s.replace('out_', '')), 'value': s}
            for s in scenarios
        ]
        first_scenario = scenarios[0]
        scenario_paths = {d.name: str(d) for d in temp_dir_path.iterdir() if d.is_dir()}
        return {
            'success': True,
            'scenarios': scenario_paths,
        }, scenario_options, first_scenario, {'display': 'block'}

    except Exception as e:
        log.error(f"Error processing ZIP: {e}", exc_info=True)
        return {'error': str(e)}, [], None, {'display': 'none'}


@app.callback(
    Output('kpi-data-store', 'data'),
    Output('main-content', 'children'),
    Input('scenario-dropdown', 'value'),
    State('data-loaded', 'data')
)
@safe_callback
def update_main_content(selected_scenario, data_status):
    """ã‚·ãƒŠãƒªã‚ªé¸æŠã«å¿œã˜ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¡ã‚¤ãƒ³UIã‚’æ›´æ–°"""
    if (
        not selected_scenario
        or not data_status
        or 'success' not in data_status
        or 'scenarios' not in data_status
    ):
        raise PreventUpdate

    data_dir = Path(data_status['scenarios'].get(selected_scenario, ''))
    if not data_dir.exists():
        raise PreventUpdate

    log.info(f"Switching to scenario {selected_scenario} at {data_dir}")

    # Scenario has changed; reset caches and store new directory
    global CURRENT_SCENARIO_DIR
    CURRENT_SCENARIO_DIR = data_dir
    clear_data_cache()

    pre_aggr = data_get('pre_aggregated_data')
    if pre_aggr is None or (isinstance(pre_aggr, pd.DataFrame) and pre_aggr.empty):
        return {}, html.Div(f"ã‚¨ãƒ©ãƒ¼: {(data_dir / 'pre_aggregated_data.parquet').name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")  # type: ignore

    kpi_data = {}

    tabs = dcc.Tabs(id='main-tabs', value='overview', children=[
        dcc.Tab(label='æ¦‚è¦', value='overview'),
        dcc.Tab(label='ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', value='heatmap'),
        dcc.Tab(label='ä¸è¶³åˆ†æ', value='shortage'),
        dcc.Tab(label='æœ€é©åŒ–åˆ†æ', value='optimization'),
        dcc.Tab(label='ä¼‘æš‡åˆ†æ', value='leave'),
        dcc.Tab(label='ã‚³ã‚¹ãƒˆåˆ†æ', value='cost'),
        dcc.Tab(label='æ¡ç”¨è¨ˆç”»', value='hire_plan'),
        dcc.Tab(label='ç–²åŠ´åˆ†æ', value='fatigue'),
        dcc.Tab(label='éœ€è¦äºˆæ¸¬', value='forecast'),
        dcc.Tab(label='å…¬å¹³æ€§', value='fairness'),
        dcc.Tab(label='åŸºæº–ä¹–é›¢åˆ†æ', value='gap'),
        dcc.Tab(label='è·å“¡å€‹åˆ¥åˆ†æ', value='individual_analysis'),
        dcc.Tab(label='ãƒãƒ¼ãƒ åˆ†æ', value='team_analysis'),
        dcc.Tab(label='ä½œæˆãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆ', value='blueprint_analysis'),
        dcc.Tab(label='ãƒ­ã‚¸ãƒƒã‚¯è§£æ˜', value='logic_analysis'),
    ])

    # å…¨ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒŠã‚’é™çš„ã«ä½œæˆï¼ˆCSSè¡¨ç¤ºåˆ¶å¾¡æ–¹å¼ï¼‰
    main_layout = html.Div([
        tabs,
        html.Div(style={'marginTop': '20px'}, children=[
            # å„ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒŠï¼ˆåˆæœŸçŠ¶æ…‹ã§ã¯æ¦‚è¦ã‚¿ãƒ–ã®ã¿è¡¨ç¤ºï¼‰
            html.Div(id='overview-tab-container', 
                    style={'display': 'block'},
                    children=[
                        dcc.Loading(
                            id="loading-overview",
                            type="circle",
                            children=html.Div(id='overview-content')
                        )
                    ]),
            html.Div(id='heatmap-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-heatmap",
                            type="circle",
                            children=html.Div(id='heatmap-content')
                        )
                    ]),
            html.Div(id='shortage-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-shortage",
                            type="circle",
                            children=html.Div(id='shortage-content')
                        )
                    ]),
            html.Div(id='optimization-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-optimization",
                            type="circle",
                            children=html.Div(id='optimization-content')
                        )
                    ]),
            html.Div(id='leave-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-leave",
                            type="circle",
                            children=html.Div(id='leave-content')
                        )
                    ]),
            html.Div(id='cost-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-cost",
                            type="circle",
                            children=html.Div(id='cost-content')
                        )
                    ]),
            html.Div(id='hire-plan-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-hire-plan",
                            type="circle",
                            children=html.Div(id='hire-plan-content')
                        )
                    ]),
            html.Div(id='fatigue-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-fatigue",
                            type="circle",
                            children=html.Div(id='fatigue-content')
                        )
                    ]),
            html.Div(id='forecast-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-forecast",
                            type="circle",
                            children=html.Div(id='forecast-content')
                        )
                    ]),
            html.Div(id='fairness-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-fairness",
                            type="circle",
                            children=html.Div(id='fairness-content')
                        )
                    ]),
            html.Div(id='gap-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-gap",
                            type="circle",
                            children=html.Div(id='gap-content')
                        )
                    ]),
            html.Div(id='individual-analysis-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-individual-analysis",
                            type="circle",
                            children=html.Div(id='individual-analysis-content')
                        )
                    ]),
            html.Div(id='team-analysis-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-team-analysis",
                            type="circle",
                            children=html.Div(id='team-analysis-content')
                        )
                    ]),
            html.Div(id='blueprint-analysis-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-blueprint-analysis",
                            type="circle",
                            children=html.Div(id='blueprint-analysis-content')
                        )
                    ]),
            html.Div(id='logic-analysis-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-logic-analysis",
                            type="circle",
                            children=html.Div(id='logic-analysis-content')
                        )
                    ])
        ])
    ])

    return kpi_data, main_layout


@app.callback(
    [Output('overview-tab-container', 'style'),
     Output('heatmap-tab-container', 'style'),
     Output('shortage-tab-container', 'style'),
     Output('optimization-tab-container', 'style'),
     Output('leave-tab-container', 'style'),
     Output('cost-tab-container', 'style'),
     Output('hire-plan-tab-container', 'style'),
     Output('fatigue-tab-container', 'style'),
     Output('forecast-tab-container', 'style'),
     Output('fairness-tab-container', 'style'),
     Output('gap-tab-container', 'style'),
     Output('individual-analysis-tab-container', 'style'),
     Output('team-analysis-tab-container', 'style'),
     Output('blueprint-analysis-tab-container', 'style'),
     Output('logic-analysis-tab-container', 'style')],
    Input('main-tabs', 'value'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def update_tab_visibility(active_tab, selected_scenario, data_status):
    """ã‚¿ãƒ–ã®è¡¨ç¤ºåˆ¶å¾¡ï¼ˆCSS visibilityæ–¹å¼ï¼‰"""
    if not selected_scenario or not data_status:
        raise PreventUpdate
    
    # å…¨ã‚¿ãƒ–ã®ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾©
    all_tabs = [
        'overview', 'heatmap', 'shortage', 'optimization', 'leave',
        'cost', 'hire_plan', 'fatigue', 'forecast', 'fairness',
        'gap', 'individual_analysis', 'team_analysis', 'blueprint_analysis', 'logic_analysis'
    ]
    
    # å„ã‚¿ãƒ–ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨­å®šï¼ˆã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚¿ãƒ–ã®ã¿è¡¨ç¤ºï¼‰
    styles = []
    for tab in all_tabs:
        if tab == active_tab:
            styles.append({'display': 'block'})
        else:
            styles.append({'display': 'none'})
    
    return styles


# å„ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆæœŸåŒ–ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
@app.callback(
    Output('overview-content', 'children'),
    Input('overview-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_overview_content(style, selected_scenario, data_status):
    """æ¦‚è¦ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_overview_tab()
    except Exception as e:
        log.error(f"æ¦‚è¦ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('heatmap-content', 'children'),
    Input('heatmap-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_heatmap_content(style, selected_scenario, data_status):
    """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_heatmap_tab()
    except Exception as e:
        log.error(f"ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('shortage-content', 'children'),
    Input('shortage-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_shortage_content(style, selected_scenario, data_status):
    """ä¸è¶³åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_shortage_tab()
    except Exception as e:
        log.error(f"ä¸è¶³åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('optimization-content', 'children'),
    Input('optimization-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_optimization_content(style, selected_scenario, data_status):
    """æœ€é©åŒ–åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_optimization_tab()
    except Exception as e:
        log.error(f"æœ€é©åŒ–åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('leave-content', 'children'),
    Input('leave-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_leave_content(style, selected_scenario, data_status):
    """ä¼‘æš‡åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_leave_analysis_tab()
    except Exception as e:
        log.error(f"ä¼‘æš‡åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('cost-content', 'children'),
    Input('cost-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_cost_content(style, selected_scenario, data_status):
    """ã‚³ã‚¹ãƒˆåˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_cost_analysis_tab()
    except Exception as e:
        log.error(f"ã‚³ã‚¹ãƒˆåˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('hire-plan-content', 'children'),
    Input('hire-plan-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_hire_plan_content(style, selected_scenario, data_status):
    """æ¡ç”¨è¨ˆç”»ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_hire_plan_tab()
    except Exception as e:
        log.error(f"æ¡ç”¨è¨ˆç”»ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('fatigue-content', 'children'),
    Input('fatigue-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_fatigue_content(style, selected_scenario, data_status):
    """ç–²åŠ´åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_fatigue_tab()
    except Exception as e:
        log.error(f"ç–²åŠ´åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('forecast-content', 'children'),
    Input('forecast-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_forecast_content(style, selected_scenario, data_status):
    """éœ€è¦äºˆæ¸¬ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_forecast_tab()
    except Exception as e:
        log.error(f"éœ€è¦äºˆæ¸¬ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('fairness-content', 'children'),
    Input('fairness-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_fairness_content(style, selected_scenario, data_status):
    """å…¬å¹³æ€§ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_fairness_tab()
    except Exception as e:
        log.error(f"å…¬å¹³æ€§ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('gap-content', 'children'),
    Input('gap-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_gap_content(style, selected_scenario, data_status):
    """åŸºæº–ä¹–é›¢åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_gap_analysis_tab()
    except Exception as e:
        log.error(f"åŸºæº–ä¹–é›¢åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('team-analysis-content', 'children'),
    Input('team-analysis-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_team_analysis_content(style, selected_scenario, data_status):
    """ãƒãƒ¼ãƒ åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_team_analysis_tab()
    except Exception as e:
        log.error(f"ãƒãƒ¼ãƒ åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('blueprint-analysis-content', 'children'),
    Input('blueprint-analysis-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_blueprint_analysis_content(style, selected_scenario, data_status):
    """ä½œæˆãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_blueprint_analysis_tab()
    except Exception as e:
        log.error(f"ä½œæˆãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('logic-analysis-content', 'children'),
    Input('logic-analysis-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_logic_analysis_content(style, selected_scenario, data_status):
    """ãƒ­ã‚¸ãƒƒã‚¯è§£æ˜ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_creation_logic_analysis_tab()
    except Exception as e:
        log.error(f"ãƒ­ã‚¸ãƒƒã‚¯è§£æ˜ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('individual-analysis-content', 'children'),
    Input('individual-analysis-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_individual_analysis_content(style, selected_scenario, data_status):
    """è·å“¡å€‹åˆ¥åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_individual_analysis_tab()
    except Exception as e:
        log.error(f"è·å“¡å€‹åˆ¥åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})


@app.callback(
    Output({'type': 'heatmap-filter-employment', 'index': ALL}, 'options'),
    Output({'type': 'heatmap-filter-employment', 'index': ALL}, 'value'),
    Input({'type': 'heatmap-filter-role', 'index': ALL}, 'value'),
)
@safe_callback
def update_employment_options(selected_roles):
    """è·ç¨®é¸æŠã«å¿œã˜ã¦é›‡ç”¨å½¢æ…‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’æ›´æ–°"""
    aggregated_df = data_get('pre_aggregated_data')
    if aggregated_df is None or aggregated_df.empty:
        default_options = [{'label': 'ã™ã¹ã¦', 'value': 'all'}]
        return [default_options, default_options], ['all', 'all']

    output_options = []
    for role in selected_roles:
        if role and role != 'all':
            employments = aggregated_df[aggregated_df['role'] == role][
                'employment'
            ].unique()
            new_options = (
                [{'label': 'ã™ã¹ã¦', 'value': 'all'}]
                + [{'label': emp, 'value': emp} for emp in sorted(employments)]
            )
        else:
            all_employments = aggregated_df['employment'].unique()
            new_options = (
                [{'label': 'ã™ã¹ã¦', 'value': 'all'}]
                + [{'label': emp, 'value': emp} for emp in sorted(all_employments)]
            )
        output_options.append(new_options)

    return output_options, ['all', 'all']


@app.callback(
    Output({'type': 'graph-output-heatmap', 'index': 1}, 'children'),
    Output({'type': 'graph-output-heatmap', 'index': 2}, 'children'),
    Input({'type': 'heatmap-filter-role', 'index': 1}, 'value'),
    Input({'type': 'heatmap-filter-employment', 'index': 1}, 'value'),
    Input({'type': 'heatmap-filter-role', 'index': 2}, 'value'),
    Input({'type': 'heatmap-filter-employment', 'index': 2}, 'value'),
)
@safe_callback
def update_comparison_heatmaps(role1, emp1, role2, emp2):
    """äº‹å‰é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‹•çš„ã«ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã€2ã‚¨ãƒªã‚¢ã‚’æ›´æ–°"""

    aggregated_df = data_get('pre_aggregated_data')
    if aggregated_df is None or aggregated_df.empty:
        error_message = html.Div("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®å…ƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")  # type: ignore
        return error_message, error_message

    def generate_dynamic_heatmap(selected_role, selected_emp):
        """é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§äº‹å‰é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ã—ãƒ”ãƒœãƒƒãƒˆåŒ–"""

        filtered_df = aggregated_df.copy()
        title_parts = []

        # é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«åˆã‚ã›ã¦ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã‚€
        if selected_role and selected_role != 'all':
            filtered_df = filtered_df[filtered_df['role'] == selected_role]
            title_parts.append(f"è·ç¨®: {selected_role}")

        if selected_emp and selected_emp != 'all':
            filtered_df = filtered_df[filtered_df['employment'] == selected_emp]
            title_parts.append(f"é›‡ç”¨å½¢æ…‹: {selected_emp}")

        title = " AND ".join(title_parts) if title_parts else "å…¨ä½“"

        if filtered_df.empty:
            time_labels = gen_labels(30)
            all_dates = sorted(aggregated_df['date_lbl'].unique())
            empty_heatmap = pd.DataFrame(index=time_labels, columns=all_dates).fillna(0)
            fig_empty = generate_heatmap_figure(empty_heatmap, f"{title} (å‹¤å‹™ãƒ‡ãƒ¼ã‚¿ãªã—)")
            return dcc.Graph(figure=fig_empty)

        # æ—¥ä»˜é †ã«ä¸¦ã³æ›¿ãˆã¦ã‹ã‚‰ãƒ”ãƒœãƒƒãƒˆ
        dynamic_heatmap_df = filtered_df.sort_values('date_lbl').pivot_table(
            index='time',
            columns='date_lbl',
            values='staff_count',
            aggfunc='sum',
            fill_value=0,
        )

        # aggregated_df['date_lbl'].unique() ã¯å¸¸ã«30æ—¥å…¨ã¦ã®æ—¥ä»˜ã‚’ä¿æŒã—ã¦ã„ã¾ã™
        all_dates_from_aggregated_data = sorted(aggregated_df['date_lbl'].unique())

        # ã¾ãšåˆ—ï¼ˆæ—¥ä»˜ï¼‰ã‚’å…¨ã¦ç¶²ç¾…ã™ã‚‹ã‚ˆã†ã«reindexã—ã€ä¸è¶³ã—ã¦ã„ã‚‹åˆ—ã¯0ã§åŸ‹ã‚ã‚‹
        dynamic_heatmap_df = dynamic_heatmap_df.reindex(columns=all_dates_from_aggregated_data, fill_value=0)

        time_labels = gen_labels(30)
        # æ¬¡ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆæ™‚é–“ï¼‰ã‚’å…¨ã¦ç¶²ç¾…ã™ã‚‹ã‚ˆã†ã«reindexã—ã€ä¸è¶³ã—ã¦ã„ã‚‹è¡Œã¯0ã§åŸ‹ã‚ã‚‹
        dynamic_heatmap_df = dynamic_heatmap_df.reindex(index=time_labels, fill_value=0)

        present_dates = dynamic_heatmap_df.columns.tolist()
        analysis_logger.info(
            f"ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— '{title}' ã®ç”Ÿæˆ: æç”»å¯¾è±¡ã®æ—¥ä»˜ ({len(present_dates)}ä»¶): {present_dates}"
        )

        long_df = data_get('long_df', pd.DataFrame())
        if not long_df.empty:
            all_dates_in_period = sorted(pd.to_datetime(long_df['ds']).dt.strftime('%Y-%m-%d').unique())
            missing_dates = sorted(list(set(all_dates_in_period) - set(present_dates)))
            if missing_dates:
                analysis_logger.warning(
                    f"ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— '{title}' ã§æ—¥ä»˜ãŒæ¬ è½ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                    f"åˆ†ææœŸé–“ä¸­ã®å…¨æ—¥ä»˜: {len(all_dates_in_period)}ä»¶, "
                    f"æç”»å¯¾è±¡ã®æ—¥ä»˜: {len(present_dates)}ä»¶, "
                    f"æ¬ è½æ—¥ä»˜ ({len(missing_dates)}ä»¶): {missing_dates}"
                )

        fig = generate_heatmap_figure(dynamic_heatmap_df, title)
        return dcc.Graph(figure=fig)

    output1 = generate_dynamic_heatmap(role1, emp1)
    output2 = generate_dynamic_heatmap(role2, emp2)

    return output1, output2


@app.callback(
    Output('shortage-heatmap-detail-container', 'children'),
    Input('shortage-heatmap-scope', 'value')
)
@safe_callback
def update_shortage_heatmap_detail(scope):
    """ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®è©³ç´°é¸æŠã‚’æ›´æ–°"""
    if scope == 'overall':
        return None
    elif scope == 'role':
        roles = data_get('roles', [])
        return html.Div([  # type: ignore
            html.Label("è·ç¨®é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'shortage-detail', 'index': 'role'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': r, 'value': r} for r in roles],
                value='ALL',
                style={'width': '200px'}
            )
        ], style={'marginBottom': '10px'})
    elif scope == 'employment':
        employments = data_get('employments', [])
        return html.Div([  # type: ignore
            html.Label("é›‡ç”¨å½¢æ…‹é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'shortage-detail', 'index': 'employment'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': e, 'value': e} for e in employments],
                value='ALL',
                style={'width': '200px'}
            )
        ], style={'marginBottom': '10px'})
    return None


@app.callback(
    Output('shortage-ratio-heatmap', 'children'),
    Input('shortage-heatmap-scope', 'value'),
    Input({'type': 'shortage-detail', 'index': ALL}, 'value')
)
@safe_callback
def update_shortage_ratio_heatmap(scope, detail_values):
    """ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ›´æ–°"""
    # é¸æŠå†…å®¹ã‹ã‚‰ã‚­ãƒ¼ã‚’çµ„ã¿ç«‹ã¦ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    key_suffix = ''
    if scope == 'role' and detail_values and detail_values[0] != 'ALL':
        # è·ç¨®åˆ¥: ç›´æ¥è·ç¨®åã‚’ä½¿ç”¨ï¼ˆrole_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹é™¤å»ï¼‰
        key_suffix = safe_filename(detail_values[0])
    elif scope == 'employment' and detail_values and detail_values[0] != 'ALL':
        # é›‡ç”¨å½¢æ…‹åˆ¥: emp_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãã§ä½¿ç”¨
        key_suffix = f"emp_{safe_filename(detail_values[0])}"

    heat_key = f"heat_{key_suffix}" if key_suffix else "heat_all"
    df_heat = data_get(heat_key, pd.DataFrame())
    
    # ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€å…ƒã®è·ç¨®åï¼ˆsafe_filenameå¤‰æ›å‰ï¼‰ã§å†è©¦è¡Œ
    if df_heat.empty and scope == 'role' and detail_values and detail_values[0] != 'ALL':
        original_heat_key = f"heat_{detail_values[0]}"
        log.info(f"Trying original key: {original_heat_key}")
        df_heat = data_get(original_heat_key, pd.DataFrame())

    if df_heat.empty:
        # ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨è¨ºæ–­æƒ…å ±ã‚’æä¾›
        available_keys = [k for k in DATA_CACHE.keys() if k.startswith('heat_')]
        debug_info = []
        debug_info.append(f"æ¢ç´¢ã‚­ãƒ¼: {heat_key}")
        debug_info.append(f"åˆ©ç”¨å¯èƒ½ãªãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚­ãƒ¼: {available_keys}")
        debug_info.append(f"é¸æŠã•ã‚ŒãŸã‚¹ã‚³ãƒ¼ãƒ—: {scope}")
        debug_info.append(f"è©³ç´°å€¤: {detail_values}")
        
        # é¡ä¼¼ã‚­ãƒ¼ã®ææ¡ˆ
        similar_keys = [k for k in available_keys if key_suffix in k] if key_suffix else []
        if similar_keys:
            debug_info.append(f"é¡ä¼¼ã‚­ãƒ¼: {similar_keys}")
        
        return html.Div([  # type: ignore
            html.P("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", style={'color': 'red', 'fontWeight': 'bold'}),
            html.P("è¨ºæ–­æƒ…å ±:", style={'fontWeight': 'bold'}),
            html.Ul([html.Li(info) for info in debug_info]),
            html.P("è§£æ±ºæ–¹æ³•:", style={'fontWeight': 'bold'}),
            html.Ul([
                html.Li("ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãåˆ†æã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"),
                html.Li("è·ç¨®åã«ç‰¹æ®Šæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„"), 
                html.Li("åˆ¥ã®è·ç¨®/é›‡ç”¨å½¢æ…‹ã‚’é¸æŠã—ã¦ã¿ã¦ãã ã•ã„")
            ])
        ])

    date_cols = [c for c in df_heat.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    staff_df = df_heat[date_cols]
    
    # â˜…â˜…â˜… é‡è¦ãªä¿®æ­£: è·ç¨®åˆ¥ãƒ»é›‡ç”¨å½¢æ…‹åˆ¥ã®å ´åˆã¯è©²å½“ã®needå€¤ã®ã¿ã‚’ä½¿ç”¨ â˜…â˜…â˜…
    if scope == 'overall':
        # å…¨ä½“ã®å ´åˆã®ã¿need_per_date_slot.parquetã‚’ä½¿ç”¨
        need_per_date_slot_df = data_get('need_per_date_slot', pd.DataFrame())
        
        if not need_per_date_slot_df.empty:
            # need_per_date_slot.parquetãŒå­˜åœ¨ã™ã‚‹å ´åˆã€å®Ÿéš›ã®æ—¥ä»˜åˆ¥needå€¤ã‚’ä½¿ç”¨
            log.info(f"Using need_per_date_slot.parquet for accurate daily need values: {need_per_date_slot_df.shape}")
            
            # åˆ—åã‚’æ–‡å­—åˆ—ã¨ã—ã¦çµ±ä¸€
            need_per_date_slot_df.columns = [str(col) for col in need_per_date_slot_df.columns]
            date_cols_str = [str(col) for col in date_cols]
            
            # å…±é€šã™ã‚‹æ—¥ä»˜åˆ—ã®ã¿ã‚’ä½¿ç”¨
            common_dates = [col for col in date_cols_str if col in need_per_date_slot_df.columns]
            
            if common_dates:
                # å®Ÿéš›ã®æ—¥ä»˜åˆ¥needå€¤ã‚’ä½¿ç”¨
                need_df = need_per_date_slot_df[common_dates].copy()
                need_df.columns = [c for c in date_cols if str(c) in common_dates]
                
                # ä¸è¶³ã—ã¦ã„ã‚‹æ—¥ä»˜ãŒã‚ã‚Œã°å¹³å‡å€¤ã§è£œå®Œ
                missing_dates = [c for c in date_cols if str(c) not in common_dates]
                if missing_dates:
                    log.warning(f"Some dates missing in need_per_date_slot.parquet, using fallback for: {missing_dates}")
                    fallback_need = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(missing_dates), axis=1),
                                               index=df_heat.index, columns=missing_dates)
                    need_df = pd.concat([need_df, fallback_need], axis=1)
                    need_df = need_df.reindex(columns=date_cols)  # å…ƒã®é †åºã‚’ä¿æŒ
            else:
                log.warning("No matching dates found in need_per_date_slot.parquet, falling back to average need")
                need_df = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                                       index=df_heat.index, columns=date_cols)
        else:
            # need_per_date_slot.parquetãŒå­˜åœ¨ã—ãªã„å ´åˆã¯å¾“æ¥ã®å¹³å‡å€¤ã‚’ä½¿ç”¨
            log.info("need_per_date_slot.parquet not available, using average need values")
            need_df = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                                   index=df_heat.index, columns=date_cols)
    else:
        # è·ç¨®åˆ¥ãƒ»é›‡ç”¨å½¢æ…‹åˆ¥ã®å ´åˆã¯ã€å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å‹•çš„needå€¤ã‚’è¨ˆç®—
        need_df = calculate_role_dynamic_need(df_heat, date_cols, heat_key)
    upper_df = pd.DataFrame(np.repeat(df_heat['upper'].values[:, np.newaxis], len(date_cols), axis=1),
                            index=df_heat.index, columns=date_cols)

    # æ­£ç¢ºãªä¸è¶³è¨ˆç®—ã®å®Ÿè£…
    # needå€¤ãŒæ­£ç¢ºã«è¨ˆç®—ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ã‚·ãƒ³ãƒ—ãƒ«ã§æ­£ç¢ºãªä¸è¶³è¨ˆç®—ã‚’è¡Œã†
    lack_count_df = (need_df - staff_df).clip(lower=0).fillna(0)
    
    # å®Ÿéš›ã®needå€¤ãŒéå¸¸ã«å°ã•ã„å ´åˆï¼ˆ0.01æœªæº€ï¼‰ã®ã¿0ã¨ã™ã‚‹ï¼ˆè¨ˆç®—èª¤å·®å¯¾ç­–ï¼‰
    mask_tiny_need = need_df < 0.01
    lack_count_df[mask_tiny_need] = 0.0
    
    log.info(f"[LACK_CALCULATION] {heat_key}: Total lack={lack_count_df.sum().sum():.2f}, Max need={need_df.max().max():.2f}, Max staff={staff_df.max().max():.2f}")
    
    excess_count_df = (staff_df - upper_df).clip(lower=0).fillna(0)
    ratio_df = calc_ratio_from_heatmap(df_heat)
    
    # ä¸è¶³æ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ä¿®æ­£
    lack_count_df_renamed = lack_count_df.copy()
    lack_count_df_renamed.columns = [date_with_weekday(c) for c in lack_count_df_renamed.columns]
    # è¿½åŠ ã®å®‰å…¨å¯¾ç­–: NaNå€¤ã‚’å†åº¦0ã§åŸ‹ã‚ã‚‹ï¼ˆæ—¥æ›œæ—¥ã®æ¬ è½å¯¾ç­–ï¼‰
    lack_count_df_renamed = lack_count_df_renamed.fillna(0)
    
    fig_lack = px.imshow(
        lack_count_df_renamed,
        aspect='auto',
        color_continuous_scale='Oranges',
        title='ä¸è¶³äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
        labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'},
        text_auto=True  # 0å€¤ã‚‚è¡¨ç¤º
    )
    
    # ä¸è¶³æ•°ã®è¡¨ç¤ºã‚¹ã‚¿ã‚¤ãƒ«ã‚’èª¿æ•´
    fig_lack.update_traces(
        texttemplate='%{text}',
        textfont={"size": 10}
    )
    fig_lack.update_xaxes(tickvals=list(range(len(lack_count_df.columns))))

    fig_excess = go.Figure()
    if not excess_count_df.empty:
        excess_count_df_renamed = excess_count_df.copy()
        excess_count_df_renamed.columns = [date_with_weekday(c) for c in excess_count_df_renamed.columns]
        fig_excess = px.imshow(
            excess_count_df_renamed,
            aspect='auto',
            color_continuous_scale='Blues',
            title='éå‰°äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
            labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'},
        )
        fig_excess.update_xaxes(tickvals=list(range(len(excess_count_df.columns))))

    fig_ratio = go.Figure()
    if not ratio_df.empty:
        ratio_df_renamed = ratio_df.copy()
        ratio_df_renamed.columns = [date_with_weekday(c) for c in ratio_df_renamed.columns]
        fig_ratio = px.imshow(
            ratio_df_renamed,
            aspect='auto',
            color_continuous_scale='RdBu_r',
            title='ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
            labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ä¸è¶³ç‡'},
        )
        fig_ratio.update_xaxes(tickvals=list(range(len(ratio_df.columns))))

    return html.Div([  # type: ignore
        html.H4('ä¸è¶³äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—'),
        dcc.Graph(figure=fig_lack),
        html.H4('éå‰°äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', style={'marginTop': '30px'}),
        dcc.Graph(figure=fig_excess),
        html.H4('ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', style={'marginTop': '30px'}),
        dcc.Graph(figure=fig_ratio),
    ])


@app.callback(
    Output('opt-detail-container', 'children'),
    Input('opt-scope', 'value')
)
@safe_callback
def update_opt_detail(scope):
    """æœ€é©åŒ–åˆ†æã®è©³ç´°é¸æŠã‚’æ›´æ–°"""
    if scope == 'overall':
        return None
    elif scope == 'role':
        roles = data_get('roles', [])
        return html.Div([  # type: ignore
            html.Label("è·ç¨®é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'opt-detail', 'index': 'role'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': r, 'value': r} for r in roles],
                value='ALL',
                style={'width': '300px', 'marginBottom': '20px'}
            )
        ])
    elif scope == 'employment':
        employments = data_get('employments', [])
        return html.Div([  # type: ignore
            html.Label("é›‡ç”¨å½¢æ…‹é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'opt-detail', 'index': 'employment'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': e, 'value': e} for e in employments],
                value='ALL',
                style={'width': '300px', 'marginBottom': '20px'}
            )
        ])
    return None

@app.callback(
    Output('optimization-content', 'children'),
    Input('opt-scope', 'value'),
    Input({'type': 'opt-detail', 'index': ALL}, 'value')
)
@safe_callback
def update_optimization_content(scope, detail_values):
    """æœ€é©åŒ–åˆ†æã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›´æ–°"""
    # é¸æŠå†…å®¹ã‹ã‚‰ã‚­ãƒ¼ã‚’çµ„ã¿ç«‹ã¦ã¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’å–å¾—
    key_suffix = ''
    if scope == 'role' and detail_values and detail_values[0] != 'ALL':
        # è·ç¨®åˆ¥: ç›´æ¥è·ç¨®åã‚’ä½¿ç”¨ï¼ˆrole_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹é™¤å»ï¼‰
        key_suffix = safe_filename(detail_values[0])
    elif scope == 'employment' and detail_values and detail_values[0] != 'ALL':
        # é›‡ç”¨å½¢æ…‹åˆ¥: emp_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãã§ä½¿ç”¨
        key_suffix = f"emp_{safe_filename(detail_values[0])}"

    heat_key = f"heat_{key_suffix}" if key_suffix else "heat_all"
    df_heat = data_get(heat_key, pd.DataFrame())
    
    # ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€å…ƒã®è·ç¨®åï¼ˆsafe_filenameå¤‰æ›å‰ï¼‰ã§å†è©¦è¡Œ
    if df_heat.empty and scope == 'role' and detail_values and detail_values[0] != 'ALL':
        original_heat_key = f"heat_{detail_values[0]}"
        log.info(f"Trying original key for optimization: {original_heat_key}")
        df_heat = data_get(original_heat_key, pd.DataFrame())

    if df_heat.empty:
        return html.Div("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã®æœ€é©åŒ–åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    date_cols = [c for c in df_heat.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    staff_df = df_heat[date_cols]
    
    # â˜…â˜…â˜… é‡è¦ãªä¿®æ­£: è·ç¨®åˆ¥ãƒ»é›‡ç”¨å½¢æ…‹åˆ¥ã®å ´åˆã¯è©²å½“ã®needå€¤ã®ã¿ã‚’ä½¿ç”¨ â˜…â˜…â˜…
    if scope == 'overall':
        # å…¨ä½“ã®å ´åˆã®ã¿need_per_date_slot.parquetã‚’ä½¿ç”¨
        need_per_date_slot_df = data_get('need_per_date_slot', pd.DataFrame())
        
        if not need_per_date_slot_df.empty:
            # need_per_date_slot.parquetãŒå­˜åœ¨ã™ã‚‹å ´åˆã€å®Ÿéš›ã®æ—¥ä»˜åˆ¥needå€¤ã‚’ä½¿ç”¨
            log.info(f"Using need_per_date_slot.parquet for optimization analysis: {need_per_date_slot_df.shape}")
            
            # åˆ—åã‚’æ–‡å­—åˆ—ã¨ã—ã¦çµ±ä¸€
            need_per_date_slot_df.columns = [str(col) for col in need_per_date_slot_df.columns]
            date_cols_str = [str(col) for col in date_cols]
            
            # å…±é€šã™ã‚‹æ—¥ä»˜åˆ—ã®ã¿ã‚’ä½¿ç”¨
            common_dates = [col for col in date_cols_str if col in need_per_date_slot_df.columns]
            
            if common_dates:
                # å®Ÿéš›ã®æ—¥ä»˜åˆ¥needå€¤ã‚’ä½¿ç”¨
                need_df = need_per_date_slot_df[common_dates].copy()
                need_df.columns = [c for c in date_cols if str(c) in common_dates]
                
                # ä¸è¶³ã—ã¦ã„ã‚‹æ—¥ä»˜ãŒã‚ã‚Œã°å¹³å‡å€¤ã§è£œå®Œ
                missing_dates = [c for c in date_cols if str(c) not in common_dates]
                if missing_dates:
                    log.warning(f"Some dates missing in need_per_date_slot.parquet for optimization, using fallback for: {missing_dates}")
                    fallback_need = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(missing_dates), axis=1),
                                               index=df_heat.index, columns=missing_dates)
                    need_df = pd.concat([need_df, fallback_need], axis=1)
                    need_df = need_df.reindex(columns=date_cols)
            else:
                log.warning("No matching dates found in need_per_date_slot.parquet for optimization, falling back to average need")
                need_df = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                                       index=df_heat.index, columns=date_cols)
        else:
            # need_per_date_slot.parquetãŒå­˜åœ¨ã—ãªã„å ´åˆã¯å¾“æ¥ã®å¹³å‡å€¤ã‚’ä½¿ç”¨
            log.info("need_per_date_slot.parquet not available for optimization, using average need values")
            need_df = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                                   index=df_heat.index, columns=date_cols)
    else:
        # è·ç¨®åˆ¥ãƒ»é›‡ç”¨å½¢æ…‹åˆ¥ã®å ´åˆã¯ã€å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å‹•çš„needå€¤ã‚’è¨ˆç®—
        need_df = calculate_role_dynamic_need(df_heat, date_cols, heat_key)
    upper_df = pd.DataFrame(np.repeat(df_heat['upper'].values[:, np.newaxis], len(date_cols), axis=1),
                            index=df_heat.index, columns=date_cols)

    # ä¸è¶³ç‡ãƒ»éå‰°ç‡ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    lack_ratio = ((need_df - staff_df) / need_df.replace(0, np.nan)).clip(lower=0).fillna(0)
    excess_ratio = ((staff_df - upper_df) / upper_df.replace(0, np.nan)).clip(lower=0).fillna(0)

    df_surplus = (staff_df - need_df).clip(lower=0).fillna(0)
    df_margin = (upper_df - staff_df).clip(lower=0).fillna(0)
    df_score = 1 - (0.6 * lack_ratio + 0.4 * excess_ratio).clip(0, 1)

    if not (_valid_df(df_surplus) and _valid_df(df_margin) and _valid_df(df_score)):
        return html.Div("æœ€é©åŒ–åˆ†æãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    surplus_df_renamed = df_surplus.copy()
    surplus_df_renamed.columns = [date_with_weekday(c) for c in surplus_df_renamed.columns]

    margin_df_renamed = df_margin.copy()
    margin_df_renamed.columns = [date_with_weekday(c) for c in margin_df_renamed.columns]

    score_df_renamed = df_score.copy()
    score_df_renamed.columns = [date_with_weekday(c) for c in score_df_renamed.columns]

    content = [
        html.Div([
            html.H4("1. å¿…è¦äººæ•°ã«å¯¾ã™ã‚‹ä½™å‰° (Surplus vs Need)"),
            html.P("å„æ™‚é–“å¸¯ã§å¿…è¦äººæ•°ï¼ˆneedï¼‰ã«å¯¾ã—ã¦ä½•äººå¤šãã‚¹ã‚¿ãƒƒãƒ•ãŒã„ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚"),
            dcc.Graph(
                figure=px.imshow(
                    surplus_df_renamed,
                    aspect='auto',
                    color_continuous_scale='Blues',
                    title='å¿…è¦äººæ•°ã«å¯¾ã™ã‚‹ä½™å‰°äººå“¡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
                    labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ä½™å‰°äººæ•°'},
                ).update_xaxes(tickvals=list(range(len(df_surplus.columns))))
            ),
        ]),
        html.Div([
            html.H4("2. ä¸Šé™ã«å¯¾ã™ã‚‹ä½™ç™½ (Margin to Upper)", style={'marginTop': '30px'}),
            html.P("å„æ™‚é–“å¸¯ã§é…ç½®äººæ•°ã®ä¸Šé™ï¼ˆupperï¼‰ã¾ã§ã‚ã¨ä½•äººã®ä½™è£•ãŒã‚ã£ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚"),
            dcc.Graph(
                figure=px.imshow(
                    margin_df_renamed,
                    aspect='auto',
                    color_continuous_scale='Greens',
                    title='ä¸Šé™äººæ•°ã¾ã§ã®ä½™ç™½ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
                    labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ä½™ç™½äººæ•°'},
                ).update_xaxes(tickvals=list(range(len(df_margin.columns))))
            ),
        ]),
        html.Div([
            html.H4("3. äººå“¡é…ç½® æœ€é©åŒ–ã‚¹ã‚³ã‚¢", style={'marginTop': '30px'}),
            html.P("äººå“¡é…ç½®ã®åŠ¹ç‡æ€§ã‚’0ã‹ã‚‰1ã®ã‚¹ã‚³ã‚¢ã§ç¤ºã—ã¾ã™ï¼ˆ1ãŒæœ€ã‚‚è‰¯ã„ï¼‰ã€‚"),
            dcc.Graph(
                figure=px.imshow(
                    score_df_renamed,
                    aspect='auto',
                    color_continuous_scale='RdYlGn',
                    zmin=0,
                    zmax=1,
                    title='æœ€é©åŒ–ã‚¹ã‚³ã‚¢ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
                    labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ã‚¹ã‚³ã‚¢'},
                ).update_xaxes(tickvals=list(range(len(df_score.columns))))
            ),
        ]),
    ]

    return html.Div(content)


@app.callback(
    Output('overview-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_overview_insights(kpi_data):
    if not kpi_data:
        return ""

    total_lack_h = kpi_data.get('total_lack_h', 0)

    if total_lack_h > 0:
        most_lacking_role = kpi_data.get('most_lacking_role_name', 'N/A')
        most_lacking_hours = kpi_data.get('most_lacking_role_hours', 0)
        insight_text = f"""
        #### ğŸ“ˆ åˆ†æãƒã‚¤ãƒ©ã‚¤ãƒˆ
        - **ç·ä¸è¶³æ™‚é–“:** {total_lack_h:.1f} æ™‚é–“
        - **æœ€é‡è¦èª²é¡Œ:** **{most_lacking_role}** ã®ä¸è¶³ãŒ **{most_lacking_hours:.1f}æ™‚é–“** ã¨æœ€ã‚‚æ·±åˆ»ã§ã™ã€‚ã“ã®è·ç¨®ã®æ¡ç”¨ã¾ãŸã¯é…ç½®è»¢æ›ãŒæ€¥å‹™ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚
        """
        return dcc.Markdown(insight_text)
    return html.P(
        "ğŸ‘ äººå“¡ä¸è¶³ã¯ç™ºç”Ÿã—ã¦ã„ã¾ã›ã‚“ã€‚ç´ æ™´ã‚‰ã—ã„å‹¤å‹™ä½“åˆ¶ã§ã™ï¼",
        style={'fontWeight': 'bold'},  # type: ignore
    )


@app.callback(
    Output('shortage-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_shortage_insights(kpi_data):
    explanation = """
    #### ä¸è¶³åˆ†æã®è©•ä¾¡æ–¹æ³•
    - **ä¸è¶³ (Shortage):** `ä¸è¶³äººæ•° = å¿…è¦äººæ•° (Need) - å®Ÿç¸¾äººæ•°` ã§è¨ˆç®—ã•ã‚Œã¾ã™ã€‚å€¤ãŒãƒ—ãƒ©ã‚¹ã®å ´åˆã€ãã®æ™‚é–“å¸¯ã¯äººå“¡ãŒä¸è¶³ã—ã¦ã„ãŸã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
    - **éå‰° (Excess):** `éå‰°äººæ•° = å®Ÿç¸¾äººæ•° - ä¸Šé™äººæ•° (Upper)` ã§è¨ˆç®—ã•ã‚Œã¾ã™ã€‚å€¤ãŒãƒ—ãƒ©ã‚¹ã®å ´åˆã€éå‰°ãªäººå“¡ãŒé…ç½®ã•ã‚Œã¦ã„ãŸã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚

    *ã€Œå¿…è¦äººæ•°ã€ã¨ã€Œä¸Šé™äººæ•°ã€ã¯ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œåˆ†æåŸºæº–è¨­å®šã€ã§æŒ‡å®šã—ãŸæ–¹æ³•ï¼ˆéå»å®Ÿç¸¾ã®çµ±è¨ˆã€ã¾ãŸã¯äººå“¡é…ç½®åŸºæº–ï¼‰ã«åŸºã¥ã„ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚*
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('hire-plan-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_hire_plan_insights(kpi_data):
    if not kpi_data:
        return ""
    total_lack_h = kpi_data.get('total_lack_h', 0)
    if total_lack_h == 0:
        return html.P("è¿½åŠ æ¡ç”¨ã®å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    role = kpi_data.get('most_lacking_role_name', 'N/A')
    return dcc.Markdown(
        f"æœ€ã‚‚ä¸è¶³ã—ã¦ã„ã‚‹ **{role}** ã®è£œå……ã‚’å„ªå…ˆçš„ã«æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
    )


@app.callback(
    Output('optimization-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_optimization_insights(kpi_data):
    explanation = """
    #### æœ€é©åŒ–åˆ†æã®è©•ä¾¡æ–¹æ³•
    äººå“¡é…ç½®ã®åŠ¹ç‡æ€§ã¯ã€ä»¥ä¸‹ã®2ã¤ã®è¦³ç‚¹ã‹ã‚‰ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’è¨ˆç®—ã—ã€æœ€çµ‚çš„ãªã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—ã¾ã™ã€‚
    - **ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ (é‡ã¿: 60%):** `(å¿…è¦äººæ•° - å®Ÿç¸¾äººæ•°) / å¿…è¦äººæ•°`
    - **éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£ (é‡ã¿: 40%):** `(å®Ÿç¸¾äººæ•° - ä¸Šé™äººæ•°) / ä¸Šé™äººæ•°`

    **æœ€é©åŒ–ã‚¹ã‚³ã‚¢ = 1 - (ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ Ã— 0.6 + éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£ Ã— 0.4)**

    *ã‚¹ã‚³ã‚¢ãŒ1ã«è¿‘ã„ã»ã©ã€ä¸è¶³ã‚‚éå‰°ã‚‚ãªãã€åŠ¹ç‡çš„ãªäººå“¡é…ç½®ãŒã§ãã¦ã„ã‚‹çŠ¶æ…‹ã‚’ç¤ºã—ã¾ã™ã€‚*
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('leave-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_leave_insights(kpi_data):
    explanation = """
    #### ä¼‘æš‡åˆ†æã®è©•ä¾¡æ–¹æ³•
    - **ä¼‘æš‡å–å¾—è€…æ•°:** `holiday_type`ãŒä¼‘æš‡é–¢é€£ï¼ˆå¸Œæœ›ä¼‘ã€æœ‰çµ¦ãªã©ï¼‰ã«è¨­å®šã•ã‚Œã€ã‹ã¤å‹¤å‹™æ™‚é–“ãŒãªã„ï¼ˆ`parsed_slots_count = 0`ï¼‰å ´åˆã«ã€Œ1æ—¥ã€ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã¾ã™ã€‚
    - **é›†ä¸­æ—¥:** ã€Œå¸Œæœ›ä¼‘ã€ã®å–å¾—è€…æ•°ãŒã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ãŸé–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3äººï¼‰ä»¥ä¸Šã«ãªã£ãŸæ—¥ã‚’ã€Œé›†ä¸­æ—¥ã€ã¨ã—ã¦ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¾ã™ã€‚
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('cost-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_cost_insights(kpi_data):
    explanation = """
    #### ã‚³ã‚¹ãƒˆåˆ†æã®è©•ä¾¡æ–¹æ³•
    æ—¥ã€…ã®äººä»¶è²»ã¯ã€å„ã‚¹ã‚¿ãƒƒãƒ•ã®å‹¤å‹™æ™‚é–“ï¼ˆã‚¹ãƒ­ãƒƒãƒˆæ•° Ã— ã‚¹ãƒ­ãƒƒãƒˆé•·ï¼‰ã«ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ãŸå˜ä¾¡åŸºæº–ï¼ˆè·ç¨®åˆ¥ã€é›‡ç”¨å½¢æ…‹åˆ¥ãªã©ï¼‰ã®æ™‚çµ¦ã‚’ä¹—ã˜ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('wage-input-container', 'children'),
    Input('cost-by-radio', 'value')
)
@safe_callback
def update_wage_inputs(by_key):
    """å˜ä¾¡å…¥åŠ›æ¬„ã‚’ç”Ÿæˆ"""
    long_df = data_get('long_df')
    if long_df is None or long_df.empty or by_key not in long_df.columns:
        return html.P("å˜ä¾¡è¨­å®šã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    unique_keys: list[str] = sorted(long_df[by_key].dropna().unique())
    inputs = []
    for key in unique_keys:
        inputs.append(html.Div([
            html.Label(f'æ™‚çµ¦: {key}'),
            dcc.Input(
                id={'type': 'wage-input', 'index': key},
                value=1500,
                type='number',
                debounce=True,
            )
        ], style={'padding': '5px', 'display': 'inline-block'}))
    return inputs


@app.callback(
    Output('cost-analysis-content', 'children'),
    Input('cost-by-radio', 'value'),
    Input({'type': 'wage-input', 'index': ALL}, 'value'),
    State({'type': 'wage-input', 'index': ALL}, 'id'),
)
@safe_callback
def update_cost_analysis_content(by_key, all_wages, all_wage_ids):
    """å˜ä¾¡å¤‰æ›´ã«å¿œã˜ã¦ã‚³ã‚¹ãƒˆåˆ†æã‚¿ãƒ–ã®å…¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å‹•çš„ã«æ›´æ–°ã™ã‚‹"""
    long_df = data_get('long_df')
    if long_df is None or long_df.empty or not all_wages:
        raise PreventUpdate

    wages = {
        wage_id['index']: (wage_val or 0) for wage_id, wage_val in zip(all_wage_ids, all_wages)
    }

    df_cost = calculate_daily_cost(long_df, wages, by=by_key)
    if df_cost.empty:
        return html.P("ã‚³ã‚¹ãƒˆè¨ˆç®—çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    df_cost['date'] = pd.to_datetime(df_cost['date'])

    if not {'day_of_week', 'total_staff', 'role_breakdown'}.issubset(df_cost.columns):
        details = (
            long_df[long_df.get('parsed_slots_count', 1) > 0]
            .assign(date=lambda x: pd.to_datetime(x['ds']).dt.normalize())
            .groupby('date')
            .agg(
                day_of_week=('ds', lambda x: ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'][x.iloc[0].weekday()]),
                total_staff=('staff', 'nunique'),
                role_breakdown=('role', lambda s: ', '.join(f"{r}:{c}" for r, c in s.value_counts().items())),
            )
            .reset_index()
        )
        df_cost = pd.merge(df_cost, details, on='date', how='left')

    df_cost = df_cost.sort_values('date')

    content = []

    total_cost = df_cost['cost'].sum()
    avg_daily_cost = df_cost['cost'].mean()
    max_cost_day = df_cost.loc[df_cost['cost'].idxmax()]
    summary_cards = html.Div([
        create_metric_card("ç·ã‚³ã‚¹ãƒˆ", f"Â¥{total_cost:,.0f}"),
        create_metric_card("æ—¥å¹³å‡ã‚³ã‚¹ãƒˆ", f"Â¥{avg_daily_cost:,.0f}"),
        create_metric_card("æœ€é«˜ã‚³ã‚¹ãƒˆæ—¥", f"{max_cost_day['date'].strftime('%m/%d')}<br>Â¥{max_cost_day['cost']:,.0f}"),
    ], style={'display': 'flex', 'justifyContent': 'space-around', 'marginBottom': '20px'})
    content.append(summary_cards)

    df_cost['cumulative_cost'] = df_cost['cost'].cumsum()
    fig_cumulative = px.area(df_cost, x='date', y='cumulative_cost', title='ç´¯è¨ˆäººä»¶è²»ã®æ¨ç§»')
    fig_cumulative.update_xaxes(tickformat="%m/%d(%a)")
    content.append(dcc.Graph(figure=fig_cumulative))

    fig_daily = px.bar(df_cost, x='date', y='cost', title='æ—¥åˆ¥ç™ºç”Ÿäººä»¶è²»ï¼ˆç·é¡ï¼‰')
    fig_daily.update_xaxes(tickformat="%m/%d(%a)")
    content.append(dcc.Graph(figure=fig_daily))

    if 'role_breakdown' in df_cost.columns and by_key == 'role':
        role_data = []
        for _, row in df_cost.iterrows():
            if pd.notna(row.get('role_breakdown')):
                date_total_cost = row['cost']
                role_counts = {r.split(':')[0]: int(r.split(':')[1]) for r in row['role_breakdown'].split(', ') if ':' in r}
                total_count = sum(role_counts.values())

                for role, count in role_counts.items():
                    role_cost = (count / total_count) * date_total_cost if total_count > 0 else 0
                    role_data.append({'date': row['date'], 'role': role, 'count': count, 'cost': role_cost})

        if role_data:
            role_df = pd.DataFrame(role_data)

            fig_stacked = px.bar(role_df, x='date', y='cost', color='role', title='æ—¥åˆ¥äººä»¶è²»ï¼ˆè·ç¨®åˆ¥å†…è¨³ï¼‰')
            fig_stacked.update_xaxes(tickformat="%m/%d(%a)")
            content.append(dcc.Graph(figure=fig_stacked))

            role_df['month'] = pd.to_datetime(role_df['date']).dt.to_period('M').astype(str)
            monthly_role = role_df.groupby(['month', 'role'])['cost'].sum().reset_index()
            fig_monthly = px.bar(monthly_role, x='month', y='cost', color='role', title='æœˆæ¬¡äººä»¶è²»ï¼ˆè·ç¨®åˆ¥å†…è¨³ï¼‰')
            content.append(dcc.Graph(figure=fig_monthly))

            total_by_role = role_df.groupby('role')['cost'].sum().reset_index()
            fig_pie = px.pie(total_by_role, values='cost', names='role', title='è·ç¨®åˆ¥ã‚³ã‚¹ãƒˆæ§‹æˆæ¯”ï¼ˆå…¨æœŸé–“ï¼‰')
            fig_pie.update_traces(textposition='inside', textinfo='percent+label')
            content.append(dcc.Graph(figure=fig_pie))

    return html.Div(content)


@app.callback(
    Output('clear-synergy-cache-btn', 'children'),
    Input('clear-synergy-cache-btn', 'n_clicks'),
    prevent_initial_call=True
)
@safe_callback
def clear_synergy_cache_callback(n_clicks):
    """ã‚·ãƒŠã‚¸ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    if n_clicks:
        clear_synergy_cache()
        return "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢æ¸ˆã¿"
    return "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"


@app.callback(
    Output('individual-analysis-content', 'children'),
    Input('individual-staff-dropdown', 'value'),
    Input('synergy-analysis-type', 'value')
)
@safe_callback
def update_individual_analysis_content(selected_staff, synergy_type):
    """è·å“¡é¸æŠã«å¿œã˜ã¦åˆ†æã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›´æ–°ã™ã‚‹"""
    if not selected_staff:
        raise PreventUpdate
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦åˆæœŸåŒ–
    global synergy_matrix_data, synergy_additional_info
    synergy_matrix_data = None
    synergy_additional_info = html.Div()

    # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬ã§èª­ã¿è¾¼ã‚€
    long_df = data_get('long_df', pd.DataFrame())
    fatigue_df = data_get('fatigue_score', pd.DataFrame())
    fairness_df = data_get('fairness_after', pd.DataFrame())
    shortage_df = data_get('shortage_time', pd.DataFrame())
    excess_df = data_get('excess_time', pd.DataFrame())

    if long_df.empty:
        return html.P("å‹¤å‹™ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    staff_df = long_df[long_df['staff'] == selected_staff].copy()

    # --- 1. å‹¤å‹™åŒºåˆ†ã”ã¨ã®å æœ‰å‰²åˆ ---
    work_dist_fig = go.Figure(layout={'title': {'text': f'{selected_staff}ã•ã‚“ã®å‹¤å‹™å‰²åˆ'}})
    if not staff_df.empty and 'code' in staff_df.columns:
        work_records = staff_df[staff_df.get('parsed_slots_count', 1) > 0]
        if not work_records.empty:
            code_counts = work_records['code'].value_counts()
            work_dist_fig = px.pie(
                values=code_counts.values, names=code_counts.index,
                title=f'{selected_staff}ã•ã‚“ã®å‹¤å‹™å‰²åˆ', hole=.3
            )
            work_dist_fig.update_traces(textposition='inside', textinfo='percent+label')

    # --- 2. ä¸å…¬å¹³ãƒ»ç–²åŠ´åº¦ã®è©³ç´°ã‚¹ã‚³ã‚¢ ---
    fatigue_score, unfairness_score = "ãƒ‡ãƒ¼ã‚¿ãªã—", "ãƒ‡ãƒ¼ã‚¿ãªã—"
    score_details_df = pd.DataFrame()
    if not fatigue_df.empty:
        fatigue_df_indexed = fatigue_df.set_index('staff') if 'staff' in fatigue_df.columns else fatigue_df
        if selected_staff in fatigue_df_indexed.index:
            fatigue_score = f"{fatigue_df_indexed.loc[selected_staff, 'fatigue_score']:.1f}"
    if not fairness_df.empty and 'staff' in fairness_df.columns:
        staff_fairness = fairness_df[fairness_df['staff'] == selected_staff]
        if not staff_fairness.empty:
            row = staff_fairness.iloc[0]
            unfairness_score = f"{row.get('unfairness_score', 0):.2f}"
            details_data = {
                "æŒ‡æ¨™": ["å¤œå‹¤æ¯”ç‡ã®ä¹–é›¢", "ç·åŠ´åƒæ™‚é–“ã®ä¹–é›¢", "é€£ä¼‘å–å¾—é »åº¦ã®ä¹–é›¢"],
                "ã‚¹ã‚³ã‚¢": [f"{row.get(col, 0):.2f}" for col in ['dev_night_ratio', 'dev_work_slots', 'dev_consecutive']]
            }
            score_details_df = pd.DataFrame(details_data)

    # --- 3. å…±åƒã—ãŸè·å“¡ãƒ©ãƒ³ã‚­ãƒ³ã‚° ---
    coworker_ranking_df = pd.DataFrame()
    my_slots = staff_df[['ds']].drop_duplicates()
    coworkers = long_df[long_df['ds'].isin(my_slots['ds']) & (long_df['staff'] != selected_staff)]
    if not coworkers.empty:
        coworker_counts = coworkers['staff'].value_counts().reset_index()
        coworker_counts.columns = ['è·å“¡', 'å…±åƒå›æ•°']
        coworker_ranking_df = coworker_counts.head(5)

    # --- 4. äººå“¡ä¸è¶³/éå‰°ã¸ã®è²¢çŒ®åº¦åˆ†æ ---
    slot_hours = 0.5
    shortage_contribution_h, excess_contribution_h = 0, 0
    staff_work_slots = staff_df[staff_df.get('parsed_slots_count', 0) > 0][['ds']].copy()
    staff_work_slots['date_str'] = staff_work_slots['ds'].dt.strftime('%Y-%m-%d')
    staff_work_slots['time'] = staff_work_slots['ds'].dt.strftime('%H:%M')
    if not shortage_df.empty:
        shortage_long = shortage_df.melt(var_name='date_str', value_name='shortage_count', ignore_index=False).reset_index().rename(columns={'index':'time'})
        merged_shortage = pd.merge(staff_work_slots, shortage_long, on=['date_str', 'time'])
        shortage_contribution_h = merged_shortage[merged_shortage['shortage_count'] > 0].shape[0] * slot_hours
    if not excess_df.empty:
        excess_long = excess_df.melt(var_name='date_str', value_name='excess_count', ignore_index=False).reset_index().rename(columns={'index':'time'})
        merged_excess = pd.merge(staff_work_slots, excess_long, on=['date_str', 'time'])
        excess_contribution_h = merged_excess[merged_excess['excess_count'] > 0].shape[0] * slot_hours

    # --- 5. å€‹äººã®ä¼‘æš‡å–å¾—å‚¾å‘ ---
    leave_by_dow_fig = go.Figure(layout={'title': {'text': 'æ›œæ—¥åˆ¥ã®ä¼‘æš‡å–å¾—æ—¥æ•°'}})
    staff_leave_df = staff_df[staff_df.get('holiday_type', 'é€šå¸¸å‹¤å‹™') != 'é€šå¸¸å‹¤å‹™']
    if not staff_leave_df.empty:
        daily_leave = leave_analyzer.get_daily_leave_counts(staff_leave_df)
        if not daily_leave.empty:
            dow_summary = leave_analyzer.summarize_leave_by_day_count(daily_leave, period='dayofweek')
            if not dow_summary.empty:
                leave_by_dow_fig = px.bar(dow_summary, x='period_unit', y='total_leave_days', color='leave_type', title=f'{selected_staff}ã•ã‚“ã®æ›œæ—¥åˆ¥ä¼‘æš‡å–å¾—æ—¥æ•°')
                leave_by_dow_fig.update_xaxes(title_text="æ›œæ—¥").update_yaxes(title_text="æ—¥æ•°")

    # --- 6. è·å“¡é–“ã®ã€ŒåŒ–å­¦åå¿œã€åˆ†æ ---
    synergy_fig = go.Figure(layout={'title': {'text': f'{selected_staff}ã•ã‚“ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼åˆ†æ'}})
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
    log.info(f"[SYNERGY] åˆ†æé–‹å§‹: {selected_staff}")
    log.info(f"[SYNERGY] long_df shape: {long_df.shape}")
    log.info(f"[SYNERGY] shortage_df shape: {shortage_df.shape}")
    log.info(f"[SYNERGY] shortage_df columns: {shortage_df.columns.tolist() if not shortage_df.empty else 'Empty'}")
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    available_data = {}
    for key in ['shortage_time', 'shortage_role_summary', 'heat_ALL', 'long_df']:
        try:
            data = data_get(key, pd.DataFrame())
            available_data[key] = f"shape: {data.shape}, empty: {data.empty}"
            if not data.empty:
                available_data[key] += f", columns: {data.columns.tolist()[:5]}"  # æœ€åˆã®5åˆ—ã®ã¿è¡¨ç¤º
        except:
            available_data[key] = "å–å¾—å¤±æ•—"
    
    log.info(f"[SYNERGY] åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿: {available_data}")
    
    # shortage_timeãŒç©ºã®å ´åˆã€ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚’è©¦ã™
    if shortage_df.empty:
        log.info("[SYNERGY] shortage_timeãŒç©ºã®ãŸã‚ã€ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚’è©¦ã—ã¾ã™")
        
        # 1. analysis_resultsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ç›´æ¥èª­ã¿å–ã‚Šã‚’è©¦ã™
        try:
            import os
            current_dir = os.getcwd()
            analysis_results_path = os.path.join(current_dir, "analysis_results")
            shortage_time_path = os.path.join(analysis_results_path, "shortage_time.parquet")
            
            if os.path.exists(shortage_time_path):
                log.info(f"[SYNERGY] ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿å–ã‚Š: {shortage_time_path}")
                shortage_df = pd.read_parquet(shortage_time_path)
                log.info(f"[SYNERGY] ç›´æ¥èª­ã¿å–ã‚ŠæˆåŠŸ: {shortage_df.shape}")
            else:
                log.info(f"[SYNERGY] ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {shortage_time_path}")
        except Exception as e:
            log.error(f"[SYNERGY] ç›´æ¥èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}")
        
        # 2. ã¾ã ç©ºã®å ´åˆã€heat_ALLãƒ‡ãƒ¼ã‚¿ã‚’è©¦ã™
        if shortage_df.empty:
            heat_all_df = data_get('heat_ALL', pd.DataFrame())
            if not heat_all_df.empty:
                log.info(f"[SYNERGY] heat_ALLã‚’ä½¿ç”¨: {heat_all_df.shape}")
                # heat_ALLã‹ã‚‰ä¸è¶³ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                shortage_df = create_shortage_from_heat_all(heat_all_df)
                log.info(f"[SYNERGY] ç”Ÿæˆã•ã‚ŒãŸshortage_df: {shortage_df.shape}")
        
        # 3. ã¾ã ç©ºã®å ´åˆã€excess_timeã‚’è©¦ã™ï¼ˆç¬¦å·ã‚’åè»¢ï¼‰
        if shortage_df.empty:
            excess_df = data_get('excess_time', pd.DataFrame())
            if not excess_df.empty:
                log.info(f"[SYNERGY] excess_timeã‚’ä½¿ç”¨ï¼ˆç¬¦å·åè»¢): {excess_df.shape}")
                # excess_timeã®ç¬¦å·ã‚’åè»¢ã—ã¦shortageã¨ã—ã¦ä½¿ç”¨
                shortage_df = -excess_df
                shortage_df = shortage_df.clip(lower=0)  # è² ã®å€¤ã¯0ã«ã‚¯ãƒªãƒƒãƒ—
                log.info(f"[SYNERGY] excess_timeã‹ã‚‰ç”Ÿæˆ: {shortage_df.shape}")
    
    # ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚’å®Ÿè¡Œï¼ˆåˆ†æã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ï¼‰
    synergy_df = pd.DataFrame()
    synergy_additional_data = None
    # synergy_matrix_data ã¨ synergy_additional_info ã¯ä¸Šã§ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦åˆæœŸåŒ–æ¸ˆã¿
    
    log.info(f"[SYNERGY] åˆ†æã‚¿ã‚¤ãƒ—: {synergy_type}")
    
    if not long_df.empty:
        try:
            if synergy_type == 'correlation_matrix':
                try:
                    if create_synergy_correlation_matrix_optimized is not None:
                        log.info("[SYNERGY] ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹åˆ†æã‚’å®Ÿè¡Œ")
                        
                        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
                        cache_key = get_synergy_cache_key(long_df, shortage_df)
                        synergy_matrix_data = SYNERGY_CACHE.get(cache_key)
                        
                        if synergy_matrix_data is not None:
                            log.info(f"[SYNERGY] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹å–å¾—: {cache_key}")
                        else:
                            log.info("[SYNERGY] ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹æ–°è¦è¨ˆç®—é–‹å§‹")
                            n_staff = len(long_df['staff'].unique())
                            total_calculations = n_staff * (n_staff - 1) // 2
                            log.info(f"[SYNERGY] è¨ˆç®—äºˆå®šãƒšã‚¢æ•°: {total_calculations}")
                            
                            synergy_matrix_data = create_synergy_correlation_matrix_optimized(long_df, shortage_df)
                            if synergy_matrix_data is not None and 'error' not in synergy_matrix_data:
                                SYNERGY_CACHE.set(cache_key, synergy_matrix_data)
                                log.info(f"[SYNERGY] ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¨ˆç®—å®Œäº†ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜: {cache_key}")
                            else:
                                log.error(f"[SYNERGY] ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¨ˆç®—å¤±æ•—: {synergy_matrix_data.get('error', 'Unknown error') if synergy_matrix_data else 'None result'}")
                                if synergy_matrix_data is None:
                                    synergy_matrix_data = {"error": "ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¨ˆç®—ã§Noneçµæœ"}
                        
                        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç›£è¦–
                        memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB
                        log.info(f"[SYNERGY] ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹åˆ†æå®Œäº†, ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_usage:.1f}MB")
                    else:
                        log.error("[SYNERGY] ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹é–¢æ•°ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                        synergy_matrix_data = {"error": "ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹é–¢æ•°ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
                except Exception as correlation_error:
                    log.error(f"[SYNERGY] ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {correlation_error}")
                    synergy_matrix_data = {"error": f"ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(correlation_error)}"}
            elif synergy_type == 'same_role' and analyze_synergy_by_role is not None:
                log.info("[SYNERGY] åŒè·ç¨®é™å®šã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚’å®Ÿè¡Œ")
                synergy_df = analyze_synergy_by_role(long_df, shortage_df, selected_staff, same_role_only=True)
                log.info(f"[SYNERGY] åŒè·ç¨®åˆ†æçµæœ: {synergy_df.shape}")
            elif synergy_type == 'all_roles' and analyze_all_roles_synergy is not None:
                log.info("[SYNERGY] å…¨è·ç¨®è©³ç´°ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚’å®Ÿè¡Œ")
                synergy_additional_data = analyze_all_roles_synergy(long_df, shortage_df, selected_staff)
                if 'error' not in synergy_additional_data and 'raw_data' in synergy_additional_data:
                    synergy_df = pd.DataFrame(synergy_additional_data['raw_data'])
                log.info(f"[SYNERGY] å…¨è·ç¨®åˆ†æçµæœ: {synergy_df.shape}")
            else:
                # åŸºæœ¬åˆ†æ
                if not shortage_df.empty:
                    log.info("[SYNERGY] åŸºæœ¬ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚’å®Ÿè¡Œ")
                    synergy_df = analyze_synergy(long_df, shortage_df, selected_staff)
                    log.info(f"[SYNERGY] åŸºæœ¬åˆ†æçµæœ: {synergy_df.shape}")
                else:
                    log.info("[SYNERGY] ã‚·ãƒ³ãƒ—ãƒ«ãªã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚’å®Ÿè¡Œ")
                    synergy_df = simple_synergy_analysis(long_df, selected_staff)
                    log.info(f"[SYNERGY] ã‚·ãƒ³ãƒ—ãƒ«åˆ†æçµæœ: {synergy_df.shape}")
        except Exception as e:
            log.error(f"[SYNERGY] åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            gc.collect()
            # ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
            if synergy_type == 'correlation_matrix':
                if synergy_matrix_data is None:  # ã¾ã è¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿
                    synergy_matrix_data = {"error": f"ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {str(e)}"}
            else:
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯åŸºæœ¬åˆ†æã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if not shortage_df.empty:
                    try:
                        synergy_df = analyze_synergy(long_df, shortage_df, selected_staff)
                    except Exception as fallback_error:
                        log.error(f"[SYNERGY] ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æã‚¨ãƒ©ãƒ¼: {fallback_error}")
                        synergy_df = simple_synergy_analysis(long_df, selected_staff)
                else:
                    synergy_df = simple_synergy_analysis(long_df, selected_staff)
    else:
        # long_dfãŒç©ºã®å ´åˆ
        log.warning("[SYNERGY] long_dfãŒç©ºã®ãŸã‚ã€ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—")
        if synergy_type == 'correlation_matrix':
            if synergy_matrix_data is None:  # ã¾ã è¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿
                synergy_matrix_data = {"error": "å‹¤å‹™ãƒ‡ãƒ¼ã‚¿ (long_df) ãŒç©ºã®ãŸã‚ã€ã‚·ãƒŠã‚¸ãƒ¼åˆ†æãŒã§ãã¾ã›ã‚“"}
        else:
            synergy_df = pd.DataFrame()
    
    # çµæœã‚’è¡¨ç¤º
    if synergy_type == 'correlation_matrix':
        if synergy_matrix_data is not None and 'error' not in synergy_matrix_data:
            # ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã®è¡¨ç¤º
            log.info("[SYNERGY] ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¡¨ç¤º")
            
            # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
            matrix_df = pd.DataFrame(synergy_matrix_data['matrix'])
            
            # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆ
            synergy_fig = go.Figure(data=go.Heatmap(
                z=matrix_df.values,
                x=matrix_df.columns,
                y=matrix_df.index,
                colorscale='RdBu',
                zmid=0,
                text=np.round(matrix_df.values, 2),
                texttemplate='%{text}',
                textfont={"size": 10},
                hoverongaps=False,
                hovertemplate='%{x} & %{y}<br>ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢: %{z:.3f}<extra></extra>'
            ))
            
            # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼šä¸è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æ—©æœŸè§£æ”¾
            del matrix_df
            gc.collect()
            
            synergy_fig.update_layout(
                title="å…¨è·å“¡é–“ã®ã‚·ãƒŠã‚¸ãƒ¼ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹",
                xaxis_title="è·å“¡",
                yaxis_title="è·å“¡",
                width=1200,
                height=1000,
                xaxis={'side': 'bottom', 'tickangle': -45},
                yaxis={'autorange': 'reversed'},
                margin=dict(l=150, r=50, t=100, b=150)
            )
            
            # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
            ranking_df = pd.DataFrame(synergy_matrix_data['ranking'])
            if not ranking_df.empty:
                # ä¸Šä½5åã¨ä¸‹ä½5åã‚’æŠ½å‡º
                top5 = ranking_df.head(5)
                bottom5 = ranking_df.tail(5)
                
                # è¿½åŠ æƒ…å ±ã®è¡¨ç¤º
                synergy_additional_info = html.Div([
                    html.H5("ã‚·ãƒŠã‚¸ãƒ¼å¹³å‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°"),
                    html.Div([
                        html.Div([
                            html.H6("ç›¸æ€§ã®è‰¯ã„è·å“¡ TOP 5", style={'color': 'green'}),
                            dash_table.DataTable(
                                data=top5.to_dict('records'),
                                columns=[
                                    {'name': 'è·å“¡', 'id': 'è·å“¡'},
                                    {'name': 'å¹³å‡ã‚·ãƒŠã‚¸ãƒ¼', 'id': 'å¹³å‡ã‚·ãƒŠã‚¸ãƒ¼', 'type': 'numeric', 'format': {'specifier': '.3f'}},
                                    {'name': 'è·ç¨®', 'id': 'role'} if 'role' in top5.columns else {},
                                ],
                                style_cell={'textAlign': 'left'},
                                style_data_conditional=[
                                    {
                                        'if': {'column_id': 'å¹³å‡ã‚·ãƒŠã‚¸ãƒ¼'},
                                        'color': 'green',
                                        'fontWeight': 'bold'
                                    }
                                ]
                            )
                        ], style={'width': '48%', 'display': 'inline-block', 'marginRight': '2%'}),
                        html.Div([
                            html.H6("ç›¸æ€§ã®æ‚ªã„è·å“¡ BOTTOM 5", style={'color': 'red'}),
                            dash_table.DataTable(
                                data=bottom5.to_dict('records'),
                                columns=[
                                    {'name': 'è·å“¡', 'id': 'è·å“¡'},
                                    {'name': 'å¹³å‡ã‚·ãƒŠã‚¸ãƒ¼', 'id': 'å¹³å‡ã‚·ãƒŠã‚¸ãƒ¼', 'type': 'numeric', 'format': {'specifier': '.3f'}},
                                    {'name': 'è·ç¨®', 'id': 'role'} if 'role' in bottom5.columns else {},
                                ],
                                style_cell={'textAlign': 'left'},
                                style_data_conditional=[
                                    {
                                        'if': {'column_id': 'å¹³å‡ã‚·ãƒŠã‚¸ãƒ¼'},
                                        'color': 'red',
                                        'fontWeight': 'bold'
                                    }
                                ]
                            )
                        ], style={'width': '48%', 'display': 'inline-block'})
                    ], style={'marginTop': '20px'})
                ])
            else:
                synergy_additional_info = html.Div()
            
            # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼šå‡¦ç†å®Œäº†å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢
            if 'synergy_matrix_data' in locals() and synergy_matrix_data is not None:
                del synergy_matrix_data
            gc.collect()
        
        else:
            # ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
            log.error(f"[SYNERGY] ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚¨ãƒ©ãƒ¼: {synergy_matrix_data.get('error', 'Unknown error') if synergy_matrix_data else 'ãƒ‡ãƒ¼ã‚¿ãªã—'}")
            synergy_fig = go.Figure()
            synergy_fig.add_annotation(
                text=f"ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹åˆ†æã‚¨ãƒ©ãƒ¼: {synergy_matrix_data.get('error', 'Unknown error') if synergy_matrix_data else 'ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ'}",
                x=0.5, y=0.5, xref="paper", yref="paper",
                showarrow=False, font=dict(size=16, color="red")
            )
            synergy_fig.update_layout(
                title="ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹åˆ†æã‚¨ãƒ©ãƒ¼",
                width=800, height=400
            )
            synergy_additional_info = html.Div()
            
    elif not synergy_df.empty:
        log.info(f"[SYNERGY] æœ€çµ‚çµæœ: {synergy_df.shape}")
        log.info(f"[SYNERGY] ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿: {synergy_df.head()}")
        
        # åˆ†æã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè¡¨ç¤º
        if synergy_type == 'all_roles' and synergy_additional_data is not None:
            # å…¨è·ç¨®è©³ç´°åˆ†æã®å ´åˆ
            if 'role' in synergy_df.columns:
                # è·ç¨®åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦è¡¨ç¤º
                synergy_fig = px.bar(
                    synergy_df.head(15), x="ç›¸æ‰‹ã®è·å“¡", y="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢", 
                    color="role", title=f"{selected_staff}ã•ã‚“ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ï¼ˆå…¨è·ç¨®è©³ç´°ï¼‰"
                )
                synergy_fig.update_layout(xaxis_title="ç›¸æ‰‹ã®è·å“¡", yaxis_title="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰")
            else:
                synergy_fig = px.bar(
                    synergy_df.head(10), x="ç›¸æ‰‹ã®è·å“¡", y="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢", color="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢",
                    color_continuous_scale='RdYlGn', title=f"{selected_staff}ã•ã‚“ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ï¼ˆå…¨è·ç¨®è©³ç´°ï¼‰"
                )
        elif synergy_type == 'same_role':
            # åŒè·ç¨®é™å®šåˆ†æã®å ´åˆ
            color_col = "role" if "role" in synergy_df.columns else "ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢"
            synergy_fig = px.bar(
                synergy_df.head(10), x="ç›¸æ‰‹ã®è·å“¡", y="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢", color=color_col,
                title=f"{selected_staff}ã•ã‚“ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ï¼ˆåŒè·ç¨®é™å®šï¼‰"
            )
            synergy_fig.update_layout(xaxis_title="ç›¸æ‰‹ã®è·å“¡", yaxis_title="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰")
        else:
            # åŸºæœ¬åˆ†æã®å ´åˆ
            synergy_df_top5 = synergy_df.head(5)
            if len(synergy_df) > 5:
                synergy_df_worst5 = synergy_df.tail(5).sort_values("ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢", ascending=True)
                synergy_display_df = pd.concat([synergy_df_top5, synergy_df_worst5])
            else:
                synergy_display_df = synergy_df_top5
            
            synergy_fig = px.bar(
                synergy_display_df, x="ç›¸æ‰‹ã®è·å“¡", y="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢", color="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢",
                color_continuous_scale='RdYlGn', title=f"{selected_staff}ã•ã‚“ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ï¼ˆåŸºæœ¬åˆ†æï¼‰"
            )
            synergy_fig.update_layout(xaxis_title="ç›¸æ‰‹ã®è·å“¡", yaxis_title="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰")
    else:
        log.warning("[SYNERGY] å…¨ã¦ã®åˆ†æãŒå¤±æ•—ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
        synergy_fig.add_annotation(
            text="ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã®ãƒ‡ãƒ¼ã‚¿ãŒä¸ååˆ†ã§ã™",
            x=0.5, y=0.5, xref="paper", yref="paper",
            showarrow=False, font=dict(size=16)
        )
    
    # ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã®è¿½åŠ æƒ…å ±ã‚’åˆæœŸåŒ–ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
    # æ—¢ã«ä¸Šéƒ¨ã§åˆæœŸåŒ–æ¸ˆã¿ã®ãŸã‚ã€ã“ã“ã§ã¯ä¸è¦

    # --- 7 & 8. åƒãæ–¹ã®ã‚¯ã‚»åˆ†æ ---
    mannelido_score, rhythm_score = "è¨ˆç®—ä¸å¯", "è¨ˆç®—ä¸å¯"
    work_records_for_role = staff_df[staff_df.get('parsed_slots_count', 0) > 0]
    if not work_records_for_role.empty:
        role_per_day = work_records_for_role[['ds', 'role']].copy()
        role_per_day['date'] = role_per_day['ds'].dt.date
        role_counts = role_per_day.drop_duplicates(subset=['date', 'role'])['role'].value_counts(normalize=True)
        if not role_counts.empty:
            mannelido_score = f"{role_counts.max():.2f}"

        daily_starts = work_records_for_role.groupby(work_records_for_role['ds'].dt.date)['ds'].min()
        if len(daily_starts) > 1:
            start_hours = daily_starts.dt.hour + daily_starts.dt.minute / 60.0
            rhythm_score = f"{start_hours.std():.2f}"
        else:
            rhythm_score = "0.00"

    # --- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®çµ„ã¿ç«‹ã¦ ---
    layout = html.Div([
        html.Div([
            html.Div([
                html.H4("ç–²åŠ´åº¦ãƒ»ä¸å…¬å¹³æ„Ÿãƒ»åƒãæ–¹ã®ã‚¯ã‚»"),
                create_metric_card("ç–²åŠ´ã‚¹ã‚³ã‚¢", fatigue_score, color="#ff7f0e"),
                create_metric_card("ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢", unfairness_score, color="#d62728"),
                create_metric_card("æ¥­å‹™ãƒãƒ³ãƒãƒªåº¦", mannelido_score, color="#9467bd"),
                create_metric_card("ç”Ÿæ´»ãƒªã‚ºãƒ ç ´å£Šåº¦", rhythm_score, color="#8c564b"),
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top', 'paddingRight': '1%'}),
            html.Div([
                html.H5("ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢ã®å†…è¨³"),
                dash_table.DataTable(
                    data=score_details_df.to_dict('records'),
                    columns=[{'name': i, 'id': i} for i in score_details_df.columns],
                ) if not score_details_df.empty else html.P("è©³ç´°ãƒ‡ãƒ¼ã‚¿ãªã—")
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top', 'paddingRight': '1%'}),
            html.Div([
                html.H5("å…±åƒãƒ©ãƒ³ã‚­ãƒ³ã‚° Top 5"),
                dash_table.DataTable(
                    data=coworker_ranking_df.to_dict('records'),
                    columns=[{'name': i, 'id': i} for i in coworker_ranking_df.columns],
                ) if not coworker_ranking_df.empty else html.P("å…±åƒãƒ‡ãƒ¼ã‚¿ãªã—"),
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top', 'paddingRight': '1%'}),
            html.Div([
                html.H5("ä¸è¶³/éå‰°ã¸ã®è²¢çŒ®åº¦"),
                create_metric_card("ä¸è¶³æ™‚é–“å¸¯ã§ã®å‹¤å‹™ (h)", f"{shortage_contribution_h:.1f}", color="#c53d40"),
                create_metric_card("éå‰°æ™‚é–“å¸¯ã§ã®å‹¤å‹™ (h)", f"{excess_contribution_h:.1f}", color="#1f77b4"),
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top'}),
        ], style={'marginBottom': '20px'}),
        html.Div([
            html.Div([dcc.Graph(figure=work_dist_fig)], style={'width': '49%', 'display': 'inline-block'}),
            html.Div([dcc.Graph(figure=leave_by_dow_fig)], style={'width': '49%', 'display': 'inline-block'}),
        ]),
        html.Div([
            html.H4("è·å“¡é–“ã®\u300cåŒ–å­¦åå¿œ\u300dåˆ†æ", style={'marginTop': '20px'}),
            html.P("ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ã¯ã€ãã®ãƒšã‚¢ãŒä¸€ç·’ã«å‹¤å‹™ã—ãŸéš›ã®\u300cäººå“¡ä¸è¶³ã®èµ·ã“ã‚Šã«ãã•\u300dã‚’ç¤ºã—ã¾ã™ã€‚ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©ã€ä¸è¶³ãŒå°‘ãªããªã‚‹è‰¯ã„çµ„ã¿åˆã‚ã›ã§ã™ã€‚"),
            
            # åˆ†æã‚¿ã‚¤ãƒ—åˆ¥ã®è¿½åŠ æƒ…å ±
            html.Div([
                html.H5("åˆ†ææƒ…å ±"),
                html.Div([
                    html.P(f"åˆ†æã‚¿ã‚¤ãƒ—: {['åŸºæœ¬åˆ†æï¼ˆå…¨è·å“¡å¯¾è±¡ï¼‰' if synergy_type == 'basic' else 'åŒè·ç¨®é™å®šåˆ†æ' if synergy_type == 'same_role' else 'å…¨è·ç¨®è©³ç´°åˆ†æ' if synergy_type == 'all_roles' else 'ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆå…¨ä½“ï¼‰'][0]}", style={'fontWeight': 'bold'})
                ] + ([
                    html.P(f"å…¨ä½“å¹³å‡ã‚·ãƒŠã‚¸ãƒ¼: {synergy_additional_data['overall_stats']['å…¨ä½“å¹³å‡ã‚·ãƒŠã‚¸ãƒ¼']:.3f}"),
                    html.P(f"åˆ†æå¯¾è±¡è·å“¡æ•°: {synergy_additional_data['overall_stats']['åˆ†æå¯¾è±¡è·å“¡æ•°']}äºº"),
                    html.P(f"å¯¾è±¡è·ç¨®æ•°: {synergy_additional_data['overall_stats']['å¯¾è±¡è·ç¨®æ•°']}è·ç¨®"),
                ] if synergy_type == 'all_roles' and synergy_additional_data is not None and 'overall_stats' in synergy_additional_data else []) + ([
                    html.P(f"åˆ†æå¯¾è±¡è·å“¡æ•°: {synergy_matrix_data['summary']['è·å“¡æ•°']}äºº"),
                    html.P(f"å…¨ä½“å¹³å‡ã‚·ãƒŠã‚¸ãƒ¼: {synergy_matrix_data['summary']['å…¨ä½“å¹³å‡ã‚·ãƒŠã‚¸ãƒ¼']:.3f}"),
                ] if synergy_type == 'correlation_matrix' and 'synergy_matrix_data' in locals() and synergy_matrix_data is not None and 'summary' in synergy_matrix_data else []))
            ], style={'marginBottom': '10px', 'padding': '10px', 'backgroundColor': '#f8f9fa', 'borderRadius': '5px'}) if synergy_type != 'basic' else html.Div(),
            
            dcc.Graph(figure=synergy_fig),
            
            # ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã®å ´åˆã€è¿½åŠ æƒ…å ±ã‚’è¡¨ç¤º
            synergy_additional_info if synergy_type == 'correlation_matrix' and 'synergy_additional_info' in locals() and synergy_additional_info is not None else html.Div()
        ])
    ])

    return layout


@app.callback(
    Output('team-criteria-value-dropdown', 'options'),
    Input('team-criteria-key-dropdown', 'value')
)
@safe_callback
def update_team_value_options(selected_key):
    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty or not selected_key:
        return []
    options = sorted(long_df[selected_key].unique())
    return [{'label': opt, 'value': opt} for opt in options]


@app.callback(
    Output('team-analysis-content', 'children'),
    Input('team-criteria-value-dropdown', 'value'),
    State('team-criteria-key-dropdown', 'value')
)
@safe_callback
def update_team_analysis_graphs(selected_value, selected_key):
    if not selected_value or not selected_key:
        raise PreventUpdate

    long_df = data_get('long_df', pd.DataFrame())
    fatigue_df = data_get('fatigue_score', pd.DataFrame())
    fairness_df = data_get('fairness_after', pd.DataFrame())

    team_criteria = {selected_key: selected_value}
    team_df = analyze_team_dynamics(long_df, fatigue_df, fairness_df, team_criteria)

    if team_df.empty:
        return html.P("ã“ã®æ¡ä»¶ã«åˆè‡´ã™ã‚‹ãƒãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    fig_fatigue = px.line(
        team_df,
        y=['avg_fatigue', 'std_fatigue'],
        title=f"ãƒãƒ¼ãƒ ã€Œ{selected_value}ã€ã®ç–²åŠ´åº¦ã‚¹ã‚³ã‚¢æ¨ç§»"
    )
    fig_fairness = px.line(
        team_df,
        y=['avg_unfairness', 'std_unfairness'],
        title=f"ãƒãƒ¼ãƒ ã€Œ{selected_value}ã€ã®ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢æ¨ç§»"
    )

    return html.Div([
        html.H4(f"ãƒãƒ¼ãƒ ã€Œ{selected_value}ã€ã®åˆ†æçµæœ"),
        
        # ã‚°ãƒ©ãƒ•ã®èª­ã¿è§£ãæ–¹èª¬æ˜ã‚’è¿½åŠ 
        html.Div([
            html.H5("ğŸ“Š ã‚°ãƒ©ãƒ•ã®èª­ã¿è§£ãæ–¹"),
            html.Div([
                html.P("ğŸ” ç–²åŠ´åº¦ã‚¹ã‚³ã‚¢æ¨ç§»ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹:", style={'fontWeight': 'bold', 'marginTop': '15px'}),
                html.Ul([
                    html.Li("å¹³å‡ç–²åŠ´åº¦ï¼ˆavg_fatigueï¼‰: ãƒãƒ¼ãƒ å…¨ä½“ã®ç–²åŠ´ãƒ¬ãƒ™ãƒ«ã€‚æ•°å€¤ãŒé«˜ã„ã»ã©ç–²åŠ´ãŒè“„ç©ã—ã¦ã„ã‚‹"),
                    html.Li("ç–²åŠ´åº¦ã®ã°ã‚‰ã¤ãï¼ˆstd_fatigueï¼‰: ãƒãƒ¼ãƒ å†…ã®ç–²åŠ´æ ¼å·®ã€‚æ•°å€¤ãŒé«˜ã„ã»ã©å€‹äººå·®ãŒå¤§ãã„"),
                    html.Li("âš ï¸ ä¸¡æ–¹ãŒé«˜ã„å ´åˆ: ãƒãƒ¼ãƒ å…¨ä½“ãŒç–²å¼Šã—ã€ã‹ã¤å€‹äººå·®ã‚‚å¤§ããä¸å®‰å®šãªçŠ¶æ…‹"),
                    html.Li("âœ… ç†æƒ³çš„ãªçŠ¶æ…‹: å¹³å‡ç–²åŠ´åº¦ãŒä½ãã€ã°ã‚‰ã¤ãã‚‚å°ã•ã„çŠ¶æ…‹")
                ]),
                
                html.P("ğŸ” ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢æ¨ç§»ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹:", style={'fontWeight': 'bold', 'marginTop': '15px'}),
                html.Ul([
                    html.Li("å¹³å‡ä¸å…¬å¹³æ„Ÿï¼ˆavg_unfairnessï¼‰: ãƒãƒ¼ãƒ å…¨ä½“ã®ä¸å…¬å¹³æ„Ÿã€‚æ•°å€¤ãŒé«˜ã„ã»ã©ä¸æº€ãŒè“„ç©ã—ã¦ã„ã‚‹"),
                    html.Li("ä¸å…¬å¹³æ„Ÿã®ã°ã‚‰ã¤ãï¼ˆstd_unfairnessï¼‰: ãƒãƒ¼ãƒ å†…ã®ä¸å…¬å¹³æ„Ÿæ ¼å·®ã€‚æ•°å€¤ãŒé«˜ã„ã»ã©å€‹äººå·®ãŒå¤§ãã„"),
                    html.Li("âš ï¸ å¹³å‡ãŒé«˜ã„å ´åˆ: æ¥­å‹™é…åˆ†ã‚„å¾…é‡ã«å…¨ä½“çš„ãªä¸å…¬å¹³æ„ŸãŒã‚ã‚‹å¯èƒ½æ€§"),
                    html.Li("âš ï¸ ã°ã‚‰ã¤ããŒå¤§ãã„å ´åˆ: ä¸€éƒ¨ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒç‰¹ã«ä¸å…¬å¹³æ„Ÿã‚’æ„Ÿã˜ã¦ã„ã‚‹å¯èƒ½æ€§"),
                    html.Li("âœ… ç†æƒ³çš„ãªçŠ¶æ…‹: å¹³å‡ä¸å…¬å¹³æ„ŸãŒä½ãã€ã°ã‚‰ã¤ãã‚‚å°ã•ã„çŠ¶æ…‹")
                ])
            ], style={
                'backgroundColor': '#f8f9fa',
                'padding': '15px',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #dee2e6'
            })
        ]),
        
        dcc.Graph(figure=fig_fatigue),
        dcc.Graph(figure=fig_fairness),
        
        # æ”¹å–„ææ¡ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
        html.Div([
            html.H5("ğŸ’¡ æ”¹å–„ææ¡ˆ"),
            html.P("åˆ†æçµæœã«åŸºã¥ãå…·ä½“çš„ãªæ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:"),
            html.Ul([
                html.Li("ç–²åŠ´åº¦ãŒé«˜ã„å ´åˆ: å‹¤å‹™é–“éš”ã®èª¿æ•´ã€ä¼‘æš‡å–å¾—ã®ä¿ƒé€²ã€æ¥­å‹™é‡ã®è¦‹ç›´ã—"),
                html.Li("ç–²åŠ´åº¦ã®ã°ã‚‰ã¤ããŒå¤§ãã„å ´åˆ: æ¥­å‹™åˆ†æ‹…ã®å‡ç­‰åŒ–ã€ç‰¹å®šãƒ¡ãƒ³ãƒãƒ¼ã®è² è·è»½æ¸›"),
                html.Li("ä¸å…¬å¹³æ„ŸãŒé«˜ã„å ´åˆ: å‹¤å‹™æ¡ä»¶ã®é€æ˜åŒ–ã€å¸Œæœ›ä¼‘æ‰¿èªã®å…¬å¹³åŒ–"),
                html.Li("ä¸å…¬å¹³æ„Ÿã®ã°ã‚‰ã¤ããŒå¤§ãã„å ´åˆ: å€‹åˆ¥é¢è«‡ã®å®Ÿæ–½ã€ä¸æº€ã®èãå–ã‚Šèª¿æŸ»")
            ])
        ], style={
            'backgroundColor': '#e7f3ff',
            'padding': '15px',
            'borderRadius': '8px',
            'marginTop': '20px',
            'border': '1px solid #b3d9ff'
        })
    ])


@app.callback(
    Output('blueprint-results-store', 'data'),
    Output('tradeoff-scatter-plot', 'figure'),
    Output('rules-data-table', 'data'),
    Output('staff-selector-dropdown', 'options'),
    Output('facts-data-table', 'data', allow_duplicate=True),
    Output('facts-summary', 'children'),
    Output('integrated-analysis-content', 'children'),
    Input('generate-blueprint-button', 'n_clicks'),
    State('blueprint-analysis-type', 'value'),
    prevent_initial_call=True
)
@safe_callback
def update_blueprint_analysis_content(n_clicks, analysis_type):
    if not n_clicks:
        raise PreventUpdate

    try:
        long_df = data_get('long_df', pd.DataFrame())
        if long_df.empty:
            empty_fig = go.Figure()
            empty_fig.update_layout(
                title="ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                annotations=[
                    dict(
                        text="ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã‹ã‚‰åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚<br><br>" +
                             "ğŸ“‹ æ‰‹é †:<br>" +
                             "1. Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰<br>" +
                             "2. ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®å®Œäº†ã‚’ç¢ºèª<br>" +
                             "3. å†åº¦åˆ†æãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯",
                        xref="paper", yref="paper",
                        x=0.5, y=0.5, xanchor='center', yanchor='middle',
                        showarrow=False,
                        font=dict(size=14, color="#666"),
                        bgcolor="rgba(240, 240, 240, 0.8)",
                        bordercolor="#ccc",
                        borderwidth=1
                    )
                ]
            )
            helpful_message = html.Div([
                html.H4("ğŸ” ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆåˆ†æã«ã¤ã„ã¦", style={'color': '#1976d2'}),
                html.P("ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆåˆ†æã¯ã€ã‚·ãƒ•ãƒˆä½œæˆè€…ã®æš—é»™çŸ¥ã‚„åˆ¤æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç™ºè¦‹ã™ã‚‹é«˜åº¦ãªåˆ†ææ©Ÿèƒ½ã§ã™ã€‚"),
                html.H5("ğŸ’¡ åˆ†æã§ç™ºè¦‹ã§ãã‚‹ã“ã¨:"),
                html.Ul([
                    html.Li("ã‚¹ã‚¿ãƒƒãƒ•å€‹åˆ¥ã®å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„åˆ¶ç´„"),
                    html.Li("ã‚·ãƒ•ãƒˆä½œæˆè€…ã®æš—é»™çš„ãªãƒ«ãƒ¼ãƒ«"),
                    html.Li("è·ç¨®ãƒ»ãƒãƒ¼ãƒ é–“ã®ç›¸äº’é–¢ä¿‚"),
                    html.Li("åŠ¹ç‡çš„ãªã‚·ãƒ•ãƒˆçµ„ã¿åˆã‚ã›"),
                ]),
                html.P("åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ã¾ãšã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚", 
                       style={'fontWeight': 'bold', 'color': '#d32f2f'})
            ], style={
                'padding': '20px', 'backgroundColor': '#f8f9fa', 'borderRadius': '8px',
                'border': '1px solid #dee2e6', 'marginTop': '20px'
            })
            return {}, empty_fig, [], [], [], helpful_message, helpful_message

        blueprint_data = create_blueprint_list(long_df)

        scatter_df = pd.DataFrame(blueprint_data.get('tradeoffs', {}).get('scatter_data', []))
        fig_scatter = px.scatter(scatter_df, x='fairness_score', y='cost_score', hover_data=['date']) if not scatter_df.empty else go.Figure()

        rules_df = blueprint_data.get('rules_df', pd.DataFrame())
        rules_table_data = []

        if not rules_df.empty:
            if 'è©³ç´°ãƒ‡ãƒ¼ã‚¿' in rules_df.columns:
                def safe_json_serialize(x):
                    if isinstance(x, dict):
                        try:
                            # NumPyå‹ã‚’æ¨™æº–Pythonå‹ã«å¤‰æ›
                            clean_dict = {}
                            for k, v in x.items():
                                if hasattr(v, 'item'):  # NumPy scalar
                                    clean_dict[k] = v.item()
                                elif isinstance(v, (list, tuple)):
                                    clean_dict[k] = [item.item() if hasattr(item, 'item') else item for item in v]
                                else:
                                    clean_dict[k] = v
                            return json.dumps(clean_dict, ensure_ascii=False, indent=2)
                        except (TypeError, ValueError):
                            return str(x)
                    else:
                        return str(x)
                
                rules_df['è©³ç´°ãƒ‡ãƒ¼ã‚¿'] = rules_df['è©³ç´°ãƒ‡ãƒ¼ã‚¿'].apply(safe_json_serialize)
            rules_table_data = rules_df.to_dict('records')

        staff_scores_df = blueprint_data.get('staff_level_scores', pd.DataFrame())
        dropdown_options = [{'label': s, 'value': s} for s in staff_scores_df.index] if not staff_scores_df.empty else []

        facts_df = blueprint_data.get('facts_df', pd.DataFrame())
        facts_table_data = []
        facts_summary = "äº‹å®Ÿãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
        
        # ğŸ” æ‹¡å¼µãƒ«ãƒ¼ãƒ«åˆ†æã®çµæœè¡¨ç¤º
        rule_stats = blueprint_data.get('rule_statistics', {})
        total_rules = rule_stats.get('total_rules', 0)
        high_conf_rules = rule_stats.get('high_confidence_rules', 0)
        
        enhanced_summary = html.Div([
            html.Div([
                html.H4("ğŸ¯ ã‚·ãƒ•ãƒˆä½œæˆè€…ã®æš—é»™çŸ¥åˆ†æçµæœ", style={'margin': '0 0 15px 0', 'color': '#1976d2'}),
                html.Div([
                    html.Div([
                        html.H3(str(total_rules), style={'margin': '0', 'color': '#2e7d32', 'fontSize': '2rem'}),
                        html.P("ç™ºè¦‹ã•ã‚ŒãŸãƒ«ãƒ¼ãƒ«", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                    ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#e8f5e8', 
                             'borderRadius': '8px', 'border': '2px solid #2e7d32', 'flex': '1'}),
                    html.Div([
                        html.H3(str(high_conf_rules), style={'margin': '0', 'color': '#ff9800', 'fontSize': '2rem'}),
                        html.P("é«˜ä¿¡é ¼åº¦ãƒ«ãƒ¼ãƒ«", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                    ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#fff3e0', 
                             'borderRadius': '8px', 'border': '2px solid #ff9800', 'flex': '1'}),
                    html.Div([
                        html.H3(f"{(high_conf_rules/total_rules*100):.1f}%" if total_rules > 0 else "0%", 
                               style={'margin': '0', 'color': '#1976d2', 'fontSize': '2rem'}),
                        html.P("ä¿¡é ¼åº¦ç‡", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                    ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#e3f2fd', 
                             'borderRadius': '8px', 'border': '2px solid #1976d2', 'flex': '1'}),
                ], style={'display': 'flex', 'gap': '15px'}),
            ], style={'padding': '20px', 'backgroundColor': 'white', 'borderRadius': '12px', 
                     'boxShadow': '0 4px 8px rgba(0,0,0,0.1)', 'marginBottom': '20px'}),
        ]) if blueprint_data.get('enhanced_rules') else html.Div([
            html.Div([
                html.H4("âš ï¸ æ‹¡å¼µåˆ†æãƒ‡ãƒ¼ã‚¿", style={'color': '#ff9800'}),
                html.P("æ‹¡å¼µåˆ†æãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿é‡ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚", 
                       style={'color': '#666', 'marginBottom': '10px'}),
                html.P("ğŸ’¡ æ”¹å–„æ–¹æ³•:", style={'fontWeight': 'bold', 'marginBottom': '5px'}),
                html.Ul([
                    html.Li("ã‚ˆã‚Šå¤šãã®ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹"),
                    html.Li("ç•°ãªã‚‹æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹"),
                    html.Li("ã‚¹ã‚¿ãƒƒãƒ•æ•°ã‚’å¢—ã‚„ã™"),
                ])
            ], style={'padding': '15px', 'backgroundColor': '#fff3e0', 'borderRadius': '8px',
                     'border': '1px solid #ff9800'})
        ])
        
        # ğŸ” æ‹¡å¼µãƒ«ãƒ¼ãƒ«ã®è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        enhanced_table_data = []
        if blueprint_data.get('enhanced_rules'):
            for rule in blueprint_data.get('enhanced_rules', []):
                enhanced_table_data.append({
                    'ã‚¹ã‚¿ãƒƒãƒ•': rule.staff_name,
                    'ãƒ«ãƒ¼ãƒ«ã‚¿ã‚¤ãƒ—': rule.rule_type,
                    'ãƒ«ãƒ¼ãƒ«å†…å®¹': rule.rule_description,
                    'ä¿¡é ¼åº¦': f"{rule.confidence_score:.2f}",
                    'ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ': rule.segment,
                    'çµ±è¨ˆçš„è¨¼æ‹ ': str(rule.statistical_evidence.get('sample_size', 'N/A'))
                })

        if not facts_df.empty:
            facts_df = facts_df.sort_values('ç¢ºä¿¡åº¦', ascending=False)
            facts_table_data = facts_df.to_dict('records')

            total_facts = len(facts_df)
            high_confidence_facts = len(facts_df[facts_df['ç¢ºä¿¡åº¦'] >= 0.8])
            unique_staff = facts_df['ã‚¹ã‚¿ãƒƒãƒ•'].nunique()

            facts_summary = html.Div([
                html.Div([
                    html.H4("ğŸ“Š äº‹å®Ÿåˆ†æã‚µãƒãƒªãƒ¼", style={'margin': '0 0 15px 0', 'color': '#1976d2'}),
                    html.Div([
                        html.Div([
                            html.H3(str(total_facts), style={'margin': '0', 'color': '#2e7d32', 'fontSize': '2rem'}),
                            html.P("ç™ºè¦‹ã•ã‚ŒãŸäº‹å®Ÿ", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                        ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#e8f5e8', 
                                 'borderRadius': '8px', 'border': '2px solid #2e7d32'}),
                        html.Div([
                            html.H3(str(high_confidence_facts), style={'margin': '0', 'color': '#ff9800', 'fontSize': '2rem'}),
                            html.P("é«˜ç¢ºä¿¡åº¦(80%+)", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                        ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#fff3e0', 
                                 'borderRadius': '8px', 'border': '2px solid #ff9800'}),
                        html.Div([
                            html.H3(str(unique_staff), style={'margin': '0', 'color': '#1976d2', 'fontSize': '2rem'}),
                            html.P("åˆ†æå¯¾è±¡ã‚¹ã‚¿ãƒƒãƒ•", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                        ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#e3f2fd', 
                                 'borderRadius': '8px', 'border': '2px solid #1976d2'}),
                    ], style={'display': 'flex', 'gap': '15px', 'marginBottom': '20px'}),
                ], style={'padding': '20px', 'backgroundColor': 'white', 'borderRadius': '12px', 
                         'boxShadow': '0 4px 8px rgba(0,0,0,0.1)', 'marginBottom': '20px'}),
                
                html.Div([
                    html.H5("ğŸ“ˆ ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥å†…è¨³", style={'marginBottom': '15px', 'color': '#1976d2'}),
                    html.Div([
                        html.Div([
                            html.Strong(f"{cat}: "),
                            html.Span(f"{len(df)}ä»¶", style={'color': '#2e7d32', 'fontWeight': 'bold'})
                        ], style={'padding': '8px 12px', 'backgroundColor': '#f5f5f5', 'borderRadius': '6px',
                                 'margin': '5px', 'display': 'inline-block', 'border': '1px solid #ddd'})
                        for cat, df in blueprint_data.get('facts_by_category', {}).items()
                        if not df.empty
                    ])
                ], style={'padding': '15px', 'backgroundColor': '#fafafa', 'borderRadius': '8px',
                         'border': '1px solid #e0e0e0'})
            ])

        # ğŸ” æ‹¡å¼µåˆ†æã¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æã®çµ±åˆè¡¨ç¤º
        segment_analysis = blueprint_data.get('segment_analysis', {})
        constraint_nature = blueprint_data.get('constraint_nature', {})
        advanced_constraints = blueprint_data.get('advanced_constraints', {})
        team_dynamics = blueprint_data.get('team_dynamics', {})
        
        integrated_content = html.Div([
            html.H5("ğŸ¯ ã‚·ãƒ•ãƒˆä½œæˆè€…ã®æš—é»™çŸ¥åˆ†æçµæœ"),
            enhanced_summary
        ])

        # Store data for other callbacks
        store_data = {
            'rules_df': rules_df.to_json(orient='split') if not rules_df.empty else None,
            'scored_df': blueprint_data.get('scored_df', pd.DataFrame()).to_json(orient='split') if blueprint_data.get('scored_df') is not None and not blueprint_data.get('scored_df').empty else None,
            'tradeoffs': blueprint_data.get('tradeoffs', {}),
            'staff_level_scores': blueprint_data.get('staff_level_scores', pd.DataFrame()).to_json(orient='split') if blueprint_data.get('staff_level_scores') is not None and not blueprint_data.get('staff_level_scores').empty else None,
            'facts_df': facts_df.to_json(orient='split') if not facts_df.empty else None,
            'facts_by_category': {k: v.to_json(orient='split') for k, v in blueprint_data.get('facts_by_category', {}).items()}
        }

        return store_data, fig_scatter, rules_table_data, dropdown_options, facts_table_data, facts_summary, integrated_content
    
    except Exception as e:
        log.error(f"ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆåˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}", exc_info=True)
        empty_fig = go.Figure()
        error_msg = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        return {}, empty_fig, [], [], [], error_msg, error_msg
@app.callback(
    Output('facts-data-table', 'data', allow_duplicate=True),
    Input('fact-category-filter', 'value'),
    State('blueprint-results-store', 'data'),
    prevent_initial_call=True
)
@safe_callback
def filter_facts_by_category(selected_category, stored_data):
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼ã§äº‹å®Ÿã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
    if not stored_data or not stored_data.get('facts_df'):
        return []

    facts_df = pd.read_json(stored_data['facts_df'], orient='split')

    if selected_category == 'all':
        filtered_df = facts_df
    else:
        filtered_df = facts_df[facts_df['ã‚«ãƒ†ã‚´ãƒªãƒ¼'] == selected_category]

    filtered_df = filtered_df.sort_values('ç¢ºä¿¡åº¦', ascending=False)

    return filtered_df.to_dict('records')


def _extract_staff_from_rule(rule_text: str, staff_names: list[str]) -> str | None:
    """Return first staff name found in rule text."""
    for name in staff_names:
        if name in rule_text:
            return name
    return None


@app.callback(
    Output('staff-radar-chart', 'figure'),
    Output('staff-related-rules-list', 'children'),
    Input('staff-selector-dropdown', 'value'),
    Input('rules-data-table', 'selected_rows'),
    State('blueprint-results-store', 'data'),
    State('rules-data-table', 'data'),
    prevent_initial_call=True,
)
@safe_callback
def update_staff_view(selected_staff, selected_row_indices, stored_data, table_data):
    if not stored_data:
        raise PreventUpdate

    rules_json = stored_data.get('rules_df')
    staff_json = stored_data.get('staff_level_scores')
    if not rules_json or not staff_json:
        return go.Figure(), "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

    rules_df = pd.read_json(rules_json, orient='split')
    staff_scores_df = pd.read_json(staff_json, orient='split')

    ctx = dash.callback_context
    trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]

    target_staff = selected_staff
    if trigger_id == 'rules-data-table' and selected_row_indices:
        clicked_rule = table_data[selected_row_indices[0]]
        target_staff = _extract_staff_from_rule(clicked_rule.get('ç™ºè¦‹ã•ã‚ŒãŸæ³•å‰‡', ''), list(staff_scores_df.index))

    if not target_staff or target_staff not in staff_scores_df.index:
        return go.Figure(), "ã‚¹ã‚¿ãƒƒãƒ•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"

    row = staff_scores_df.loc[target_staff]
    score_cols = ['fairness_score', 'cost_score', 'risk_score', 'satisfaction_score']
    fig_radar = go.Figure()
    fig_radar.add_trace(
        go.Scatterpolar(
            r=row[score_cols].tolist(),
            theta=['å…¬å¹³æ€§', 'ã‚³ã‚¹ãƒˆ', 'ãƒªã‚¹ã‚¯', 'æº€è¶³åº¦'],
            fill='toself',
            name=target_staff,
        )
    )
    fig_radar.update_layout(polar=dict(radialaxis=dict(range=[0, 1])), showlegend=False)

    related_rules = rules_df[rules_df['ç™ºè¦‹ã•ã‚ŒãŸæ³•å‰‡'].str.contains(target_staff)]
    rule_list_items = [html.P(r) for r in related_rules['ç™ºè¦‹ã•ã‚ŒãŸæ³•å‰‡'].tolist()] if not related_rules.empty else [html.P('é–¢é€£ãƒ«ãƒ¼ãƒ«ãªã—')]

    return fig_radar, rule_list_items


@app.callback(
    Output('sim-shortage-graph', 'figure'),
    Output('sim-cost-text', 'children'),
    Input('sim-work-pattern-dropdown', 'value'),
    Input('sim-hire-fte-slider', 'value'),
    State('kpi-data-store', 'data'),
)
@safe_callback
def update_hire_simulation(selected_pattern, added_fte, kpi_data):
    if not kpi_data or not selected_pattern:
        raise PreventUpdate

    from shift_suite.tasks.h2hire import (
        AVG_HOURLY_WAGE,
        RECRUIT_COST_PER_HIRE,
    )

    df_work_patterns = data_get('work_patterns', pd.DataFrame())
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame()).copy()

    pattern_info = df_work_patterns[df_work_patterns['code'] == selected_pattern]
    if pattern_info.empty:
        raise PreventUpdate
    slots_per_day = pattern_info['parsed_slots_count'].iloc[0]
    hours_per_day = slots_per_day * 0.5
    reduction_hours = added_fte * hours_per_day * 20

    if not df_shortage_role.empty:
        most_lacking_role_index = df_shortage_role['lack_h'].idxmax()
        original_hours = df_shortage_role.loc[most_lacking_role_index, 'lack_h']
        df_shortage_role.loc[most_lacking_role_index, 'lack_h'] = max(0, original_hours - reduction_hours)

    fig = px.bar(
        df_shortage_role,
        x='role',
        y='lack_h',
        title=f'ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¾Œ: {selected_pattern}å‹¤å‹™è€…ã‚’{added_fte}äººè¿½åŠ æ¡ç”¨ã—ãŸå ´åˆã®æ®‹å­˜ä¸è¶³æ™‚é–“',
        labels={'lack_h': 'æ®‹å­˜ä¸è¶³æ™‚é–“(h)'},
    )

    # æ­£ã—ã„ç·ä¸è¶³æ™‚é–“ã®è¨ˆç®—
    new_total_lack_h = 0
    if 'lack_h' in df_shortage_role.columns:
        total_rows = df_shortage_role[df_shortage_role['role'].isin(['å…¨ä½“', 'åˆè¨ˆ', 'ç·è¨ˆ'])]
        if not total_rows.empty:
            new_total_lack_h = total_rows['lack_h'].iloc[0]
        else:
            shortage_time_df = data_get('shortage_time', pd.DataFrame())
            if not shortage_time_df.empty:
                try:
                    shortage_values = shortage_time_df.select_dtypes(include=[np.number]).values
                    new_total_lack_h = float(np.nansum(shortage_values) * 0.5)
                except:
                    new_total_lack_h = df_shortage_role['lack_h'].sum()
            else:
                new_total_lack_h = df_shortage_role['lack_h'].sum()
    
    original_total_lack_h = kpi_data.get('total_lack_h', 0)

    cost_before = original_total_lack_h * 2200
    cost_after_temp = new_total_lack_h * 2200

    added_labor_cost = reduction_hours * AVG_HOURLY_WAGE
    added_recruit_cost = added_fte * RECRUIT_COST_PER_HIRE
    cost_after_hire = cost_after_temp + added_labor_cost + added_recruit_cost

    cost_text = f"""
    #### ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
    - **æ¡ç”¨ã‚³ã‚¹ãƒˆ:** {added_recruit_cost:,.0f} å†† (ä¸€æ™‚)
    - **è¿½åŠ äººä»¶è²»:** {added_labor_cost:,.0f} å†† (æœŸé–“ä¸­)
    - **ç·ã‚³ã‚¹ãƒˆ (æ¡ç”¨ã‚·ãƒŠãƒªã‚ª):** {cost_after_hire:,.0f} å††
    - **æ¯”è¼ƒ (å…¨ã¦æ´¾é£ã§è£œå¡«ã—ãŸå ´åˆ):** {cost_before:,.0f} å††
    """

    return fig, dcc.Markdown(cost_text)


@app.callback(
    Output('factor-output', 'children'),
    Input('factor-train-button', 'n_clicks')
)
@safe_callback
def run_factor_analysis(n_clicks):
    if not n_clicks:
        raise PreventUpdate

    heat_df = data_get('heat_ALL')
    short_df = data_get('shortage_time')
    leave_df = data_get('leave_analysis')

    if heat_df is None or heat_df.empty or short_df is None or short_df.empty:
        return html.Div('å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“')

    analyzer = ShortageFactorAnalyzer()
    feat_df = analyzer.generate_features(pd.DataFrame(), heat_df, short_df, leave_df, set())
    model, fi_df = analyzer.train_and_get_feature_importance(feat_df)
    DATA_CACHE.set('factor_features', feat_df)
    DATA_CACHE.set('factor_importance', fi_df)

    table = dash_table.DataTable(
        data=fi_df.head(5).to_dict('records'),
        columns=[{'name': c, 'id': c} for c in fi_df.columns]
    )
    return html.Div([html.H5('å½±éŸ¿åº¦ã®é«˜ã„è¦å›  ãƒˆãƒƒãƒ—5'), table])  # type: ignore


def generate_lightweight_tree_visualization(tree_model):
    """Generate a small decision tree visualisation."""
    if not tree_model or not hasattr(tree_model, 'tree_'):
        return html.P('æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚')

    try:
        buf = io.BytesIO()
        fig, ax = plt.subplots(figsize=(12, 6))
        plot_tree(
            tree_model,
            filled=True,
            feature_names=tree_model.feature_names_in_[:20],
            max_depth=2,
            fontsize=8,
            ax=ax,
            impurity=False,
            proportion=True,
        )
        fig.savefig(buf, format='png', dpi=72, bbox_inches='tight')
        plt.close(fig)
        buf.seek(0)
        encoded = base64.b64encode(buf.getvalue()).decode()
        return html.Img(
            src=f"data:image/png;base64,{encoded}",
            style={'width': '100%', 'maxWidth': '1000px'},
        )
    except Exception as exc:  # noqa: BLE001
        log.error(f'æ±ºå®šæœ¨å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {exc}')
        return html.P(f'æ±ºå®šæœ¨ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}')


def generate_results_display(full_results):
    """Create the final display for logic analysis results."""
    mind_results = full_results.get('mind_reading', {})

    if 'error' in mind_results:
        return html.Div(f"åˆ†æã‚¨ãƒ©ãƒ¼: {mind_results['error']}", style={'color': 'red'})

    importance_df = pd.DataFrame(mind_results.get('feature_importance', []))
    fig_bar = px.bar(
        importance_df.sort_values('importance', ascending=False).head(15),
        x='importance',
        y='feature',
        orientation='h',
        title='åˆ¤æ–­åŸºæº–ã®é‡è¦åº¦ï¼ˆTOP15ï¼‰',
    )

    tree_content = generate_lightweight_tree_visualization(
        mind_results.get('thinking_process_tree')
    )

    return html.Div([
        html.H4('åˆ†æå®Œäº†ï¼'),
        html.Hr(),
        html.H4('åˆ¤æ–­åŸºæº–ã®é‡è¦åº¦'),
        html.P('ä½œæˆè€…ãŒã©ã®è¦ç´ ã‚’é‡è¦–ã—ã¦ã„ã‚‹ã‹ã‚’æ•°å€¤åŒ–ã—ãŸã‚‚ã®ã§ã™ã€‚'),
        dcc.Graph(figure=fig_bar),
        html.H4('æ€è€ƒãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ', style={'marginTop': '30px'}),
        html.P('é…ç½®ã‚’æ±ºå®šã™ã‚‹éš›ã®æ€è€ƒã®åˆ†å²ã‚’æ¨¡å€£ã—ãŸã‚‚ã®ã§ã™ã€‚'),
        tree_content,
    ])


@app.callback(
    Output('save-log-msg', 'children'),
    Input('save-log-button', 'n_clicks'),
    State('over-shortage-table', 'data'),
    State('log-save-mode', 'value')
)
@safe_callback
def save_over_shortage_log(n_clicks, table_data, mode):
    if not n_clicks:
        raise PreventUpdate

    log_path = data_get('shortage_log_path')
    if not log_path:
        return 'ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'  # type: ignore

    df = pd.DataFrame(table_data)
    over_shortage_log.save_log(df, log_path, mode=mode)
    return 'ãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ'


@app.callback(Output('log-viewer', 'value'), Input('log-interval', 'n_intervals'))
@safe_callback
def update_log_viewer(n):
    """ãƒ­ã‚°ãƒãƒƒãƒ•ã‚¡ã®å†…å®¹ã‚’å®šæœŸçš„ã«æ›´æ–°"""
    log_stream.seek(0)
    return log_stream.read()


@app.callback(
    Output('creation-logic-results', 'children'),
    Output('full-analysis-store', 'data'),
    Input('analyze-creation-logic-button', 'n_clicks'),
    State('analysis-detail-level', 'value'),
    prevent_initial_call=True,
)
@safe_callback
def update_logic_analysis_immediate(n_clicks, detail_level):
    """Show basic results immediately and start deep analysis."""

    if not n_clicks:
        raise PreventUpdate

    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty:
        return html.Div('åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚', style={'color': 'red'}), None

    basic_stats = get_basic_shift_stats(long_df)
    quick_patterns = get_quick_patterns(long_df.head(500))

    immediate_results = html.Div([
        html.H4('âœ… åŸºæœ¬åˆ†æå®Œäº†ï¼ˆè©³ç´°åˆ†æå®Ÿè¡Œä¸­...ï¼‰', style={'color': 'green'}),
        html.Hr(),
        html.Div([
            html.H5('ğŸ“Š ã‚·ãƒ•ãƒˆã®åŸºæœ¬çµ±è¨ˆ'),
            create_stats_cards(basic_stats),
        ]),
        html.Div([
            html.H5('ğŸ” ç™ºè¦‹ã•ã‚ŒãŸä¸»è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆç°¡æ˜“ç‰ˆï¼‰'),
            create_pattern_list(quick_patterns),
        ], style={'marginTop': '20px'}),
        html.Div([
            html.H5('ğŸ§  AIã«ã‚ˆã‚‹æ·±å±¤åˆ†æ'),
            dcc.Loading(id='deep-analysis-loading', children=html.Div(id='deep-analysis-results'), type='circle'),
        ], style={'marginTop': '30px'}),
        dcc.Interval(id='background-trigger', interval=100, n_intervals=0, max_intervals=1),
    ])

    return immediate_results, {'status': 'pending', 'level': detail_level}


@app.callback(
    Output('deep-analysis-results', 'children'),
    Input('background-trigger', 'n_intervals'),
    State('analysis-detail-level', 'value'),
    prevent_initial_call=True,
)
@safe_callback
def run_deep_analysis_background(n_intervals, detail_level):
    """Run deeper analysis in the background."""

    if n_intervals == 0:
        raise PreventUpdate

    long_df = data_get('long_df', pd.DataFrame())
    results = run_optimized_analysis(long_df, detail_level)

    return create_deep_analysis_display(results)


@app.callback(
    Output('progress-bar', 'figure'),
    Output('progress-message', 'children'),
    Input('logic-analysis-interval', 'n_intervals'),
    State('logic-analysis-progress', 'data'),
    prevent_initial_call=True,
)
@safe_callback
def update_progress_bar(n_intervals, progress_data):
    """Update the progress bar display."""
    if not progress_data:
        raise PreventUpdate

    progress = progress_data.get('progress', 0)
    stage = progress_data.get('stage', 'loading')

    messages = {
        'loading': 'ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...',
        'analyzing': 'ã‚·ãƒ•ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã¦ã„ã¾ã™...',
        'visualizing': 'çµæœã‚’å¯è¦–åŒ–ã—ã¦ã„ã¾ã™...',
    }

    figure = {
        'data': [{
            'x': [progress],
            'y': ['Progress'],
            'type': 'bar',
            'orientation': 'h',
            'marker': {'color': '#1f77b4'},
        }],
        'layout': {
            'xaxis': {'range': [0, 100], 'title': 'é€²æ—ç‡ (%)'},
            'yaxis': {'visible': False},
            'height': 100,
            'margin': {'l': 0, 'r': 0, 't': 30, 'b': 30},
        },
    }

    return figure, messages.get(stage, 'å‡¦ç†ä¸­...')



# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹• ---
if __name__ == '__main__':
    app.run_server(debug=True, port=8050, host='127.0.0.1')
