# ğŸš¨ çµ±ä¸€åˆ†æç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  é‡å¤§å•é¡Œã®ä¿®æ­£æ–¹æ³•

## å•é¡Œã®æ ¸å¿ƒçš„åŸå› 

### ç™ºè¦‹ã—ãŸå•é¡Œ
1. **çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã¸ã®çµæœç™»éŒ²ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹**ï¼ˆapp.py 2404è¡Œç›®ï¼‰
2. **ã—ã‹ã—ã€AIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ™‚ã«çµæœãŒå–å¾—ã§ããªã„**

### æ ¹æœ¬åŸå› 
**ãƒ•ã‚¡ã‚¤ãƒ«åã®ä¸ä¸€è‡´**å•é¡Œï¼š
- ç™»éŒ²æ™‚: `file_name`ï¼ˆä¾‹: "ãƒ‡ã‚¤_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿_ä¼‘æ—¥ç²¾ç·».xlsx"ï¼‰
- å–å¾—æ™‚: `file_name`ã®å½¢å¼ãŒç•°ãªã‚‹å¯èƒ½æ€§

## å³åº§ã«é©ç”¨ã™ã¹ãä¿®æ­£

### 1. çµ±ä¸€åˆ†æç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ 

```python
# shift_suite/tasks/unified_analysis_manager.py ã®367è¡Œç›®ä»˜è¿‘
def get_ai_compatible_results(self, file_pattern: str = None) -> Dict[str, Any]:
    """AIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”¨ã®çµæœè¾æ›¸ç”Ÿæˆ"""
    ai_results = {}
    
    # ğŸ”§ ä¿®æ­£: ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’è¿½åŠ 
    log.info(f"[get_ai_compatible_results] æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³: '{file_pattern}'")
    log.info(f"[get_ai_compatible_results] ãƒ¬ã‚¸ã‚¹ãƒˆãƒªå†…ã®ã‚­ãƒ¼æ•°: {len(self.results_registry)}")
    
    # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªå†…ã®ã‚­ãƒ¼ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    if self.results_registry:
        log.debug("[get_ai_compatible_results] ãƒ¬ã‚¸ã‚¹ãƒˆãƒªå†…ã®ã‚­ãƒ¼:")
        for key in list(self.results_registry.keys())[:5]:  # æœ€åˆã®5å€‹ã®ã¿
            log.debug(f"  - {key}")
    else:
        log.warning("[get_ai_compatible_results] âš ï¸ ãƒ¬ã‚¸ã‚¹ãƒˆãƒªãŒç©ºã§ã™ï¼")
    
    for key, result in self.results_registry.items():
        # ğŸ”§ ä¿®æ­£: ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã‚’æ”¹å–„
        if file_pattern is None:
            match = True
        else:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã®éƒ¨åˆ†ä¸€è‡´ã‚’è¨±å¯
            clean_pattern = Path(file_pattern).stem  # æ‹¡å¼µå­ã‚’é™¤å»
            match = clean_pattern in key or file_pattern in key
            
        if match:
            log.debug(f"[get_ai_compatible_results] ãƒãƒƒãƒ: {key}")
            # åˆ†æã‚¿ã‚¤ãƒ—ã”ã¨ã«æ•´ç†
            analysis_type = result.analysis_type
            if analysis_type not in ai_results:
                ai_results[analysis_type] = []
            
            ai_results[analysis_type].append(result.get_ai_compatible_dict())
    
    # ä»¥ä¸‹ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰...
```

### 2. app.pyã§ã®ãƒ•ã‚¡ã‚¤ãƒ«åã®ä¸€è²«æ€§ç¢ºä¿

```python
# app.py ã®3363è¡Œç›®ä»˜è¿‘ã‚’ä¿®æ­£
# çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰AIäº’æ›å½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
# ğŸ”§ ä¿®æ­£: ãƒ•ã‚¡ã‚¤ãƒ«åã®ã‚¹ãƒ†ãƒ ï¼ˆæ‹¡å¼µå­ãªã—ï¼‰ã‚’ä½¿ç”¨
file_stem = Path(file_name).stem
log.info(f"[AIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ] ãƒ•ã‚¡ã‚¤ãƒ«å: {file_name} â†’ ã‚¹ãƒ†ãƒ : {file_stem}")

unified_results = st.session_state.unified_analysis_manager.get_ai_compatible_results(file_stem)

# çµæœãŒç©ºã®å ´åˆã®è©³ç´°è¨ºæ–­
if not unified_results:
    log.warning(f"[AIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ] çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰çµæœãŒå–å¾—ã§ãã¾ã›ã‚“")
    log.warning(f"  æ¤œç´¢ã‚­ãƒ¼: {file_stem}")
    log.warning(f"  ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚µã‚¤ã‚º: {len(st.session_state.unified_analysis_manager.results_registry)}")
```

### 3. ä¸è¶³åˆ†æçµæœãŒ0ã«ãªã‚‹å•é¡Œã®ä¿®æ­£

```python
# shift_suite/tasks/shortage.py ã«è¨ºæ–­ãƒ­ã‚°ã‚’è¿½åŠ 
def run_shortage(...):
    # æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰...
    
    # ğŸ”§ ä¿®æ­£: heat_all_dfã®å†…å®¹ã‚’è¨ºæ–­
    log.info(f"[shortage] heat_all_df shape: {heat_all_df.shape}")
    log.info(f"[shortage] ã‚«ãƒ©ãƒ æ•°: {len(heat_all_df.columns)}")
    
    # need/actualã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
    need_cols = [col for col in heat_all_df.columns if 'need' in col]
    actual_cols = [col for col in heat_all_df.columns if 'actual' in col]
    
    log.info(f"[shortage] needã‚«ãƒ©ãƒ æ•°: {len(need_cols)}")
    log.info(f"[shortage] actualã‚«ãƒ©ãƒ æ•°: {len(actual_cols)}")
    
    if not need_cols:
        log.error("[shortage] âš ï¸ needã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼")
    if not actual_cols:
        log.error("[shortage] âš ï¸ actualã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼")
```

## ä¿®æ­£é©ç”¨æ‰‹é †

### Step 1: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆæ—¢ã«å®Ÿè¡Œæ¸ˆã¿ï¼‰
```bash
# backup_20250730_094336 ã«ä¿å­˜æ¸ˆã¿
```

### Step 2: ä¿®æ­£ã®é©ç”¨
1. `shift_suite/tasks/unified_analysis_manager.py`ã®`get_ai_compatible_results`ãƒ¡ã‚½ãƒƒãƒ‰ã«ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ 
2. `app.py`ã®3363è¡Œç›®ä»˜è¿‘ã§ãƒ•ã‚¡ã‚¤ãƒ«åã‚’stemã«å¤‰æ›
3. `shift_suite/tasks/shortage.py`ã«è¨ºæ–­ãƒ­ã‚°è¿½åŠ 

### Step 3: å‹•ä½œç¢ºèª
```bash
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•
streamlit run app.py

# åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ãƒ­ã‚°ç›£è¦–
tail -f shift_suite.log | grep -E "get_ai_compatible_results|AIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ|shortage"
```

### Step 4: å†åº¦åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã§åˆ†æå®Ÿè¡Œ
1. "ãƒ‡ã‚¤_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿_ä¼‘æ—¥ç²¾ç·».xlsx"ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
2. åˆ†æå®Ÿè¡Œ
3. ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ä»¥ä¸‹ã‚’ç¢ºèªï¼š
   - ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«ãƒ‡ãƒ¼ã‚¿ãŒç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‹
   - ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒãƒƒãƒãƒ³ã‚°ãŒæˆåŠŸã—ã¦ã„ã‚‹ã‹
   - ä¸è¶³æ™‚é–“ãŒæ­£ã—ãè¨ˆç®—ã•ã‚Œã¦ã„ã‚‹ã‹

## æœŸå¾…ã•ã‚Œã‚‹çµæœ

ä¿®æ­£å¾Œã®ãƒ­ã‚°å‡ºåŠ›ä¾‹ï¼š
```
[get_ai_compatible_results] æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³: 'ãƒ‡ã‚¤_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿_ä¼‘æ—¥ç²¾ç·»'
[get_ai_compatible_results] ãƒ¬ã‚¸ã‚¹ãƒˆãƒªå†…ã®ã‚­ãƒ¼æ•°: 3
[get_ai_compatible_results] ãƒ¬ã‚¸ã‚¹ãƒˆãƒªå†…ã®ã‚­ãƒ¼:
  - ãƒ‡ã‚¤_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿_ä¼‘æ—¥ç²¾ç·»_default_shortage_20250730_093000_abc123
  - ãƒ‡ã‚¤_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿_ä¼‘æ—¥ç²¾ç·»_default_fatigue_20250730_093005_def456
  - ãƒ‡ã‚¤_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿_ä¼‘æ—¥ç²¾ç·»_default_fairness_20250730_093010_ghi789
[get_ai_compatible_results] ãƒãƒƒãƒ: ãƒ‡ã‚¤_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿_ä¼‘æ—¥ç²¾ç·»_default_shortage_20250730_093000_abc123
```

ã“ã‚Œã«ã‚ˆã‚Šã€ä¸è¶³æ™‚é–“ãŒ0ã§ã¯ãªãå®Ÿéš›ã®å€¤ã¨ã—ã¦å‡ºåŠ›ã•ã‚Œã‚‹ã¯ãšã§ã™ã€‚