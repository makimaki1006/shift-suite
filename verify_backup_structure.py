#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ§‹é€ ã®è©³ç´°æ¤œè¨¼
"""

import json
import zipfile
from pathlib import Path

def verify_backup_structure():
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ§‹é€ ã®è©³ç´°æ¤œè¨¼"""
    
    print("=" * 80)
    print("ğŸ” ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ§‹é€ æ¤œè¨¼")
    print("=" * 80)
    
    # 1. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®æ¤œè¨¼
    backup_dir = Path("PHASE3_COMPLETE_BACKUP_20250802_100555")
    
    print("ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :")
    
    # æœŸå¾…ã•ã‚Œã‚‹æ§‹é€ 
    expected_structure = {
        "ãƒ«ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«": [
            "backup_metadata.json",
            "restore_phase3.py",
            "verify_backup.py",
            "README.md"
        ],
        "Phaseå®Ÿè£…": [
            "shift_suite/tasks/fact_extractor_prototype.py",
            "shift_suite/tasks/lightweight_anomaly_detector.py",
            "shift_suite/tasks/fact_book_visualizer.py",
            "shift_suite/tasks/dash_fact_book_integration.py"
        ],
        "è¨­è¨ˆæ›¸": [
            "PHASE3_LIGHTWEIGHT_ANOMALY_DETECTION_DESIGN.md",
            "PHASE3_2_FACT_BOOK_INTEGRATION_GUIDE.md"
        ]
    }
    
    for category, files in expected_structure.items():
        print(f"\n{category}:")
        for file_path in files:
            full_path = backup_dir / file_path
            exists = full_path.exists()
            status = "âœ…" if exists else "âŒ"
            print(f"  {status} {file_path}")
            
            if exists and file_path.endswith('.json'):
                # JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å¦¥å½“æ€§æ¤œè¨¼
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        json.load(f)
                    print(f"      âœ… JSONå½¢å¼å¦¥å½“")
                except:
                    print(f"      âŒ JSONå½¢å¼ã‚¨ãƒ©ãƒ¼")
    
    # 2. ZIPã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®å®Œå…¨æ€§æ¤œè¨¼
    print("\nğŸ“¦ ZIPã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¤œè¨¼:")
    
    zip_path = Path("PHASE3_COMPLETE_BACKUP_20250802_100555.zip")
    if zip_path.exists():
        try:
            with zipfile.ZipFile(zip_path, 'r') as zf:
                # ZIPæ•´åˆæ€§ãƒ†ã‚¹ãƒˆ
                result = zf.testzip()
                if result is None:
                    print("  âœ… ZIPæ•´åˆæ€§OK")
                else:
                    print(f"  âŒ ZIPç ´æ: {result}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ç¢ºèª
                file_list = zf.namelist()
                print(f"  ğŸ“Š ZIPãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(file_list)}")
                
                # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
                important_files = [
                    "backup_metadata.json",
                    "shift_suite/tasks/fact_extractor_prototype.py",
                    "shift_suite/tasks/lightweight_anomaly_detector.py",
                    "shift_suite/tasks/fact_book_visualizer.py"
                ]
                
                for imp_file in important_files:
                    # ZIPãƒ‘ã‚¹å½¢å¼ã«å¤‰æ›
                    zip_file_path = f"PHASE3_COMPLETE_BACKUP_20250802_100555/{imp_file}"
                    exists_in_zip = any(zip_file_path in f for f in file_list)
                    status = "âœ…" if exists_in_zip else "âŒ"
                    print(f"    {status} {imp_file}")
                    
        except Exception as e:
            print(f"  âŒ ZIPã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print("  âŒ ZIPãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨")
    
    # 3. å¾©å…ƒå¯èƒ½æ€§ã®æ¤œè¨¼
    print("\nğŸ”„ å¾©å…ƒå¯èƒ½æ€§:")
    
    # å¾©å…ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å†…å®¹ç¢ºèª
    restore_script = backup_dir / "restore_phase3.py"
    if restore_script.exists():
        with open(restore_script, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å¿…è¦ãªæ©Ÿèƒ½ã®å­˜åœ¨ç¢ºèª
        required_functions = [
            ("restore_phase3_backup", "ãƒ¡ã‚¤ãƒ³å¾©å…ƒé–¢æ•°"),
            ("shutil.copy2", "ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼æ©Ÿèƒ½"),
            ("json.load", "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"),
            ("Path", "ãƒ‘ã‚¹æ“ä½œ")
        ]
        
        for func, desc in required_functions:
            exists = func in content
            status = "âœ…" if exists else "âŒ"
            print(f"  {status} {desc}")
    
    # 4. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§
    print("\nğŸ“‹ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§:")
    
    metadata_path = backup_dir / "backup_metadata.json"
    if metadata_path.exists():
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç¢ºèª
        required_fields = [
            ("backup_info", "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—åŸºæœ¬æƒ…å ±"),
            ("implementation_status", "å®Ÿè£…çŠ¶æ³"),
            ("critical_files", "é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§"),
            ("backup_verification", "æ¤œè¨¼æƒ…å ±")
        ]
        
        for field, desc in required_fields:
            exists = field in metadata
            status = "âœ…" if exists else "âŒ"
            print(f"  {status} {desc}")
            
            if exists and field == "critical_files":
                # ãƒ•ã‚¡ã‚¤ãƒ«æ¯ã®å¿…é ˆæƒ…å ±ç¢ºèª
                file_count = len(metadata[field])
                checksum_count = len([f for f in metadata[field] if f.get("checksum")])
                print(f"      - ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {file_count}")
                print(f"      - ãƒã‚§ãƒƒã‚¯ã‚µãƒ ä»˜ä¸: {checksum_count}/{file_count}")
    
    print("\nâœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ§‹é€ æ¤œè¨¼å®Œäº†")

if __name__ == "__main__":
    verify_backup_structure()