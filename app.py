# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  app.py  (Part 1 / 3)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Shift-Suite Streamlit GUI + ÂÜÖËîµ„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ  v1.30.0 (‰ºëÊöáÂàÜÊûêÊ©üËÉΩËøΩÂä†)
# ==============================================================================
# Â§âÊõ¥Â±•Ê≠¥
#   ‚Ä¢ v1.30.0: ‰ºëÊöáÂàÜÊûêÊ©üËÉΩ„ÇíËøΩÂä†„ÄÇleave_analyzer „É¢„Ç∏„É•„Éº„É´„Å®„ÅÆÈÄ£Êê∫„ÇíÂÆüË£Ö„ÄÇ
#   ‚Ä¢ v1.29.13: st.experimental_rerun() „Çí st.rerun() „Å´‰øÆÊ≠£„ÄÇ
#   ‚Ä¢ v1.29.12: need_ref_start/end_date_widget „ÅÆ StreamlitAPIException ÂØæÁ≠ñ„ÄÇ
#               „Éï„Ç°„Ç§„É´„Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÊôÇ„ÅÆÊó•‰ªòÁØÑÂõ≤Êé®ÂÆöÁµêÊûú„Çí„ÄÅ„Éï„É©„Ç∞„ÇíÁî®„ÅÑ„Å¶
#               Ê¨°Âõû„ÅÆ„Çπ„ÇØ„É™„Éó„ÉàÂÆüË°åÊôÇ„Å´„Ç¶„Ç£„Ç∏„Çß„ÉÉ„Éà„ÅÆ„Éá„Éï„Ç©„É´„ÉàÂÄ§„Å®„Åó„Å¶ÂÆâÂÖ®„Å´ÂèçÊò†„Åô„Çã„Çà„ÅÜ‰øÆÊ≠£„ÄÇ
#   ‚Ä¢ v1.29.11: „É≠„Ç∞„ÅßÊåáÊëò„Åï„Çå„Åü„Ç®„É©„ÉºÁÆáÊâÄ„Çí‰øÆÊ≠£„ÄÇ
#               - shift_sheets_multiselect_widget „ÅÆ StreamlitAPIException ÂØæÁ≠ñ„ÄÇ
#               - param_penalty_per_lack „ÅÆ NameError ‰øÆÊ≠£„ÄÇ
#               - progress_bar_exec_main_run Á≠â„ÅÆ NameError ‰øÆÊ≠£„ÄÇ
#               - „É≠„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏ÂÜÖ„ÅÆ„Çø„Ç§„Éù‰øÆÊ≠£„ÄÇ
#   ‚Ä¢ v1.29.10: selectbox„ÅÆdefaultÂºïÊï∞„Ç®„É©„Éº„Çíindex„Å´Áµ±‰∏Ä„Åó„ÄÅ„Ç™„Éó„Ç∑„Éß„É≥„É™„Çπ„Éà„Çí„Çª„ÉÉ„Ç∑„Éß„É≥„Åã„ÇâÊ≠£„Åó„ÅèÂèÇÁÖß„ÄÇ
#               ÂÖ®„Å¶„ÅÆ„Ç¶„Ç£„Ç∏„Çß„ÉÉ„Éà„ÅÆÂÄ§„Çí„Çª„ÉÉ„Ç∑„Éß„É≥„Çπ„ÉÜ„Éº„Éà„ÅßÁÆ°ÁêÜ„Åó„ÄÅÂàùÊúüÂåñ„ÇíÂæπÂ∫ï„ÄÇ
#               „Éò„ÉÉ„ÉÄ„ÉºÈñãÂßãË°åUI„ÅÆË°®Á§∫„Å®ÂÄ§„ÅÆÂà©Áî®„ÇíÁ¢∫ÂÆüÂåñ„ÄÇ
#               ExcelÊó•‰ªòÁØÑÂõ≤Êé®ÂÆö„ÅÆÂÆâÂÆöÂåñ„ÄÇ
#               on_change„Ç≥„Éº„É´„Éê„ÉÉ„ÇØ„ÇíÂâäÈô§„Åó„ÄÅ„Çà„Çä„Ç∑„É≥„Éó„É´„Å™„Çª„ÉÉ„Ç∑„Éß„É≥„Çπ„ÉÜ„Éº„ÉàÁÆ°ÁêÜ„ÇíÁõÆÊåá„Åô„ÄÇ
# ==============================================================================

from __future__ import annotations

import datetime
import io
import logging
import sys
import tempfile
import zipfile
from pathlib import Path
from typing import Optional

import pandas as pd
import streamlit as st
from streamlit.runtime import exists as st_runtime_exists
import plotly.express as px
import plotly.graph_objects as go

try:
    from streamlit_plotly_events import plotly_events
except ModuleNotFoundError:  # pragma: no cover - optional dependency
    plotly_events = None
    logging.getLogger(__name__).warning(
        "streamlit-plotly-events not installed; interactive plots disabled"
    )
import datetime as dt

# ‚îÄ‚îÄ Shift-Suite task modules ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
from shift_suite.tasks.io_excel import ingest_excel
from shift_suite.tasks.heatmap import build_heatmap
from shift_suite.tasks.shortage import shortage_and_brief, merge_shortage_leave
from shift_suite.tasks.build_stats import build_stats
from shift_suite.tasks.anomaly import detect_anomaly
from shift_suite.tasks.fatigue import train_fatigue
from shift_suite.tasks.cluster import cluster_staff
from shift_suite.tasks.skill_nmf import build_skill_matrix
from shift_suite.tasks.fairness import run_fairness
from shift_suite.tasks.forecast import build_demand_series, forecast_need
from shift_suite.tasks.rl import learn_roster
from shift_suite.tasks.hire_plan import build_hire_plan
from shift_suite.tasks.h2hire import build_hire_plan as build_hire_plan_from_kpi
from shift_suite.tasks.cost_benefit import analyze_cost_benefit
from shift_suite.tasks.constants import SUMMARY5 as SUMMARY5_CONST
from shift_suite.tasks import leave_analyzer  # ‚òÖ Êñ∞Ë¶è„Ç§„É≥„Éù„Éº„Éà
from shift_suite.tasks.leave_analyzer import (
    LEAVE_TYPE_REQUESTED,
    LEAVE_TYPE_PAID,
)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
from shift_suite.tasks.analyzers import (
    RestTimeAnalyzer,
    WorkPatternAnalyzer,
    AttendanceBehaviorAnalyzer,
    CombinedScoreCalculator,
    LowStaffLoadAnalyzer,
)

# ‚îÄ‚îÄ „É≠„Ç¨„ÉºË®≠ÂÆö ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
log = logging.getLogger("shift_suite_app")
if not log.handlers:
    log.setLevel(logging.INFO)
    handler = logging.StreamHandler(sys.stdout)
    formatter = logging.Formatter(
        "%(asctime)s [%(levelname)s] %(name)s [%(module)s.%(funcName)s:%(lineno)d] - %(message)s"
    )
    handler.setFormatter(formatter)
    log.addHandler(handler)

    from shift_suite.tasks.utils import log as tasks_log

    if not tasks_log.handlers:
        tasks_log.addHandler(handler)
        tasks_log.setLevel(logging.DEBUG)


# ‚îÄ‚îÄ Utility: log error to terminal and show in Streamlit ‚îÄ‚îÄ
def log_and_display_error(msg: str, exc: Exception) -> None:
    """Log an error and also show it in the Streamlit interface."""
    log.error(f"{msg}: {exc}", exc_info=True)
    st.error(f"{msg}: {exc}")


# ‚îÄ‚îÄ Êó•Êú¨Ë™û„É©„Éô„É´ËæûÊõ∏ & _() ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
JP = {
    "Overview": "Ê¶ÇË¶Å",
    "Heatmap": "„Éí„Éº„Éà„Éû„ÉÉ„Éó",
    "Shortage": "‰∏çË∂≥ÂàÜÊûê",
    "Fatigue": "Áñ≤Âä¥",
    "Forecast": "ÈúÄË¶Å‰∫àÊ∏¨",
    "Fairness": "ÂÖ¨Âπ≥ÊÄß",
    "Cost Sim": "„Ç≥„Çπ„ÉàË©¶ÁÆó",
    "Hire Plan": "Êé°Áî®Ë®àÁîª",
    "PPT Report": "PPT„É¨„Éù„Éº„Éà",
    "Leave Analysis": "‰ºëÊöáÂàÜÊûê",  # ‚òÖ ËøΩÂä†
    "Alerts": "„Ç¢„É©„Éº„Éà",
    "Slot (min)": "„Çπ„É≠„ÉÉ„Éà (ÂàÜ)",
    "Need Calculation Settings (Day of Week Pattern)": "üìä NeedÁÆóÂá∫Ë®≠ÂÆö (ÊõúÊó•„Éë„Çø„Éº„É≥Âà•)",
    "Reference Period for Need Calculation": "ÂèÇÁÖßÊúüÈñì (NeedÁÆóÂá∫Áî®)",
    "Rest Time Analysis": "‰ºëÊÅØÊôÇÈñìÂàÜÊûê",
    "Work Pattern Analysis": "Âã§Âãô„Éë„Çø„Éº„É≥ÂàÜÊûê",
    "Attendance Analysis": "Âá∫Âã§Áä∂Ê≥ÅÂàÜÊûê",
    "Combined Score": "Á∑èÂêà„Çπ„Ç≥„Ç¢",
    "Low Staff Load": "Â∞ë‰∫∫Êï∞Âã§ÂãôÂàÜÊûê",
    "Start Date": "ÈñãÂßãÊó•",
    "End Date": "ÁµÇ‰∫ÜÊó•",
    "Statistical Metric for Need": "Áµ±Ë®àÁöÑÊåáÊ®ô (NeedÁÆóÂá∫Áî®)",
    "Remove Outliers for Need Calculation": "Â§ñ„ÇåÂÄ§„ÇíÈô§Âéª„Åó„Å¶Need„ÇíÁÆóÂá∫",
    "(Optional) Upper Limit Calculation Method": "(„Ç™„Éó„Ç∑„Éß„É≥) ‰∏äÈôêÂÄ§ÁÆóÂá∫ÊñπÊ≥ï",
    "Min-staff method (for Upper)": "ÊúÄÂ∞ë‰∫∫Êï∞ÁÆóÂá∫Ê≥ï (‰∏äÈôêÂÄ§Áî®)",
    "Max-staff method (for Upper)": "ÊúÄÂ§ß‰∫∫Êï∞ÁÆóÂá∫Ê≥ï (‰∏äÈôêÂÄ§Áî®)",
    "Extra modules": "ËøΩÂä†„É¢„Ç∏„É•„Éº„É´",
    "Save method": "‰øùÂ≠òÊñπÊ≥ï",
    "ZIP Download": "ZIPÂΩ¢Âºè„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
    "Save to folder": "„Éï„Ç©„É´„ÉÄ„Å´‰øùÂ≠ò",
    "Run Analysis": "‚ñ∂ Ëß£ÊûêÂÆüË°å",
    "Cost & Hire Parameters": "üí∞ „Ç≥„Çπ„Éà„ÉªÊé°Áî®Ë®àÁîª„Éë„É©„É°„Éº„Çø",
    "Standard work hours (h/month)": "ÊâÄÂÆöÂä¥ÂÉçÊôÇÈñì (h/Êúà)",
    "Safety factor (shortage h multiplier)": "ÂÆâÂÖ®‰øÇÊï∞ (‰∏çË∂≥hÂÄçÁéá)",
    "Target coverage rate": "ÁõÆÊ®ôÂÖÖË∂≥Áéá",
    "Direct employee labor cost (¬•/h)": "Ê≠£ËÅ∑Âì° ‰∫∫‰ª∂Ë≤ª (¬•/h)",
    "Temporary staff labor cost (¬•/h)": "Ê¥æÈÅ£ ‰∫∫‰ª∂Ë≤ª (¬•/h)",
    "One-time hiring cost (¬•/person)": "Êé°Áî®‰∏ÄÊôÇ„Ç≥„Çπ„Éà (¬•/‰∫∫)",
    "Penalty for shortage (¬•/h)": "‰∏çË∂≥„Éö„Éä„É´„ÉÜ„Ç£ (¬•/h)",
    "Upload Excel shift file (*.xlsx)": "Excel „Ç∑„Éï„ÉàË°® (*.xlsx) „Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ",
    "Select shift sheets to analyze (multiple)": "Ëß£Êûê„Åô„Çã„Ç∑„Éï„Éà„Ç∑„Éº„ÉàÔºàË§áÊï∞ÂèØÔºâ",
    "Header start row (1-indexed)": "„Éò„ÉÉ„ÉÄ„ÉºÈñãÂßãË°å (1-indexed)",
    "File Preview (first 8 rows)": "„Éï„Ç°„Ç§„É´„Éó„É¨„Éì„É•„Éº (ÂÖàÈ†≠8Ë°å)",
    "Error during preview display": "„Éó„É¨„Éì„É•„Éº„ÅÆË°®Á§∫‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü",
    "Error saving Excel file": "Excel„Éï„Ç°„Ç§„É´„ÅÆ‰øùÂ≠ò‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü",
    "Error getting sheet names from Excel": "Excel„Éï„Ç°„Ç§„É´„Åã„Çâ„Ç∑„Éº„ÉàÂêç„ÅÆÂèñÂæó‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü",
    "No analysis target sheets found": "Âã§ÂãôÂå∫ÂàÜ„Ç∑„Éº„Éà‰ª•Â§ñ„ÅÆËß£ÊûêÂØæË±°„Ç∑„Éº„Éà„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑ„Åã„ÄÅÂÖ®„Å¶„ÅÆ„Ç∑„Éº„ÉàÂêç„Å´„ÄåÂã§ÂãôÂå∫ÂàÜ„Äç„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ",
    "Analysis in progress...": "Ëß£ÊûêÊ∫ñÂÇô‰∏≠...",
    "Ingest: Reading Excel data...": "Excel„Éá„Éº„ÇøË™≠„ÅøËæº„Åø‰∏≠‚Ä¶",
    "Heatmap: Generating heatmap...": "HeatmapÁîüÊàê‰∏≠‚Ä¶",
    "Shortage: Analyzing shortage...": "Shortage (‰∏çË∂≥ÂàÜÊûê) ‰∏≠‚Ä¶",
    "Stats: Processing...": "Stats (Áµ±Ë®àÊÉÖÂ†±) ÁîüÊàê‰∏≠‚Ä¶",
    "Anomaly: Processing...": "Anomaly (Áï∞Â∏∏Ê§úÁü•) ‰∏≠‚Ä¶",
    "Fatigue: Processing...": "Fatigue (Áñ≤Âä¥ÂàÜÊûê) ‰∏≠‚Ä¶",
    "Cluster: Processing...": "Cluster („ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞) ‰∏≠‚Ä¶",
    "Skill: Processing...": "Skill („Çπ„Ç≠„É´NMF) ‰∏≠‚Ä¶",
    "Fairness: Processing...": "Fairness (ÂÖ¨Âπ≥ÊÄßÂàÜÊûê) ‰∏≠‚Ä¶",
    "Leave Analysis: Processing...": "Leave Analysis (‰ºëÊöáÂàÜÊûê) ‰∏≠‚Ä¶",  # ‚òÖ ËøΩÂä†
    "Need forecast: Processing...": "Need forecast (ÈúÄË¶Å‰∫àÊ∏¨) ‰∏≠‚Ä¶",
    "RL roster (PPO): Processing...": "RL roster (Âº∑ÂåñÂ≠¶Áøí„Ç∑„Éï„Éà) ‰∏≠‚Ä¶",
    "RL roster (model): Processing...": "RL roster (Â≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´) ‰∏≠‚Ä¶",
    "Rest Time Analysis: Processing...": "Rest Time Analysis (‰ºëÊÅØÊôÇÈñìÂàÜÊûê) ‰∏≠‚Ä¶",
    "Work Pattern Analysis: Processing...": "Âã§Âãô„Éë„Çø„Éº„É≥ÂàÜÊûê ‰∏≠‚Ä¶",
    "Attendance Analysis: Processing...": "Âá∫Âã§Áä∂Ê≥ÅÂàÜÊûê ‰∏≠‚Ä¶",
    "Combined Score: Processing...": "Á∑èÂêà„Çπ„Ç≥„Ç¢Ë®àÁÆó ‰∏≠‚Ä¶",
    "Low Staff Load: Processing...": "Â∞ë‰∫∫Êï∞Âã§ÂãôÂàÜÊûê ‰∏≠‚Ä¶",
    "Hire plan: Processing...": "Hire plan (Êé°Áî®Ë®àÁîª) ‰∏≠‚Ä¶",
    "Cost / Benefit: Processing...": "Cost / Benefit („Ç≥„Çπ„Éà‰æøÁõäÂàÜÊûê) ‰∏≠‚Ä¶",
    "Ingest: Excel data read complete.": "‚úÖ Excel„Éá„Éº„ÇøË™≠„ÅøËæº„ÅøÂÆå‰∫Ü",
    "All processes complete!": "üéâ ÂÖ®„Å¶„ÅÆËß£Êûê„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ",
    "Error during analysis (ValueError)": "Ëß£Êûê‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü (ValueError)",
    "Required file not found": "ÂøÖË¶Å„Å™„Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü",
    "Unexpected error occurred": "‰∫àÊúü„Åõ„Å¨„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü",
    "Save Analysis Results": "üìÅ Ëß£ÊûêÁµêÊûú„ÅÆ‰øùÂ≠ò",
    "Output folder": "Âá∫ÂäõÂÖà„Éï„Ç©„É´„ÉÄ",
    "Open the above path in Explorer.": "„Ç®„ÇØ„Çπ„Éó„É≠„Éº„É©„Éº„Åß‰∏äË®ò„ÅÆ„Éë„Çπ„ÇíÈñã„ÅÑ„Å¶„ÅîÁ¢∫Ë™ç„Åè„Å†„Åï„ÅÑ„ÄÇ",
    "Download analysis results as ZIP": "üì• Ëß£ÊûêÁµêÊûú„ÇíZIP„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
    "Error creating ZIP file": "ZIP„Éï„Ç°„Ç§„É´„ÅÆ‰ΩúÊàê‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü",
    "Dashboard (Upload ZIP)": "üìä „ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ (ZIP „Ç¢„ÉÉ„Éó„É≠„Éº„Éâ)",
    "Upload ZIP file of 'out' folder": "out „Éï„Ç©„É´„ÉÄ„Çí ZIP ÂúßÁ∏Æ„Åó„Å¶„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ",
    "heat_ALL.xlsx not found in ZIP": "„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åï„Çå„ÅüZIP„Éï„Ç°„Ç§„É´ÂÜÖ„Å´ heat_ALL.xlsx „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇZIP„ÅÆÊßãÈÄ†„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
    "Failed to extract ZIP file.": "ZIP„Éï„Ç°„Ç§„É´„ÅÆÂ±ïÈñã„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ",
    "Uploaded file is not a valid ZIP file.": "„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åï„Çå„Åü„Éï„Ç°„Ç§„É´„ÅØÊúâÂäπ„Å™ZIP„Éï„Ç°„Ç§„É´„Åß„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ",
    "Error during ZIP file extraction": "ZIP„Éï„Ç°„Ç§„É´„ÅÆÂ±ïÈñã‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü",
    "Invalid path in ZIP file.": "ZIP„Éï„Ç°„Ç§„É´„Å´‰∏çÊ≠£„Å™„Éë„Çπ„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„Åæ„Åó„Åü„ÄÇ",
    "Display Mode": "Ë°®Á§∫„É¢„Éº„Éâ",
    "Raw Count": "‰∫∫Êï∞",
    "Ratio (staff √∑ need)": "Ratio (staff √∑ need)",
    "Color Scale Max (zmax)": "„Ç´„É©„Éº„Çπ„Ç±„Éº„É´‰∏äÈôê (zmax)",
    "Shortage by Role (hours)": "ËÅ∑Á®ÆÂà•‰∏çË∂≥ÊôÇÈñì (h)",
    "Shortage by Employment (hours)": "ÈõáÁî®ÂΩ¢ÊÖãÂà•‰∏çË∂≥ÊôÇÈñì (h)",
    "Shortage by Time (count per day)": "ÊôÇÈñìÂ∏ØÂà•‰∏çË∂≥‰∫∫Êï∞ (Êó•Âà•)",
    "Shortage Frequency (days)": "‰∏çË∂≥Áô∫ÁîüÈ†ªÂ∫¶ (Êó•Êï∞)",
    "Shortage with Leave": "‰∏çË∂≥„Å®‰ºëÊöáÊï∞",
    "Net Shortage": "Â∑ÆÂºï‰∏çË∂≥",
    "Select date to display": "Ë°®Á§∫„Åô„ÇãÊó•‰ªò„ÇíÈÅ∏Êäû",
    "No date columns in shortage data.": "‰∏çË∂≥ÊôÇÈñì„Éá„Éº„Çø„Å´Êó•‰ªòÂàó„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ",
    "Display all time-slot shortage data": "ÂÖ®ÊôÇÈñìÂ∏ØÂà•‰∏çË∂≥„Éá„Éº„ÇøË°®Á§∫",
    "Fatigue Score per Staff": "„Çπ„Çø„ÉÉ„ÉïÂà•Áñ≤Âä¥„Çπ„Ç≥„Ç¢",
    "Demand Forecast (yhat)": "ÈúÄË¶Å‰∫àÊ∏¨ÁµêÊûú (yhat)",
    "Actual (y)": "ÂÆüÁ∏æ (y)",
    "Display forecast data": "‰∫àÊ∏¨„Éá„Éº„ÇøË°®Á§∫",
    "Fairness (Night Shift Ratio)": "ÂÖ¨Âπ≥ÊÄß (Â§úÂã§ÊØîÁéá)",
    "Cost Simulation (Million ¬•)": "„Ç≥„Çπ„ÉàË©¶ÁÆó (Áôæ‰∏áÂÜÜ)",
    "Hiring Plan (Needed FTE)": "Êé°Áî®Ë®àÁîª (ÂøÖË¶ÅÊé°Áî®‰∫∫Êï∞)",
    "Hiring Plan Parameters": "Êé°Áî®Ë®àÁîª„Éë„É©„É°„Éº„Çø",
    "Required FTE per Role": "ËÅ∑Á®ÆÂà•ÂøÖË¶ÅFTEÊï∞",
    "Monthly Shortage Hours by Employment": "ÈõáÁî®ÂΩ¢ÊÖãÂà•ÊúàÊ¨°‰∏çË∂≥ÊôÇÈñì",
    "Generate PowerPoint Report (Œ≤)": "üìä PowerPoint„É¨„Éù„Éº„ÉàÁîüÊàê (Œ≤Áâà)",
    "Generating PowerPoint report...": "PowerPoint„É¨„Éù„Éº„Éà„ÇíÁîüÊàê‰∏≠„Åß„Åô... Â∞ë„ÄÖ„ÅäÂæÖ„Å°„Åè„Å†„Åï„ÅÑ„ÄÇ",
    "PowerPoint report ready.": "PowerPoint„É¨„Éù„Éº„Éà„ÅÆÊ∫ñÂÇô„Åå„Åß„Åç„Åæ„Åó„Åü„ÄÇ",
    "Download Report (PPTX)": "üì• „É¨„Éù„Éº„Éà(PPTX)„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
    "python-pptx library required for PPT": "PowerPoint„É¨„Éù„Éº„Éà„ÅÆÁîüÊàê„Å´„ÅØ `python-pptx` „É©„Ç§„Éñ„É©„É™„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ\n„Ç§„É≥„Çπ„Éà„Éº„É´„Åó„Å¶„Åè„Å†„Åï„ÅÑ: `pip install python-pptx`",
    "Error generating PowerPoint report": "PowerPoint„É¨„Éù„Éº„Éà„ÅÆÁîüÊàê‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü",
    "Click button to generate report.": "„Éú„Çø„É≥„Çí„ÇØ„É™„ÉÉ„ÇØ„Åô„Çã„Å®„ÄÅ‰∏ªË¶Å„Å™ÂàÜÊûêÁµêÊûú„ÇíÂê´„ÇÄPowerPoint„É¨„Éù„Éº„Éà„ÅåÁîüÊàê„Åï„Çå„Åæ„ÅôÔºàÁèæÂú®„ÅØŒ≤Áâà„Åß„ÅôÔºâ„ÄÇ",
    "Holiday file parse error": "‰ºëÊó•„Éï„Ç°„Ç§„É´„ÅÆËß£Êûê„Ç®„É©„Éº",
    "Need forecast": "ÈúÄË¶Å‰∫àÊ∏¨",
    "Forecast days": "‰∫àÊ∏¨Êó•Êï∞",
    "RL Roster": "Âº∑ÂåñÂ≠¶Áøí„Ç∑„Éï„Éà",
    "Estimated Cost Impact (Million ¬•)": "ÊÉ≥ÂÆö„Ç≥„Çπ„ÉàÂΩ±ÈüøÈ°ç (Áôæ‰∏áÂÜÜ)",
    "zmax mode": "zmax „É¢„Éº„Éâ",
    "Manual": "ÊâãÂãï",
    "90th percentile": "90„Éë„Éº„Çª„É≥„Çø„Ç§„É´",
    "95th percentile": "95„Éë„Éº„Çª„É≥„Çø„Ç§„É´",
    "99th percentile": "99„Éë„Éº„Çª„É≥„Çø„Ç§„É´",
    "Month": "Êúà",
    "Time": "ÊôÇÈñìÂ∏Ø",
    "Role": "ËÅ∑Á®Æ",
    "Employment": "ÈõáÁî®ÂΩ¢ÊÖã",
    "Shortage Hours": "‰∏çË∂≥ÊôÇÈñì(h)",
    "Total Leave Days": "Á∑è‰ºëÊöáÊó•Êï∞",
    "Staff": "„Çπ„Çø„ÉÉ„Éï",
    "Score": "„Çπ„Ç≥„Ç¢",
    "Night Shift Ratio": "Â§úÂã§ÊØîÁéá",
    "Need Hours": "ÂøÖË¶ÅÊôÇÈñì(h)",
    "Staff Hours": "ÂÆüÂÉçÊôÇÈñì(h)",
    "Working Days": "Á®ºÂÉçÊó•Êï∞",
    "Note": "ÂÇôËÄÉ",
    "Excess Hours": "ÈÅéÂâ∞ÊôÇÈñì(h)",
    "Excess by Role (hours)": "ËÅ∑Á®ÆÂà•ÈÅéÂâ∞ÊôÇÈñì (h)",
    "Excess by Employment (hours)": "ÈõáÁî®ÂΩ¢ÊÖãÂà•ÈÅéÂâ∞ÊôÇÈñì (h)",
    "Excess by Time (count per day)": "ÊôÇÈñìÂ∏ØÂà•ÈÅéÂâ∞‰∫∫Êï∞ (Êó•Âà•)",
    "Excess Ratio by Time": "ÈÅéÂâ∞ÊØîÁéá (ÊôÇÈñìÂ∏ØÂà•)",
    "Excess Frequency (days)": "ÈÅéÂâ∞Áô∫ÁîüÈ†ªÂ∫¶ (Êó•Êï∞)",
    "No date columns in excess data.": "ÈÅéÂâ∞„Éá„Éº„Çø„Å´Êó•‰ªòÂàó„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ",
    "Display all time-slot excess data": "ÂÖ®ÊôÇÈñìÂ∏ØÂà•ÈÅéÂâ∞„Éá„Éº„ÇøË°®Á§∫",
    "Monthly Excess Hours by Role": "ËÅ∑Á®ÆÂà•ÊúàÊ¨°ÈÅéÂâ∞ÊôÇÈñì",
    "Monthly Excess Hours by Employment": "ÈõáÁî®ÂΩ¢ÊÖãÂà•ÊúàÊ¨°ÈÅéÂâ∞ÊôÇÈñì",
    "hire_fte": "ÂøÖË¶ÅFTE",
    "hire_need": "ÂøÖË¶ÅÊé°Áî®‰∫∫Êï∞",
    "No leave analysis results available.": "‰ºëÊöáÂàÜÊûê„ÅÆÁµêÊûú„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ",
    "Results for {fname}": "{fname} „ÅÆÁµêÊûú",
    "Data": "„Éá„Éº„Çø",
}


def _(text_key: str) -> str:
    return JP.get(text_key, text_key)


def _file_mtime(path: Path) -> float:
    """Return the modification time of a file for cache keys."""
    try:
        return path.stat().st_mtime
    except OSError:
        return 0.0


def _valid_df(df: pd.DataFrame) -> bool:
    """Return True if ``df`` is a non-empty ``pd.DataFrame``."""
    return isinstance(df, pd.DataFrame) and not df.empty


@st.cache_data(show_spinner=False)
def load_excel_cached(
    file_path: str,
    *,
    sheet_name: str | int | None = 0,
    index_col: int | str | None = None,
    parse_dates=None,
    file_mtime: float | None = None,
):
    """Load an Excel file with caching based on file path and mtime."""
    kwargs = {"sheet_name": sheet_name, "index_col": index_col}
    if parse_dates is not None:
        kwargs["parse_dates"] = parse_dates
    return pd.read_excel(file_path, **kwargs)


@st.cache_resource(show_spinner=False)
def load_excelfile_cached(file_path: str, *, file_mtime: float | None = None):
    """Load ``pd.ExcelFile`` with caching so repeated reads are fast.

    ``pd.ExcelFile`` objects are not picklable so we cache the handle as a
    resource rather than using ``st.cache_data``.
    """
    return pd.ExcelFile(file_path)


st.set_page_config(
    page_title="Shift-Suite", layout="wide", initial_sidebar_state="expanded"
)
st.title("üóÇÔ∏è Shift-Suite : Âã§Âãô„Ç∑„Éï„ÉàÂàÜÊûê„ÉÑ„Éº„É´")

master_sheet_keyword = "Âã§ÂãôÂå∫ÂàÜ"

# --- „Çª„ÉÉ„Ç∑„Éß„É≥„Çπ„ÉÜ„Éº„Éà„ÅÆÂàùÊúüÂåñ (‰∏ÄÂ∫¶„Å†„ÅëÂÆüË°å) ---
if "app_initialized" not in st.session_state:
    st.session_state.app_initialized = True
    st.session_state.analysis_done = False
    st.session_state.work_root_path_str = None
    st.session_state.out_dir_path_str = None
    st.session_state.current_step_for_progress = 0

    today_val = datetime.date.today()

    # „Çµ„Ç§„Éâ„Éê„Éº„ÅÆ„Ç¶„Ç£„Ç∏„Çß„ÉÉ„Éà„ÅÆ„Ç≠„Éº„Å®„Éá„Éï„Ç©„É´„ÉàÂÄ§„Çí„Çª„ÉÉ„Ç∑„Éß„É≥„Çπ„ÉÜ„Éº„Éà„Å´ÂàùÊúüË®≠ÂÆö
    st.session_state.slot_input_widget = 30
    st.session_state.header_row_input_widget = 3
    st.session_state.candidate_sheet_list_for_ui = []
    st.session_state.shift_sheets_multiselect_widget = []
    st.session_state._force_update_multiselect_flag = False

    st.session_state.need_ref_start_date_widget = today_val - datetime.timedelta(
        days=59
    )  # ÂàùÊúü„Éá„Éï„Ç©„É´„Éà
    st.session_state.need_ref_end_date_widget = today_val - datetime.timedelta(
        days=1
    )  # ÂàùÊúü„Éá„Éï„Ç©„É´„Éà
    st.session_state._force_update_need_ref_dates_flag = False
    st.session_state._intended_need_ref_start_date = None
    st.session_state._intended_need_ref_end_date = None

    st.session_state.need_stat_method_options_widget = [
        "10„Éë„Éº„Çª„É≥„Çø„Ç§„É´",
        "25„Éë„Éº„Çª„É≥„Çø„Ç§„É´",
        "‰∏≠Â§ÆÂÄ§",
        "Âπ≥ÂùáÂÄ§",
    ]
    st.session_state.need_stat_method_widget = "‰∏≠Â§ÆÂÄ§"
    st.session_state.need_remove_outliers_widget = True

    st.session_state.min_method_for_upper_options_widget = ["mean-1s", "p25", "mode"]
    st.session_state.min_method_for_upper_widget = "p25"
    st.session_state.max_method_for_upper_options_widget = ["mean+1s", "p75"]
    st.session_state.max_method_for_upper_widget = "p75"

    # ‚òÖ ‰ºëÊöáÂàÜÊûê„ÇíÂê´„ÇÄËøΩÂä†„É¢„Ç∏„É•„Éº„É´„É™„Çπ„Éà
    st.session_state.available_ext_opts_widget = [
        "Stats",
        "Anomaly",
        "Fatigue",
        "Cluster",
        "Skill",
        "Fairness",
        "Rest Time Analysis",
        "Work Pattern Analysis",
        "Attendance Analysis",
        "Combined Score",
        "Low Staff Load",
        _("Leave Analysis"),
        "Need forecast",
        "RL roster (PPO)",
        "RL roster (model)",
        "Hire plan",
        "Cost / Benefit",
    ]
    # „Éá„Éï„Ç©„É´„Éà„Åß‰ºëÊöáÂàÜÊûê„ÇÇÈÅ∏ÊäûÁä∂ÊÖã„Å´„Åô„Çã„Åã„ÅØ„ÅäÂ•Ω„Åø„Åß
    st.session_state.ext_opts_multiselect_widget = (
        st.session_state.available_ext_opts_widget[:]
    )

    st.session_state.save_mode_selectbox_options_widget = [
        _("ZIP Download"),
        _("Save to folder"),
    ]
    st.session_state.save_mode_selectbox_widget = _("ZIP Download")

    st.session_state.std_work_hours_widget = 160
    st.session_state.safety_factor_widget = 0.0
    st.session_state.target_coverage_widget = 0.95
    st.session_state.wage_direct_widget = 1500
    st.session_state.wage_temp_widget = 2200
    st.session_state.hiring_cost_once_widget = 180000
    st.session_state.penalty_per_lack_widget = 4000
    st.session_state.forecast_period_widget = 30

    # ‚òÖ ‰ºëÊöáÂàÜÊûêÁî®„Éë„É©„É°„Éº„Çø„ÅÆÂàùÊúüÂåñ
    st.session_state.leave_analysis_target_types_widget = [
        LEAVE_TYPE_REQUESTED,
        LEAVE_TYPE_PAID,
    ]  # „Éá„Éï„Ç©„É´„Éà„Åß‰∏°Êñπ
    st.session_state.leave_concentration_threshold_widget = (
        3  # Â∏åÊúõ‰ºëÈõÜ‰∏≠Â∫¶ÈñæÂÄ§„ÅÆ„Éá„Éï„Ç©„É´„Éà
    )

    # ‚òÖ ‰ºëÊöáÂàÜÊûêÁµêÊûúÊ†ºÁ¥çÁî®
    st.session_state.leave_analysis_results = {}

    st.session_state.rest_time_results = None
    st.session_state.rest_time_monthly = None
    st.session_state.work_pattern_results = None
    st.session_state.work_pattern_monthly = None
    st.session_state.attendance_results = None
    st.session_state.combined_score_results = None
    st.session_state.low_staff_load_results = None
    st.session_state.uploaded_files_info = {}
    st.session_state.file_options = {}
    st.session_state.analysis_results = {}
    log.info("„Çª„ÉÉ„Ç∑„Éß„É≥„Çπ„ÉÜ„Éº„Éà„ÇíÂàùÊúüÂåñ„Åó„Åæ„Åó„Åü„ÄÇ")

# --- „Çµ„Ç§„Éâ„Éê„Éº„ÅÆUIË¶ÅÁ¥† ---
with st.sidebar:
    st.header("üõ†Ô∏è Ëß£ÊûêË®≠ÂÆö")

    st.number_input(
        _("Slot (min)"), 5, 120, key="slot_input_widget", help="ÂàÜÊûê„ÅÆÊôÇÈñìÈñìÈöîÔºàÂàÜÔºâ"
    )

    st.subheader("üìÑ „Ç∑„Éº„ÉàÈÅ∏Êäû„Å®„Éò„ÉÉ„ÉÄ„Éº")

    if st.session_state.get("_force_update_multiselect_flag", False):
        new_options = st.session_state.candidate_sheet_list_for_ui
        current_selection = st.session_state.get("shift_sheets_multiselect_widget", [])
        valid_selection = [s for s in current_selection if s in new_options]
        if not valid_selection and new_options:
            st.session_state.shift_sheets_multiselect_widget = new_options[:]
        elif valid_selection:
            st.session_state.shift_sheets_multiselect_widget = valid_selection
        else:
            st.session_state.shift_sheets_multiselect_widget = []
        st.session_state._force_update_multiselect_flag = False

    st.multiselect(
        _("Select shift sheets to analyze (multiple)"),
        options=st.session_state.candidate_sheet_list_for_ui,
        default=st.session_state.shift_sheets_multiselect_widget,
        key="shift_sheets_multiselect_widget",
    )
    st.number_input(
        _("Header start row (1-indexed)"), 1, 20, key="header_row_input_widget"
    )

    st.subheader(_("Need Calculation Settings (Day of Week Pattern)"))

    if st.session_state.get("_force_update_need_ref_dates_flag", False):
        if st.session_state.get("_intended_need_ref_start_date"):
            st.session_state.need_ref_start_date_widget = (
                st.session_state._intended_need_ref_start_date
            )
        if st.session_state.get("_intended_need_ref_end_date"):
            st.session_state.need_ref_end_date_widget = (
                st.session_state._intended_need_ref_end_date
            )
        st.session_state._force_update_need_ref_dates_flag = False
        if "_intended_need_ref_start_date" in st.session_state:
            del st.session_state["_intended_need_ref_start_date"]
        if "_intended_need_ref_end_date" in st.session_state:
            del st.session_state["_intended_need_ref_end_date"]

    c1_need_ui, c2_need_ui = st.columns(2)
    with c1_need_ui:
        st.date_input(
            _("Start Date"),
            key="need_ref_start_date_widget",
            help="NeedÁÆóÂá∫„ÅÆÂèÇÁÖßÊúüÈñì„ÅÆÈñãÂßãÊó•",
        )
    with c2_need_ui:
        st.date_input(
            _("End Date"),
            key="need_ref_end_date_widget",
            help="NeedÁÆóÂá∫„ÅÆÂèÇÁÖßÊúüÈñì„ÅÆÁµÇ‰∫ÜÊó•",
        )
    st.caption(_("Reference Period for Need Calculation"))

    current_need_stat_method_idx_val = 0
    try:
        current_need_stat_method_idx_val = (
            st.session_state.need_stat_method_options_widget.index(
                st.session_state.need_stat_method_widget
            )
        )
    except (ValueError, AttributeError):
        current_need_stat_method_idx_val = 2
    st.selectbox(
        _("Statistical Metric for Need"),
        options=st.session_state.need_stat_method_options_widget,
        index=current_need_stat_method_idx_val,
        key="need_stat_method_widget",
        help="ÊõúÊó•Âà•„ÉªÊôÇÈñìÂ∏ØÂà•„ÅÆNeed„ÇíÁÆóÂá∫„Åô„ÇãÈöõ„ÅÆÁµ±Ë®àÊåáÊ®ô",
    )
    st.checkbox(
        _("Remove Outliers for Need Calculation"),
        key="need_remove_outliers_widget",
        help="IQRÊ≥ï„ÅßÂ§ñ„ÇåÂÄ§„ÇíÈô§Âéª„Åó„Å¶„Åã„ÇâÁµ±Ë®àÈáè„ÇíË®àÁÆó„Åó„Åæ„Åô",
    )

    with st.expander(_("(Optional) Upper Limit Calculation Method"), expanded=False):
        current_min_method_upper_idx_val = 0
        try:
            current_min_method_upper_idx_val = (
                st.session_state.min_method_for_upper_options_widget.index(
                    st.session_state.min_method_for_upper_widget
                )
            )
        except (ValueError, AttributeError):
            current_min_method_upper_idx_val = 1
        st.selectbox(
            _("Min-staff method (for Upper)"),
            options=st.session_state.min_method_for_upper_options_widget,
            index=current_min_method_upper_idx_val,
            key="min_method_for_upper_widget",
            help="Ôºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ„Éí„Éº„Éà„Éû„ÉÉ„Éó„ÅÆ„Äé‰ª£Ë°®ÁöÑ„Å™‰∏äÈôê„Çπ„Çø„ÉÉ„ÉïÊï∞„Äè„ÅÆÁÆóÂá∫ÊñπÊ≥ï„ÅÆ‰∏ÄÈÉ®",
        )
        current_max_method_upper_idx_val = 0
        try:
            current_max_method_upper_idx_val = (
                st.session_state.max_method_for_upper_options_widget.index(
                    st.session_state.max_method_for_upper_widget
                )
            )
        except (ValueError, AttributeError):
            current_max_method_upper_idx_val = 0
        st.selectbox(
            _("Max-staff method (for Upper)"),
            options=st.session_state.max_method_for_upper_options_widget,
            index=current_max_method_upper_idx_val,
            key="max_method_for_upper_widget",
            help="Ôºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ„Éí„Éº„Éà„Éû„ÉÉ„Éó„ÅÆ„Äé‰ª£Ë°®ÁöÑ„Å™‰∏äÈôê„Çπ„Çø„ÉÉ„ÉïÊï∞„Äè„ÅÆÁÆóÂá∫ÊñπÊ≥ï",
        )

    st.divider()
    st.subheader("ËøΩÂä†ÂàÜÊûê„É¢„Ç∏„É•„Éº„É´")

    st.multiselect(
        _("Extra modules"),
        st.session_state.available_ext_opts_widget,
        default=st.session_state.ext_opts_multiselect_widget,  # ÂàùÊúüÂÄ§„ÅØ„Çª„ÉÉ„Ç∑„Éß„É≥„Çπ„ÉÜ„Éº„Éà„Åã„Çâ
        key="ext_opts_multiselect_widget",
        help="ÂÆüË°å„Åô„ÇãËøΩÂä†„ÅÆÂàÜÊûê„É¢„Ç∏„É•„Éº„É´„ÇíÈÅ∏Êäû„Åó„Åæ„Åô„ÄÇ",
    )

    # ‚òÖ ‰ºëÊöáÂàÜÊûê„ÅåÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅÆ„Åø„ÄÅÈñ¢ÈÄ£„Éë„É©„É°„Éº„ÇøË®≠ÂÆöUI„ÇíË°®Á§∫
    if _("Leave Analysis") in st.session_state.ext_opts_multiselect_widget:
        with st.expander("üìä " + _("Leave Analysis") + " Ë®≠ÂÆö", expanded=True):
            st.multiselect(
                "ÂàÜÊûêÂØæË±°„ÅÆ‰ºëÊöá„Çø„Ç§„Éó",
                options=[
                    LEAVE_TYPE_REQUESTED,
                    LEAVE_TYPE_PAID,
                ],  # Â∞ÜÊù•ÁöÑ„Å´ '„Åù„ÅÆ‰ªñ‰ºëÊöá' „Å™„Å©„ÇÇËøΩÂä†ÂèØËÉΩ
                key="leave_analysis_target_types_widget",
                help="ÂàÜÊûê„Åô„Çã‰ºëÊöá„ÅÆÁ®ÆÈ°û„ÇíÈÅ∏Êäû„Åó„Åæ„Åô„ÄÇ",
            )
            # Â∏åÊúõ‰ºë„ÅåÂàÜÊûêÂØæË±°„Å´Âê´„Åæ„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅÆ„ÅøÈñæÂÄ§Ë®≠ÂÆö„ÇíË°®Á§∫
            if (
                LEAVE_TYPE_REQUESTED
                in st.session_state.leave_analysis_target_types_widget
            ):
                st.number_input(
                    "Â∏åÊúõ‰ºë ÈõÜ‰∏≠Â∫¶Âà§ÂÆöÈñæÂÄ§ (‰∫∫)",
                    min_value=1,
                    step=1,
                    key="leave_concentration_threshold_widget",
                    help="ÂêåÊó•„Å´„Åì„ÅÆ‰∫∫Êï∞‰ª•‰∏ä„ÅÆÂ∏åÊúõ‰ºë„Åå„ÅÇ„Å£„ÅüÂ†¥Âêà„Å´„ÄåÈõÜ‰∏≠„Äç„Å®„Åø„Å™„Åó„Åæ„Åô„ÄÇ",
                )

    current_save_mode_idx_val = 0
    try:
        current_save_mode_idx_val = (
            st.session_state.save_mode_selectbox_options_widget.index(
                st.session_state.save_mode_selectbox_widget
            )
        )
    except (ValueError, AttributeError):
        current_save_mode_idx_val = 0
    st.selectbox(
        _("Save method"),
        options=st.session_state.save_mode_selectbox_options_widget,
        index=current_save_mode_idx_val,
        key="save_mode_selectbox_widget",
        help="Ëß£ÊûêÁµêÊûú„ÅÆ‰øùÂ≠òÊñπÊ≥ï„ÇíÈÅ∏Êäû„Åó„Åæ„Åô„ÄÇ",
    )

    with st.expander(_("Cost & Hire Parameters")):
        st.number_input(
            _("Standard work hours (h/month)"), 100, 300, key="std_work_hours_widget"
        )
        st.slider(
            _("Safety factor (shortage h multiplier)"),
            0.00,
            2.00,
            key="safety_factor_widget",
            help="‰∏çË∂≥ÊôÇÈñì„Å´‰πóÁÆó„Åô„ÇãÂÄçÁéá (‰æã: 1.10 „ÅØ 10% ‰∏ä‰πó„Åõ)",
        )
        st.slider(_("Target coverage rate"), 0.50, 1.00, key="target_coverage_widget")
        st.number_input(
            _("Direct employee labor cost (¬•/h)"), 500, 10000, key="wage_direct_widget"
        )
        st.number_input(
            _("Temporary staff labor cost (¬•/h)"), 800, 12000, key="wage_temp_widget"
        )
        st.number_input(
            _("One-time hiring cost (¬•/person)"),
            0,
            1000000,
            key="hiring_cost_once_widget",
        )
        st.number_input(
            _("Penalty for shortage (¬•/h)"), 0, 20000, key="penalty_per_lack_widget"
        )

    st.number_input(
        _("Forecast days"),
        1,
        365,
        key="forecast_period_widget",
        help="Need forecast „É¢„Ç∏„É•„Éº„É´„ÅßÂÖàË™≠„Åø„Åô„ÇãÊó•Êï∞",
    )

# --- „É°„Ç§„É≥„Ç≥„É≥„ÉÜ„É≥„ÉÑ„Ç®„É™„Ç¢ ---
st.header("1. „Éï„Ç°„Ç§„É´„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Å®Ë®≠ÂÆö")
uploaded_files = st.file_uploader(
    _("Upload Excel shift file (*.xlsx)"),
    type=["xlsx"],
    key="excel_uploader_main_content_area_key",
    help="Âã§ÂãôÂÆüÁ∏æ„Å®Âã§ÂãôÂå∫ÂàÜ„ÅåË®òËºâ„Åï„Çå„ÅüExcel„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
    accept_multiple_files=True,
)
holiday_file_global_uploaded = st.file_uploader(
    _("Global holiday file (CSV or JSON)"),
    type=["csv", "json"],
    key="holiday_file_global_widget",
    help="ÂÖ®ÂõΩÂÖ±ÈÄö„ÅÆÁ•ùÊó•„Å™„Å© (YYYY-MM-DD)",
)
holiday_file_local_uploaded = st.file_uploader(
    _("Local holiday file (CSV or JSON)"),
    type=["csv", "json"],
    key="holiday_file_local_widget",
    help="ÊñΩË®≠Âõ∫Êúâ„ÅÆ‰ºëÊ•≠Êó• (YYYY-MM-DD)",
)

if uploaded_files:
    for uploaded_file in uploaded_files:
        saved_info = st.session_state.uploaded_files_info.get(uploaded_file.name)
        if saved_info is None or saved_info.get("size") != uploaded_file.size:
            if (
                st.session_state.work_root_path_str is None
                or not Path(st.session_state.work_root_path_str).exists()
            ):
                st.session_state.work_root_path_str = tempfile.mkdtemp(
                    prefix="ShiftSuite_"
                )
                log.info(
                    f"Êñ∞„Åó„ÅÑ‰∏ÄÊôÇ„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê„Åó„Åæ„Åó„Åü: {st.session_state.work_root_path_str}"
                )

            st.session_state.analysis_done = False
            work_root_on_upload = Path(st.session_state.work_root_path_str)
            excel_path_for_processing = work_root_on_upload / uploaded_file.name

            try:
                with open(excel_path_for_processing, "wb") as f_wb:
                    f_wb.write(uploaded_file.getbuffer())
                log.info(
                    f"„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åï„Çå„ÅüExcel„Éï„Ç°„Ç§„É´„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü: {excel_path_for_processing}"
                )
                st.session_state.uploaded_files_info[uploaded_file.name] = {
                    "path": str(excel_path_for_processing),
                    "size": uploaded_file.size,
                }

                # --- NEW: „Ç∑„Éº„ÉàÂêç„É™„Çπ„Éà„ÇíÂèñÂæó„Åó„Å¶UI„ÇíÊõ¥Êñ∞ ---
                try:
                    xls = pd.ExcelFile(excel_path_for_processing)
                    candidate_sheets = [
                        s for s in xls.sheet_names if master_sheet_keyword not in s
                    ]
                    if not candidate_sheets:
                        st.warning(_("No analysis target sheets found"))
                    st.session_state.candidate_sheet_list_for_ui = (
                        candidate_sheets or []
                    )
                    st.session_state._force_update_multiselect_flag = True
                    st.rerun()
                except Exception as e_get_sheet:
                    log_and_display_error(
                        _("Error getting sheet names from Excel"), e_get_sheet
                    )
            except Exception as e_save_file_process:
                log_and_display_error(_("Error saving Excel file"), e_save_file_process)

# „ÄåËß£ÊûêÂÆüË°å„Äç„Éú„Çø„É≥
run_button_disabled_status = (
    not st.session_state.uploaded_files_info
    or not st.session_state.get("shift_sheets_multiselect_widget", [])
)
run_button_clicked = st.button(
    _("Run Analysis"),
    key="run_analysis_button_final_trigger",
    use_container_width=True,
    type="primary",
    disabled=run_button_disabled_status,
)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  app.py  (Part 2 / 3)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if run_button_clicked:
    st.session_state.analysis_done = False
    st.session_state.analysis_results = {}

    holiday_dates_global_for_run = None
    holiday_dates_local_for_run = None

    def _read_holiday_upload(uploaded_file):
        if uploaded_file.name.lower().endswith(".json"):
            import json

            return [pd.to_datetime(d).date() for d in json.load(uploaded_file)]
        df_h = pd.read_csv(uploaded_file, header=None)
        return [pd.to_datetime(x).date() for x in df_h.iloc[:, 0].dropna().unique()]

    if holiday_file_global_uploaded is not None:
        try:
            holiday_dates_global_for_run = _read_holiday_upload(
                holiday_file_global_uploaded
            )
        except Exception as e_hread:
            st.warning(_("Holiday file parse error") + f": {e_hread}")
            log.warning(f"Holiday file parse error: {e_hread}")

    if holiday_file_local_uploaded is not None:
        try:
            holiday_dates_local_for_run = _read_holiday_upload(
                holiday_file_local_uploaded
            )
        except Exception as e_hread:
            st.warning(_("Holiday file parse error") + f": {e_hread}")
            log.warning(f"Holiday file parse error: {e_hread}")

    for file_name, file_info in st.session_state.uploaded_files_info.items():
        st.session_state.current_step_for_progress = 0

        excel_path_to_use = Path(file_info["path"])
        if (
            st.session_state.work_root_path_str is None
            or not excel_path_to_use.exists()
        ):
            log_and_display_error(
                "Excel„Éï„Ç°„Ç§„É´„ÅåÊ≠£„Åó„Åè„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ„Éï„Ç°„Ç§„É´„ÇíÂÜç„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
                FileNotFoundError(excel_path_to_use),
            )
            st.stop()

        work_root_exec = excel_path_to_use.parent
        st.session_state.out_dir_path_str = str(work_root_exec / "out")
        out_dir_exec = Path(st.session_state.out_dir_path_str)
        out_dir_exec.mkdir(parents=True, exist_ok=True)
        log.info(f"Ëß£ÊûêÂá∫Âäõ„Éá„Ç£„É¨„ÇØ„Éà„É™: {out_dir_exec} (file: {file_name})")

        # --- ÂÆüË°åÊôÇ„ÅÆUI„ÅÆÂÄ§„Çí„Çª„ÉÉ„Ç∑„Éß„É≥„Çπ„ÉÜ„Éº„Éà„Åã„ÇâÂèñÂæó ---
        param_selected_sheets = st.session_state.shift_sheets_multiselect_widget
        param_header_row = st.session_state.header_row_input_widget
        param_slot = st.session_state.slot_input_widget
        param_ref_start = st.session_state.need_ref_start_date_widget
        param_ref_end = st.session_state.need_ref_end_date_widget
        param_need_stat = st.session_state.need_stat_method_widget
        param_need_outlier = st.session_state.need_remove_outliers_widget
        param_min_method_upper = st.session_state.min_method_for_upper_widget
        param_max_method_upper = st.session_state.max_method_for_upper_widget
        param_ext_opts = st.session_state.ext_opts_multiselect_widget
        param_save_mode = st.session_state.save_mode_selectbox_widget
        param_std_work_hours = st.session_state.std_work_hours_widget
        param_safety_factor = st.session_state.safety_factor_widget
        param_target_coverage = st.session_state.target_coverage_widget
        param_wage_direct = st.session_state.wage_direct_widget
        param_wage_temp = st.session_state.wage_temp_widget
        param_hiring_cost = st.session_state.hiring_cost_once_widget
        param_penalty_lack = st.session_state.penalty_per_lack_widget
        param_forecast_period = st.session_state.forecast_period_widget

        # ‚òÖ ‰ºëÊöáÂàÜÊûêÁî®„Éë„É©„É°„Éº„Çø„ÅÆÂèñÂæó
        param_leave_target_types = st.session_state.leave_analysis_target_types_widget
        param_leave_concentration_threshold = (
            st.session_state.leave_concentration_threshold_widget
        )

        # ‚òÖ „Çª„ÉÉ„Ç∑„Éß„É≥„Çπ„ÉÜ„Éº„ÉàÂÜÖ„ÅÆÂâçÂõûÁµêÊûú„Çí„ÇØ„É™„Ç¢
        st.session_state.leave_analysis_results = {}
        # --- UIÂÄ§ÂèñÂæó„Åì„Åì„Åæ„Åß ---

        st.session_state.rest_time_results = None
        st.session_state.work_pattern_results = None
        st.session_state.attendance_results = None
        st.session_state.combined_score_results = None
        st.session_state.low_staff_load_results = None
        progress_text_area = st.empty()
        progress_bar_val = st.progress(0)
        total_steps_exec_run = 3 + len(param_ext_opts)

        def update_progress_exec_run(step_name_key_exec: str):
            st.session_state.current_step_for_progress += 1
            progress_percentage_exec_run = int(
                (st.session_state.current_step_for_progress / total_steps_exec_run)
                * 100
            )
            progress_percentage_exec_run = min(progress_percentage_exec_run, 100)
            try:
                progress_bar_val.progress(progress_percentage_exec_run)
                progress_text_area.info(
                    f"‚öôÔ∏è {st.session_state.current_step_for_progress}/{total_steps_exec_run} - {_(step_name_key_exec)}"
                )
            except Exception as e_prog_exec_run:
                log.warning(f"ÈÄ≤ÊçóË°®Á§∫„ÅÆÊõ¥Êñ∞‰∏≠„Å´„Ç®„É©„Éº: {e_prog_exec_run}")

        st.markdown("---")
        st.header("2. Ëß£ÊûêÂá¶ÁêÜ")
        try:
            if param_selected_sheets and excel_path_to_use:
                update_progress_exec_run("File Preview (first 8 rows)")
                st.subheader(_("File Preview (first 8 rows)"))
                try:
                    preview_df_exec_run = pd.read_excel(
                        excel_path_to_use,
                        sheet_name=param_selected_sheets[0],
                        header=None,
                        nrows=8,
                    )
                    st.dataframe(
                        preview_df_exec_run.astype(str), use_container_width=True
                    )
                except Exception as e_prev_exec_run:
                    st.warning(
                        _("Error during preview display") + f": {e_prev_exec_run}"
                    )
                    log.warning(
                        f"„Éó„É¨„Éì„É•„ÉºË°®Á§∫„Ç®„É©„Éº: {e_prev_exec_run}", exc_info=True
                    )
            else:
                st.warning(
                    "„Éó„É¨„Éì„É•„Éº„ÇíË°®Á§∫„Åô„Çã„Ç∑„Éº„Éà„ÅåÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑ„Åã„ÄÅ„Éï„Ç°„Ç§„É´„Éë„Çπ„ÅåÁÑ°Âäπ„Åß„Åô„ÄÇ"
                )

            update_progress_exec_run("Ingest: Reading Excel data...")
            long_df, wt_df = ingest_excel(
                excel_path_to_use,
                shift_sheets=param_selected_sheets,
                header_row=param_header_row,
                slot_minutes=param_slot,
            )
            log.info(
                f"IngestÂÆå‰∫Ü. long_df shape: {long_df.shape}, wt_df shape: {wt_df.shape if wt_df is not None else 'N/A'}"
            )
            st.success(_("Ingest: Excel data read complete."))

            update_progress_exec_run("Heatmap: Generating heatmap...")
            build_heatmap(
                long_df,
                out_dir_exec,
                param_slot,
                ref_start_date_for_need=param_ref_start,
                ref_end_date_for_need=param_ref_end,
                need_statistic_method=param_need_stat,
                need_remove_outliers=param_need_outlier,
                need_iqr_multiplier=1.5,
                min_method=param_min_method_upper,
                max_method=param_max_method_upper,
            )
            st.success("‚úÖ HeatmapÁîüÊàêÂÆå‰∫Ü")

            update_progress_exec_run("Shortage: Analyzing shortage...")
            shortage_result_exec_run = shortage_and_brief(
                out_dir_exec,
                param_slot,
                holidays_global=holiday_dates_global_for_run,
                holidays_local=holiday_dates_local_for_run,
            )
            if shortage_result_exec_run is None:
                st.warning("Shortage (‰∏çË∂≥ÂàÜÊûê) „ÅÆ‰∏ÄÈÉ®„Åæ„Åü„ÅØÂÖ®„Å¶„ÅåÂÆå‰∫Ü„Åó„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ")
            else:
                st.success("‚úÖ Shortage (‰∏çË∂≥ÂàÜÊûê) ÂÆå‰∫Ü")
                if "Hire plan" in param_ext_opts:
                    try:
                        build_hire_plan_from_kpi(
                            out_dir_exec,
                            monthly_hours_fte=param_std_work_hours,
                            hourly_wage=param_wage_direct,
                            recruit_cost=param_hiring_cost,
                            safety_factor=param_safety_factor,
                        )
                    except Exception as e:
                        log.warning(f"hire_plan generation error: {e}")

            # ‚òÖ----- ‰ºëÊöáÂàÜÊûê„É¢„Ç∏„É•„Éº„É´„ÅÆÂÆüË°å -----‚òÖ
            # "‰ºëÊöáÂàÜÊûê" (Êó•Êú¨Ë™û) „ÅåÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç
            if _("Leave Analysis") in param_ext_opts:
                update_progress_exec_run("Leave Analysis: Processing...")
                st.info(f"{_('Leave Analysis')} Âá¶ÁêÜ‰∏≠‚Ä¶")
                try:
                    if "long_df" in locals() and not long_df.empty:
                        # 1. Êó•Ê¨°„ÉªËÅ∑Âì°Âà•„ÅÆ‰ºëÊöáÂèñÂæó„Éï„É©„Ç∞„Éá„Éº„Çø„ÇíÁîüÊàê
                        daily_leave_df = leave_analyzer.get_daily_leave_counts(
                            long_df, target_leave_types=param_leave_target_types
                        )
                        st.session_state.leave_analysis_results["daily_leave_df"] = (
                            daily_leave_df
                        )

                        if not daily_leave_df.empty:
                            leave_results_temp = {}  # ‰∏ÄÊôÇÁöÑ„Å™ÁµêÊûúÊ†ºÁ¥çÁî®

                            # 2. Â∏åÊúõ‰ºëÈñ¢ÈÄ£„ÅÆÈõÜË®à„Å®ÂàÜÊûê
                            if LEAVE_TYPE_REQUESTED in param_leave_target_types:
                                requested_leave_daily = daily_leave_df[
                                    daily_leave_df["leave_type"] == LEAVE_TYPE_REQUESTED
                                ]
                                if not requested_leave_daily.empty:
                                    leave_results_temp["summary_dow_requested"] = (
                                        leave_analyzer.summarize_leave_by_day_count(
                                            requested_leave_daily.copy(),
                                            period="dayofweek",
                                        )
                                    )
                                    leave_results_temp[
                                        "summary_month_period_requested"
                                    ] = leave_analyzer.summarize_leave_by_day_count(
                                        requested_leave_daily.copy(),
                                        period="month_period",
                                    )
                                    leave_results_temp["summary_month_requested"] = (
                                        leave_analyzer.summarize_leave_by_day_count(
                                            requested_leave_daily.copy(), period="month"
                                        )
                                    )

                                    daily_requested_applicants_counts = (
                                        leave_analyzer.summarize_leave_by_day_count(
                                            requested_leave_daily.copy(), period="date"
                                        )
                                    )
                                    leave_results_temp["concentration_requested"] = (
                                        leave_analyzer.analyze_leave_concentration(
                                            daily_requested_applicants_counts,
                                            leave_type_to_analyze=LEAVE_TYPE_REQUESTED,
                                            concentration_threshold=param_leave_concentration_threshold,
                                            daily_leave_df=requested_leave_daily.copy(),
                                        )
                                    )
                                    # --- Êñ∞Ë¶è: Âã§Âãô‰∫àÂÆö‰∫∫Êï∞„Å®„ÅÆÊØîËºÉ„Éá„Éº„Çø‰ΩúÊàê ---
                                    try:
                                        total_staff_per_day = (
                                            long_df[long_df["parsed_slots_count"] > 0]
                                            .assign(
                                                date=lambda df: pd.to_datetime(
                                                    df["ds"]
                                                ).dt.normalize()
                                            )
                                            .groupby("date")["staff"]
                                            .nunique()
                                            .reset_index(name="total_staff")
                                        )
                                        staff_balance = total_staff_per_day.merge(
                                            daily_requested_applicants_counts.rename(
                                                columns={
                                                    "total_leave_days": "leave_applicants_count"
                                                }
                                            )[["date", "leave_applicants_count"]],
                                            on="date",
                                            how="left",
                                        )
                                        staff_balance["leave_applicants_count"] = (
                                            staff_balance["leave_applicants_count"]
                                            .fillna(0)
                                            .astype(int)
                                        )
                                        staff_balance["non_leave_staff"] = (
                                            staff_balance["total_staff"]
                                            - staff_balance["leave_applicants_count"]
                                        )
                                        staff_balance["leave_ratio"] = (
                                            staff_balance["leave_applicants_count"]
                                            / staff_balance["total_staff"]
                                        )
                                        leave_results_temp["staff_balance_daily"] = (
                                            staff_balance
                                        )
                                    except Exception as e:
                                        log.error(f"Âã§Âãô‰∫àÂÆö‰∫∫Êï∞„ÅÆË®àÁÆó‰∏≠„Å´„Ç®„É©„Éº: {e}")
                                else:
                                    log.info(
                                        f"{LEAVE_TYPE_REQUESTED} „ÅÆ„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çâ„Å™„Åã„Å£„Åü„Åü„ÇÅ„ÄÅÈñ¢ÈÄ£„Åô„ÇãÈõÜË®à„ÉªÂàÜÊûê„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åó„Åü„ÄÇ"
                                    )
                                    leave_results_temp["summary_dow_requested"] = (
                                        pd.DataFrame()
                                    )
                                    leave_results_temp[
                                        "summary_month_period_requested"
                                    ] = pd.DataFrame()
                                    leave_results_temp["summary_month_requested"] = (
                                        pd.DataFrame()
                                    )
                                    leave_results_temp["concentration_requested"] = (
                                        pd.DataFrame()
                                    )

                            # 3. ÊúâÁµ¶‰ºëÊöáÈñ¢ÈÄ£„ÅÆÈõÜË®à
                            if LEAVE_TYPE_PAID in param_leave_target_types:
                                paid_leave_daily = daily_leave_df[
                                    daily_leave_df["leave_type"] == LEAVE_TYPE_PAID
                                ]
                                if not paid_leave_daily.empty:
                                    leave_results_temp["summary_dow_paid"] = (
                                        leave_analyzer.summarize_leave_by_day_count(
                                            paid_leave_daily.copy(), period="dayofweek"
                                        )
                                    )
                                    leave_results_temp["summary_month_paid"] = (
                                        leave_analyzer.summarize_leave_by_day_count(
                                            paid_leave_daily.copy(), period="month"
                                        )
                                    )
                                else:
                                    log.info(
                                        f"{LEAVE_TYPE_PAID} „ÅÆ„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çâ„Å™„Åã„Å£„Åü„Åü„ÇÅ„ÄÅÈñ¢ÈÄ£„Åô„ÇãÈõÜË®à„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åó„Åü„ÄÇ"
                                    )
                                    leave_results_temp["summary_dow_paid"] = (
                                        pd.DataFrame()
                                    )
                                    leave_results_temp["summary_month_paid"] = (
                                        pd.DataFrame()
                                    )

                            # 4. ËÅ∑Âì°Âà•‰ºëÊöá„É™„Çπ„Éà (ÁµÇÊó•„ÅÆ„Åø)
                            leave_results_temp["staff_leave_list"] = (
                                leave_analyzer.get_staff_leave_list(
                                    long_df, target_leave_types=param_leave_target_types
                                )
                            )

                            st.session_state.leave_analysis_results.update(
                                leave_results_temp
                            )

                            # Save summary by date for external use
                            try:
                                daily_summary = (
                                    leave_analyzer.summarize_leave_by_day_count(
                                        daily_leave_df.copy(), period="date"
                                    )
                                )
                                st.session_state.leave_analysis_results[
                                    "daily_summary"
                                ] = daily_summary
                                try:
                                    both_conc = leave_analyzer.analyze_both_leave_concentration(
                                        daily_summary.copy(),
                                        concentration_threshold=param_leave_concentration_threshold,
                                    )
                                    st.session_state.leave_analysis_results[
                                        "concentration_both"
                                    ] = both_conc
                                except Exception as e_both:
                                    log.warning(
                                        f"concentration_both generation error: {e_both}"
                                    )
                                leave_csv = out_dir_exec / "leave_analysis.csv"
                                daily_summary.to_csv(leave_csv, index=False)

                                # Also generate shortage_leave.xlsx for the Shortage tab
                                merge_shortage_leave(out_dir_exec, leave_csv=leave_csv)
                            except Exception as e_save:
                                log.warning(
                                    f"leave_analysis.csv Êõ∏„ÅçÂá∫„Åó„Åæ„Åü„ÅØ shortage_leave.xlsx ÁîüÊàê‰∏≠„Å´„Ç®„É©„Éº: {e_save}"
                                )

                            st.success(f"‚úÖ {_('Leave Analysis')} ÂÆå‰∫Ü")
                        else:
                            st.info(
                                f"{_('Leave Analysis')}: ÂàÜÊûêÂØæË±°„Å®„Å™„Çã‰ºëÊöá„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ"
                            )
                    else:
                        st.warning(
                            f"{_('Leave Analysis')}: ÂâçÊèê„Å®„Å™„Çã long_df „ÅåÂ≠òÂú®„Åó„Å™„ÅÑ„ÅãÁ©∫„ÅÆ„Åü„ÇÅ„ÄÅÂá¶ÁêÜ„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åó„Åü„ÄÇ"
                        )
                except Exception as e_leave:
                    log_and_display_error(
                        f"{_('Leave Analysis')} „ÅÆÂá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü", e_leave
                    )
            # ‚òÖ----- ‰ºëÊöáÂàÜÊûê„É¢„Ç∏„É•„Éº„É´„ÅÆÂÆüË°å„Åì„Åì„Åæ„Åß -----‚òÖ

            # ‰ªñ„ÅÆËøΩÂä†„É¢„Ç∏„É•„Éº„É´„ÅÆÂÆüË°å
            for opt_module_name_exec_run in st.session_state.available_ext_opts_widget:
                if (
                    opt_module_name_exec_run in param_ext_opts
                    and opt_module_name_exec_run != _("Leave Analysis")
                ):
                    progress_key_exec_run = f"{opt_module_name_exec_run}: Processing..."
                    update_progress_exec_run(progress_key_exec_run)
                    st.info(f"{_(opt_module_name_exec_run)} Âá¶ÁêÜ‰∏≠‚Ä¶")
                    try:
                        if opt_module_name_exec_run == "Stats":
                            build_stats(out_dir_exec)
                        elif opt_module_name_exec_run == "Anomaly":
                            detect_anomaly(out_dir_exec)
                        elif opt_module_name_exec_run == "Fatigue":
                            train_fatigue(long_df, out_dir_exec)
                        elif opt_module_name_exec_run == "Cluster":
                            cluster_staff(long_df, out_dir_exec)
                        elif opt_module_name_exec_run == "Skill":
                            build_skill_matrix(long_df, out_dir_exec)
                        elif opt_module_name_exec_run == "Fairness":
                            run_fairness(long_df, out_dir_exec)
                        elif opt_module_name_exec_run == "Rest Time Analysis":
                            rta = RestTimeAnalyzer()
                            st.session_state.rest_time_results = rta.analyze(
                                long_df, slot_minutes=param_slot
                            )
                            st.session_state.rest_time_results.to_csv(
                                out_dir_exec / "rest_time.csv", index=False
                            )
                            st.session_state.rest_time_monthly = rta.monthly(
                                st.session_state.rest_time_results
                            )
                            if st.session_state.rest_time_monthly is not None:
                                st.session_state.rest_time_monthly.to_csv(
                                    out_dir_exec / "rest_time_monthly.csv", index=False
                                )
                        elif opt_module_name_exec_run == "Work Pattern Analysis":
                            wpa = WorkPatternAnalyzer()
                            st.session_state.work_pattern_results = wpa.analyze(long_df)
                            st.session_state.work_pattern_results.to_csv(
                                out_dir_exec / "work_patterns.csv", index=False
                            )
                            st.session_state.work_pattern_monthly = wpa.analyze_monthly(
                                long_df
                            )
                            if st.session_state.work_pattern_monthly is not None:
                                st.session_state.work_pattern_monthly.to_csv(
                                    out_dir_exec / "work_pattern_monthly.csv",
                                    index=False,
                                )
                        elif opt_module_name_exec_run == "Attendance Analysis":
                            st.session_state.attendance_results = (
                                AttendanceBehaviorAnalyzer().analyze(long_df)
                            )
                            st.session_state.attendance_results.to_csv(
                                out_dir_exec / "attendance.csv", index=False
                            )
                        elif opt_module_name_exec_run == "Low Staff Load":
                            lsl = LowStaffLoadAnalyzer()
                            st.session_state.low_staff_load_results = lsl.analyze(
                                long_df, threshold=0.25
                            )
                            st.session_state.low_staff_load_results.to_csv(
                                out_dir_exec / "low_staff_load.csv", index=False
                            )
                        elif opt_module_name_exec_run == "Combined Score":
                            rest_df = (
                                st.session_state.rest_time_results
                                if st.session_state.rest_time_results is not None
                                else pd.DataFrame()
                            )
                            work_df = (
                                st.session_state.work_pattern_results
                                if st.session_state.work_pattern_results is not None
                                else pd.DataFrame()
                            )
                            att_df = (
                                st.session_state.attendance_results
                                if st.session_state.attendance_results is not None
                                else pd.DataFrame()
                            )
                            st.session_state.combined_score_results = (
                                CombinedScoreCalculator().calculate(
                                    rest_df, work_df, att_df
                                )
                            )
                            st.session_state.combined_score_results.to_csv(
                                out_dir_exec / "combined_score.csv", index=False
                            )
                        elif opt_module_name_exec_run == "Need forecast":
                            demand_csv_exec_run_fc = out_dir_exec / "demand_series.csv"
                            forecast_xls_exec_run_fc = out_dir_exec / "forecast.xlsx"
                            heat_all_for_fc_exec_run_fc = out_dir_exec / "heat_ALL.xlsx"
                            if not heat_all_for_fc_exec_run_fc.exists():
                                st.warning(
                                    _("Need forecast")
                                    + f": ÂøÖÈ†à„Éï„Ç°„Ç§„É´ {heat_all_for_fc_exec_run_fc.name} „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"
                                )
                            else:
                                build_demand_series(
                                    heat_all_for_fc_exec_run_fc,
                                    demand_csv_exec_run_fc,
                                    leave_csv=out_dir_exec / "leave_analysis.csv"
                                    if (out_dir_exec / "leave_analysis.csv").exists()
                                    else None,
                                )
                                if demand_csv_exec_run_fc.exists():
                                    fc_leave = out_dir_exec / "leave_analysis.csv"
                                    forecast_need(
                                        demand_csv_exec_run_fc,
                                        forecast_xls_exec_run_fc,
                                        periods=param_forecast_period,
                                        leave_csv=fc_leave
                                        if fc_leave.exists()
                                        else None,
                                        holidays=(holiday_dates_global_for_run or [])
                                        + (holiday_dates_local_for_run or []),
                                        log_csv=out_dir_exec / "forecast_history.csv",
                                    )
                                else:
                                    st.warning(
                                        _("Need forecast")
                                        + ": demand_series.csv „ÅÆÁîüÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ"
                                    )
                        elif opt_module_name_exec_run == "RL roster (PPO)":
                            demand_csv_rl_exec_run_rl = (
                                out_dir_exec / "demand_series.csv"
                            )
                            rl_roster_xls_exec_run_rl = out_dir_exec / "rl_roster.xlsx"
                            model_zip_rl = out_dir_exec / "ppo_model.zip"
                            fc_xls = out_dir_exec / "forecast.xlsx"
                            shortage_xlsx = out_dir_exec / "shortage_time.xlsx"
                            if demand_csv_rl_exec_run_rl.exists():
                                learn_roster(
                                    demand_csv_rl_exec_run_rl,
                                    rl_roster_xls_exec_run_rl,
                                    forecast_csv=fc_xls if fc_xls.exists() else None,
                                    shortage_csv=shortage_xlsx
                                    if shortage_xlsx.exists()
                                    else None,
                                    model_path=model_zip_rl,
                                )
                            else:
                                st.warning(
                                    _("RL Roster")
                                    + ": ÈúÄË¶Å‰∫àÊ∏¨„Éá„Éº„Çø (demand_series.csv) „Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ"
                                )
                        elif opt_module_name_exec_run == "RL roster (model)":
                            demand_csv_rl_exec_run_rl = (
                                out_dir_exec / "demand_series.csv"
                            )
                            rl_roster_xls_use = out_dir_exec / "rl_roster.xlsx"
                            model_zip_rl = out_dir_exec / "ppo_model.zip"
                            fc_xls = out_dir_exec / "forecast.xlsx"
                            shortage_xlsx = out_dir_exec / "shortage_time.xlsx"
                            if model_zip_rl.exists() and fc_xls.exists():
                                learn_roster(
                                    demand_csv_rl_exec_run_rl
                                    if demand_csv_rl_exec_run_rl.exists()
                                    else fc_xls,
                                    rl_roster_xls_use,
                                    forecast_csv=fc_xls,
                                    shortage_csv=shortage_xlsx
                                    if shortage_xlsx.exists()
                                    else None,
                                    model_path=model_zip_rl,
                                    use_saved_model=True,
                                )
                            else:
                                st.warning(
                                    _("RL Roster")
                                    + ": Â≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„Åæ„Åü„ÅØ forecast.xlsx „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"
                                )
                        elif opt_module_name_exec_run == "Hire plan":
                            demand_csv_hp_exec_run_hp = (
                                out_dir_exec / "demand_series.csv"
                            )
                            hire_xls_exec_run_hp = out_dir_exec / "hire_plan.xlsx"
                            if demand_csv_hp_exec_run_hp.exists():
                                build_hire_plan(
                                    demand_csv_hp_exec_run_hp,
                                    hire_xls_exec_run_hp,
                                    param_std_work_hours,
                                    param_safety_factor,
                                    param_target_coverage,
                                )
                            else:
                                st.warning(
                                    _("Hire Plan")
                                    + ": ÈúÄË¶Å‰∫àÊ∏¨„Éá„Éº„Çø (demand_series.csv) „Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ"
                                )
                        elif opt_module_name_exec_run == "Cost / Benefit":
                            analyze_cost_benefit(
                                out_dir_exec,
                                param_wage_direct,
                                param_wage_temp,
                                param_hiring_cost,
                                param_penalty_lack,
                            )
                        st.success(f"‚úÖ {_(opt_module_name_exec_run)} ÂÆå‰∫Ü")
                    except FileNotFoundError as fe_opt_exec_run_loop:
                        log_and_display_error(
                            f"{_(opt_module_name_exec_run)} „ÅÆÂá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº („Éï„Ç°„Ç§„É´Êú™Ê§úÂá∫)",
                            fe_opt_exec_run_loop,
                        )
                        log.error(
                            f"{opt_module_name_exec_run} Âá¶ÁêÜ„Ç®„É©„Éº (FileNotFoundError): {fe_opt_exec_run_loop}",
                            exc_info=True,
                        )
                    except Exception as e_opt_exec_run_loop:
                        log_and_display_error(
                            f"{_(opt_module_name_exec_run)} „ÅÆÂá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü",
                            e_opt_exec_run_loop,
                        )
                        log.error(
                            f"{opt_module_name_exec_run} Âá¶ÁêÜ„Ç®„É©„Éº: {e_opt_exec_run_loop}",
                            exc_info=True,
                        )

            progress_bar_val.progress(100)
            progress_text_area.success("‚ú® ÂÖ®Â∑•Á®ãÂÆå‰∫ÜÔºÅ")
            st.balloons()
            st.success(_("All processes complete!"))
            st.session_state.analysis_done = True
        except ValueError as ve_exec_run_main:
            log_and_display_error(
                _("Error during analysis (ValueError)"), ve_exec_run_main
            )
            log.error(f"Ëß£Êûê„Ç®„É©„Éº (ValueError): {ve_exec_run_main}", exc_info=True)
            st.session_state.analysis_done = False
        except FileNotFoundError as fe_exec_run_main:
            log_and_display_error(_("Required file not found"), fe_exec_run_main)
            log.error(f"„Éï„Ç°„Ç§„É´Êú™Ê§úÂá∫„Ç®„É©„Éº: {fe_exec_run_main}", exc_info=True)
            st.session_state.analysis_done = False
        except Exception as e_exec_run_main:
            log_and_display_error(_("Unexpected error occurred"), e_exec_run_main)
            log.error(f"‰∫àÊúü„Åõ„Å¨„Ç®„É©„Éº: {e_exec_run_main}", exc_info=True)
            st.session_state.analysis_done = False
        finally:
            if "progress_bar_val" in locals() and progress_bar_val is not None:
                progress_bar_val.empty()
            if "progress_text_area" in locals() and progress_text_area is not None:
                progress_text_area.empty()

        if st.session_state.analysis_done and st.session_state.out_dir_path_str:
            out_dir_to_save_exec_main_run = Path(st.session_state.out_dir_path_str)
            if out_dir_to_save_exec_main_run.exists():
                st.markdown("---")
                st.header("3. " + _("Save Analysis Results"))
                current_save_mode_exec_main_run = (
                    st.session_state.save_mode_selectbox_widget
                )
                if current_save_mode_exec_main_run == _("Save to folder"):
                    st.info(_("Output folder") + f": `{out_dir_to_save_exec_main_run}`")
                    st.markdown(_("Open the above path in Explorer."))
                else:  # ZIP Download
                    zip_base_name_exec_main_run = f"ShiftSuite_Analysis_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    if st.session_state.work_root_path_str is None:
                        log_and_display_error(
                            "‰∏ÄÊôÇ‰ΩúÊ•≠„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇZIP„Éï„Ç°„Ç§„É´„ÅÆ‰ΩúÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ",
                            FileNotFoundError("work_root"),
                        )
                    else:
                        work_root_for_zip_dl_exec_main_run = Path(
                            st.session_state.work_root_path_str
                        )
                        zip_path_obj_to_download_exec_main_run = (
                            work_root_for_zip_dl_exec_main_run
                            / f"{zip_base_name_exec_main_run}.zip"
                        )
                        try:
                            with zipfile.ZipFile(
                                zip_path_obj_to_download_exec_main_run,
                                "w",
                                zipfile.ZIP_DEFLATED,
                            ) as zf_dl_exec_main_run:
                                for (
                                    file_to_zip_dl_exec_main_run
                                ) in out_dir_to_save_exec_main_run.rglob("*"):
                                    if file_to_zip_dl_exec_main_run.is_file():
                                        zf_dl_exec_main_run.write(
                                            file_to_zip_dl_exec_main_run,
                                            file_to_zip_dl_exec_main_run.relative_to(
                                                out_dir_to_save_exec_main_run
                                            ),
                                        )
                            with open(
                                zip_path_obj_to_download_exec_main_run, "rb"
                            ) as fp_zip_data_to_download_dl_exec_main_run:
                                st.download_button(
                                    label=_("Download analysis results as ZIP"),
                                    data=fp_zip_data_to_download_dl_exec_main_run,
                                    file_name=f"{zip_base_name_exec_main_run}.zip",
                                    mime="application/zip",
                                    use_container_width=True,
                                )
                            log.info(
                                f"ZIP„Éï„Ç°„Ç§„É´„Çí‰ΩúÊàê„Åó„ÄÅ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Éú„Çø„É≥„ÇíË°®Á§∫„Åó„Åæ„Åó„Åü: {zip_path_obj_to_download_exec_main_run}"
                            )
                        except Exception as e_zip_final_exec_run_main_ex_v3:
                            log_and_display_error(
                                _("Error creating ZIP file"),
                                e_zip_final_exec_run_main_ex_v3,
                            )
                            log.error(
                                f"ZIP‰ΩúÊàê„Ç®„É©„Éº (ÊúÄÁµÇÊÆµÈöé): {e_zip_final_exec_run_main_ex_v3}",
                                exc_info=True,
                            )
        else:
            log.warning(
                f"Ëß£Êûê„ÅØÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„Åå„ÄÅÂá∫Âäõ„Éá„Ç£„É¨„ÇØ„Éà„É™ '{st.session_state.out_dir_path_str}' „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"
            )

        st.session_state.analysis_results[file_name] = {
            "out_dir_path_str": st.session_state.out_dir_path_str,
            "leave_analysis_results": st.session_state.leave_analysis_results,
            "rest_time_results": st.session_state.rest_time_results,
            "work_pattern_results": st.session_state.work_pattern_results,
            "attendance_results": st.session_state.attendance_results,
            "combined_score_results": st.session_state.combined_score_results,
            "low_staff_load_results": st.session_state.low_staff_load_results,
        }

st.session_state.analysis_done = True

# ÂÆåÂÖ®‰øÆÊ≠£Áâà - ‰ºëÊöáÂàÜÊûêÁµêÊûúË°®Á§∫„Ç≥„Éº„ÉâÂÖ®‰Ωì

# Plotly„ÅÆÂÖ®‰ΩìÂïèÈ°å„Çí‰øÆÊ≠£„Åó„Åü‰ºëÊöáÂàÜÊûê„Ç≥„Éº„Éâ


# ‚òÖ Êñ∞„Åó„ÅÑ„Äå‰ºëÊöáÂàÜÊûê„Äç„Çø„Éñ„ÅÆË°®Á§∫ (Ëß£Êûê„ÅåÂÆå‰∫Ü„Åó„ÄÅ‰ºëÊöáÂàÜÊûê„ÅåÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  app.py  (Part 3 / 3)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def display_overview_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Overview"))
        kpi_fp = data_dir / "shortage_role.xlsx"
        lack_h = 0.0
        if kpi_fp.exists():
            try:
                df_sh_role = load_excel_cached(
                    str(kpi_fp),
                    sheet_name="role_summary",
                    file_mtime=_file_mtime(kpi_fp),
                )
                lack_h = df_sh_role["lack_h"].sum() if "lack_h" in df_sh_role else 0.0
            except Exception as e:
                st.warning(f"shortage_role.xlsx Ë™≠Ëæº/ÈõÜË®à„Ç®„É©„Éº: {e}")
        fair_fp_meta = data_dir / "fairness_before.xlsx"
        jain_display = "N/A"
        if fair_fp_meta.exists():
            try:
                meta_df = load_excel_cached(
                    str(fair_fp_meta),
                    sheet_name="meta_summary",
                    file_mtime=_file_mtime(fair_fp_meta),
                )
                jain_row = meta_df[meta_df["metric"] == "jain_index"]
                if not jain_row.empty:
                    jain_display = f"{float(jain_row['value'].iloc[0]):.3f}"
            except Exception:
                pass
        c1, c2 = st.columns(2)
        c1.metric(_("‰∏çË∂≥ÊôÇÈñì(h)"), f"{lack_h:.1f}")
        c2.metric("Â§úÂã§ JainÊåáÊï∞", jain_display)


def display_heatmap_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Heatmap"))
        fp = data_dir / "heat_ALL.xlsx"
        if fp.exists():
            try:
                df_heat = load_excel_cached(
                    str(fp),
                    sheet_name="ALL",
                    index_col=0,
                    file_mtime=_file_mtime(fp),
                )
                if not _valid_df(df_heat):
                    st.info("Data not available")
                    return
                mode_opts = {"Raw": _("Raw Count"), "Ratio": _("Ratio (staff √∑ need)")}
                mode_lbl = st.radio(
                    _("Display Mode"),
                    list(mode_opts.values()),
                    horizontal=True,
                    key="dash_heat_mode_radio",
                )
                mode_key = [k for k, v in mode_opts.items() if v == mode_lbl][0]
                z_def, z_min, z_max, z_stp = (
                    (11.0, 1.0, 50.0, 1.0)
                    if mode_key == "Raw"
                    else (1.5, 0.1, 3.0, 0.1)
                )
                disp_df_heat = df_heat.drop(
                    columns=[c for c in SUMMARY5_CONST if c in df_heat.columns],
                    errors="ignore",
                )

                if mode_key == "Raw":
                    pos_vals = disp_df_heat[disp_df_heat > 0].stack()
                    p90 = (
                        float(pos_vals.quantile(0.90)) if not pos_vals.empty else z_def
                    )
                    p95 = (
                        float(pos_vals.quantile(0.95)) if not pos_vals.empty else z_def
                    )
                    p99 = (
                        float(pos_vals.quantile(0.99)) if not pos_vals.empty else z_def
                    )
                    zmode = st.selectbox(
                        _("zmax mode"),
                        [
                            "Manual",
                            "90th percentile",
                            "95th percentile",
                            "99th percentile",
                        ],
                        key="dash_heat_zmax_mode",
                        format_func=lambda x: _(x),
                    )
                    if zmode == "Manual":
                        zmax = st.slider(
                            _("Color Scale Max (zmax)"),
                            z_min,
                            z_max,
                            z_def,
                            z_stp,
                            key="dash_heat_zmax_slider",
                        )
                    else:
                        perc_map = {
                            "90th percentile": p90,
                            "95th percentile": p95,
                            "99th percentile": p99,
                        }
                        z_val = perc_map.get(zmode, z_def)
                        st.slider(
                            _("Color Scale Max (zmax)"),
                            z_min,
                            z_max,
                            z_val,
                            z_stp,
                            key="dash_heat_zmax_slider",
                            disabled=True,
                        )
                        zmax = z_val
                    fig = px.imshow(
                        disp_df_heat,
                        aspect="auto",
                        color_continuous_scale="Blues",
                        zmax=zmax,
                        labels={
                            "x": _("Date"),
                            "y": _("Time"),
                            "color": _("Raw Count"),
                        },
                    )
                else:
                    zmax = st.slider(
                        _("Color Scale Max (zmax)"),
                        z_min,
                        z_max,
                        z_def,
                        z_stp,
                        key="dash_heat_zmax_slider",
                    )
                    if (
                        "need" in df_heat.columns
                        and "staff" in df_heat.columns
                        and not disp_df_heat.empty
                    ):
                        disp_df_heat.copy()
                        # RatioË®àÁÆó: ÂêÑÊó•‰ªòÂàó„ÅÆÂêÑÊôÇÈñìÂ∏Ø„ÅÆÂÄ§„Çí„ÄÅ„Åù„ÅÆÊôÇÈñìÂ∏Ø„ÅÆ staff ÂÄ§ / need ÂÄ§„ÅßÊõ¥Êñ∞
                        if (
                            "need" in df_heat.columns
                            and df_heat["need"].replace(0, pd.NA).notna().any()
                        ):  # need„Åå0„Åß„Å™„ÅÑÊúâÂäπ„Å™ÂÄ§„ÇíÊåÅ„Å§„Åã
                            ratio_display_df = disp_df_heat.apply(
                                lambda date_col: date_col
                                / df_heat["need"].replace(0, pd.NA),
                                axis=0,
                            )
                            ratio_display_df = ratio_display_df.clip(upper=zmax)
                            fig = px.imshow(
                                ratio_display_df,
                                aspect="auto",
                                color_continuous_scale=px.colors.sequential.RdBu_r,
                                zmin=0,
                                zmax=zmax,
                                labels={
                                    "x": _("Date"),
                                    "y": _("Time"),
                                    "color": _("Ratio (staff √∑ need)"),
                                },
                            )
                        else:
                            st.warning(
                                "RatioË°®Á§∫„Å´ÂøÖË¶Å„Å™'need'Âàó„Éá„Éº„Çø„Åå0„Åæ„Åü„ÅØÂ≠òÂú®„Åó„Åæ„Åõ„Çì„ÄÇ"
                            )
                            fig = go.Figure()
                    else:
                        st.warning(
                            "RatioË°®Á§∫„Å´ÂøÖË¶Å„Å™'staff'Âàó„ÄÅ'need'Âàó„ÄÅ„Åæ„Åü„ÅØÊó•‰ªò„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"
                        )
                        fig = go.Figure()
                st.plotly_chart(fig, use_container_width=True, key="heatmap_chart")
            except Exception as e:
                log_and_display_error("„Éí„Éº„Éà„Éû„ÉÉ„ÉóË°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Heatmap") + " (heat_ALL.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))


def display_shortage_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Shortage"))
        fp_s_role = data_dir / "shortage_role.xlsx"
        if fp_s_role.exists():
            try:
                xls = load_excelfile_cached(
                    str(fp_s_role),
                    file_mtime=_file_mtime(fp_s_role),
                )
                sheet_role = (
                    "role_summary"
                    if "role_summary" in xls.sheet_names
                    else xls.sheet_names[0]
                )
                df_s_role = xls.parse(sheet_role)
                if not _valid_df(df_s_role):
                    st.info("Data not available")
                    return
                display_role_df = df_s_role.rename(
                    columns={
                        "role": _("Role"),
                        "need_h": _("Need Hours"),
                        "staff_h": _("Staff Hours"),
                        "lack_h": _("Shortage Hours"),
                        "excess_h": _("Excess Hours"),
                        "working_days_considered": _("Working Days"),
                        "note": _("Note"),
                    }
                )
                st.dataframe(display_role_df, use_container_width=True, hide_index=True)
                if "role" in df_s_role and "lack_h" in df_s_role:
                    fig_role = px.bar(
                        df_s_role,
                        x="role",
                        y="lack_h",
                        labels={"role": _("Role"), "lack_h": _("Shortage Hours")},
                        color_discrete_sequence=["#FFA500"],
                    )
                    st.plotly_chart(
                        fig_role, use_container_width=True, key="short_role_chart"
                    )
                if "role" in df_s_role and "excess_h" in df_s_role:
                    fig_role_ex = px.bar(
                        df_s_role,
                        x="role",
                        y="excess_h",
                        labels={"role": _("Role"), "excess_h": _("Excess Hours")},
                        color_discrete_sequence=["#00BFFF"],
                    )
                    st.plotly_chart(
                        fig_role_ex, use_container_width=True, key="excess_role_chart"
                    )

                fp_hire = data_dir / "hire_plan.xlsx"
                if fp_hire.exists():
                    try:
                        df_hire = load_excel_cached(
                            str(fp_hire),
                            sheet_name="hire_plan",
                            file_mtime=_file_mtime(fp_hire),
                        )
                        if not _valid_df(df_hire):
                            st.info("Data not available")
                            return
                        if {"role", "hire_fte"}.issubset(df_hire.columns):
                            st.markdown(_("Required FTE per Role"))
                            display_hire_df = df_hire[["role", "hire_fte"]].rename(
                                columns={"role": _("Role"), "hire_fte": _("hire_fte")}
                            )
                            st.dataframe(
                                display_hire_df,
                                use_container_width=True,
                                hide_index=True,
                            )
                            fig_hire = px.bar(
                                df_hire,
                                x="role",
                                y="hire_fte",
                                labels={"role": _("Role"), "hire_fte": _("hire_fte")},
                                color_discrete_sequence=["#1f77b4"],
                            )
                            st.plotly_chart(
                                fig_hire,
                                use_container_width=True,
                                key="short_hire_chart",
                            )
                    except Exception as e:
                        log_and_display_error("hire_plan.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)

                if "role_monthly" in xls.sheet_names:
                    df_month = xls.parse("role_monthly")
                    if not _valid_df(df_month):
                        st.info("Data not available")
                        return
                    if not df_month.empty and {"month", "role", "lack_h"}.issubset(
                        df_month.columns
                    ):
                        fig_m = px.bar(
                            df_month,
                            x="month",
                            y="lack_h",
                            color="role",
                            barmode="stack",
                            title=_("Monthly Shortage Hours by Role"),
                            labels={
                                "month": _("Month"),
                                "lack_h": _("Shortage Hours"),
                                "role": _("Role"),
                            },
                        )
                        st.plotly_chart(
                            fig_m, use_container_width=True, key="short_month_chart"
                        )
                        with st.expander(_("Monthly shortage data")):
                            st.dataframe(
                                df_month, use_container_width=True, hide_index=True
                            )
            except Exception as e:
                log_and_display_error("shortage_role.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Shortage") + " (shortage_role.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))

        fp_s_emp = data_dir / "shortage_employment.xlsx"
        if fp_s_emp.exists():
            try:
                xls_emp = load_excelfile_cached(
                    str(fp_s_emp),
                    file_mtime=_file_mtime(fp_s_emp),
                )
                sheet_emp = (
                    "employment_summary"
                    if "employment_summary" in xls_emp.sheet_names
                    else xls_emp.sheet_names[0]
                )
                df_s_emp = xls_emp.parse(sheet_emp)
                if _valid_df(df_s_emp):
                    display_emp_df = df_s_emp.rename(
                        columns={
                            "employment": _("Employment"),
                            "need_h": _("Need Hours"),
                            "staff_h": _("Staff Hours"),
                            "lack_h": _("Shortage Hours"),
                            "excess_h": _("Excess Hours"),
                            "working_days_considered": _("Working Days"),
                            "note": _("Note"),
                        }
                    )
                    st.dataframe(
                        display_emp_df, use_container_width=True, hide_index=True
                    )
                    if "employment" in df_s_emp and "lack_h" in df_s_emp:
                        fig_emp = px.bar(
                            df_s_emp,
                            x="employment",
                            y="lack_h",
                            labels={
                                "employment": _("Employment"),
                                "lack_h": _("Shortage Hours"),
                            },
                            color_discrete_sequence=["#2ca02c"],
                        )
                        st.plotly_chart(
                            fig_emp, use_container_width=True, key="short_emp_chart"
                        )
                    if "employment" in df_s_emp and "excess_h" in df_s_emp:
                        fig_emp_ex = px.bar(
                            df_s_emp,
                            x="employment",
                            y="excess_h",
                            labels={
                                "employment": _("Employment"),
                                "excess_h": _("Excess Hours"),
                            },
                            color_discrete_sequence=["#00BFFF"],
                        )
                        st.plotly_chart(
                            fig_emp_ex, use_container_width=True, key="excess_emp_chart"
                        )
                if "employment_monthly" in xls_emp.sheet_names:
                    df_emp_month = xls_emp.parse("employment_monthly")
                    if _valid_df(df_emp_month) and {
                        "month",
                        "employment",
                        "lack_h",
                    }.issubset(df_emp_month.columns):
                        fig_emp_m = px.bar(
                            df_emp_month,
                            x="month",
                            y="lack_h",
                            color="employment",
                            barmode="stack",
                            title=_("Monthly Shortage Hours by Employment"),
                            labels={
                                "month": _("Month"),
                                "lack_h": _("Shortage Hours"),
                                "employment": _("Employment"),
                            },
                        )
                        st.plotly_chart(
                            fig_emp_m,
                            use_container_width=True,
                            key="short_emp_month_chart",
                        )
                        with st.expander(_("Monthly shortage data")):
                            st.dataframe(
                                df_emp_month, use_container_width=True, hide_index=True
                            )
            except Exception as e:
                log_and_display_error("shortage_employment.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(
                _("Shortage") + " (shortage_employment.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
            )
        st.markdown("---")
        fp_s_time = data_dir / "shortage_time.xlsx"
        if fp_s_time.exists():
            try:
                df_s_time = load_excel_cached(
                    str(fp_s_time),
                    sheet_name="lack_time",
                    index_col=0,
                    file_mtime=_file_mtime(fp_s_time),
                )
                if not _valid_df(df_s_time):
                    st.info("Data not available")
                    return
                st.write(_("Shortage by Time (count per day)"))
                avail_dates = df_s_time.columns.tolist()
                if avail_dates:
                    sel_date = st.selectbox(
                        _("Select date to display"),
                        avail_dates,
                        key="dash_short_time_date",
                    )
                    if sel_date:
                        fig_time = px.bar(
                            df_s_time[sel_date].reset_index(),
                            x=df_s_time.index.name or "index",
                            y=sel_date,
                            labels={
                                df_s_time.index.name or "index": _("Time"),
                                sel_date: _("Shortage Hours"),
                            },
                            color_discrete_sequence=["#FFA500"],
                        )
                        st.plotly_chart(
                            fig_time, use_container_width=True, key="short_time_chart"
                        )
                else:
                    st.info(_("No date columns in shortage data."))
                with st.expander(_("Display all time-slot shortage data")):
                    st.dataframe(df_s_time, use_container_width=True)
            except Exception as e:
                log_and_display_error("shortage_time.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Shortage") + " (shortage_time.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))

        fp_e_time = data_dir / "excess_time.xlsx"
        if fp_e_time.exists():
            try:
                df_e_time = load_excel_cached(
                    str(fp_e_time),
                    sheet_name="excess_time",
                    index_col=0,
                    file_mtime=_file_mtime(fp_e_time),
                )
                if not _valid_df(df_e_time):
                    st.info("Data not available")
                    return
                st.write(_("Excess by Time (count per day)"))
                avail_e_dates = df_e_time.columns.tolist()
                if avail_e_dates:
                    sel_e_date = st.selectbox(
                        _("Select date to display"),
                        avail_e_dates,
                        key="excess_time_date",
                    )
                    if sel_e_date:
                        fig_e_time = px.bar(
                            df_e_time[sel_e_date].reset_index(),
                            x=df_e_time.index.name or "index",
                            y=sel_e_date,
                            labels={
                                df_e_time.index.name or "index": _("Time"),
                                sel_e_date: _("Excess Hours"),
                            },
                            color_discrete_sequence=["#00BFFF"],
                        )
                        st.plotly_chart(
                            fig_e_time, use_container_width=True, key="excess_time_chart"
                        )
                else:
                    st.info(_("No date columns in excess data."))
                with st.expander(_("Display all time-slot excess data")):
                    st.dataframe(df_e_time, use_container_width=True)
            except Exception as e:
                log_and_display_error("excess_time.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Excess by Time (count per day)") + " (excess_time.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))

        fp_s_ratio = data_dir / "shortage_ratio.xlsx"
        if fp_s_ratio.exists():
            try:
                df_ratio = load_excel_cached(
                    str(fp_s_ratio),
                    sheet_name="lack_ratio",
                    index_col=0,
                    file_mtime=_file_mtime(fp_s_ratio),
                )
                if not _valid_df(df_ratio):
                    st.info("Data not available")
                    return
                st.write(_("Shortage Ratio by Time"))
                avail_ratio_dates = df_ratio.columns.tolist()
                if avail_ratio_dates:
                    sel_ratio_date = st.selectbox(
                        _("Select date for ratio"),
                        avail_ratio_dates,
                        key="short_ratio_date",
                    )
                    if sel_ratio_date:
                        fig_ratio = px.bar(
                            df_ratio[sel_ratio_date].reset_index(),
                            x=df_ratio.index.name or "index",
                            y=sel_ratio_date,
                            labels={
                                df_ratio.index.name or "index": _("Time"),
                                sel_ratio_date: _("Shortage Ratio"),
                            },
                            color_discrete_sequence=["#FF6347"],
                        )
                        st.plotly_chart(
                            fig_ratio, use_container_width=True, key="short_ratio_chart"
                        )
                else:
                    st.info(_("No date columns in shortage ratio."))
                with st.expander(_("Display all ratio data")):
                    st.dataframe(df_ratio, use_container_width=True)
            except Exception as e:
                log_and_display_error("shortage_ratio.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Shortage") + " (shortage_ratio.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))

        fp_e_ratio = data_dir / "excess_ratio.xlsx"
        if fp_e_ratio.exists():
            try:
                df_e_ratio = load_excel_cached(
                    str(fp_e_ratio),
                    sheet_name="excess_ratio",
                    index_col=0,
                    file_mtime=_file_mtime(fp_e_ratio),
                )
                if not _valid_df(df_e_ratio):
                    st.info("Data not available")
                    return
                st.write(_("Excess Ratio by Time"))
                avail_er_dates = df_e_ratio.columns.tolist()
                if avail_er_dates:
                    sel_er_date = st.selectbox(
                        _("Select date for ratio"),
                        avail_er_dates,
                        key="excess_ratio_date",
                    )
                    if sel_er_date:
                        fig_er = px.bar(
                            df_e_ratio[sel_er_date].reset_index(),
                            x=df_e_ratio.index.name or "index",
                            y=sel_er_date,
                            labels={
                                df_e_ratio.index.name or "index": _("Time"),
                                sel_er_date: _("Excess Hours"),
                            },
                            color_discrete_sequence=["#00BFFF"],
                        )
                        st.plotly_chart(
                            fig_er, use_container_width=True, key="excess_ratio_chart"
                        )
                else:
                    st.info(_("No date columns in excess data."))
                with st.expander(_("Display all ratio data")):
                    st.dataframe(df_e_ratio, use_container_width=True)
            except Exception as e:
                log_and_display_error("excess_ratio.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Excess Ratio by Time") + " (excess_ratio.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))

        fp_s_freq = data_dir / "shortage_freq.xlsx"
        if fp_s_freq.exists():
            try:
                df_freq = load_excel_cached(
                    str(fp_s_freq),
                    sheet_name="freq_by_time",
                    index_col=0,
                    file_mtime=_file_mtime(fp_s_freq),
                )
                if not _valid_df(df_freq):
                    st.info("Data not available")
                    return
                st.write(_("Shortage Frequency (days)"))
                fig_freq = px.bar(
                    df_freq.reset_index(),
                    x=df_freq.index.name or "index",
                    y="shortage_days",
                    labels={
                        df_freq.index.name or "index": _("Time"),
                        "shortage_days": _("Shortage Frequency (days)"),
                    },
                    color_discrete_sequence=["#708090"],
                )
                st.plotly_chart(
                    fig_freq, use_container_width=True, key="short_freq_chart"
                )
                with st.expander(_("Data")):
                    st.dataframe(df_freq, use_container_width=True)
            except Exception as e:
                log_and_display_error("shortage_freq.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Shortage") + " (shortage_freq.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))

        fp_e_freq = data_dir / "excess_freq.xlsx"
        if fp_e_freq.exists():
            try:
                df_e_freq = load_excel_cached(
                    str(fp_e_freq),
                    sheet_name="freq_by_time",
                    index_col=0,
                    file_mtime=_file_mtime(fp_e_freq),
                )
                if not _valid_df(df_e_freq):
                    st.info("Data not available")
                    return
                st.write(_("Excess Frequency (days)"))
                fig_efreq = px.bar(
                    df_e_freq.reset_index(),
                    x=df_e_freq.index.name or "index",
                    y="excess_days",
                    labels={
                        df_e_freq.index.name or "index": _("Time"),
                        "excess_days": _("Excess Frequency (days)"),
                    },
                    color_discrete_sequence=["#00BFFF"],
                )
                st.plotly_chart(
                    fig_efreq, use_container_width=True, key="excess_freq_chart"
                )
                with st.expander(_("Data")):
                    st.dataframe(df_e_freq, use_container_width=True)
            except Exception as e:
                log_and_display_error("excess_freq.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Excess Frequency (days)") + " (excess_freq.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))

        fp_s_leave = data_dir / "shortage_leave.xlsx"
        if fp_s_leave.exists():
            try:
                df_sl = load_excel_cached(
                    str(fp_s_leave),
                    sheet_name="shortage_leave",
                    file_mtime=_file_mtime(fp_s_leave),
                )
                if not _valid_df(df_sl):
                    st.info("Data not available")
                    return
                st.write(_("Shortage with Leave"))
                display_sl = df_sl.rename(
                    columns={
                        "time": _("Time"),
                        "date": _("Date"),
                        "lack": _("Shortage Hours"),
                        "leave_applicants": _("Total Leave Days"),
                        "net_shortage": _("Net Shortage"),
                    }
                )
                st.dataframe(display_sl, use_container_width=True, hide_index=True)
            except Exception as e:
                log_and_display_error("shortage_leave.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Shortage") + " (shortage_leave.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))

        fp_cost = data_dir / "cost_benefit.xlsx"
        if fp_cost.exists():
            st.markdown("---")
            try:
                df_cost = load_excel_cached(
                    str(fp_cost),
                    sheet_name=0,
                    index_col=0,
                    file_mtime=_file_mtime(fp_cost),
                )
                if not _valid_df(df_cost):
                    st.info("Data not available")
                    return
                st.write(_("Estimated Cost Impact (Million ¬•)"))
                if "Cost_Million" in df_cost:
                    fig_cost = px.bar(
                        df_cost.reset_index(),
                        x=df_cost.index.name or "index",
                        y="Cost_Million",
                        labels={"Cost_Million": _("Estimated Cost Impact (Million ¬•)")},
                    )
                    st.plotly_chart(
                        fig_cost, use_container_width=True, key="short_cost_chart"
                    )
                st.dataframe(df_cost, use_container_width=True)
            except Exception as e:
                log_and_display_error("cost_benefit.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)

        fp_stats = data_dir / "stats.xlsx"
        if fp_stats.exists():
            try:
                xls_stats = load_excelfile_cached(
                    str(fp_stats),
                    file_mtime=_file_mtime(fp_stats),
                )
                if "alerts" in xls_stats.sheet_names:
                    df_alerts = xls_stats.parse("alerts")
                    if not _valid_df(df_alerts):
                        st.info("Data not available")
                        return
                    if not df_alerts.empty:
                        st.markdown("---")
                        st.subheader(_("Alerts"))
                        st.dataframe(
                            df_alerts, use_container_width=True, hide_index=True
                        )
            except Exception as e:
                log_and_display_error("stats.xlsx alertsË°®Á§∫„Ç®„É©„Éº", e)


def display_fatigue_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Fatigue Score per Staff"))
        fp = data_dir / "fatigue_score.xlsx"
        if fp.exists():
            try:
                df = load_excel_cached(
                    str(fp),
                    sheet_name="fatigue",
                    file_mtime=_file_mtime(fp),
                )
                if not _valid_df(df):
                    st.info(_("Data not available or empty"))
                    return

                try:
                    display_df = df.rename(
                        columns={"staff": _("Staff"), "fatigue_score": _("Score")}
                    )
                    st.dataframe(display_df, use_container_width=True, hide_index=True)
                    if "fatigue_score" in df and "staff" in df:
                        fig_fatigue = px.bar(
                            df,
                            x="staff",
                            y="fatigue_score",
                            labels={"staff": _("Staff"), "fatigue_score": _("Score")},
                            color_discrete_sequence=["#FF8C00"],
                        )
                        st.plotly_chart(
                            fig_fatigue, use_container_width=True, key="fatigue_chart"
                        )
                except AttributeError as e:
                    log_and_display_error(
                        "Invalid data format in fatigue_score.xlsx", e
                    )
            except Exception as e:
                log_and_display_error("fatigue_score.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Fatigue") + " (fatigue_score.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))


def display_forecast_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Demand Forecast (yhat)"))
        fp_fc = data_dir / "forecast.xlsx"
        if fp_fc.exists():
            try:
                df_fc = load_excel_cached(
                    str(fp_fc),
                    sheet_name="forecast",
                    parse_dates=["ds"],
                    file_mtime=_file_mtime(fp_fc),
                )
                if not _valid_df(df_fc):
                    st.info(_("Forecast data not available or empty"))
                    return

                try:
                    fig = go.Figure()
                    if "ds" in df_fc and "yhat" in df_fc:
                        fig.add_trace(
                            go.Scatter(
                                x=df_fc["ds"],
                                y=df_fc["yhat"],
                                mode="lines+markers",
                                name=_("Demand Forecast (yhat)"),
                            )
                        )
                    fp_demand = data_dir / "demand_series.csv"
                    if fp_demand.exists():
                        df_actual = pd.read_csv(fp_demand, parse_dates=["ds"])
                        if (
                            _valid_df(df_actual)
                            and "ds" in df_actual
                            and "y" in df_actual
                        ):
                            fig.add_trace(
                                go.Scatter(
                                    x=df_actual["ds"],
                                    y=df_actual["y"],
                                    mode="lines",
                                    name=_("Actual (y)"),
                                    line=dict(dash="dash"),
                                )
                            )
                    fig.update_layout(
                        title=_("Demand Forecast vs Actual"),
                        xaxis_title=_("Date"),
                        yaxis_title=_("Demand"),
                    )
                    st.plotly_chart(fig, use_container_width=True, key="forecast_chart")
                    with st.expander(_("Display forecast data")):
                        st.dataframe(df_fc, use_container_width=True, hide_index=True)
                except AttributeError as e:
                    log_and_display_error("Invalid data format in forecast.xlsx", e)
            except Exception as e:
                log_and_display_error("forecast.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Forecast") + " (forecast.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))


def display_fairness_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Fairness (Night Shift Ratio)"))
        fp = data_dir / "fairness_after.xlsx"
        if fp.exists():
            try:
                df = load_excel_cached(
                    str(fp),
                    sheet_name="after_summary",
                    file_mtime=_file_mtime(fp),
                )
                if not _valid_df(df):
                    st.info(_("Fairness data not available or empty"))
                    return

                try:
                    display_df = df.rename(
                        columns={
                            "staff": _("Staff"),
                            "night_ratio": _("Night Shift Ratio")
                            if "Night Shift Ratio" in JP
                            else "night_ratio",
                        }
                    )
                    st.dataframe(display_df, use_container_width=True, hide_index=True)
                    if "staff" in df and "night_ratio" in df:
                        fig_fair = px.bar(
                            df,
                            x="staff",
                            y="night_ratio",
                            labels={
                                "staff": _("Staff"),
                                "night_ratio": _("Night Shift Ratio")
                                if "Night Shift Ratio" in JP
                                else "night_ratio",
                            },
                            color_discrete_sequence=["#FF8C00"],
                        )
                        st.plotly_chart(
                            fig_fair, use_container_width=True, key="fairness_chart"
                        )
                except AttributeError as e:
                    log_and_display_error(
                        "Invalid data format in fairness_after.xlsx", e
                    )
            except Exception as e:
                log_and_display_error("fairness_after.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Fairness") + " (fairness_after.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))


def display_costsim_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Cost Simulation (Million ¬•)"))
        fp = data_dir / "cost_benefit.xlsx"
        if fp.exists():
            try:
                df = load_excel_cached(
                    str(fp),
                    sheet_name=0,
                    index_col=0,
                    file_mtime=_file_mtime(fp),
                )
                if not _valid_df(df):
                    st.info(_("Cost simulation data not available or empty"))
                    return

                try:
                    if "Cost_Million" in df:
                        fig_cost = px.bar(
                            df.reset_index(),
                            x=df.index.name or "index",
                            y="Cost_Million",
                            labels={
                                "Cost_Million": _("Estimated Cost Impact (Million ¬•)")
                            },
                        )
                        st.plotly_chart(
                            fig_cost, use_container_width=True, key="costsim_chart"
                        )
                    st.dataframe(df, use_container_width=True)
                except AttributeError as e:
                    log_and_display_error("Invalid data format in cost_benefit.xlsx", e)
            except Exception as e:
                log_and_display_error("cost_benefit.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(
                _("Cost Simulation") + " (cost_benefit.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
            )


def display_hireplan_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Hiring Plan (Needed FTE)"))
        fp = data_dir / "hire_plan.xlsx"
        if fp.exists():
            try:
                xls = load_excelfile_cached(
                    str(fp),
                    file_mtime=_file_mtime(fp),
                )
                if (
                    not isinstance(xls, pd.ExcelFile)
                    or "hire_plan" not in xls.sheet_names
                ):
                    st.info(_("Hiring plan data not available or in invalid format"))
                    return

                try:
                    df_plan = xls.parse("hire_plan")
                    if not _valid_df(df_plan):
                        st.info(_("Hiring plan data is empty"))
                        return

                    display_plan_df = df_plan.rename(
                        columns={"role": _("Role"), "hire_fte": _("hire_fte")}
                    )
                    st.dataframe(
                        display_plan_df, use_container_width=True, hide_index=True
                    )
                    if "role" in df_plan and "hire_fte" in df_plan:
                        fig_plan = px.bar(
                            df_plan,
                            x="role",
                            y="hire_fte",
                            labels={"role": _("Role"), "hire_fte": _("hire_fte")},
                        )
                        st.plotly_chart(
                            fig_plan, use_container_width=True, key="hireplan_chart"
                        )
                except AttributeError as e:
                    log_and_display_error("Invalid data format in hire_plan.xlsx", e)
            except Exception as e:
                log_and_display_error("hire_plan.xlsx Ë°®Á§∫„Ç®„É©„Éº", e)
        else:
            st.info(_("Hiring Plan") + " (hire_plan.xlsx) " + _("„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ"))


def load_leave_results_from_dir(data_dir: Path) -> dict:
    """Load leave analysis results from ``data_dir``.

    Parameters
    ----------
    data_dir : Path
        Directory containing ``leave_analysis.csv`` and optional CSVs.

    Returns
    -------
    dict
        Dictionary with keys ``daily_summary``, ``staff_balance_daily`` and
        ``concentration_requested`` when available or reconstructed.
    """

    results: dict[str, pd.DataFrame] = {}

    fp_daily = data_dir / "leave_analysis.csv"
    if fp_daily.exists():
        try:
            results["daily_summary"] = pd.read_csv(fp_daily, parse_dates=["date"])
        except Exception as e:
            log_and_display_error("leave_analysis.csv Ë°®Á§∫„Ç®„É©„Éº", e)

    fp_staff_bal = data_dir / "staff_balance_daily.csv"
    if fp_staff_bal.exists():
        try:
            results["staff_balance_daily"] = pd.read_csv(
                fp_staff_bal, parse_dates=["date"]
            )
        except Exception as e:
            log_and_display_error("staff_balance_daily.csv Ë°®Á§∫„Ç®„É©„Éº", e)

    fp_conc = data_dir / "concentration_requested.csv"
    if fp_conc.exists():
        try:
            results["concentration_requested"] = pd.read_csv(
                fp_conc, parse_dates=["date"]
            )
        except Exception as e:
            log_and_display_error("concentration_requested.csv Ë°®Á§∫„Ç®„É©„Éº", e)

    daily_df = results.get("daily_summary")
    if "staff_balance_daily" not in results and _valid_df(daily_df):
        heat_fp = data_dir / "heat_ALL.xlsx"
        if heat_fp.exists():
            try:
                heat = pd.read_excel(heat_fp, index_col=0)
                date_cols = [c for c in heat.columns if c not in SUMMARY5_CONST]
                total_staff = (
                    (heat[date_cols] > 0)
                    .astype(int)
                    .sum()
                    .reset_index()
                    .rename(columns={"index": "date", 0: "total_staff"})
                )
                total_staff["date"] = pd.to_datetime(total_staff["date"])
                req_df = daily_df[
                    daily_df["leave_type"] == LEAVE_TYPE_REQUESTED
                ].rename(columns={"total_leave_days": "leave_applicants_count"})[
                    ["date", "leave_applicants_count"]
                ]
                sb = total_staff.merge(req_df, on="date", how="left")
                sb["leave_applicants_count"] = (
                    sb["leave_applicants_count"].fillna(0).astype(int)
                )
                sb["non_leave_staff"] = sb["total_staff"] - sb["leave_applicants_count"]
                sb["leave_ratio"] = sb["leave_applicants_count"] / sb["total_staff"]
                results["staff_balance_daily"] = sb
            except Exception as e:
                log.warning(f"Failed to reconstruct staff_balance_daily: {e}")

    if "concentration_requested" not in results and _valid_df(daily_df):
        try:
            conc_df = daily_df[daily_df["leave_type"] == LEAVE_TYPE_REQUESTED].rename(
                columns={"total_leave_days": "leave_applicants_count"}
            )[["date", "leave_applicants_count"]]
            if "staff_balance_daily" in results:
                conc_df = conc_df.merge(
                    results["staff_balance_daily"][["date", "leave_ratio"]],
                    on="date",
                    how="left",
                )
            conc_df["is_concentrated"] = conc_df["leave_applicants_count"] >= 3
            conc_df["staff_names"] = [[] for _ in range(len(conc_df))]
            results["concentration_requested"] = conc_df
        except Exception as e:
            log.warning(f"Failed to reconstruct concentration_requested: {e}")

    if "concentration_both" not in results and _valid_df(daily_df):
        try:
            conc_both = leave_analyzer.analyze_both_leave_concentration(
                daily_df.copy(), concentration_threshold=3
            )
            results["concentration_both"] = conc_both
        except Exception as e:
            log.warning(f"Failed to reconstruct concentration_both: {e}")

    return results


def display_leave_analysis_tab(tab_container, results_dict: dict | None = None):
    """Display leave analysis results with interactive charts.

    Parameters
    ----------
    tab_container : Any
        Streamlit tab container.
    results_dict : dict | None
        In-memory results dictionary produced by ``leave_analyzer``.  If ``None``
        the function falls back to ``st.session_state.leave_analysis_results``.
    """

    with tab_container:
        st.subheader(_("Leave Analysis"))

        if results_dict is None:
            results_dict = st.session_state.leave_analysis_results

        leave_df = results_dict.get("daily_summary")

        if not isinstance(leave_df, pd.DataFrame) or leave_df.empty:
            st.info(_("No leave analysis results available."))
            return

        st.dataframe(leave_df, use_container_width=True, hide_index=True)

        staff_balance = results_dict.get("staff_balance_daily")
        if isinstance(staff_balance, pd.DataFrame) and not staff_balance.empty:
            st.subheader("Âã§Âãô‰∫àÂÆö‰∫∫Êï∞„Å®Â∏åÊúõ‰ºëÂèñÂæóËÄÖÊï∞")
            fig_bal = px.line(
                staff_balance,
                x="date",
                y=["total_staff", "leave_applicants_count", "non_leave_staff"],
                markers=True,
                labels={
                    "date": _("Date"),
                    "value": _("Count"),
                    "variable": _("Metric"),
                    "total_staff": _("Total staff"),
                    "leave_applicants_count": _("Leave applicants"),
                    "non_leave_staff": _("Non-leave staff"),
                },
            )
            st.plotly_chart(
                fig_bal, use_container_width=True, key="staff_balance_chart"
            )
            st.dataframe(staff_balance, use_container_width=True, hide_index=True)

        conc_both = results_dict.get("concentration_both")
        if isinstance(conc_both, pd.DataFrame) and not conc_both.empty:
            st.subheader("Requested + Paid concentration")
            fig_both = px.line(
                conc_both,
                x="date",
                y=["requested_count", "paid_count"],
                markers=True,
                labels={
                    "date": _("Date"),
                    "value": _("Count"),
                    "variable": _("Leave type"),
                    "requested_count": _("Requested"),
                    "paid_count": _("Paid"),
                },
            )
            st.plotly_chart(fig_both, use_container_width=True, key="leave_both_chart")
            st.dataframe(conc_both, use_container_width=True, hide_index=True)

        concentration = results_dict.get("concentration_requested")
        if isinstance(concentration, pd.DataFrame) and not concentration.empty:
            conc_df = concentration[concentration.get("is_concentrated")]
            if not conc_df.empty:
                st.subheader(_("Leave concentration graphs"))

                fig_conc = px.line(
                    conc_df,
                    x="date",
                    y="leave_applicants_count",
                    markers=True,
                    labels={
                        "date": _("Date"),
                        "leave_applicants_count": _("Leave applicants"),
                    },
                )

                events = []
                if plotly_events is not None:
                    events = plotly_events(
                        fig_conc,
                        click_event=True,
                        select_event=True,
                        override_height=None,
                        key="leave_conc_chart",
                    )
                else:
                    st.plotly_chart(
                        fig_conc, use_container_width=True, key="leave_conc_chart"
                    )

                if "leave_ratio" not in conc_df.columns:
                    sb = results_dict.get("staff_balance_daily")
                    if isinstance(sb, pd.DataFrame) and {
                        "date",
                        "leave_ratio",
                    }.issubset(sb.columns):
                        conc_df = conc_df.merge(
                            sb[["date", "leave_ratio"]], on="date", how="left"
                        )

                if "leave_ratio" in conc_df.columns:
                    fig_ratio = px.line(
                        conc_df,
                        x="date",
                        y="leave_ratio",
                        markers=True,
                        labels={
                            "date": _("Date"),
                            "leave_ratio": _("Leave ratio"),
                        },
                    )
                    st.plotly_chart(
                        fig_ratio, use_container_width=True, key="leave_ratio_chart"
                    )
                else:
                    st.info(_("Leave ratio not available."))

                if "selected_leave_dates" not in st.session_state:
                    st.session_state.selected_leave_dates = set()

                for ev in events:
                    if isinstance(ev, dict) and "x" in ev:
                        try:
                            st.session_state.selected_leave_dates.add(
                                pd.to_datetime(ev["x"]).normalize()
                            )
                        except Exception:
                            pass

                if st.button("ÈÅ∏Êäû„Çí„ÇØ„É™„Ç¢"):
                    st.session_state.selected_leave_dates = set()

                selected_dates = sorted(st.session_state.selected_leave_dates)
                if selected_dates:
                    name_lists = conc_df[conc_df["date"].isin(selected_dates)][
                        "staff_names"
                    ]
                    all_names: list[str] = []
                    for names in name_lists:
                        if isinstance(names, list):
                            all_names.extend(names)

                    if all_names:
                        st.markdown(
                            "**"
                            + _("Selected staff")
                            + ":** "
                            + ", ".join(sorted(set(all_names)))
                        )
                        cnt_df = (
                            pd.Series(all_names)
                            .value_counts()
                            .reset_index()
                            .rename(columns={"index": "staff", 0: "count"})
                        )
                        fig_bar = px.bar(
                            cnt_df,
                            x="staff",
                            y="count",
                            labels={"staff": _("Staff"), "count": _("Count")},
                        )
                        st.plotly_chart(
                            fig_bar,
                            use_container_width=True,
                            key="selected_staff_chart",
                        )


def display_ppt_tab(tab_container, data_dir_ignored, key_prefix: str = ""):
    with tab_container:
        st.subheader(_("PPT Report"))
        button_key = f"dash_generate_ppt_button_{key_prefix or 'default'}"
        if st.button(
            _("Generate PowerPoint Report (Œ≤)"),
            key=button_key,
            use_container_width=True,
        ):
            st.info(_("Generating PowerPoint report..."))
            try:
                from shift_suite.tasks.ppt import build_ppt

                ppt_path = build_ppt(data_dir_ignored)
                with open(ppt_path, "rb") as ppt_file_data_dash:
                    st.download_button(
                        label=_("Download Report (PPTX)"),
                        data=ppt_file_data_dash,
                        file_name=f"ShiftSuite_Report_{dt.datetime.now().strftime('%Y%m%d_%H%M')}.pptx",
                        mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                        use_container_width=True,
                    )
                Path(ppt_path).unlink(missing_ok=True)
                st.success(_("PowerPoint report ready."))
            except ImportError as e:
                log_and_display_error("python-pptx library required for PPT", e)
            except Exception as e_ppt_dash:
                log_and_display_error(
                    _("Error generating PowerPoint report"), e_ppt_dash
                )
        else:
            st.markdown(_("Click button to generate report."))


# Multi-file results display
if st.session_state.get("analysis_done", False) and st.session_state.analysis_results:
    st.divider()
    file_tabs = st.tabs(list(st.session_state.analysis_results.keys()))
    for tab_obj, fname in zip(file_tabs, st.session_state.analysis_results.keys()):
        with tab_obj:
            results = st.session_state.analysis_results[fname]
            st.subheader(_("Results for {fname}").format(fname=fname))
            data_dir = Path(results["out_dir_path_str"])
            tab_keys_en_dash = [
                "Overview",
                "Heatmap",
                "Shortage",
                "Fatigue",
                "Forecast",
                "Fairness",
                "Leave Analysis",
                "Cost Sim",
                "Hire Plan",
                "PPT Report",
            ]
            tab_labels_dash = [_(key) for key in tab_keys_en_dash]
            inner_tabs = st.tabs(tab_labels_dash)
            tab_func_map_dash = {
                "Overview": display_overview_tab,
                "Heatmap": display_heatmap_tab,
                "Shortage": display_shortage_tab,
                "Fatigue": display_fatigue_tab,
                "Forecast": display_forecast_tab,
                "Fairness": display_fairness_tab,
                "Leave Analysis": display_leave_analysis_tab,
                "Cost Sim": display_costsim_tab,
                "Hire Plan": display_hireplan_tab,
                "PPT Report": display_ppt_tab,
            }
            for i, key in enumerate(tab_keys_en_dash):
                if key in tab_func_map_dash:
                    if key == "PPT Report":
                        tab_func_map_dash[key](
                            inner_tabs[i], data_dir, key_prefix=fname
                        )
                    elif key == "Leave Analysis":
                        tab_func_map_dash[key](
                            inner_tabs[i], results.get("leave_analysis_results")
                        )
                    else:
                        tab_func_map_dash[key](inner_tabs[i], data_dir)


st.divider()
st.header(_("Dashboard (Upload ZIP)"))
zip_file_uploaded_dash_final_v3_display_main_dash = st.file_uploader(
    _("Upload ZIP file of 'out' folder"),
    type=["zip"],
    key="dashboard_zip_uploader_widget_final_v3_key_dash",
)

if zip_file_uploaded_dash_final_v3_display_main_dash:
    dashboard_temp_base = Path(tempfile.gettempdir()) / "ShiftSuite_Dash_Uploads"
    dashboard_temp_base.mkdir(parents=True, exist_ok=True)
    current_dash_tmp_dir = Path(
        tempfile.mkdtemp(prefix="dash_", dir=dashboard_temp_base)
    )
    log.info(f"„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„ÉâÁî®‰∏ÄÊôÇ„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê: {current_dash_tmp_dir}")
    extracted_data_dir: Optional[Path] = None
    try:
        with zipfile.ZipFile(
            io.BytesIO(zip_file_uploaded_dash_final_v3_display_main_dash.read())
        ) as zf:
            base_resolved = current_dash_tmp_dir.resolve()
            for file_name in zf.namelist():
                dest_path = (current_dash_tmp_dir / file_name).resolve()
                if not dest_path.is_relative_to(base_resolved):
                    st.error(_("Invalid path in ZIP file."))
                    log.warning(f"ZIPÂ±ïÈñã‰∏≠„Å´‰∏çÊ≠£„Å™„Éë„Çπ„ÇíÊ§úÂá∫: {file_name}")
                    st.stop()
                zf.extract(file_name, current_dash_tmp_dir)
            if (current_dash_tmp_dir / "out").exists() and (
                current_dash_tmp_dir / "out" / "heat_ALL.xlsx"
            ).exists():
                extracted_data_dir = current_dash_tmp_dir / "out"
            elif (current_dash_tmp_dir / "heat_ALL.xlsx").exists():
                extracted_data_dir = current_dash_tmp_dir
            else:
                found_heat_all = list(current_dash_tmp_dir.rglob("heat_ALL.xlsx"))
                if found_heat_all:
                    extracted_data_dir = found_heat_all[0].parent
                else:
                    log_and_display_error(
                        _("heat_ALL.xlsx not found in ZIP"),
                        FileNotFoundError("heat_ALL.xlsx"),
                    )
                    log.error(
                        f"ZIPÂ±ïÈñãÂæå„ÄÅheat_ALL.xlsx „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì in {current_dash_tmp_dir}"
                    )
                    st.stop()
        log.info(f"„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„ÉâË°®Á§∫Áî®„ÅÆ„Éá„Éº„Çø„Éá„Ç£„É¨„ÇØ„Éà„É™: {extracted_data_dir}")
    except Exception as e_zip:
        log_and_display_error(_("Error during ZIP file extraction"), e_zip)
        log.error(f"ZIPÂ±ïÈñã‰∏≠„Ç®„É©„Éº: {e_zip}", exc_info=True)
        st.stop()

    import plotly.express as px
    import plotly.graph_objects as go

    tab_keys_en_dash = [
        "Overview",
        "Heatmap",
        "Shortage",
        "Fatigue",
        "Forecast",
        "Fairness",
        "Leave Analysis",
        "Cost Sim",
        "Hire Plan",
        "PPT Report",
    ]
    tab_labels_dash = [_(key) for key in tab_keys_en_dash]
    tabs_obj_dash = st.tabs(tab_labels_dash)

    if extracted_data_dir:
        tab_function_map_dash = {
            "Overview": display_overview_tab,
            "Heatmap": display_heatmap_tab,
            "Shortage": display_shortage_tab,
            "Fatigue": display_fatigue_tab,
            "Forecast": display_forecast_tab,
            "Fairness": display_fairness_tab,
            "Leave Analysis": display_leave_analysis_tab,
            "Cost Sim": display_costsim_tab,
            "Hire Plan": display_hireplan_tab,
            "PPT Report": display_ppt_tab,
        }

        # ÂêÑ„Çø„Éñ„Å´ÂØæÂøú„Åô„ÇãË°®Á§∫Èñ¢Êï∞„ÇíÂëº„Å≥Âá∫„Åô
        for i, tab_key in enumerate(tab_keys_en_dash):
            if tab_key in tab_function_map_dash:
                if tab_key == "PPT Report":
                    tab_function_map_dash[tab_key](
                        tabs_obj_dash[i], extracted_data_dir, key_prefix="zip"
                    )
                elif tab_key == "Leave Analysis":
                    leave_results_zip = load_leave_results_from_dir(extracted_data_dir)
                    tab_function_map_dash[tab_key](tabs_obj_dash[i], leave_results_zip)
                else:
                    tab_function_map_dash[tab_key](tabs_obj_dash[i], extracted_data_dir)
            else:
                with tabs_obj_dash[i]:
                    st.subheader(_(tab_key))
                    st.info(f"{_(tab_key)} „ÅÆË°®Á§∫„ÅØÁèæÂú®Ê∫ñÂÇô‰∏≠„Åß„Åô„ÄÇ")
    else:
        st.warning(
            "„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ„ÇíË°®Á§∫„Åô„Çã„Åü„ÇÅ„ÅÆ„Éá„Éº„Çø„Åå„É≠„Éº„Éâ„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇZIP„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        )

if __name__ == "__main__" and not st_runtime_exists():
    import argparse

    log.info("CLI„É¢„Éº„Éâ„Åßapp.py„ÇíÂÆüË°å„Åó„Åæ„Åô„ÄÇ")
    parser = argparse.ArgumentParser(
        description="Shift-Suite CLI (app.pyÁµåÁî±„ÅÆ„Éá„Éê„ÉÉ„Ç∞Áî®)"
    )
    parser.add_argument("xlsx_file_cli", help="Excel „Ç∑„Éï„ÉàÂéüÊú¨ (.xlsx)")
    parser.add_argument(
        "--sheets_cli", nargs="+", required=True, help="Ëß£ÊûêÂØæË±°„ÅÆ„Ç∑„Éº„ÉàÂêç"
    )
    parser.add_argument(
        "--header_cli", type=int, default=3, help="„Éò„ÉÉ„ÉÄ„ÉºÈñãÂßãË°å (1-indexed)"
    )
    try:
        cli_args = parser.parse_args()
        log.info(
            f"CLI Args: file='{cli_args.xlsx_file_cli}', sheets={cli_args.sheets_cli}, header={cli_args.header_cli}"
        )
    except SystemExit:
        pass
    except Exception as e_cli:
        log.error(f"CLI„É¢„Éº„Éâ„Åß„ÅÆÂÆüË°å‰∏≠„Å´„Ç®„É©„Éº: {e_cli}", exc_info=True)
