# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  app.py  (Part 1 / 3)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Shift-Suite Streamlit GUI + å†…è”µãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰  v1.30.0 (ä¼‘æš‡åˆ†ææ©Ÿèƒ½è¿½åŠ )
# ==============================================================================
# å¤‰æ›´å±¥æ­´
#   â€¢ v1.30.0: ä¼‘æš‡åˆ†ææ©Ÿèƒ½ã‚’è¿½åŠ ã€‚leave_analyzer ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã®é€£æºã‚’å®Ÿè£…ã€‚
#   â€¢ v1.29.13: st.experimental_rerun() ã‚’ st.rerun() ã«ä¿®æ­£ã€‚
#   â€¢ v1.29.12: need_ref_start/end_date_widget ã® StreamlitAPIException å¯¾ç­–ã€‚
#               ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®æ—¥ä»˜ç¯„å›²æ¨å®šçµæœã‚’ã€ãƒ•ãƒ©ã‚°ã‚’ç”¨ã„ã¦
#               æ¬¡å›ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œæ™‚ã«ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ã—ã¦å®‰å…¨ã«åæ˜ ã™ã‚‹ã‚ˆã†ä¿®æ­£ã€‚
#   â€¢ v1.29.11: ãƒ­ã‚°ã§æŒ‡æ‘˜ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ç®‡æ‰€ã‚’ä¿®æ­£ã€‚
#               - shift_sheets_multiselect_widget ã® StreamlitAPIException å¯¾ç­–ã€‚
#               - param_penalty_per_lack ã® NameError ä¿®æ­£ã€‚
#               - progress_bar_exec_main_run ç­‰ã® NameError ä¿®æ­£ã€‚
#               - ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…ã®ã‚¿ã‚¤ãƒä¿®æ­£ã€‚
#   â€¢ v1.29.10: selectboxã®defaultå¼•æ•°ã‚¨ãƒ©ãƒ¼ã‚’indexã«çµ±ä¸€ã—ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒªã‚¹ãƒˆã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰æ­£ã—ãå‚ç…§ã€‚
#               å…¨ã¦ã®ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®å€¤ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ç®¡ç†ã—ã€åˆæœŸåŒ–ã‚’å¾¹åº•ã€‚
#               ãƒ˜ãƒƒãƒ€ãƒ¼é–‹å§‹è¡ŒUIã®è¡¨ç¤ºã¨å€¤ã®åˆ©ç”¨ã‚’ç¢ºå®ŸåŒ–ã€‚
#               Excelæ—¥ä»˜ç¯„å›²æ¨å®šã®å®‰å®šåŒ–ã€‚
#               on_changeã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‰Šé™¤ã—ã€ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆç®¡ç†ã‚’ç›®æŒ‡ã™ã€‚
# ==============================================================================

from __future__ import annotations

import datetime
import io
import json
import logging
import sys
import tempfile
import zipfile
from pathlib import Path
from typing import List, Tuple, Optional, Any

import pandas as pd
import numpy as np
import streamlit as st
from streamlit.runtime import exists as st_runtime_exists
import openpyxl
import plotly.express as px
import plotly.graph_objects as go
import datetime as dt

# â”€â”€ Shift-Suite task modules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from shift_suite.tasks.io_excel import ingest_excel
from shift_suite.tasks.utils import _parse_as_date
from shift_suite.tasks.heatmap import build_heatmap
from shift_suite.tasks.shortage import shortage_and_brief
from shift_suite.tasks.build_stats import build_stats
from shift_suite.tasks.anomaly import detect_anomaly
from shift_suite.tasks.fatigue import train_fatigue
from shift_suite.tasks.cluster import cluster_staff
from shift_suite.tasks.skill_nmf import build_skill_matrix
from shift_suite.tasks.fairness import run_fairness
from shift_suite.tasks.forecast import build_demand_series, forecast_need
from shift_suite.tasks.rl import learn_roster
from shift_suite.tasks.hire_plan import build_hire_plan
from shift_suite.tasks.cost_benefit import analyze_cost_benefit
from shift_suite.tasks.constants import SUMMARY5 as SUMMARY5_CONST
from shift_suite.tasks import leave_analyzer # â˜… æ–°è¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from shift_suite.tasks.leave_analyzer import LEAVE_TYPE_REQUESTED, LEAVE_TYPE_PAID # â˜… å®šæ•°ã‚‚ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from shift_suite.tasks.analyzers import (
    RestTimeAnalyzer,
    WorkPatternAnalyzer,
    AttendanceBehaviorAnalyzer,
    CombinedScoreCalculator,
    LowStaffLoadAnalyzer,
)
from shift_suite.tasks import dashboard

# â”€â”€ ãƒ­ã‚¬ãƒ¼è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log = logging.getLogger("shift_suite_app")
if not log.handlers:
    log.setLevel(logging.INFO)
    handler = logging.StreamHandler(sys.stdout)
    formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(name)s [%(module)s.%(funcName)s:%(lineno)d] - %(message)s')
    handler.setFormatter(formatter)
    log.addHandler(handler)

    from shift_suite.tasks.utils import log as tasks_log
    if not tasks_log.handlers:
        tasks_log.addHandler(handler)
        tasks_log.setLevel(logging.DEBUG)

# â”€â”€ æ—¥æœ¬èªãƒ©ãƒ™ãƒ«è¾æ›¸ & _() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
JP = {
    "Overview": "æ¦‚è¦", "Heatmap": "ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", "Shortage": "ä¸è¶³åˆ†æ",
    "Fatigue": "ç–²åŠ´", "Forecast": "éœ€è¦äºˆæ¸¬", "Fairness": "å…¬å¹³æ€§",
    "Cost Sim": "ã‚³ã‚¹ãƒˆè©¦ç®—", "Hire Plan": "æ¡ç”¨è¨ˆç”»", "PPT Report": "PPTãƒ¬ãƒãƒ¼ãƒˆ",
    "Leave Analysis": "ä¼‘æš‡åˆ†æ",  # â˜… è¿½åŠ 
    "Slot (min)": "ã‚¹ãƒ­ãƒƒãƒˆ (åˆ†)",
    "Need Calculation Settings (Day of Week Pattern)": "ğŸ“Š Needç®—å‡ºè¨­å®š (æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥)",
    "Reference Period for Need Calculation": "å‚ç…§æœŸé–“ (Needç®—å‡ºç”¨)",
    "Rest Time Analysis": "ä¼‘æ¯æ™‚é–“åˆ†æ", "Work Pattern Analysis": "å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ", "Attendance Analysis": "å‡ºå‹¤çŠ¶æ³åˆ†æ", "Combined Score": "ç·åˆã‚¹ã‚³ã‚¢",
    "Low Staff Load": "å°‘äººæ•°å‹¤å‹™åˆ†æ",
    "Start Date": "é–‹å§‹æ—¥", "End Date": "çµ‚äº†æ—¥",
    "Statistical Metric for Need": "çµ±è¨ˆçš„æŒ‡æ¨™ (Needç®—å‡ºç”¨)",
    "Remove Outliers for Need Calculation": "å¤–ã‚Œå€¤ã‚’é™¤å»ã—ã¦Needã‚’ç®—å‡º",
    "(Optional) Upper Limit Calculation Method": "(ã‚ªãƒ—ã‚·ãƒ§ãƒ³) ä¸Šé™å€¤ç®—å‡ºæ–¹æ³•",
    "Min-staff method (for Upper)": "æœ€å°‘äººæ•°ç®—å‡ºæ³• (ä¸Šé™å€¤ç”¨)",
    "Max-staff method (for Upper)": "æœ€å¤§äººæ•°ç®—å‡ºæ³• (ä¸Šé™å€¤ç”¨)",
    "Extra modules": "è¿½åŠ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«", "Save method": "ä¿å­˜æ–¹æ³•",
    "ZIP Download": "ZIPå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", "Save to folder": "ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜",
    "Run Analysis": "â–¶ è§£æå®Ÿè¡Œ", "Cost & Hire Parameters": "ğŸ’° ã‚³ã‚¹ãƒˆãƒ»æ¡ç”¨è¨ˆç”»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
    "Standard work hours (h/month)": "æ‰€å®šåŠ´åƒæ™‚é–“ (h/æœˆ)",
    "Safety factor (shortage h multiplier)": "å®‰å…¨ä¿‚æ•° (ä¸è¶³hä¸Šä¹—ã›)",
    "Target coverage rate": "ç›®æ¨™å……è¶³ç‡",
    "Direct employee labor cost (Â¥/h)": "æ­£è·å“¡ äººä»¶è²» (Â¥/h)",
    "Temporary staff labor cost (Â¥/h)": "æ´¾é£ äººä»¶è²» (Â¥/h)",
    "One-time hiring cost (Â¥/person)": "æ¡ç”¨ä¸€æ™‚ã‚³ã‚¹ãƒˆ (Â¥/äºº)",
    "Penalty for shortage (Â¥/h)": "ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ (Â¥/h)",
    "Upload Excel shift file (*.xlsx)": "Excel ã‚·ãƒ•ãƒˆè¡¨ (*.xlsx) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    "Select shift sheets to analyze (multiple)": "è§£æã™ã‚‹ã‚·ãƒ•ãƒˆã‚·ãƒ¼ãƒˆï¼ˆè¤‡æ•°å¯ï¼‰",
    "Header start row (1-indexed)": "ãƒ˜ãƒƒãƒ€ãƒ¼é–‹å§‹è¡Œ (1-indexed)",
    "File Preview (first 8 rows)": "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å…ˆé ­8è¡Œ)",
    "Error during preview display": "ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
    "Error saving Excel file": "Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
    "Error getting sheet names from Excel": "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚·ãƒ¼ãƒˆåã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
    "No analysis target sheets found": "å‹¤å‹™åŒºåˆ†ã‚·ãƒ¼ãƒˆä»¥å¤–ã®è§£æå¯¾è±¡ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€å…¨ã¦ã®ã‚·ãƒ¼ãƒˆåã«ã€Œå‹¤å‹™åŒºåˆ†ã€ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚",
    "Analysis in progress...": "è§£ææº–å‚™ä¸­...",
    "Ingest: Reading Excel data...": "Excelãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­â€¦",
    "Heatmap: Generating heatmap...": "Heatmapç”Ÿæˆä¸­â€¦",
    "Shortage: Analyzing shortage...": "Shortage (ä¸è¶³åˆ†æ) ä¸­â€¦",
    "Stats: Processing...": "Stats (çµ±è¨ˆæƒ…å ±) ç”Ÿæˆä¸­â€¦",
    "Anomaly: Processing...": "Anomaly (ç•°å¸¸æ¤œçŸ¥) ä¸­â€¦",
    "Fatigue: Processing...": "Fatigue (ç–²åŠ´åˆ†æ) ä¸­â€¦",
    "Cluster: Processing...": "Cluster (ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°) ä¸­â€¦",
    "Skill: Processing...": "Skill (ã‚¹ã‚­ãƒ«NMF) ä¸­â€¦",
    "Fairness: Processing...": "Fairness (å…¬å¹³æ€§åˆ†æ) ä¸­â€¦",
    "Leave Analysis: Processing...": "Leave Analysis (ä¼‘æš‡åˆ†æ) ä¸­â€¦",  # â˜… è¿½åŠ 
    "Need forecast: Processing...": "Need forecast (éœ€è¦äºˆæ¸¬) ä¸­â€¦",
    "RL roster (PPO): Processing...": "RL roster (å¼·åŒ–å­¦ç¿’ã‚·ãƒ•ãƒˆ) ä¸­â€¦",
    "Rest Time Analysis: Processing...": "Rest Time Analysis (ä¼‘æ¯æ™‚é–“åˆ†æ) ä¸­â€¦",
    "Work Pattern Analysis: Processing...": "å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ ä¸­â€¦",
    "Attendance Analysis: Processing...": "å‡ºå‹¤çŠ¶æ³åˆ†æ ä¸­â€¦",
    "Combined Score: Processing...": "ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®— ä¸­â€¦",
    "Low Staff Load: Processing...": "å°‘äººæ•°å‹¤å‹™åˆ†æ ä¸­â€¦",
    "Hire plan: Processing...": "Hire plan (æ¡ç”¨è¨ˆç”») ä¸­â€¦",
    "Cost / Benefit: Processing...": "Cost / Benefit (ã‚³ã‚¹ãƒˆä¾¿ç›Šåˆ†æ) ä¸­â€¦",
    "Ingest: Excel data read complete.": "âœ… Excelãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†",
    "All processes complete!": "ğŸ‰ å…¨ã¦ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼",
    "Error during analysis (ValueError)": "è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (ValueError)",
    "Required file not found": "å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
    "Unexpected error occurred": "äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
    "Save Analysis Results": "ğŸ“ è§£æçµæœã®ä¿å­˜",
    "Output folder": "å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€",
    "Open the above path in Explorer.": "ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼ã§ä¸Šè¨˜ã®ãƒ‘ã‚¹ã‚’é–‹ã„ã¦ã”ç¢ºèªãã ã•ã„ã€‚",
    "Download analysis results as ZIP": "ğŸ“¥ è§£æçµæœã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
    "Error creating ZIP file": "ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
    "Dashboard (Upload ZIP)": "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ (ZIP ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰)",
    "Upload ZIP file of 'out' folder": "out ãƒ•ã‚©ãƒ«ãƒ€ã‚’ ZIP åœ§ç¸®ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    "heat_ALL.xlsx not found in ZIP": "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸZIPãƒ•ã‚¡ã‚¤ãƒ«å†…ã« heat_ALL.xlsx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ZIPã®æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
    "Failed to extract ZIP file.": "ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®å±•é–‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
    "Uploaded file is not a valid ZIP file.": "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯æœ‰åŠ¹ãªZIPãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
    "Error during ZIP file extraction": "ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®å±•é–‹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
    "Display Mode": "è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰", "Raw Count": "äººæ•°", "Ratio (staff Ã· need)": "Ratio (staff Ã· need)",
    "Color Scale Max (zmax)": "ã‚«ãƒ©ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ä¸Šé™ (zmax)",
    "Shortage by Role (hours)": "è·ç¨®åˆ¥ä¸è¶³æ™‚é–“ (h)",
    "Shortage by Time (count per day)": "æ™‚é–“å¸¯åˆ¥ä¸è¶³äººæ•° (æ—¥åˆ¥)",
    "Select date to display": "è¡¨ç¤ºã™ã‚‹æ—¥ä»˜ã‚’é¸æŠ",
    "No date columns in shortage data.": "ä¸è¶³æ™‚é–“ãƒ‡ãƒ¼ã‚¿ã«æ—¥ä»˜åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
    "Display all time-slot shortage data": "å…¨æ™‚é–“å¸¯åˆ¥ä¸è¶³ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º",
    "Fatigue Score per Staff": "ã‚¹ã‚¿ãƒƒãƒ•åˆ¥ç–²åŠ´ã‚¹ã‚³ã‚¢",
    "Demand Forecast (yhat)": "éœ€è¦äºˆæ¸¬çµæœ (yhat)", "Actual (y)": "å®Ÿç¸¾ (y)",
    "Display forecast data": "äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º",
    "Fairness (Night Shift Ratio)": "å…¬å¹³æ€§ (å¤œå‹¤æ¯”ç‡)",
    "Cost Simulation (Million Â¥)": "ã‚³ã‚¹ãƒˆè©¦ç®— (ç™¾ä¸‡å††)",
    "Hiring Plan (Needed FTE)": "æ¡ç”¨è¨ˆç”» (å¿…è¦æ¡ç”¨äººæ•°)",
    "Hiring Plan Parameters": "æ¡ç”¨è¨ˆç”»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
    "Generate PowerPoint Report (Î²)": "ğŸ“Š PowerPointãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ (Î²ç‰ˆ)",
    "Generating PowerPoint report...": "PowerPointãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­ã§ã™... å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã€‚",
    "PowerPoint report ready.": "PowerPointãƒ¬ãƒãƒ¼ãƒˆã®æº–å‚™ãŒã§ãã¾ã—ãŸã€‚",
    "Download Report (PPTX)": "ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆ(PPTX)ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
    "python-pptx library required for PPT": "PowerPointãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«ã¯ `python-pptx` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ã€‚\nã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: `pip install python-pptx`",
    "Error generating PowerPoint report": "PowerPointãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
    "Click button to generate report.": "ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€ä¸»è¦ãªåˆ†æçµæœã‚’å«ã‚€PowerPointãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã™ï¼ˆç¾åœ¨ã¯Î²ç‰ˆã§ã™ï¼‰ã€‚",
}
def _(text_key: str) -> str:
    return JP.get(text_key, text_key)

st.set_page_config(page_title="Shift-Suite", layout="wide", initial_sidebar_state="expanded")
st.title("ğŸ—‚ï¸ Shift-Suite : å‹¤å‹™ã‚·ãƒ•ãƒˆåˆ†æãƒ„ãƒ¼ãƒ«")

master_sheet_keyword = "å‹¤å‹™åŒºåˆ†"

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– (ä¸€åº¦ã ã‘å®Ÿè¡Œ) ---
if "app_initialized" not in st.session_state:
    st.session_state.app_initialized = True
    st.session_state.analysis_done = False
    st.session_state.work_root_path_str = None
    st.session_state.out_dir_path_str = None
    st.session_state.current_step_for_progress = 0

    today_val = datetime.date.today()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®ã‚­ãƒ¼ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«åˆæœŸè¨­å®š
    st.session_state.slot_input_widget = 30
    st.session_state.header_row_input_widget = 3
    st.session_state.candidate_sheet_list_for_ui = []
    st.session_state.shift_sheets_multiselect_widget = []
    st.session_state._force_update_multiselect_flag = False

    st.session_state.need_ref_start_date_widget = today_val - datetime.timedelta(days=59) # åˆæœŸãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    st.session_state.need_ref_end_date_widget = today_val - datetime.timedelta(days=1)   # åˆæœŸãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    st.session_state._force_update_need_ref_dates_flag = False
    st.session_state._intended_need_ref_start_date = None
    st.session_state._intended_need_ref_end_date = None

    st.session_state.need_stat_method_options_widget = ["10ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«", "25ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«", "ä¸­å¤®å€¤", "å¹³å‡å€¤"]
    st.session_state.need_stat_method_widget = "ä¸­å¤®å€¤"
    st.session_state.need_remove_outliers_widget = True

    st.session_state.min_method_for_upper_options_widget = ["mean-1s", "p25", "mode"]
    st.session_state.min_method_for_upper_widget = "p25"
    st.session_state.max_method_for_upper_options_widget = ["mean+1s", "p75"]
    st.session_state.max_method_for_upper_widget = "p75"

    # â˜… ä¼‘æš‡åˆ†æã‚’å«ã‚€è¿½åŠ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒªã‚¹ãƒˆ
    st.session_state.available_ext_opts_widget = [
        "Stats", "Anomaly", "Fatigue", "Cluster", "Skill", "Fairness", "Rest Time Analysis", "Work Pattern Analysis", "Attendance Analysis", "Combined Score", "Low Staff Load", _("Leave Analysis"), "Need forecast", "RL roster (PPO)", "Hire plan", "Cost / Benefit"
    ]
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ä¼‘æš‡åˆ†æã‚‚é¸æŠçŠ¶æ…‹ã«ã™ã‚‹ã‹ã¯ãŠå¥½ã¿ã§
    st.session_state.ext_opts_multiselect_widget = st.session_state.available_ext_opts_widget[:] 

    st.session_state.save_mode_selectbox_options_widget = [_("ZIP Download"), _("Save to folder")]
    st.session_state.save_mode_selectbox_widget = _("ZIP Download")

    st.session_state.std_work_hours_widget = 160
    st.session_state.safety_factor_widget = 1.10
    st.session_state.target_coverage_widget = 0.95
    st.session_state.wage_direct_widget = 1500
    st.session_state.wage_temp_widget = 2200
    st.session_state.hiring_cost_once_widget = 180000
    st.session_state.penalty_per_lack_widget = 4000

    st.session_state.excel_path_for_run_script_str = None
    st.session_state.last_uploaded_file_name = None
    st.session_state.last_uploaded_file_size = None

    # â˜… ä¼‘æš‡åˆ†æç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆæœŸåŒ–
    st.session_state.leave_analysis_target_types_widget = [LEAVE_TYPE_REQUESTED, LEAVE_TYPE_PAID] # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ä¸¡æ–¹
    st.session_state.leave_concentration_threshold_widget = 3 # å¸Œæœ›ä¼‘é›†ä¸­åº¦é–¾å€¤ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    # â˜… ä¼‘æš‡åˆ†æçµæœæ ¼ç´ç”¨
    st.session_state.leave_analysis_results = {}
    
    st.session_state.rest_time_results = None
    st.session_state.rest_time_monthly = None
    st.session_state.work_pattern_results = None
    st.session_state.work_pattern_monthly = None
    st.session_state.attendance_results = None
    st.session_state.combined_score_results = None
    st.session_state.low_staff_load_results = None
    log.info("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®UIè¦ç´  ---
with st.sidebar:
    st.header("ğŸ› ï¸ è§£æè¨­å®š")

    st.number_input(_("Slot (min)"), 5, 120,
                    key="slot_input_widget", help="åˆ†æã®æ™‚é–“é–“éš”ï¼ˆåˆ†ï¼‰")

    st.subheader("ğŸ“„ ã‚·ãƒ¼ãƒˆé¸æŠã¨ãƒ˜ãƒƒãƒ€ãƒ¼")

    if st.session_state.get("_force_update_multiselect_flag", False):
        new_options = st.session_state.candidate_sheet_list_for_ui
        current_selection = st.session_state.get("shift_sheets_multiselect_widget", [])
        valid_selection = [s for s in current_selection if s in new_options]
        if not valid_selection and new_options:
             st.session_state.shift_sheets_multiselect_widget = new_options[:]
        elif valid_selection:
             st.session_state.shift_sheets_multiselect_widget = valid_selection
        else:
             st.session_state.shift_sheets_multiselect_widget = []
        st.session_state._force_update_multiselect_flag = False

    st.multiselect(
        _("Select shift sheets to analyze (multiple)"),
        options=st.session_state.candidate_sheet_list_for_ui,
        default=st.session_state.shift_sheets_multiselect_widget,
        key="shift_sheets_multiselect_widget"
    )
    st.number_input(
        _("Header start row (1-indexed)"), 1, 20,
        key="header_row_input_widget"
    )

    st.subheader(_("Need Calculation Settings (Day of Week Pattern)"))

    if st.session_state.get("_force_update_need_ref_dates_flag", False):
        if st.session_state.get("_intended_need_ref_start_date"):
            st.session_state.need_ref_start_date_widget = st.session_state._intended_need_ref_start_date
        if st.session_state.get("_intended_need_ref_end_date"):
            st.session_state.need_ref_end_date_widget = st.session_state._intended_need_ref_end_date
        st.session_state._force_update_need_ref_dates_flag = False
        if "_intended_need_ref_start_date" in st.session_state: del st.session_state["_intended_need_ref_start_date"]
        if "_intended_need_ref_end_date" in st.session_state: del st.session_state["_intended_need_ref_end_date"]

    c1_need_ui, c2_need_ui = st.columns(2)
    with c1_need_ui:
        st.date_input(
            _("Start Date"),
            key="need_ref_start_date_widget", help="Needç®—å‡ºã®å‚ç…§æœŸé–“ã®é–‹å§‹æ—¥"
        )
    with c2_need_ui:
        st.date_input(
            _("End Date"),
            key="need_ref_end_date_widget", help="Needç®—å‡ºã®å‚ç…§æœŸé–“ã®çµ‚äº†æ—¥"
        )
    st.caption(_("Reference Period for Need Calculation"))

    current_need_stat_method_idx_val = 0
    try:
        current_need_stat_method_idx_val = st.session_state.need_stat_method_options_widget.index(st.session_state.need_stat_method_widget)
    except (ValueError, AttributeError):
        current_need_stat_method_idx_val = 2
    st.selectbox(
        _("Statistical Metric for Need"), options=st.session_state.need_stat_method_options_widget,
        index=current_need_stat_method_idx_val,
        key="need_stat_method_widget", help="æ›œæ—¥åˆ¥ãƒ»æ™‚é–“å¸¯åˆ¥ã®Needã‚’ç®—å‡ºã™ã‚‹éš›ã®çµ±è¨ˆæŒ‡æ¨™"
    )
    st.checkbox(
        _("Remove Outliers for Need Calculation"),
        key="need_remove_outliers_widget", help="IQRæ³•ã§å¤–ã‚Œå€¤ã‚’é™¤å»ã—ã¦ã‹ã‚‰çµ±è¨ˆé‡ã‚’è¨ˆç®—ã—ã¾ã™"
    )

    with st.expander(_("(Optional) Upper Limit Calculation Method"), expanded=False):
        current_min_method_upper_idx_val = 0
        try: current_min_method_upper_idx_val = st.session_state.min_method_for_upper_options_widget.index(st.session_state.min_method_for_upper_widget)
        except (ValueError, AttributeError): current_min_method_upper_idx_val = 1
        st.selectbox(
            _("Min-staff method (for Upper)"), options=st.session_state.min_method_for_upper_options_widget,
            index=current_min_method_upper_idx_val, key="min_method_for_upper_widget",
            help="ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ã€ä»£è¡¨çš„ãªä¸Šé™ã‚¹ã‚¿ãƒƒãƒ•æ•°ã€ã®ç®—å‡ºæ–¹æ³•ã®ä¸€éƒ¨"
        )
        current_max_method_upper_idx_val = 0
        try: current_max_method_upper_idx_val = st.session_state.max_method_for_upper_options_widget.index(st.session_state.max_method_for_upper_widget)
        except (ValueError, AttributeError): current_max_method_upper_idx_val = 0
        st.selectbox(
            _("Max-staff method (for Upper)"), options=st.session_state.max_method_for_upper_options_widget,
            index=current_max_method_upper_idx_val, key="max_method_for_upper_widget",
            help="ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ã€ä»£è¡¨çš„ãªä¸Šé™ã‚¹ã‚¿ãƒƒãƒ•æ•°ã€ã®ç®—å‡ºæ–¹æ³•"
        )

    st.divider()
    st.subheader("è¿½åŠ åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«")

    st.multiselect(
        _("Extra modules"), st.session_state.available_ext_opts_widget,
        default=st.session_state.ext_opts_multiselect_widget, # åˆæœŸå€¤ã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰
        key="ext_opts_multiselect_widget", help="å®Ÿè¡Œã™ã‚‹è¿½åŠ ã®åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’é¸æŠã—ã¾ã™ã€‚"
    )

    # â˜… ä¼‘æš‡åˆ†æãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ã€é–¢é€£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šUIã‚’è¡¨ç¤º
    if _("Leave Analysis") in st.session_state.ext_opts_multiselect_widget:
        with st.expander("ğŸ“Š " + _("Leave Analysis") + " è¨­å®š", expanded=True):
            st.multiselect(
                "åˆ†æå¯¾è±¡ã®ä¼‘æš‡ã‚¿ã‚¤ãƒ—",
                options=[LEAVE_TYPE_REQUESTED, LEAVE_TYPE_PAID], # å°†æ¥çš„ã« 'ãã®ä»–ä¼‘æš‡' ãªã©ã‚‚è¿½åŠ å¯èƒ½
                key="leave_analysis_target_types_widget",
                help="åˆ†æã™ã‚‹ä¼‘æš‡ã®ç¨®é¡ã‚’é¸æŠã—ã¾ã™ã€‚"
            )
            # å¸Œæœ›ä¼‘ãŒåˆ†æå¯¾è±¡ã«å«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿é–¾å€¤è¨­å®šã‚’è¡¨ç¤º
            if LEAVE_TYPE_REQUESTED in st.session_state.leave_analysis_target_types_widget:
                st.number_input(
                    "å¸Œæœ›ä¼‘ é›†ä¸­åº¦åˆ¤å®šé–¾å€¤ (äºº)", 
                    min_value=1, 
                    step=1,
                    key="leave_concentration_threshold_widget",
                    help="åŒæ—¥ã«ã“ã®äººæ•°ä»¥ä¸Šã®å¸Œæœ›ä¼‘ãŒã‚ã£ãŸå ´åˆã«ã€Œé›†ä¸­ã€ã¨ã¿ãªã—ã¾ã™ã€‚"
                )

    current_save_mode_idx_val = 0
    try: current_save_mode_idx_val = st.session_state.save_mode_selectbox_options_widget.index(st.session_state.save_mode_selectbox_widget)
    except (ValueError, AttributeError): current_save_mode_idx_val = 0
    st.selectbox(
        _("Save method"), options=st.session_state.save_mode_selectbox_options_widget,
        index=current_save_mode_idx_val,
        key="save_mode_selectbox_widget", help="è§£æçµæœã®ä¿å­˜æ–¹æ³•ã‚’é¸æŠã—ã¾ã™ã€‚"
    )

    with st.expander(_("Cost & Hire Parameters")):
        st.number_input(_("Standard work hours (h/month)"),   100, 300, key="std_work_hours_widget")
        st.slider      (_("Safety factor (shortage h multiplier)"), 1.00, 2.00, key="safety_factor_widget")
        st.slider      (_("Target coverage rate"), 0.50, 1.00, key="target_coverage_widget")
        st.number_input(_("Direct employee labor cost (Â¥/h)"),   500, 10000, key="wage_direct_widget")
        st.number_input(_("Temporary staff labor cost (Â¥/h)"),   800, 12000, key="wage_temp_widget")
        st.number_input(_("One-time hiring cost (Â¥/person)"), 0, 1000000, key="hiring_cost_once_widget")
        st.number_input(_("Penalty for shortage (Â¥/h)"), 0, 20000, key="penalty_per_lack_widget")

# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢ ---
st.header("1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨è¨­å®š")
uploaded_file = st.file_uploader(
    _("Upload Excel shift file (*.xlsx)"),
    type=["xlsx"],
    key="excel_uploader_main_content_area_key",
    help="å‹¤å‹™å®Ÿç¸¾ã¨å‹¤å‹™åŒºåˆ†ãŒè¨˜è¼‰ã•ã‚ŒãŸExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
)

if uploaded_file:
    if st.session_state.get("last_uploaded_file_name") != uploaded_file.name or \
       st.session_state.get("last_uploaded_file_size") != uploaded_file.size:

        st.session_state.last_uploaded_file_name = uploaded_file.name
        st.session_state.last_uploaded_file_size = uploaded_file.size

        if st.session_state.work_root_path_str is None or not Path(st.session_state.work_root_path_str).exists():
            st.session_state.work_root_path_str = tempfile.mkdtemp(prefix="ShiftSuite_")
            log.info(f"æ–°ã—ã„ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {st.session_state.work_root_path_str}")

        st.session_state.analysis_done = False
        work_root_on_upload = Path(st.session_state.work_root_path_str)
        st.session_state.excel_path_for_run_script_str = str(work_root_on_upload / uploaded_file.name)

        excel_path_for_processing = Path(st.session_state.excel_path_for_run_script_str)

        try:
            with open(excel_path_for_processing, "wb") as f_wb:
                f_wb.write(uploaded_file.getbuffer())
            log.info(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {excel_path_for_processing}")

            current_header_for_est = st.session_state.header_row_input_widget - 1
            try:
                temp_sheets_data = pd.read_excel(excel_path_for_processing, sheet_name=None, header=current_header_for_est, nrows=1)
                all_sheet_names_from_file = list(temp_sheets_data.keys())

                candidate_sheets_from_file = [s_name for s_name in all_sheet_names_from_file if master_sheet_keyword.lower() not in s_name.lower()]
                st.session_state.candidate_sheet_list_for_ui = candidate_sheets_from_file
                st.session_state._force_update_multiselect_flag = True

                first_content_sheet_name = next((s for s in candidate_sheets_from_file if s in temp_sheets_data), None)
                if first_content_sheet_name:
                    df_sample = temp_sheets_data[first_content_sheet_name]
                    parsed_dates_in_sample: List[datetime.date] = []
                    for col_header in df_sample.columns:
                        parsed_date = _parse_as_date(str(col_header))
                        if parsed_date: parsed_dates_in_sample.append(parsed_date)

                    valid_dates_final = sorted([d for d in parsed_dates_in_sample if d is not pd.NaT and d is not None])
                    if valid_dates_final:
                        st.session_state._intended_need_ref_start_date = valid_dates_final[0]
                        st.session_state._intended_need_ref_end_date = valid_dates_final[-1]
                        st.session_state._force_update_need_ref_dates_flag = True
                        log.info(f"Excelæ—¥ä»˜ç¯„å›²æ¨å®š(Needå‚ç…§æœŸé–“ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”¨): {valid_dates_final[0]} - {valid_dates_final[-1]}")
                    else: log.warning("Excelã‹ã‚‰æœ‰åŠ¹ãªæ—¥ä»˜åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãšã€æ—¥ä»˜ç¯„å›²ã‚’æ¨å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                else: log.warning("å‹¤å‹™åŒºåˆ†ã‚·ãƒ¼ãƒˆä»¥å¤–ã®è§£æå¯¾è±¡ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãšã€æ—¥ä»˜ç¯„å›²ã‚’æ¨å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

                st.rerun()

            except Exception as e_date_range_process:
                log.warning(f"Excelã®æ—¥ä»˜ç¯„å›²ãƒ»ã‚·ãƒ¼ãƒˆåå–å¾—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_date_range_process}", exc_info=True)
        except Exception as e_save_file_process:
            st.error(_("Error saving Excel file") + f": {e_save_file_process}")

# ã€Œè§£æå®Ÿè¡Œã€ãƒœã‚¿ãƒ³
run_button_disabled_status = not st.session_state.get("excel_path_for_run_script_str") or \
                               not st.session_state.get("shift_sheets_multiselect_widget", [])
run_button_clicked = st.button(
    _("Run Analysis"), key="run_analysis_button_final_trigger", use_container_width=True, type="primary",
    disabled=run_button_disabled_status
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  app.py  (Part 2 / 3)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if run_button_clicked:
    st.session_state.analysis_done = False
    st.session_state.current_step_for_progress = 0

    excel_path_to_use = Path(st.session_state.excel_path_for_run_script_str) if st.session_state.excel_path_for_run_script_str else None
    if st.session_state.work_root_path_str is None or excel_path_to_use is None :
        st.error("Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    work_root_exec = Path(st.session_state.work_root_path_str)
    st.session_state.out_dir_path_str = str(work_root_exec / "out")
    out_dir_exec = Path(st.session_state.out_dir_path_str)
    out_dir_exec.mkdir(parents=True, exist_ok=True)
    log.info(f"è§£æå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {out_dir_exec}")

    # --- å®Ÿè¡Œæ™‚ã®UIã®å€¤ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰å–å¾— ---
    param_selected_sheets = st.session_state.shift_sheets_multiselect_widget
    param_header_row = st.session_state.header_row_input_widget
    param_slot = st.session_state.slot_input_widget
    param_ref_start = st.session_state.need_ref_start_date_widget
    param_ref_end = st.session_state.need_ref_end_date_widget
    param_need_stat = st.session_state.need_stat_method_widget
    param_need_outlier = st.session_state.need_remove_outliers_widget
    param_min_method_upper = st.session_state.min_method_for_upper_widget
    param_max_method_upper = st.session_state.max_method_for_upper_widget
    param_ext_opts = st.session_state.ext_opts_multiselect_widget
    param_save_mode = st.session_state.save_mode_selectbox_widget
    param_std_work_hours = st.session_state.std_work_hours_widget
    param_safety_factor = st.session_state.safety_factor_widget
    param_target_coverage = st.session_state.target_coverage_widget
    param_wage_direct = st.session_state.wage_direct_widget
    param_wage_temp = st.session_state.wage_temp_widget
    param_hiring_cost = st.session_state.hiring_cost_once_widget
    param_penalty_lack = st.session_state.penalty_per_lack_widget
    
    # â˜… ä¼‘æš‡åˆ†æç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å–å¾—
    param_leave_target_types = st.session_state.leave_analysis_target_types_widget
    param_leave_concentration_threshold = st.session_state.leave_concentration_threshold_widget
    
    # â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆå†…ã®å‰å›çµæœã‚’ã‚¯ãƒªã‚¢
    st.session_state.leave_analysis_results = {}
    # --- UIå€¤å–å¾—ã“ã“ã¾ã§ ---

    st.session_state.rest_time_results = None
    st.session_state.work_pattern_results = None
    st.session_state.attendance_results = None
    st.session_state.combined_score_results = None
    st.session_state.low_staff_load_results = None
    progress_text_area = st.empty()
    progress_bar_val = st.progress(0)
    total_steps_exec_run = 3 + len(param_ext_opts)

    def update_progress_exec_run(step_name_key_exec: str):
        st.session_state.current_step_for_progress += 1
        progress_percentage_exec_run = int((st.session_state.current_step_for_progress / total_steps_exec_run) * 100)
        progress_percentage_exec_run = min(progress_percentage_exec_run, 100)
        try:
            progress_bar_val.progress(progress_percentage_exec_run)
            progress_text_area.info(f"âš™ï¸ {st.session_state.current_step_for_progress}/{total_steps_exec_run} - {_(step_name_key_exec)}")
        except Exception as e_prog_exec_run: 
            log.warning(f"é€²æ—è¡¨ç¤ºã®æ›´æ–°ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e_prog_exec_run}")

    st.markdown("---")
    st.header("2. è§£æå‡¦ç†")
    try:
        if param_selected_sheets and excel_path_to_use:
            update_progress_exec_run("File Preview (first 8 rows)")
            st.subheader(_("File Preview (first 8 rows)"))
            try:
                preview_df_exec_run = pd.read_excel(excel_path_to_use, sheet_name=param_selected_sheets[0], header=None, nrows=8)
                st.dataframe(preview_df_exec_run.astype(str), use_container_width=True)
            except Exception as e_prev_exec_run: 
                st.warning(_("Error during preview display") + f": {e_prev_exec_run}")
                log.warning(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e_prev_exec_run}", exc_info=True)
        else: 
            st.warning("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹ã‚·ãƒ¼ãƒˆãŒé¸æŠã•ã‚Œã¦ã„ãªã„ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒç„¡åŠ¹ã§ã™ã€‚")

        update_progress_exec_run("Ingest: Reading Excel data...")
        long_df, wt_df = ingest_excel(excel_path_to_use, shift_sheets=param_selected_sheets, header_row=param_header_row)
        log.info(f"Ingestå®Œäº†. long_df shape: {long_df.shape}, wt_df shape: {wt_df.shape if wt_df is not None else 'N/A'}")
        st.success(_("Ingest: Excel data read complete."))

        update_progress_exec_run("Heatmap: Generating heatmap...")
        build_heatmap(
            long_df, out_dir_exec, param_slot,
            ref_start_date_for_need=param_ref_start,
            ref_end_date_for_need=param_ref_end,
            need_statistic_method=param_need_stat,
            need_remove_outliers=param_need_outlier,
            need_iqr_multiplier=1.5,
            min_method=param_min_method_upper,
            max_method=param_max_method_upper
        )
        st.success("âœ… Heatmapç”Ÿæˆå®Œäº†")

        update_progress_exec_run("Shortage: Analyzing shortage...")
        shortage_result_exec_run = shortage_and_brief(out_dir_exec, param_slot)
        if shortage_result_exec_run is None: 
            st.warning("Shortage (ä¸è¶³åˆ†æ) ã®ä¸€éƒ¨ã¾ãŸã¯å…¨ã¦ãŒå®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
        else: 
            st.success("âœ… Shortage (ä¸è¶³åˆ†æ) å®Œäº†")

        # â˜…----- ä¼‘æš‡åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®Ÿè¡Œ -----â˜…
        # "ä¼‘æš‡åˆ†æ" (æ—¥æœ¬èª) ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        if _("Leave Analysis") in param_ext_opts:
            update_progress_exec_run("Leave Analysis: Processing...")
            st.info(f"{_('Leave Analysis')} å‡¦ç†ä¸­â€¦")
            try:
                if 'long_df' in locals() and not long_df.empty:
                    # 1. æ—¥æ¬¡ãƒ»è·å“¡åˆ¥ã®ä¼‘æš‡å–å¾—ãƒ•ãƒ©ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                    daily_leave_df = leave_analyzer.get_daily_leave_counts(
                        long_df,
                        target_leave_types=param_leave_target_types
                    )
                    st.session_state.leave_analysis_results['daily_leave_df'] = daily_leave_df
                    
                    if not daily_leave_df.empty:
                        leave_results_temp = {} # ä¸€æ™‚çš„ãªçµæœæ ¼ç´ç”¨
                        
                        # 2. å¸Œæœ›ä¼‘é–¢é€£ã®é›†è¨ˆã¨åˆ†æ
                        if LEAVE_TYPE_REQUESTED in param_leave_target_types:
                            requested_leave_daily = daily_leave_df[daily_leave_df['leave_type'] == LEAVE_TYPE_REQUESTED]
                            if not requested_leave_daily.empty:
                                leave_results_temp['summary_dow_requested'] = leave_analyzer.summarize_leave_by_day_count(requested_leave_daily.copy(), period='dayofweek')
                                leave_results_temp['summary_month_period_requested'] = leave_analyzer.summarize_leave_by_day_count(requested_leave_daily.copy(), period='month_period')
                                leave_results_temp['summary_month_requested'] = leave_analyzer.summarize_leave_by_day_count(requested_leave_daily.copy(), period='month')
                                
                                daily_requested_applicants_counts = leave_analyzer.summarize_leave_by_day_count(requested_leave_daily.copy(), period='date')
                                leave_results_temp['concentration_requested'] = leave_analyzer.analyze_leave_concentration(
                                    daily_requested_applicants_counts,
                                    leave_type_to_analyze=LEAVE_TYPE_REQUESTED,
                                    concentration_threshold=param_leave_concentration_threshold
                                )
                                # --- æ–°è¦: å‹¤å‹™äºˆå®šäººæ•°ã¨ã®æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ä½œæˆ ---
                                try:
                                    total_staff_per_day = (
                                        long_df[long_df["parsed_slots_count"] > 0]
                                        .assign(date=lambda df: pd.to_datetime(df["ds"]).dt.normalize())
                                        .groupby("date")["staff"].nunique()
                                        .reset_index(name="total_staff")
                                    )
                                    staff_balance = total_staff_per_day.merge(
                                        daily_requested_applicants_counts.rename(columns={"total_leave_days": "leave_applicants_count"})[["date", "leave_applicants_count"]],
                                        on="date",
                                        how="left",
                                    )
                                    staff_balance["leave_applicants_count"] = staff_balance["leave_applicants_count"].fillna(0).astype(int)
                                    staff_balance["non_leave_staff"] = staff_balance["total_staff"] - staff_balance["leave_applicants_count"]
                                    leave_results_temp["staff_balance_daily"] = staff_balance
                                except Exception as e:
                                    log.error(f"å‹¤å‹™äºˆå®šäººæ•°ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                            else:
                                log.info(f"{LEAVE_TYPE_REQUESTED} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€é–¢é€£ã™ã‚‹é›†è¨ˆãƒ»åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
                                leave_results_temp['summary_dow_requested'] = pd.DataFrame()
                                leave_results_temp['summary_month_period_requested'] = pd.DataFrame()
                                leave_results_temp['summary_month_requested'] = pd.DataFrame()
                                leave_results_temp['concentration_requested'] = pd.DataFrame()
                        
                        # 3. æœ‰çµ¦ä¼‘æš‡é–¢é€£ã®é›†è¨ˆ
                        if LEAVE_TYPE_PAID in param_leave_target_types:
                            paid_leave_daily = daily_leave_df[daily_leave_df['leave_type'] == LEAVE_TYPE_PAID]
                            if not paid_leave_daily.empty:
                                leave_results_temp['summary_dow_paid'] = leave_analyzer.summarize_leave_by_day_count(paid_leave_daily.copy(), period='dayofweek')
                                leave_results_temp['summary_month_paid'] = leave_analyzer.summarize_leave_by_day_count(paid_leave_daily.copy(), period='month')
                            else:
                                log.info(f"{LEAVE_TYPE_PAID} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€é–¢é€£ã™ã‚‹é›†è¨ˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
                                leave_results_temp['summary_dow_paid'] = pd.DataFrame()
                                leave_results_temp['summary_month_paid'] = pd.DataFrame()
                        
                        # 4. è·å“¡åˆ¥ä¼‘æš‡ãƒªã‚¹ãƒˆ (çµ‚æ—¥ã®ã¿)
                        leave_results_temp['staff_leave_list'] = leave_analyzer.get_staff_leave_list(long_df, target_leave_types=param_leave_target_types)
                        
                        st.session_state.leave_analysis_results.update(leave_results_temp)
                        st.success(f"âœ… {_('Leave Analysis')} å®Œäº†")
                    else:
                        st.info(f"{_('Leave Analysis')}: åˆ†æå¯¾è±¡ã¨ãªã‚‹ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                else:
                    st.warning(f"{_('Leave Analysis')}: å‰æã¨ãªã‚‹ long_df ãŒå­˜åœ¨ã—ãªã„ã‹ç©ºã®ãŸã‚ã€å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
            except Exception as e_leave:
                st.error(f"{_('Leave Analysis')} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e_leave}")
                log.error(f"ä¼‘æš‡åˆ†æã‚¨ãƒ©ãƒ¼: {e_leave}", exc_info=True)
        # â˜…----- ä¼‘æš‡åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®Ÿè¡Œã“ã“ã¾ã§ -----â˜…

        # ä»–ã®è¿½åŠ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®Ÿè¡Œ
        for opt_module_name_exec_run in st.session_state.available_ext_opts_widget:
            if opt_module_name_exec_run in param_ext_opts and opt_module_name_exec_run != _("Leave Analysis"):
                progress_key_exec_run = f"{opt_module_name_exec_run}: Processing..."
                update_progress_exec_run(progress_key_exec_run)
                st.info(f"{_(opt_module_name_exec_run)} å‡¦ç†ä¸­â€¦")
                try:
                    if opt_module_name_exec_run == "Stats": 
                        build_stats(out_dir_exec)
                    elif opt_module_name_exec_run == "Anomaly": 
                        detect_anomaly(out_dir_exec)
                    elif opt_module_name_exec_run == "Fatigue": 
                        train_fatigue(long_df, out_dir_exec)
                    elif opt_module_name_exec_run == "Cluster": 
                        cluster_staff(long_df, out_dir_exec)
                    elif opt_module_name_exec_run == "Skill": 
                        build_skill_matrix(long_df, out_dir_exec)
                    elif opt_module_name_exec_run == "Fairness": 
                        run_fairness(long_df, out_dir_exec)
                    elif opt_module_name_exec_run == "Rest Time Analysis":
                        rta = RestTimeAnalyzer()
                        st.session_state.rest_time_results = rta.analyze(long_df)
                        st.session_state.rest_time_results.to_csv(out_dir_exec / "rest_time.csv", index=False)
                        st.session_state.rest_time_monthly = rta.monthly(st.session_state.rest_time_results)
                        if st.session_state.rest_time_monthly is not None:
                            st.session_state.rest_time_monthly.to_csv(out_dir_exec / "rest_time_monthly.csv", index=False)
                    elif opt_module_name_exec_run == "Work Pattern Analysis":
                        wpa = WorkPatternAnalyzer()
                        st.session_state.work_pattern_results = wpa.analyze(long_df)
                        st.session_state.work_pattern_results.to_csv(out_dir_exec / "work_patterns.csv", index=False)
                        st.session_state.work_pattern_monthly = wpa.analyze_monthly(long_df)
                        if st.session_state.work_pattern_monthly is not None:
                            st.session_state.work_pattern_monthly.to_csv(out_dir_exec / "work_pattern_monthly.csv", index=False)
                    elif opt_module_name_exec_run == "Attendance Analysis":
                        st.session_state.attendance_results = AttendanceBehaviorAnalyzer().analyze(long_df)
                        st.session_state.attendance_results.to_csv(out_dir_exec / "attendance.csv", index=False)
                    elif opt_module_name_exec_run == "Low Staff Load":
                        lsl = LowStaffLoadAnalyzer()
                        st.session_state.low_staff_load_results = lsl.analyze(long_df, threshold=0.25)
                        st.session_state.low_staff_load_results.to_csv(out_dir_exec / "low_staff_load.csv", index=False)
                    elif opt_module_name_exec_run == "Combined Score":
                        rest_df = st.session_state.rest_time_results if st.session_state.rest_time_results is not None else pd.DataFrame()
                        work_df = st.session_state.work_pattern_results if st.session_state.work_pattern_results is not None else pd.DataFrame()
                        att_df = st.session_state.attendance_results if st.session_state.attendance_results is not None else pd.DataFrame()
                        st.session_state.combined_score_results = CombinedScoreCalculator().calculate(rest_df, work_df, att_df)
                        st.session_state.combined_score_results.to_csv(out_dir_exec / "combined_score.csv", index=False)
                    elif opt_module_name_exec_run == "Need forecast":
                        demand_csv_exec_run_fc = out_dir_exec / "demand_series.csv"
                        forecast_xls_exec_run_fc = out_dir_exec / "forecast.xlsx"
                        heat_all_for_fc_exec_run_fc = out_dir_exec / "heat_ALL.xlsx"
                        if not heat_all_for_fc_exec_run_fc.exists(): 
                            st.warning(f"Need forecast: å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ« {heat_all_for_fc_exec_run_fc.name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                        else:
                            build_demand_series(heat_all_for_fc_exec_run_fc, demand_csv_exec_run_fc)
                            if demand_csv_exec_run_fc.exists(): 
                                forecast_need(demand_csv_exec_run_fc, forecast_xls_exec_run_fc)
                            else: 
                                st.warning("Need forecast: demand_series.csv ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    elif opt_module_name_exec_run == "RL roster (PPO)":
                        demand_csv_rl_exec_run_rl = out_dir_exec / "demand_series.csv"
                        rl_roster_xls_exec_run_rl = out_dir_exec / "rl_roster.xlsx"
                        if demand_csv_rl_exec_run_rl.exists(): 
                            learn_roster(demand_csv_rl_exec_run_rl, rl_roster_xls_exec_run_rl)
                        else: 
                            st.warning("RL Roster: éœ€è¦äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ (demand_series.csv) ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    elif opt_module_name_exec_run == "Hire plan":
                        demand_csv_hp_exec_run_hp = out_dir_exec / "demand_series.csv"
                        hire_xls_exec_run_hp = out_dir_exec / "hire_plan.xlsx"
                        if demand_csv_hp_exec_run_hp.exists(): 
                            build_hire_plan(demand_csv_hp_exec_run_hp, hire_xls_exec_run_hp, param_std_work_hours, param_safety_factor, param_target_coverage)
                        else: 
                            st.warning("Hire Plan: éœ€è¦äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ (demand_series.csv) ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    elif opt_module_name_exec_run == "Cost / Benefit":
                        analyze_cost_benefit(out_dir_exec, param_wage_direct, param_wage_temp, param_hiring_cost, param_penalty_lack)
                    st.success(f"âœ… {_(opt_module_name_exec_run)} å®Œäº†")
                except FileNotFoundError as fe_opt_exec_run_loop:
                    st.error(f"{_(opt_module_name_exec_run)} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ (ãƒ•ã‚¡ã‚¤ãƒ«æœªæ¤œå‡º): {fe_opt_exec_run_loop}")
                    log.error(f"{opt_module_name_exec_run} å‡¦ç†ã‚¨ãƒ©ãƒ¼ (FileNotFoundError): {fe_opt_exec_run_loop}", exc_info=True)
                except Exception as e_opt_exec_run_loop:
                    st.error(f"{_(opt_module_name_exec_run)} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e_opt_exec_run_loop}")
                    log.error(f"{opt_module_name_exec_run} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e_opt_exec_run_loop}", exc_info=True)

        progress_bar_val.progress(100)
        progress_text_area.success("âœ¨ å…¨å·¥ç¨‹å®Œäº†ï¼")
        st.balloons()
        st.success(_("All processes complete!"))
        st.session_state.analysis_done = True
    except ValueError as ve_exec_run_main:
        st.error(_("Error during analysis (ValueError)") + f": {ve_exec_run_main}")
        log.error(f"è§£æã‚¨ãƒ©ãƒ¼ (ValueError): {ve_exec_run_main}", exc_info=True)
        st.session_state.analysis_done = False
    except FileNotFoundError as fe_exec_run_main:
        st.error(_("Required file not found") + f": {fe_exec_run_main}")
        log.error(f"ãƒ•ã‚¡ã‚¤ãƒ«æœªæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {fe_exec_run_main}", exc_info=True)
        st.session_state.analysis_done = False
    except Exception as e_exec_run_main:
        st.error(_("Unexpected error occurred") + f": {e_exec_run_main}")
        log.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_exec_run_main}", exc_info=True)
        st.session_state.analysis_done = False
    finally:
        if 'progress_bar_val' in locals() and progress_bar_val is not None: 
            progress_bar_val.empty()
        if 'progress_text_area' in locals() and progress_text_area is not None: 
            progress_text_area.empty()

    if st.session_state.analysis_done and st.session_state.out_dir_path_str:
        out_dir_to_save_exec_main_run = Path(st.session_state.out_dir_path_str)
        if out_dir_to_save_exec_main_run.exists():
            st.markdown("---")
            st.header("3. " + _("Save Analysis Results"))
            current_save_mode_exec_main_run = st.session_state.save_mode_selectbox_widget
            if current_save_mode_exec_main_run == _("Save to folder"):
                st.info(_("Output folder") + f": `{out_dir_to_save_exec_main_run}`")
                st.markdown(_("Open the above path in Explorer."))
            else: # ZIP Download
                zip_base_name_exec_main_run = f"ShiftSuite_Analysis_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
                if st.session_state.work_root_path_str is None:
                    st.error("ä¸€æ™‚ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                else:
                    work_root_for_zip_dl_exec_main_run = Path(st.session_state.work_root_path_str)
                    zip_path_obj_to_download_exec_main_run = work_root_for_zip_dl_exec_main_run / f"{zip_base_name_exec_main_run}.zip"
                    try:
                        with zipfile.ZipFile(zip_path_obj_to_download_exec_main_run, 'w', zipfile.ZIP_DEFLATED) as zf_dl_exec_main_run:
                            for file_to_zip_dl_exec_main_run in out_dir_to_save_exec_main_run.rglob('*'):
                                if file_to_zip_dl_exec_main_run.is_file():
                                    zf_dl_exec_main_run.write(file_to_zip_dl_exec_main_run, file_to_zip_dl_exec_main_run.relative_to(out_dir_to_save_exec_main_run))
                        with open(zip_path_obj_to_download_exec_main_run, "rb") as fp_zip_data_to_download_dl_exec_main_run:
                            st.download_button(label=_("Download analysis results as ZIP"), data=fp_zip_data_to_download_dl_exec_main_run,
                                               file_name=f"{zip_base_name_exec_main_run}.zip", mime="application/zip", use_container_width=True)
                        log.info(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã—ã¾ã—ãŸ: {zip_path_obj_to_download_exec_main_run}")
                    except Exception as e_zip_final_exec_run_main_ex_v3:
                        st.error(_("Error creating ZIP file") + f": {e_zip_final_exec_run_main_ex_v3}")
                        log.error(f"ZIPä½œæˆã‚¨ãƒ©ãƒ¼ (æœ€çµ‚æ®µéš): {e_zip_final_exec_run_main_ex_v3}", exc_info=True)
        else: 
            log.warning(f"è§£æã¯å®Œäº†ã—ã¾ã—ãŸãŒã€å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{out_dir_to_save_exec_main_run}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

# å®Œå…¨ä¿®æ­£ç‰ˆ - ä¼‘æš‡åˆ†æçµæœè¡¨ç¤ºã‚³ãƒ¼ãƒ‰å…¨ä½“

# Plotlyã®å…¨ä½“å•é¡Œã‚’ä¿®æ­£ã—ãŸä¼‘æš‡åˆ†æã‚³ãƒ¼ãƒ‰

# â˜… æ–°ã—ã„ã€Œä¼‘æš‡åˆ†æã€ã‚¿ãƒ–ã®è¡¨ç¤º (è§£æãŒå®Œäº†ã—ã€ä¼‘æš‡åˆ†æãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆ)
if st.session_state.get("analysis_done", False) and \
   _("Leave Analysis") in st.session_state.get("ext_opts_multiselect_widget", []) and \
   st.session_state.get("leave_analysis_results"):
    st.divider()
    st.header("ğŸ“Š " + _("Leave Analysis") + " çµæœ")
    results = st.session_state.leave_analysis_results
    
    # ãƒ‡ãƒãƒƒã‚°ç”¨ã«çµæœãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ è¡¨ç¤º
    with st.expander("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼‰", expanded=False):
        st.write("çµæœã‚­ãƒ¼:", list(results.keys()))
        for key, value in results.items():
            if isinstance(value, pd.DataFrame):
                st.write(f"{key} ã®åˆ—å:", list(value.columns))
                st.write(f"{key} ã®æœ€åˆã®æ•°è¡Œ:")
                st.dataframe(value.head())
    
    tab_leave_requested, tab_leave_paid, tab_leave_staff_detail, tab_leave_insights, tab_vac_analysis = st.tabs([
        "å¸Œæœ›ä¼‘ åˆ†æ",
        "æœ‰çµ¦ä¼‘æš‡ åˆ†æ",
        "è·å“¡åˆ¥ è©³ç´°åˆ†æ",
        "çµ±åˆã‚¤ãƒ³ã‚µã‚¤ãƒˆ",
        "ä¼‘æš‡åˆ†æ"
    ])
    
    # å¸Œæœ›ä¼‘åˆ†æã‚¿ãƒ–
    with tab_leave_requested:
        st.subheader("å¸Œæœ›ä¼‘ã®å‚¾å‘")
        if LEAVE_TYPE_REQUESTED in st.session_state.get("leave_analysis_target_types_widget", []):
            
            # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ åã‚’ç‰¹å®š
            daily_leave_df = results.get('daily_leave_df')
            if daily_leave_df is not None and not daily_leave_df.empty:
                leave_type_column = None
                for possible_col in ['leave_type', 'holiday_type', 'type', 'ä¼‘æš‡ç¨®åˆ¥', 'leave_category']:
                    if possible_col in daily_leave_df.columns:
                        leave_type_column = possible_col
                        break
                        
                if leave_type_column:
                    col1_req, col2_req = st.columns(2)
                    
                    with col1_req:
                        # æ›œæ—¥åˆ¥åˆ†æï¼ˆè·å“¡è©³ç´°ä»˜ãï¼‰
                        summary_dow_req = results.get('summary_dow_requested')
                        if summary_dow_req is not None and not summary_dow_req.empty:
                            st.write("**æ›œæ—¥åˆ¥ å¸Œæœ›ä¼‘å–å¾—ä»¶æ•°:**")
                            
                            # æ›œæ—¥åã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
                            dow_mapping = {0: 'æœˆæ›œ', 1: 'ç«æ›œ', 2: 'æ°´æ›œ', 3: 'æœ¨æ›œ', 4: 'é‡‘æ›œ', 5: 'åœŸæ›œ', 6: 'æ—¥æ›œ'}
                            
                            # ã‚°ãƒ©ãƒ•è¡¨ç¤º
                            if 'period_unit' in summary_dow_req.columns:
                                try:
                                    dow_chart_data = summary_dow_req.copy()
                                    dow_chart_data['æ›œæ—¥'] = dow_chart_data['period_unit'].map(dow_mapping)
                                    fig_dow_req = px.bar(dow_chart_data, x='æ›œæ—¥', y='total_leave_days',
                                                      title="æ›œæ—¥åˆ¥ å¸Œæœ›ä¼‘å–å¾—ä»¶æ•°")
                                    st.plotly_chart(fig_dow_req, use_container_width=True)
                                except Exception as e:
                                    st.error(f"æ›œæ—¥åˆ¥ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                            
                            # æ›œæ—¥é¸æŠã§è©³ç´°è¡¨ç¤º
                            selected_dow = st.selectbox(
                                "è©³ç´°ã‚’è¦‹ã‚‹æ›œæ—¥ã‚’é¸æŠ", 
                                options=list(dow_mapping.values()),
                                key="dow_detail_select_req"
                            )
                            
                            # é¸æŠã—ãŸæ›œæ—¥ã®è©³ç´°è·å“¡ãƒªã‚¹ãƒˆ
                            if selected_dow:
                                try:
                                    dow_num = {v: k for k, v in dow_mapping.items()}[selected_dow]
                                    req_daily_df = daily_leave_df[daily_leave_df[leave_type_column] == LEAVE_TYPE_REQUESTED].copy()
                                        
                                    if not req_daily_df.empty:
                                        date_column = 'date' if 'date' in req_daily_df.columns else ('leave_date' if 'leave_date' in req_daily_df.columns else None)
                                        if date_column:
                                            req_daily_df['dow'] = pd.to_datetime(req_daily_df[date_column]).dt.dayofweek
                                            dow_detail = req_daily_df[req_daily_df['dow'] == dow_num]
                                        
                                        if not dow_detail.empty:
                                            st.write(f"**{selected_dow}ã«å¸Œæœ›ä¼‘ã‚’å–å¾—ã—ãŸè·å“¡:**")
                                            staff_counts = dow_detail['staff'].value_counts()
                                            st.dataframe(
                                                staff_counts.reset_index().rename(
                                                    columns={'index': 'è·å“¡å', 'staff': f'{selected_dow}ã®å–å¾—å›æ•°'}
                                                )
                                            )
                                except Exception as e:
                                    st.error(f"æ›œæ—¥åˆ¥è©³ç´°è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                    
                    with col2_req:
                        # æœˆå†…åˆ†å¸ƒåˆ†æ
                        summary_month_period_req = results.get('summary_month_period_requested')
                        if summary_month_period_req is not None and not summary_month_period_req.empty:
                            st.write("**æœˆå†…åˆ†å¸ƒ (æœˆåˆãƒ»æœˆä¸­ãƒ»æœˆæœ«):**")
                            try:
                                fig_period_req = px.bar(summary_month_period_req, 
                                                      x='period_unit', y='total_leave_days',
                                                      title="æœˆå†…æœŸé–“åˆ¥ å¸Œæœ›ä¼‘å–å¾—ä»¶æ•°")
                                st.plotly_chart(fig_period_req, use_container_width=True)
                            except Exception as e:
                                st.error(f"æœˆå†…åˆ†å¸ƒã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                    
                    # é›†ä¸­åº¦åˆ†æ
                    concentration_req = results.get('concentration_requested')
                    if concentration_req is not None and not concentration_req.empty:
                        st.subheader("å¸Œæœ›ä¼‘ é›†ä¸­åº¦åˆ†æ")
                        concentrated_days_req = concentration_req[concentration_req['is_concentrated']]
                        
                        if not concentrated_days_req.empty:
                            st.write(f"**å¸Œæœ›ä¼‘ãŒ {st.session_state.leave_concentration_threshold_widget} äººä»¥ä¸Šé›†ä¸­ã—ã¦ã„ã‚‹æ—¥:**")
                            
                            # é›†ä¸­æ—¥ã®ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼è¡¨ç¤ºé¢¨ã‚°ãƒ©ãƒ•
                            try:
                                req_staff_by_date = (
                                    daily_leave_df[daily_leave_df[leave_type_column] == LEAVE_TYPE_REQUESTED]
                                    .groupby("date")["staff"]
                                    .apply(lambda s: ", ".join(sorted(s.unique())))
                                    .reset_index(name="applicant_names")
                                )
                                concentrated_days_req = concentrated_days_req.merge(
                                    req_staff_by_date, on="date", how="left"
                                )
                                concentrated_days_req["date_label"] = pd.to_datetime(
                                    concentrated_days_req["date"]
                                ).dt.strftime("%Y-%m-%d (%a)")

                                fig_concentration = px.scatter(
                                    concentrated_days_req,
                                    x="date_label",
                                    y="leave_applicants_count",
                                    size="leave_applicants_count",
                                    title=f"å¸Œæœ›ä¼‘é›†ä¸­æ—¥ (é–¾å€¤: {st.session_state.leave_concentration_threshold_widget}äºº)",
                                    hover_data=["date", "leave_applicants_count", "applicant_names"],
                                )
                                fig_concentration.update_layout(
                                    xaxis_title="æ—¥ä»˜ (æ›œæ—¥)", xaxis_tickangle=-45
                                )
                                st.plotly_chart(
                                    fig_concentration, use_container_width=True
                                )
                                # --- æ–°è¦: å‹¤å‹™äºˆå®šäººæ•°æ¯”è¼ƒã‚°ãƒ©ãƒ• ---
                                staff_balance_daily = results.get("staff_balance_daily")
                                if staff_balance_daily is not None and not staff_balance_daily.empty:
                                    try:
                                        plot_df = staff_balance_daily.copy()
                                        plot_df["date_label"] = pd.to_datetime(plot_df["date"]).dt.strftime("%Y-%m-%d (%a)")
                                        fig_balance = px.bar(
                                            plot_df,
                                            x="date_label",
                                            y=["leave_applicants_count", "non_leave_staff"],
                                            barmode="group",
                                            title="å‹¤å‹™äºˆå®šäººæ•°ã¨å¸Œæœ›ä¼‘å–å¾—è€…æ•°ã®æ¯”è¼ƒ",
                                        )
                                        fig_balance.update_layout(xaxis_title="æ—¥ä»˜ (æ›œæ—¥)", xaxis_tickangle=-45)
                                        st.plotly_chart(fig_balance, use_container_width=True)
                                    except Exception as e:
                                        st.error(f"å‹¤å‹™äºˆå®šäººæ•°ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                            except Exception as e:
                                st.error(f"é›†ä¸­åº¦ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                            
                            # é›†ä¸­æ—¥è©³ç´°
                            st.dataframe(
                                concentrated_days_req[['date', 'leave_applicants_count']].rename(
                                    columns={'date':'æ—¥ä»˜', 'leave_applicants_count':'å¸Œæœ›ä¼‘å–å¾—è€…æ•°'}
                                ).reset_index(drop=True)
                            )
                            
                            # ç‰¹å®šã®é›†ä¸­æ—¥ã®è·å“¡ãƒªã‚¹ãƒˆ
                            selected_conc_date = st.selectbox(
                                "è©³ç´°ã‚’è¦‹ã‚‹é›†ä¸­æ—¥ã‚’é¸æŠ",
                                options=concentrated_days_req['date'].tolist(),
                                key="conc_date_select"
                            )
                            
                            if selected_conc_date:
                                try:
                                    req_daily_df = daily_leave_df[daily_leave_df[leave_type_column] == LEAVE_TYPE_REQUESTED].copy()
                                    date_column = 'date' if 'date' in req_daily_df.columns else 'leave_date'
                                    date_detail = req_daily_df[req_daily_df[date_column] == selected_conc_date]
                                    
                                    if not date_detail.empty:
                                        st.write(f"**{selected_conc_date} ã«å¸Œæœ›ä¼‘ã‚’å–å¾—ã—ãŸè·å“¡:**")
                                        st.write(", ".join(date_detail['staff'].tolist()))
                                except Exception as e:
                                    st.error(f"é›†ä¸­æ—¥è©³ç´°è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                        else:
                            st.write(f"å¸Œæœ›ä¼‘ãŒ {st.session_state.leave_concentration_threshold_widget} äººä»¥ä¸Šé›†ä¸­ã—ã¦ã„ã‚‹æ—¥ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                        st.write("å¸Œæœ›ä¼‘ã®é›†ä¸­åº¦ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    st.warning("ä¼‘æš‡ç¨®åˆ¥ã‚’ç¤ºã™ã‚«ãƒ©ãƒ åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                st.warning("æ—¥æ¬¡ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.info("å¸Œæœ›ä¼‘ã¯åˆ†æå¯¾è±¡ã¨ã—ã¦é¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    
    # æœ‰çµ¦ä¼‘æš‡åˆ†æã‚¿ãƒ–
    with tab_leave_paid:
        st.subheader("æœ‰çµ¦ä¼‘æš‡ã®å‚¾å‘ (çµ‚æ—¥ã®ã¿)")
        if LEAVE_TYPE_PAID in st.session_state.get("leave_analysis_target_types_widget", []):
            
            # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ åã‚’ç‰¹å®š
            daily_leave_df = results.get('daily_leave_df')
            if daily_leave_df is not None and not daily_leave_df.empty:
                leave_type_column = None
                for possible_col in ['leave_type', 'holiday_type', 'type', 'ä¼‘æš‡ç¨®åˆ¥', 'leave_category']:
                    if possible_col in daily_leave_df.columns:
                        leave_type_column = possible_col
                        break
                        
                if leave_type_column:
                    col1_paid, col2_paid = st.columns(2)
                    
                    with col1_paid:
                        # æ›œæ—¥åˆ¥åˆ†æ
                        summary_dow_paid = results.get('summary_dow_paid')
                        if summary_dow_paid is not None and not summary_dow_paid.empty:
                            st.write("**æ›œæ—¥åˆ¥ æœ‰çµ¦ä¼‘æš‡å–å¾—æ—¥æ•°:**")
                            
                            # æ›œæ—¥åãƒãƒƒãƒ”ãƒ³ã‚°
                            dow_mapping = {0: 'æœˆæ›œ', 1: 'ç«æ›œ', 2: 'æ°´æ›œ', 3: 'æœ¨æ›œ', 4: 'é‡‘æ›œ', 5: 'åœŸæ›œ', 6: 'æ—¥æ›œ'}
                            
                            if 'period_unit' in summary_dow_paid.columns:
                                try:
                                    dow_chart_data_paid = summary_dow_paid.copy()
                                    dow_chart_data_paid['æ›œæ—¥'] = dow_chart_data_paid['period_unit'].map(dow_mapping)
                                    fig_dow_paid = px.bar(dow_chart_data_paid, x='æ›œæ—¥', y='total_leave_days',
                                                        title="æ›œæ—¥åˆ¥ æœ‰çµ¦ä¼‘æš‡å–å¾—æ—¥æ•°")
                                    st.plotly_chart(fig_dow_paid, use_container_width=True)
                                except Exception as e:
                                    st.error(f"æ›œæ—¥åˆ¥æœ‰çµ¦ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                    
                    with col2_paid:
                        # æœˆåˆ¥åˆ†æ
                        summary_month_paid = results.get('summary_month_paid')
                        if summary_month_paid is not None and not summary_month_paid.empty:
                            st.write("**æœˆåˆ¥ æœ‰çµ¦ä¼‘æš‡å–å¾—æ—¥æ•°:**")
                            try:
                                fig_month_paid = px.line(summary_month_paid, 
                                                       x='period_unit', y='total_leave_days',
                                                       title="æœˆåˆ¥ æœ‰çµ¦ä¼‘æš‡å–å¾—æ—¥æ•°",
                                                       markers=True)
                                st.plotly_chart(fig_month_paid, use_container_width=True)
                            except Exception as e:
                                st.error(f"æœˆåˆ¥æœ‰çµ¦ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                            
                    # æœ‰çµ¦ä¼‘æš‡å–å¾—è€…ãƒªã‚¹ãƒˆ
                    try:
                        paid_daily_df = daily_leave_df[daily_leave_df[leave_type_column] == LEAVE_TYPE_PAID].copy()
                        if not paid_daily_df.empty:
                            st.subheader("æœ‰çµ¦ä¼‘æš‡å–å¾— è·å“¡åˆ¥é›†è¨ˆ")
                            staff_paid_counts = paid_daily_df['staff'].value_counts().reset_index()
                            staff_paid_counts.columns = ['è·å“¡å', 'æœ‰çµ¦ä¼‘æš‡å–å¾—å›æ•°']
                            
                            # ä¸Šä½10åã‚’ã‚°ãƒ©ãƒ•è¡¨ç¤º
                            top_10_paid = staff_paid_counts.head(10)
                            fig_staff_paid = px.bar(
                                top_10_paid, 
                                x='è·å“¡å', y='æœ‰çµ¦ä¼‘æš‡å–å¾—å›æ•°',
                                title="æœ‰çµ¦ä¼‘æš‡å–å¾—å›æ•° ä¸Šä½10å"
                            )
                            # æ­£ã—ã„æ–¹æ³•ã§è»¸ã®è§’åº¦ã‚’å¤‰æ›´
                            fig_staff_paid.update_layout(xaxis=dict(tickangle=45))
                            st.plotly_chart(fig_staff_paid, use_container_width=True)
                            
                            # å…¨è·å“¡ã®æœ‰çµ¦å–å¾—ä¸€è¦§
                            st.dataframe(staff_paid_counts, use_container_width=True)
                    except Exception as e:
                        st.error(f"æœ‰çµ¦ä¼‘æš‡å–å¾—è€…ãƒªã‚¹ãƒˆè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    st.warning("ä¼‘æš‡ç¨®åˆ¥ã‚’ç¤ºã™ã‚«ãƒ©ãƒ åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                st.warning("æ—¥æ¬¡ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.info("æœ‰çµ¦ä¼‘æš‡ã¯åˆ†æå¯¾è±¡ã¨ã—ã¦é¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            
    # è·å“¡åˆ¥è©³ç´°åˆ†æã‚¿ãƒ–
    with tab_leave_staff_detail:
        st.subheader("è·å“¡åˆ¥ è©³ç´°åˆ†æ")
        staff_leave_list_df = results.get('staff_leave_list')
        
        if staff_leave_list_df is not None and not staff_leave_list_df.empty:
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ§‹é€ ç¢ºèª
            st.write("åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿åˆ—:", list(staff_leave_list_df.columns))
            
            # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ åã®ç¢ºèª
            leave_type_column = None
            for possible_col in ['leave_type', 'holiday_type', 'type', 'ä¼‘æš‡ç¨®åˆ¥', 'leave_category']:
                if possible_col in staff_leave_list_df.columns:
                    leave_type_column = possible_col
                    break
            
            all_staff_names = sorted(staff_leave_list_df['staff'].unique())
            
            # è·å“¡é¸æŠ (è¤‡æ•°é¸æŠã«å¯¾å¿œ)
            selected_staffs_for_detail = st.multiselect(
                "åˆ†æã™ã‚‹è·å“¡ã‚’é¸æŠ",
                options=all_staff_names,
                default=all_staff_names[:1],
                key="leave_detail_staff_select"
            )

            if selected_staffs_for_detail:
                # ã‚¹ã‚¿ãƒƒãƒ•ã”ã¨ã«ã‚¿ãƒ–ã‚’åˆ†ã‘ã¦è¡¨ç¤º
                staff_tabs = st.tabs(selected_staffs_for_detail) if len(selected_staffs_for_detail) > 1 else [st.container()]
                for tab_obj, staff_name in zip(staff_tabs, selected_staffs_for_detail):
                    with tab_obj:
                        staff_data = staff_leave_list_df[staff_leave_list_df['staff'] == staff_name]

                        # è·å“¡ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
                        col1_staff, col2_staff, col3_staff = st.columns(3)

                        with col1_staff:
                            total_leave_days = len(staff_data)
                            st.metric("ç·ä¼‘æš‡å–å¾—æ—¥æ•°", total_leave_days)

                        with col2_staff:
                            if leave_type_column:
                                # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€å€¤ã®ç¨®é¡ã‚’ç¢ºèª
                                unique_leave_types = staff_data[leave_type_column].unique()
                                st.write("ä¼‘æš‡ç¨®åˆ¥:", list(unique_leave_types))

                                if LEAVE_TYPE_REQUESTED in unique_leave_types:
                                    requested_count = sum(staff_data[leave_type_column] == LEAVE_TYPE_REQUESTED)
                                    st.metric("å¸Œæœ›ä¼‘æ—¥æ•°", requested_count)
                                else:
                                    st.metric("å¸Œæœ›ä¼‘æ—¥æ•°", "N/A")
                            else:
                                # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
                                st.metric("å¸Œæœ›ä¼‘æ—¥æ•°", "N/A")

                        with col3_staff:
                            if leave_type_column:
                                unique_leave_types = staff_data[leave_type_column].unique()
                                if LEAVE_TYPE_PAID in unique_leave_types:
                                    paid_count = sum(staff_data[leave_type_column] == LEAVE_TYPE_PAID)
                                    st.metric("æœ‰çµ¦ä¼‘æš‡æ—¥æ•°", paid_count)
                                else:
                                    st.metric("æœ‰çµ¦ä¼‘æš‡æ—¥æ•°", "N/A")
                            else:
                                # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
                                st.metric("æœ‰çµ¦ä¼‘æš‡æ—¥æ•°", "N/A")

                        # è·å“¡ã®ä¼‘æš‡ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼è¡¨ç¤º
                        if not staff_data.empty:
                            st.subheader(f"{staff_name} ã®ä¼‘æš‡ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
                    
                    # æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                    calendar_data = staff_data.copy()
                    date_column = None
                    if 'date' in calendar_data.columns:
                        date_column = 'date'
                    elif 'leave_date' in calendar_data.columns:
                        date_column = 'leave_date'

                    if date_column:
                        try:
                            calendar_data['date'] = pd.to_datetime(calendar_data[date_column])
                            calendar_data['month'] = calendar_data['date'].dt.month
                            calendar_data['day'] = calendar_data['date'].dt.day
                            calendar_data['year'] = calendar_data['date'].dt.year
                            calendar_data['dow'] = calendar_data['date'].dt.dayofweek
                            
                            
                            # æœˆåˆ¥ã®ä¼‘æš‡é›†è¨ˆ
                            if leave_type_column:
                                # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆã®æœˆåˆ¥é›†è¨ˆ
                                monthly_pattern = calendar_data.groupby(['month', leave_type_column]).size().reset_index(name='count')
                                if not monthly_pattern.empty:
                                    fig_monthly = px.bar(
                                        monthly_pattern, 
                                        x='month', y='count', 
                                        color=leave_type_column,
                                        title=f"{staff_name} ã®æœˆåˆ¥ä¼‘æš‡å–å¾—ãƒ‘ã‚¿ãƒ¼ãƒ³",
                                        labels={'month': 'æœˆ', 'count': 'å–å¾—æ—¥æ•°'}
                                    )
                                    st.plotly_chart(fig_monthly, use_container_width=True)
                            else:
                                # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ ãŒãªã„å ´åˆã¯åˆè¨ˆã®ã¿è¡¨ç¤º
                                monthly_total = calendar_data.groupby(['month']).size().reset_index(name='count')
                                if not monthly_total.empty:
                                    fig_monthly_total = px.bar(
                                        monthly_total, 
                                        x='month', y='count',
                                        title=f"{staff_name} ã®æœˆåˆ¥ä¼‘æš‡å–å¾—ãƒ‘ã‚¿ãƒ¼ãƒ³ (å…¨ç¨®åˆ¥åˆè¨ˆ)",
                                        labels={'month': 'æœˆ', 'count': 'å–å¾—æ—¥æ•°'}
                                    )
                                    st.plotly_chart(fig_monthly_total, use_container_width=True)
                            
                            # æ›œæ—¥åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³
                            try:
                                if leave_type_column:
                                    # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆã®æ›œæ—¥åˆ¥é›†è¨ˆ
                                    dow_pattern = calendar_data.groupby(['dow', leave_type_column]).size().reset_index(name='count')
                                    if not dow_pattern.empty:
                                        dow_mapping = {0: 'æœˆ', 1: 'ç«', 2: 'æ°´', 3: 'æœ¨', 4: 'é‡‘', 5: 'åœŸ', 6: 'æ—¥'}
                                        dow_pattern['æ›œæ—¥'] = dow_pattern['dow'].map(dow_mapping)
                                        
                                        fig_dow = px.bar(
                                            dow_pattern, 
                                            x='æ›œæ—¥', y='count', 
                                            color=leave_type_column,
                                            title=f"{staff_name} ã®æ›œæ—¥åˆ¥ä¼‘æš‡å–å¾—ãƒ‘ã‚¿ãƒ¼ãƒ³"
                                        )
                                        st.plotly_chart(fig_dow, use_container_width=True)
                                else:
                                    # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ ãŒãªã„å ´åˆã¯åˆè¨ˆã®ã¿è¡¨ç¤º
                                    dow_total = calendar_data.groupby(['dow']).size().reset_index(name='count')
                                    if not dow_total.empty:
                                        dow_mapping = {0: 'æœˆ', 1: 'ç«', 2: 'æ°´', 3: 'æœ¨', 4: 'é‡‘', 5: 'åœŸ', 6: 'æ—¥'}
                                        dow_total['æ›œæ—¥'] = dow_total['dow'].map(dow_mapping)
                                        
                                        fig_dow_total = px.bar(
                                            dow_total, 
                                            x='æ›œæ—¥', y='count',
                                            title=f"{staff_name} ã®æ›œæ—¥åˆ¥ä¼‘æš‡å–å¾—ãƒ‘ã‚¿ãƒ¼ãƒ³ (å…¨ç¨®åˆ¥åˆè¨ˆ)"
                                        )
                                        st.plotly_chart(fig_dow_total, use_container_width=True)
                            except Exception as e:
                                st.error(f"æ›œæ—¥åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                        except Exception as e:
                            st.error(f"ä¼‘æš‡ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                    else:
                        st.warning("æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æãŒã§ãã¾ã›ã‚“ã€‚")
                
                    # è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
                    st.subheader("ä¼‘æš‡å–å¾—è©³ç´°")
                    date_column = None
                    if 'date' in staff_data.columns:
                        date_column = 'date'
                    elif 'leave_date' in staff_data.columns:
                        date_column = 'leave_date'

                    if date_column:
                        display_columns = [date_column]
                
                        if leave_type_column:
                            display_columns.append(leave_type_column)
                        
                        # ä»–ã®å¯èƒ½æ€§ã®ã‚ã‚‹ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
                        optional_columns = ['shift_code', 'role', 'position', 'department']
                        for col in optional_columns:
                            if col in staff_data.columns:
                                display_columns.append(col)
                        
                        # ã‚«ãƒ©ãƒ åã®ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸
                        col_mapping = {
                            'date': 'æ—¥ä»˜',
                            'leave_type': 'ä¼‘æš‡ç¨®åˆ¥',
                            'holiday_type': 'ä¼‘æš‡ç¨®åˆ¥',
                            'type': 'ç¨®åˆ¥',
                            'shift_code': 'ã‚·ãƒ•ãƒˆã‚³ãƒ¼ãƒ‰',
                            'role': 'è·ç¨®',
                            'position': 'å½¹è·',
                            'department': 'éƒ¨ç½²'
                        }
                        
                        # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨                        
                        rename_dict = {col: col_mapping.get(col, col) for col in display_columns if col in col_mapping}
                        # leave_date ã‚‚æ—¥ä»˜ã¨ã—ã¦æ‰±ã†ã‚ˆã†ã«è¿½åŠ 
                        if 'leave_date' in display_columns and 'leave_date' not in rename_dict:
                            rename_dict['leave_date'] = 'æ—¥ä»˜'
                            
                        try:
                            df_to_display = staff_data[display_columns].rename(columns=rename_dict)
                            if 'æ—¥ä»˜' in df_to_display.columns:
                                df_to_display = df_to_display.sort_values('æ—¥ä»˜')
                            st.dataframe(df_to_display, use_container_width=True)
                        except Exception as e:
                            st.error(f"è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…¨ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                            st.write("å…¨ãƒ‡ãƒ¼ã‚¿:")
                            st.dataframe(staff_data)
                    else:
                        st.warning("æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
            else:
                st.info("è·å“¡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            st.write("è¡¨ç¤ºã§ãã‚‹è·å“¡åˆ¥ã®ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # çµ±åˆã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚¿ãƒ–
    with tab_leave_insights:
        st.subheader("çµ±åˆã‚¤ãƒ³ã‚µã‚¤ãƒˆ")
        
        # å…¨ä½“çµ±è¨ˆ
        staff_leave_list_df = results.get('staff_leave_list')
        if staff_leave_list_df is not None and not staff_leave_list_df.empty:
            
            # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ åã‚’ç‰¹å®š
            leave_type_column = None
            for possible_col in ['leave_type', 'holiday_type', 'type', 'ä¼‘æš‡ç¨®åˆ¥', 'leave_category']:
                if possible_col in staff_leave_list_df.columns:
                    leave_type_column = possible_col
                    break
            
            # ç·åˆçµ±è¨ˆ
            col1_ins, col2_ins, col3_ins, col4_ins = st.columns(4)
            
            with col1_ins:
                total_staff = staff_leave_list_df['staff'].nunique()
                st.metric("åˆ†æå¯¾è±¡è·å“¡æ•°", total_staff)
            
            with col2_ins:
                total_leave_instances = len(staff_leave_list_df)
                st.metric("ç·ä¼‘æš‡å–å¾—å›æ•°", total_leave_instances)
            
            with col3_ins:
                if total_staff > 0:
                    avg_per_staff = total_leave_instances / total_staff
                    st.metric("è·å“¡ã‚ãŸã‚Šå¹³å‡ä¼‘æš‡æ—¥æ•°", f"{avg_per_staff:.1f}")
            
            with col4_ins:
                date_column = None
                if 'date' in staff_leave_list_df.columns:
                    date_column = 'date'
                elif 'leave_date' in staff_leave_list_df.columns:
                    date_column = 'leave_date'

                if date_column:
                    try:
                        date_range = pd.to_datetime(staff_leave_list_df[date_column])
                        period_days = (date_range.max() - date_range.min()).days
                        if period_days > 0:
                            st.metric("åˆ†ææœŸé–“", f"{period_days}æ—¥")
                    except Exception as e:
                        st.error(f"åˆ†ææœŸé–“è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")            
            
            
            # è·å“¡åˆ¥ä¼‘æš‡å–å¾—ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            st.subheader("è·å“¡åˆ¥ ä¼‘æš‡å–å¾—ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            
            try:
                # åŸºæœ¬é›†è¨ˆã‚’å®Ÿæ–½
                date_col = 'date' if 'date' in staff_leave_list_df.columns else staff_leave_list_df.columns[0]
                staff_ranking = staff_leave_list_df.groupby('staff').size().reset_index(name='ç·ä¼‘æš‡æ—¥æ•°')
                
                # ä¼‘æš‡ç¨®åˆ¥ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®è©³ç´°é›†è¨ˆ
                if leave_type_column:
                    # ç¨®åˆ¥ã®ä¸€è¦§ã‚’å–å¾—
                    leave_types = staff_leave_list_df[leave_type_column].unique()
                    
                    if LEAVE_TYPE_REQUESTED in leave_types:
                        # å¸Œæœ›ä¼‘ã‚’ã‚¯ãƒ­ã‚¹é›†è¨ˆ
                        requested_counts = staff_leave_list_df[staff_leave_list_df[leave_type_column] == LEAVE_TYPE_REQUESTED] \
                            .groupby('staff').size().reset_index(name='å¸Œæœ›ä¼‘æ—¥æ•°')
                        staff_ranking = pd.merge(staff_ranking, requested_counts, on='staff', how='left')
                        staff_ranking['å¸Œæœ›ä¼‘æ—¥æ•°'] = staff_ranking['å¸Œæœ›ä¼‘æ—¥æ•°'].fillna(0).astype(int)
                    
                    if LEAVE_TYPE_PAID in leave_types:
                        # æœ‰çµ¦ä¼‘æš‡ã‚’ã‚¯ãƒ­ã‚¹é›†è¨ˆ
                        paid_counts = staff_leave_list_df[staff_leave_list_df[leave_type_column] == LEAVE_TYPE_PAID] \
                            .groupby('staff').size().reset_index(name='æœ‰çµ¦ä¼‘æš‡æ—¥æ•°')
                        staff_ranking = pd.merge(staff_ranking, paid_counts, on='staff', how='left')
                        staff_ranking['æœ‰çµ¦ä¼‘æš‡æ—¥æ•°'] = staff_ranking['æœ‰çµ¦ä¼‘æš‡æ—¥æ•°'].fillna(0).astype(int)
                
                # é™é †ã‚½ãƒ¼ãƒˆ
                staff_ranking = staff_ranking.sort_values('ç·ä¼‘æš‡æ—¥æ•°', ascending=False)
                
                # ä¸Šä½10åã®ã‚°ãƒ©ãƒ•
                if len(staff_ranking) > 0:
                    top_10_staff = staff_ranking.head(10)
                    fig_ranking = px.bar(
                        top_10_staff, 
                        x='staff', y='ç·ä¼‘æš‡æ—¥æ•°',
                        title="è·å“¡åˆ¥ ç·ä¼‘æš‡å–å¾—æ—¥æ•° (ä¸Šä½10å)"
                    )
                    # æ­£ã—ã„æ–¹æ³•ã§Xè»¸ã®ãƒ©ãƒ™ãƒ«è§’åº¦ã‚’è¨­å®š
                    fig_ranking.update_layout(xaxis=dict(tickangle=45))
                    st.plotly_chart(fig_ranking, use_container_width=True)
                    
                    # è©³ç´°ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
                    st.dataframe(staff_ranking, use_container_width=True)
                else:
                    st.info("é›†è¨ˆã§ãã‚‹ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            except Exception as e:
                st.error(f"è·å“¡åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                st.write("ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            st.write("çµ±åˆã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ä¼‘æš‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    # ä¼‘æš‡åˆ†æã‚¿ãƒ– (ä»–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµæœ)
    with tab_vac_analysis:
        if st.session_state.get("rest_time_results") is not None:
            st.subheader(_("Rest Time Analysis"))
            df_rest = st.session_state.rest_time_results
            st.dataframe(df_rest, use_container_width=True)
            if not df_rest.empty and {"staff", "rest_hours"}.issubset(df_rest.columns):
                avg_rest = df_rest.groupby("staff")["rest_hours"].mean().reset_index()
                fig_rest = px.bar(avg_rest, x="staff", y="rest_hours", title="Average Rest Hours per Staff")
                st.plotly_chart(fig_rest, use_container_width=True)

        if st.session_state.get("work_pattern_results") is not None:
            st.subheader(_("Work Pattern Analysis"))
            st.dataframe(st.session_state.work_pattern_results, use_container_width=True)

        if st.session_state.get("attendance_results") is not None:
            st.subheader(_("Attendance Analysis"))
            st.dataframe(st.session_state.attendance_results, use_container_width=True)

        if st.session_state.get("low_staff_load_results") is not None:
            st.subheader(_("Low Staff Load"))
            st.dataframe(st.session_state.low_staff_load_results, use_container_width=True)

        if st.session_state.get("combined_score_results") is not None:
            st.subheader(_("Combined Score"))
            df_score = st.session_state.combined_score_results
            st.dataframe(df_score, use_container_width=True)
            if not df_score.empty:
                try:
                    st.plotly_chart(dashboard.employee_overview(df_score), use_container_width=True)
                    if 'long_df' in locals():
                        st.plotly_chart(dashboard.department_overview(df_score, long_df), use_container_width=True)
                except Exception as e:
                    st.error(f"Error displaying combined score charts: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  app.py  (Part 3 / 3)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def display_overview_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Overview"))
        kpi_fp = data_dir / "shortage_role.xlsx"; lack_h = 0.0
        if kpi_fp.exists():
            try: df_sh_role = pd.read_excel(kpi_fp); lack_h = df_sh_role["lack_h"].sum() if "lack_h" in df_sh_role else 0.0
            except Exception as e: st.warning(f"shortage_role.xlsx èª­è¾¼/é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
        fair_fp_meta = data_dir / "fairness_before.xlsx"; jain_display = "N/A"
        if fair_fp_meta.exists():
            try:
                meta_df = pd.read_excel(fair_fp_meta, sheet_name="meta_summary")
                jain_row = meta_df[meta_df["metric"] == "jain_index"]
                if not jain_row.empty: jain_display = f"{float(jain_row['value'].iloc[0]):.3f}"
            except Exception: pass 
        c1, c2 = st.columns(2)
        c1.metric(_("ä¸è¶³æ™‚é–“(h)"), f"{lack_h:.1f}")
        c2.metric("å¤œå‹¤ JainæŒ‡æ•°", jain_display)

def display_heatmap_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Heatmap"))
        fp = data_dir / "heat_ALL.xlsx"
        if fp.exists():
            try:
                df_heat = pd.read_excel(fp, index_col=0)
                mode_opts = {"Raw": _("Raw Count"), "Ratio": _("Ratio (staff Ã· need)")}
                mode_lbl = st.radio(_("Display Mode"), list(mode_opts.values()), horizontal=True, key="dash_heat_mode_radio")
                mode_key = [k for k,v in mode_opts.items() if v == mode_lbl][0]
                z_def, z_min, z_max, z_stp = (11.,1.,50.,1.) if mode_key=="Raw" else (1.5,.1,3.,.1)
                disp_df_heat = df_heat.drop(columns=[c for c in SUMMARY5_CONST if c in df_heat.columns], errors="ignore")

                if mode_key == "Raw":
                    pos_vals = disp_df_heat[disp_df_heat > 0].stack()
                    p90 = float(pos_vals.quantile(0.90)) if not pos_vals.empty else z_def
                    p95 = float(pos_vals.quantile(0.95)) if not pos_vals.empty else z_def
                    p99 = float(pos_vals.quantile(0.99)) if not pos_vals.empty else z_def
                    zmode = st.selectbox("zmax mode", ["Manual", "90th percentile", "95th percentile", "99th percentile"], key="dash_heat_zmax_mode")
                    if zmode == "Manual":
                        zmax = st.slider(_("Color Scale Max (zmax)"), z_min, z_max, z_def, z_stp, key="dash_heat_zmax_slider")
                    else:
                        perc_map = {"90th percentile": p90, "95th percentile": p95, "99th percentile": p99}
                        z_val = perc_map.get(zmode, z_def)
                        st.slider(_("Color Scale Max (zmax)"), z_min, z_max, z_val, z_stp, key="dash_heat_zmax_slider", disabled=True)
                        zmax = z_val
                    fig = px.imshow(disp_df_heat, aspect="auto", color_continuous_scale="Blues", zmax=zmax, labels={"x":_("Date"),"y":_("Time"),"color":_("Raw Count")})
                else:
                    zmax = st.slider(_("Color Scale Max (zmax)"), z_min, z_max, z_def, z_stp, key="dash_heat_zmax_slider")
                    if "need" in df_heat.columns and "staff" in df_heat.columns and not disp_df_heat.empty :
                        ratio_calc_df = disp_df_heat.copy()
                        # Ratioè¨ˆç®—: å„æ—¥ä»˜åˆ—ã®å„æ™‚é–“å¸¯ã®å€¤ã‚’ã€ãã®æ™‚é–“å¸¯ã® staff å€¤ / need å€¤ã§æ›´æ–°
                        if 'need' in df_heat.columns and df_heat['need'].replace(0, pd.NA).notna().any(): # needãŒ0ã§ãªã„æœ‰åŠ¹ãªå€¤ã‚’æŒã¤ã‹
                            ratio_display_df = disp_df_heat.apply(lambda date_col: date_col / df_heat['need'].replace(0, pd.NA), axis=0)
                            ratio_display_df = ratio_display_df.clip(upper=zmax)
                            fig = px.imshow(ratio_display_df, aspect="auto", color_continuous_scale=px.colors.sequential.RdBu_r, zmin=0, zmax=zmax, labels={"x":_("Date"),"y":_("Time"),"color":_("Ratio (staff Ã· need)")})
                        else:
                            st.warning("Ratioè¡¨ç¤ºã«å¿…è¦ãª'need'åˆ—ãƒ‡ãƒ¼ã‚¿ãŒ0ã¾ãŸã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
                            fig = go.Figure()
                    else:
                        st.warning("Ratioè¡¨ç¤ºã«å¿…è¦ãª'staff'åˆ—ã€'need'åˆ—ã€ã¾ãŸã¯æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                        fig = go.Figure()
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e: st.error(f"ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
        else: st.info(_("Heatmap") + " (heat_ALL.xlsx) " + _("ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

def display_shortage_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Shortage"))
        fp_s_role = data_dir / "shortage_role.xlsx"
        if fp_s_role.exists():
            try:
                df_s_role = pd.read_excel(fp_s_role); st.dataframe(df_s_role,use_container_width=True,hide_index=True)
                if "role" in df_s_role and "lack_h" in df_s_role: st.bar_chart(df_s_role.set_index("role")["lack_h"], color="#FFA500")
            except Exception as e: st.error(f"shortage_role.xlsx è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
        else: st.info(_("Shortage") + " (shortage_role.xlsx) " + _("ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))
        st.markdown("---")
        fp_s_time = data_dir / "shortage_time.xlsx"
        if fp_s_time.exists():
            try:
                df_s_time = pd.read_excel(fp_s_time, index_col=0)
                st.write(_("Shortage by Time (count per day)"))
                avail_dates = df_s_time.columns.tolist()
                if avail_dates:
                    sel_date = st.selectbox(_("Select date to display"), avail_dates, key="dash_short_time_date")
                    if sel_date: st.bar_chart(df_s_time[sel_date])
                else: st.info(_("No date columns in shortage data."))
                with st.expander(_("Display all time-slot shortage data")): st.dataframe(df_s_time, use_container_width=True)
            except Exception as e: st.error(f"shortage_time.xlsx è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
        else: st.info(_("Shortage") + " (shortage_time.xlsx) " + _("ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))
        
def display_fatigue_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Fatigue Score per Staff"))
        fp = data_dir / "fatigue_score.xlsx"
        if fp.exists():
            try:
                df = pd.read_excel(fp) 
                st.dataframe(df, use_container_width=True, hide_index=True)
                if "fatigue_score" in df and "staff" in df: 
                    st.bar_chart(df.set_index("staff")["fatigue_score"])
            except Exception as e: st.error(f"fatigue_score.xlsx è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
        else: st.info(_("Fatigue") + " (fatigue_score.xlsx) " + _("ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

def display_forecast_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Demand Forecast (yhat)"))
        fp_fc = data_dir / "forecast.xlsx"
        if fp_fc.exists():
            try:
                df_fc = pd.read_excel(fp_fc, parse_dates=["ds"])
                fig = go.Figure()
                if "ds" in df_fc and "yhat" in df_fc:
                    fig.add_trace(go.Scatter(x=df_fc["ds"], y=df_fc["yhat"], mode='lines+markers', name=_("Demand Forecast (yhat)")))
                fp_demand = data_dir / "demand_series.csv"
                if fp_demand.exists():
                    df_actual = pd.read_csv(fp_demand, parse_dates=["ds"])
                    if "ds" in df_actual and "y" in df_actual:
                         fig.add_trace(go.Scatter(x=df_actual["ds"], y=df_actual["y"], mode='lines', name=_("Actual (y)"), line=dict(dash='dash')))
                fig.update_layout(title=_("Demand Forecast vs Actual"), xaxis_title=_("Date"), yaxis_title=_("Demand"))
                st.plotly_chart(fig, use_container_width=True)
                with st.expander(_("Display forecast data")): st.dataframe(df_fc, use_container_width=True, hide_index=True)
            except Exception as e: st.error(f"forecast.xlsx è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
        else: st.info(_("Forecast") + " (forecast.xlsx) " + _("ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

def display_fairness_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Fairness (Night Shift Ratio)"))
        fp = data_dir / "fairness_after.xlsx"
        if fp.exists():
            try:
                df = pd.read_excel(fp); st.dataframe(df, use_container_width=True, hide_index=True)
                if "staff" in df and "night_ratio" in df: st.bar_chart(df.set_index("staff")["night_ratio"], color="#FF8C00")
            except Exception as e: st.error(f"fairness_after.xlsx è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
        else: st.info(_("Fairness") + " (fairness_after.xlsx) " + _("ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

def display_costsim_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Cost Simulation (Million Â¥)"))
        fp = data_dir / "cost_benefit.xlsx"
        if fp.exists():
            try:
                df = pd.read_excel(fp, index_col=0)
                if "Cost_Million" in df: st.bar_chart(df["Cost_Million"])
                st.dataframe(df, use_container_width=True)
            except Exception as e: st.error(f"cost_benefit.xlsx è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
        else: st.info(_("Cost Sim") + " (cost_benefit.xlsx) " + _("ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

def display_hireplan_tab(tab_container, data_dir):
    with tab_container:
        st.subheader(_("Hiring Plan (Needed FTE)"))
        fp = data_dir / "hire_plan.xlsx"
        if fp.exists():
            try:
                xls = pd.ExcelFile(fp)
                if "hire_plan" in xls.sheet_names:
                    df_plan = xls.parse("hire_plan"); st.dataframe(df_plan, use_container_width=True, hide_index=True)
                    if "role" in df_plan and "hire_need" in df_plan: st.bar_chart(df_plan.set_index("role")["hire_need"])
                if "meta" in xls.sheet_names:
                    with st.expander(_("Hiring Plan Parameters")): st.table(xls.parse("meta"))
            except Exception as e: st.error(f"hire_plan.xlsx è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
        else: st.info(_("Hire Plan") + " (hire_plan.xlsx) " + _("ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

def display_ppt_tab(tab_container, data_dir_ignored): 
    with tab_container:
        st.subheader(_("PPT Report"))
        if st.button(_("Generate PowerPoint Report (Î²)"), key="dash_generate_ppt_button", use_container_width=True):
            st.info(_("Generating PowerPoint report..."))
            try:
                from pptx import Presentation 
                prs = Presentation()
                prs.slides.add_slide(prs.slide_layouts[5]).shapes.title.text = "ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒ¬ãƒãƒ¼ãƒˆ"
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pptx") as tmp_ppt_dash:
                    temp_ppt_dash_path = tmp_ppt_dash.name
                prs.save(temp_ppt_dash_path)
                with open(temp_ppt_dash_path, "rb") as ppt_file_data_dash:
                    st.download_button(
                        label=_("Download Report (PPTX)"), data=ppt_file_data_dash,
                        file_name=f"ShiftSuite_Dashboard_Report_{dt.datetime.now().strftime('%Y%m%d_%H%M')}.pptx",
                        mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                        use_container_width=True
                    )
                Path(temp_ppt_dash_path).unlink()
                st.success(_("PowerPoint report ready."))
            except ImportError: st.error(_("python-pptx library required for PPT"))
            except Exception as e_ppt_dash: st.error(_("Error generating PowerPoint report") + f": {e_ppt_dash}")
        else:
            st.markdown(_("Click button to generate report."))


st.divider()
st.header(_("Dashboard (Upload ZIP)"))
zip_file_uploaded_dash_final_v3_display_main_dash = st.file_uploader(_("Upload ZIP file of 'out' folder"), type=["zip"], key="dashboard_zip_uploader_widget_final_v3_key_dash")

if zip_file_uploaded_dash_final_v3_display_main_dash:
    dashboard_temp_base = Path(tempfile.gettempdir()) / "ShiftSuite_Dash_Uploads"
    dashboard_temp_base.mkdir(parents=True, exist_ok=True)
    current_dash_tmp_dir = Path(tempfile.mkdtemp(prefix="dash_", dir=dashboard_temp_base))
    log.info(f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ: {current_dash_tmp_dir}")
    extracted_data_dir: Optional[Path] = None
    try:
        with zipfile.ZipFile(io.BytesIO(zip_file_uploaded_dash_final_v3_display_main_dash.read())) as zf:
            zf.extractall(current_dash_tmp_dir)
            if (current_dash_tmp_dir / "out").exists() and (current_dash_tmp_dir / "out" / "heat_ALL.xlsx").exists():
                extracted_data_dir = current_dash_tmp_dir / "out"
            elif (current_dash_tmp_dir / "heat_ALL.xlsx").exists():
                 extracted_data_dir = current_dash_tmp_dir
            else:
                found_heat_all = list(current_dash_tmp_dir.rglob("heat_ALL.xlsx"))
                if found_heat_all: 
                    extracted_data_dir = found_heat_all[0].parent
                else: 
                    st.error(_("heat_ALL.xlsx not found in ZIP"))
                    log.error(f"ZIPå±•é–‹å¾Œã€heat_ALL.xlsx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ in {current_dash_tmp_dir}")
                    st.stop()
        log.info(f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {extracted_data_dir}")
    except Exception as e_zip:
        st.error(_("Error during ZIP file extraction") + f": {e_zip}")
        log.error(f"ZIPå±•é–‹ä¸­ã‚¨ãƒ©ãƒ¼: {e_zip}", exc_info=True)
        st.stop()

    import plotly.express as px
    import plotly.graph_objects as go

    tab_keys_en_dash = ["Overview", "Heatmap", "Shortage", "Fatigue", "Forecast", "Fairness", "Cost Sim", "Hire Plan", "PPT Report"]
    tab_labels_dash = [_(key) for key in tab_keys_en_dash]
    tabs_obj_dash = st.tabs(tab_labels_dash)


    if extracted_data_dir:
        tab_function_map_dash = {
            "Overview": display_overview_tab, 
            "Heatmap": display_heatmap_tab,
            "Shortage": display_shortage_tab, 
            "Fatigue": display_fatigue_tab,
            "Forecast": display_forecast_tab, 
            "Fairness": display_fairness_tab,
            "Cost Sim": display_costsim_tab, 
            "Hire Plan": display_hireplan_tab,
            "PPT Report": display_ppt_tab,
        }
        
        # å„ã‚¿ãƒ–ã«å¯¾å¿œã™ã‚‹è¡¨ç¤ºé–¢æ•°ã‚’å‘¼ã³å‡ºã™
        for i, tab_key in enumerate(tab_keys_en_dash):
            if tab_key in tab_function_map_dash:
                tab_function_map_dash[tab_key](tabs_obj_dash[i], extracted_data_dir)
            else:
                with tabs_obj_dash[i]: 
                    st.subheader(_(tab_key))
                    st.info(f"{_(tab_key)} ã®è¡¨ç¤ºã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚")
    else:
        st.warning("ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__" and not st_runtime_exists():
    import argparse
    log.info("CLIãƒ¢ãƒ¼ãƒ‰ã§app.pyã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
    parser = argparse.ArgumentParser(description="Shift-Suite CLI (app.pyçµŒç”±ã®ãƒ‡ãƒãƒƒã‚°ç”¨)")
    parser.add_argument("xlsx_file_cli", help="Excel ã‚·ãƒ•ãƒˆåŸæœ¬ (.xlsx)")
    parser.add_argument("--sheets_cli", nargs="+", required=True, help="è§£æå¯¾è±¡ã®ã‚·ãƒ¼ãƒˆå")
    parser.add_argument("--header_cli", type=int, default=3, help="ãƒ˜ãƒƒãƒ€ãƒ¼é–‹å§‹è¡Œ (1-indexed)")
    try:
        cli_args = parser.parse_args()
        log.info(f"CLI Args: file='{cli_args.xlsx_file_cli}', sheets={cli_args.sheets_cli}, header={cli_args.header_cli}")
    except SystemExit: 
        pass
    except Exception as e_cli:
        log.error(f"CLIãƒ¢ãƒ¼ãƒ‰ã§ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e_cli}", exc_info=True)
