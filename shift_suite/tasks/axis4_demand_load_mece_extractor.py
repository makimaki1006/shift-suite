#!/usr/bin/env python3
"""
è»¸4: éœ€è¦ãƒ»è² è·ç®¡ç† MECEäº‹å®ŸæŠ½å‡ºã‚¨ãƒ³ã‚¸ãƒ³

12è»¸åˆ†æãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®è»¸4ã‚’æ‹…å½“
éå»ã‚·ãƒ•ãƒˆå®Ÿç¸¾ã‹ã‚‰éœ€è¦å¤‰å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨è² è·åˆ†æ•£ã«é–¢ã™ã‚‹åˆ¶ç´„ã‚’æŠ½å‡º

ä½œæˆæ—¥: 2025å¹´7æœˆ
"""

import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict
import json

log = logging.getLogger(__name__)

class DemandLoadMECEFactExtractor:
    """è»¸4: éœ€è¦ãƒ»è² è·ç®¡ç†ã®MECEäº‹å®ŸæŠ½å‡ºå™¨"""
    
    def __init__(self):
        self.axis_number = 4
        self.axis_name = "éœ€è¦ãƒ»è² è·ç®¡ç†"
        
    def extract_axis4_demand_load_rules(self, long_df: pd.DataFrame, wt_df: pd.DataFrame = None) -> Dict[str, Any]:
        """
        è»¸4: éœ€è¦ãƒ»è² è·ç®¡ç†ãƒ«ãƒ¼ãƒ«ã‚’MECEåˆ†è§£ã«ã‚ˆã‚ŠæŠ½å‡º
        
        Args:
            long_df: éå»ã®ã‚·ãƒ•ãƒˆå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿
            wt_df: å‹¤å‹™åŒºåˆ†ãƒã‚¹ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            Dict: æŠ½å‡ºçµæœï¼ˆhuman_readable, machine_readable, extraction_metadataï¼‰
        """
        log.info(f"ğŸ¯ è»¸4: {self.axis_name} MECEäº‹å®ŸæŠ½å‡ºã‚’é–‹å§‹")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
            if long_df.empty:
                raise ValueError("é•·æœŸãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            
            # è»¸4ã®MECEåˆ†è§£ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆ8ã¤ï¼‰
            mece_facts = {
                "éœ€è¦äºˆæ¸¬åˆ¶ç´„": self._extract_demand_forecasting_constraints(long_df, wt_df),
                "ãƒ”ãƒ¼ã‚¯è² è·åˆ¶ç´„": self._extract_peak_load_constraints(long_df, wt_df),
                "è² è·åˆ†æ•£åˆ¶ç´„": self._extract_load_distribution_constraints(long_df, wt_df),
                "éœ€è¦å¤‰å‹•å¯¾å¿œåˆ¶ç´„": self._extract_demand_variation_constraints(long_df, wt_df),
                "ãƒªã‚½ãƒ¼ã‚¹é…åˆ†åˆ¶ç´„": self._extract_resource_allocation_constraints(long_df, wt_df),
                "ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£åˆ¶ç´„": self._extract_capacity_constraints(long_df, wt_df),
                "éœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¶ç´„": self._extract_demand_pattern_constraints(long_df, wt_df),
                "è² è·å¹³æº–åŒ–åˆ¶ç´„": self._extract_load_leveling_constraints(long_df, wt_df)
            }
            
            # äººé–“å¯èª­å½¢å¼ã®çµæœç”Ÿæˆ
            human_readable = self._generate_human_readable_results(mece_facts, long_df)
            
            # æ©Ÿæ¢°å¯èª­å½¢å¼ã®åˆ¶ç´„ç”Ÿæˆ
            machine_readable = self._generate_machine_readable_constraints(mece_facts, long_df)
            
            # æŠ½å‡ºãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            extraction_metadata = self._generate_extraction_metadata(long_df, wt_df, mece_facts)
            
            log.info(f"âœ… è»¸4: {self.axis_name} MECEäº‹å®ŸæŠ½å‡ºå®Œäº†")
            
            return {
                'human_readable': human_readable,
                'machine_readable': machine_readable,
                'extraction_metadata': extraction_metadata
            }
            
        except Exception as e:
            log.error(f"âŒ è»¸4: {self.axis_name} æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise e
    
    def _extract_demand_forecasting_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """éœ€è¦äºˆæ¸¬åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # æ™‚é–“å¸¯åˆ¥éœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            if 'ds' in long_df.columns and 'role' in long_df.columns:
                # æ™‚é–“å¸¯åˆ¥ã‚¹ã‚¿ãƒƒãƒ•é…ç½®æ•°ã‚’åˆ†æ
                long_df['hour'] = pd.to_datetime(long_df['ds']).dt.hour
                hourly_demand = long_df.groupby(['hour', 'role']).size().reset_index(name='demand_count')
                
                # é«˜éœ€è¦æ™‚é–“å¸¯ã®ç‰¹å®š
                peak_hours = hourly_demand.groupby('hour')['demand_count'].sum().nlargest(3).index.tolist()
                constraints.append(f"é«˜éœ€è¦æ™‚é–“å¸¯: {peak_hours}æ™‚ã«é›†ä¸­çš„ãªäººå“¡é…ç½®ãŒå¿…è¦")
                
                # è·ç¨®åˆ¥éœ€è¦å¤‰å‹•
                role_variations = {}
                for role in long_df['role'].unique():
                    role_hourly = hourly_demand[hourly_demand['role'] == role]['demand_count']
                    if len(role_hourly) > 1:
                        cv = role_hourly.std() / role_hourly.mean() if role_hourly.mean() > 0 else 0
                        role_variations[role] = cv
                
                # å¤‰å‹•ã®å¤§ãã„è·ç¨®
                high_variation_roles = [role for role, cv in role_variations.items() if cv > 0.5]
                if high_variation_roles:
                    constraints.append(f"éœ€è¦å¤‰å‹•ã®å¤§ãã„è·ç¨®: {', '.join(high_variation_roles)} - äºˆæ¸¬ç²¾åº¦å‘ä¸ŠãŒé‡è¦")
            
            # æ›œæ—¥åˆ¥éœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³
            if 'ds' in long_df.columns:
                long_df['weekday'] = pd.to_datetime(long_df['ds']).dt.day_name()
                daily_demand = long_df.groupby('weekday').size()
                peak_day = daily_demand.idxmax()
                low_day = daily_demand.idxmin()
                constraints.append(f"æ›œæ—¥åˆ¥éœ€è¦: {peak_day}ãŒæœ€é«˜ã€{low_day}ãŒæœ€ä½éœ€è¦")
                
        except Exception as e:
            log.warning(f"éœ€è¦äºˆæ¸¬åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("éœ€è¦äºˆæ¸¬åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["éœ€è¦äºˆæ¸¬ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_peak_load_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """ãƒ”ãƒ¼ã‚¯è² è·åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # æ—¥åˆ¥ã‚¹ã‚¿ãƒƒãƒ•æ•°ã§ãƒ”ãƒ¼ã‚¯è² è·ã‚’åˆ†æ
            if 'ds' in long_df.columns:
                daily_staff_count = long_df.groupby(long_df['ds'].dt.date)['staff'].nunique()
                peak_threshold = daily_staff_count.quantile(0.9)
                peak_days = daily_staff_count[daily_staff_count >= peak_threshold]
                
                constraints.append(f"ãƒ”ãƒ¼ã‚¯è² è·æ—¥æ•°: {len(peak_days)}æ—¥ (é–¾å€¤: {peak_threshold:.1f}äººä»¥ä¸Š)")
                
                # ãƒ”ãƒ¼ã‚¯è² è·ã®æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³
                if len(peak_days) > 0:
                    peak_weekdays = pd.to_datetime(peak_days.index).day_name().value_counts()
                    most_common_peak = peak_weekdays.index[0]
                    constraints.append(f"ãƒ”ãƒ¼ã‚¯è² è·é »ç™ºæ›œæ—¥: {most_common_peak} ({peak_weekdays.iloc[0]}å›)")
            
            # æ™‚é–“å¸¯åˆ¥ãƒ”ãƒ¼ã‚¯è² è·
            if 'ds' in long_df.columns:
                long_df['hour'] = pd.to_datetime(long_df['ds']).dt.hour
                hourly_load = long_df.groupby('hour')['staff'].nunique()
                peak_hour = hourly_load.idxmax()
                peak_count = hourly_load.max()
                constraints.append(f"ãƒ”ãƒ¼ã‚¯è² è·æ™‚é–“: {peak_hour}æ™‚ ({peak_count}äºº)")
                
        except Exception as e:
            log.warning(f"ãƒ”ãƒ¼ã‚¯è² è·åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("ãƒ”ãƒ¼ã‚¯è² è·åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["ãƒ”ãƒ¼ã‚¯è² è·ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_load_distribution_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """è² è·åˆ†æ•£åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # ã‚¹ã‚¿ãƒƒãƒ•é–“ã®è² è·åˆ†æ•£ã‚’åˆ†æ
            if 'staff' in long_df.columns:
                staff_workload = long_df['staff'].value_counts()
                workload_cv = staff_workload.std() / staff_workload.mean() if staff_workload.mean() > 0 else 0
                
                if workload_cv > 0.3:
                    constraints.append(f"è² è·ä¸å‡è¡¡æ¤œå‡º: CV={workload_cv:.2f} - è² è·åˆ†æ•£ã®æ”¹å–„ãŒå¿…è¦")
                else:
                    constraints.append(f"è² è·åˆ†æ•£è‰¯å¥½: CV={workload_cv:.2f}")
                
                # éè² è·ã‚¹ã‚¿ãƒƒãƒ•ã®ç‰¹å®š
                workload_threshold = staff_workload.quantile(0.8)
                overloaded_staff = staff_workload[staff_workload >= workload_threshold]
                if len(overloaded_staff) > 0:
                    constraints.append(f"é«˜è² è·ã‚¹ã‚¿ãƒƒãƒ•æ•°: {len(overloaded_staff)}äºº (é–¾å€¤: {workload_threshold:.1f}å‹¤å‹™ä»¥ä¸Š)")
            
            # è·ç¨®é–“è² è·åˆ†æ•£
            if 'role' in long_df.columns:
                role_workload = long_df['role'].value_counts()
                role_cv = role_workload.std() / role_workload.mean() if role_workload.mean() > 0 else 0
                constraints.append(f"è·ç¨®é–“è² è·åˆ†æ•£: CV={role_cv:.2f}")
                
        except Exception as e:
            log.warning(f"è² è·åˆ†æ•£åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("è² è·åˆ†æ•£åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["è² è·åˆ†æ•£ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_demand_variation_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """éœ€è¦å¤‰å‹•å¯¾å¿œåˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # éœ€è¦å¤‰å‹•ã®åˆ†æ
            if 'ds' in long_df.columns:
                # æ—¥åˆ¥ã‚¹ã‚¿ãƒƒãƒ•æ•°ã®å¤‰å‹•
                daily_count = long_df.groupby(long_df['ds'].dt.date).size()
                if len(daily_count) > 1:
                    variation_cv = daily_count.std() / daily_count.mean()
                    
                    if variation_cv > 0.2:
                        constraints.append(f"é«˜éœ€è¦å¤‰å‹•: CV={variation_cv:.2f} - æŸ”è»Ÿãªäººå“¡èª¿æ•´ãŒå¿…è¦")
                    else:
                        constraints.append(f"å®‰å®šéœ€è¦: CV={variation_cv:.2f}")
                
                # çŸ­æœŸå¤‰å‹•ï¼ˆé€±å˜ä½ï¼‰
                if len(daily_count) >= 7:
                    weekly_means = []
                    for i in range(0, len(daily_count), 7):
                        week_data = daily_count.iloc[i:i+7]
                        if len(week_data) >= 3:  # æœ€ä½3æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹é€±ã®ã¿
                            weekly_means.append(week_data.mean())
                    
                    if len(weekly_means) > 1:
                        weekly_cv = np.std(weekly_means) / np.mean(weekly_means)
                        constraints.append(f"é€±æ¬¡éœ€è¦å¤‰å‹•: CV={weekly_cv:.2f}")
                
        except Exception as e:
            log.warning(f"éœ€è¦å¤‰å‹•å¯¾å¿œåˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("éœ€è¦å¤‰å‹•å¯¾å¿œåˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["éœ€è¦å¤‰å‹•å¯¾å¿œã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_resource_allocation_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """ãƒªã‚½ãƒ¼ã‚¹é…åˆ†åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # è·ç¨®åˆ¥ãƒªã‚½ãƒ¼ã‚¹é…åˆ†
            if 'role' in long_df.columns and 'employment' in long_df.columns:
                role_employment_matrix = pd.crosstab(long_df['role'], long_df['employment'])
                
                # å„è·ç¨®ã®é›‡ç”¨å½¢æ…‹åˆ†æ•£åº¦
                for role in role_employment_matrix.index:
                    role_data = role_employment_matrix.loc[role]
                    if role_data.sum() > 0:
                        employment_ratio = role_data / role_data.sum()
                        dominant_employment = employment_ratio.idxmax()
                        dominant_ratio = employment_ratio.max()
                        
                        if dominant_ratio > 0.8:
                            constraints.append(f"{role}: {dominant_employment}ã«åé‡ ({dominant_ratio:.1%})")
                        else:
                            constraints.append(f"{role}: ãƒãƒ©ãƒ³ã‚¹è‰¯ã„é›‡ç”¨å½¢æ…‹é…åˆ†")
            
            # æ™‚é–“å¸¯åˆ¥ãƒªã‚½ãƒ¼ã‚¹é…åˆ†
            if 'ds' in long_df.columns and 'role' in long_df.columns:
                long_df['hour'] = pd.to_datetime(long_df['ds']).dt.hour
                hourly_role_count = pd.crosstab(long_df['hour'], long_df['role'])
                
                # å„æ™‚é–“å¸¯ã§ã®ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã®åã‚Š
                for hour in hourly_role_count.index:
                    hour_data = hourly_role_count.loc[hour]
                    if hour_data.sum() > 0:
                        hour_cv = hour_data.std() / hour_data.mean()
                        if hour_cv > 1.0:
                            constraints.append(f"{hour}æ™‚: è·ç¨®é…åˆ†ã«åã‚Š (CV={hour_cv:.2f})")
                
        except Exception as e:
            log.warning(f"ãƒªã‚½ãƒ¼ã‚¹é…åˆ†åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("ãƒªã‚½ãƒ¼ã‚¹é…åˆ†åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_capacity_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # æœ€å¤§ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ã®åˆ†æ
            if 'staff' in long_df.columns:
                total_unique_staff = long_df['staff'].nunique()
                constraints.append(f"ç·ã‚¹ã‚¿ãƒƒãƒ•æ•°: {total_unique_staff}äºº")
                
                # åŒæ™‚å‹¤å‹™æœ€å¤§äººæ•°
                if 'ds' in long_df.columns:
                    simultaneous_staff = long_df.groupby('ds')['staff'].nunique()
                    max_simultaneous = simultaneous_staff.max()
                    avg_simultaneous = simultaneous_staff.mean()
                    utilization_rate = max_simultaneous / total_unique_staff
                    
                    constraints.append(f"æœ€å¤§åŒæ™‚å‹¤å‹™: {max_simultaneous}äºº (ç¨¼åƒç‡: {utilization_rate:.1%})")
                    constraints.append(f"å¹³å‡åŒæ™‚å‹¤å‹™: {avg_simultaneous:.1f}äºº")
                    
                    # ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£åˆ¶ç´„ã®å³ã—ã•
                    if utilization_rate > 0.8:
                        constraints.append("ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£åˆ¶ç´„: å³ã—ã„ - äººå“¡å¢—å“¡ã®æ¤œè¨ãŒå¿…è¦")
                    elif utilization_rate < 0.5:
                        constraints.append("ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£åˆ¶ç´„: ä½™è£•ã‚ã‚Š - åŠ¹ç‡åŒ–ã®ä½™åœ°")
                    else:
                        constraints.append("ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£åˆ¶ç´„: é©æ­£ãƒ¬ãƒ™ãƒ«")
            
            # è·ç¨®åˆ¥ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£
            if 'role' in long_df.columns and 'staff' in long_df.columns:
                role_capacity = long_df.groupby('role')['staff'].nunique()
                for role, capacity in role_capacity.items():
                    constraints.append(f"{role}ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£: {capacity}äºº")
                
        except Exception as e:
            log.warning(f"ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_demand_pattern_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """éœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
            if 'ds' in long_df.columns:
                long_df['date'] = long_df['ds'].dt.date
                daily_pattern = long_df.groupby('date').size()
                
                # é€±å˜ä½ãƒ‘ã‚¿ãƒ¼ãƒ³
                long_df['weekday'] = pd.to_datetime(long_df['ds']).dt.day_name()
                weekday_pattern = long_df.groupby('weekday').size()
                
                # æœ€é«˜ãƒ»æœ€ä½éœ€è¦æ›œæ—¥
                peak_weekday = weekday_pattern.idxmax()
                low_weekday = weekday_pattern.idxmin()
                ratio = weekday_pattern.max() / weekday_pattern.min() if weekday_pattern.min() > 0 else float('inf')
                
                constraints.append(f"é€±æ¬¡éœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³: {peak_weekday}æœ€é«˜, {low_weekday}æœ€ä½ (æ¯”ç‡: {ratio:.1f}å€)")
                
                # æœˆå˜ä½ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒååˆ†ã«ã‚ã‚‹å ´åˆï¼‰
                if len(daily_pattern) >= 30:
                    long_df['month'] = pd.to_datetime(long_df['ds']).dt.month
                    monthly_pattern = long_df.groupby('month').size()
                    peak_month = monthly_pattern.idxmax()
                    constraints.append(f"æœˆæ¬¡éœ€è¦ãƒ”ãƒ¼ã‚¯: {peak_month}æœˆ")
            
            # æ™‚é–“å¸¯åˆ¥éœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³
            if 'ds' in long_df.columns:
                long_df['hour'] = pd.to_datetime(long_df['ds']).dt.hour
                hourly_pattern = long_df.groupby('hour').size()
                peak_hours = hourly_pattern.nlargest(3).index.tolist()
                low_hours = hourly_pattern.nsmallest(3).index.tolist()
                
                constraints.append(f"éœ€è¦ãƒ”ãƒ¼ã‚¯æ™‚é–“å¸¯: {peak_hours}")
                constraints.append(f"éœ€è¦ä½ä¸‹æ™‚é–“å¸¯: {low_hours}")
                
        except Exception as e:
            log.warning(f"éœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("éœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["éœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _extract_load_leveling_constraints(self, long_df: pd.DataFrame, wt_df: pd.DataFrame) -> List[str]:
        """è² è·å¹³æº–åŒ–åˆ¶ç´„ã®æŠ½å‡º"""
        constraints = []
        
        try:
            # è² è·å¹³æº–åŒ–ã®å¿…è¦æ€§åˆ†æ
            if 'ds' in long_df.columns and 'staff' in long_df.columns:
                # æ—¥åˆ¥è² è·ã®å¤‰å‹•
                daily_load = long_df.groupby(long_df['ds'].dt.date)['staff'].nunique()
                if len(daily_load) > 1:
                    load_cv = daily_load.std() / daily_load.mean()
                    
                    if load_cv > 0.3:
                        constraints.append(f"è² è·å¹³æº–åŒ–å¿…è¦: æ—¥åˆ¥å¤‰å‹•CV={load_cv:.2f}")
                        
                        # å¹³æº–åŒ–ã®ææ¡ˆ
                        high_load_days = daily_load[daily_load > daily_load.mean() + daily_load.std()]
                        low_load_days = daily_load[daily_load < daily_load.mean() - daily_load.std()]
                        
                        if len(high_load_days) > 0 and len(low_load_days) > 0:
                            constraints.append(f"å¹³æº–åŒ–æ©Ÿä¼š: é«˜è² è·æ—¥{len(high_load_days)}æ—¥ â†’ ä½è² è·æ—¥{len(low_load_days)}æ—¥ã¸ã®åˆ†æ•£")
                    else:
                        constraints.append(f"è² è·å¹³æº–åŒ–è‰¯å¥½: æ—¥åˆ¥å¤‰å‹•CV={load_cv:.2f}")
            
            # ã‚¹ã‚¿ãƒƒãƒ•å€‹äººãƒ¬ãƒ™ãƒ«ã®è² è·å¹³æº–åŒ–
            if 'staff' in long_df.columns:
                staff_workdays = long_df['staff'].value_counts()
                staff_cv = staff_workdays.std() / staff_workdays.mean() if staff_workdays.mean() > 0 else 0
                
                if staff_cv > 0.5:
                    constraints.append(f"å€‹äººè² è·å¹³æº–åŒ–å¿…è¦: ã‚¹ã‚¿ãƒƒãƒ•é–“å¤‰å‹•CV={staff_cv:.2f}")
                else:
                    constraints.append(f"å€‹äººè² è·å¹³æº–åŒ–è‰¯å¥½: ã‚¹ã‚¿ãƒƒãƒ•é–“å¤‰å‹•CV={staff_cv:.2f}")
                
        except Exception as e:
            log.warning(f"è² è·å¹³æº–åŒ–åˆ¶ç´„æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            constraints.append("è² è·å¹³æº–åŒ–åˆ¶ç´„ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return constraints if constraints else ["è² è·å¹³æº–åŒ–ã«é–¢ã™ã‚‹åˆ¶ç´„ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    def _generate_human_readable_results(self, mece_facts: Dict[str, List[str]], long_df: pd.DataFrame) -> Dict[str, Any]:
        """äººé–“å¯èª­å½¢å¼ã®çµæœç”Ÿæˆ"""
        
        # äº‹å®Ÿç·æ•°è¨ˆç®—
        total_facts = sum(len(facts) for facts in mece_facts.values())
        
        return {
            'æŠ½å‡ºäº‹å®Ÿã‚µãƒãƒªãƒ¼': {
                'ç·äº‹å®Ÿæ•°': total_facts,
                'åˆ†æè»¸': f'è»¸{self.axis_number}: {self.axis_name}',
                'åˆ†æå¯¾è±¡ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°': len(long_df),
                'MECEã‚«ãƒ†ã‚´ãƒªãƒ¼æ•°': len(mece_facts),
                **{category: len(facts) for category, facts in mece_facts.items()}
            },
            'MECEåˆ†è§£äº‹å®Ÿ': mece_facts,
            'ç¢ºä¿¡åº¦åˆ¥åˆ†é¡': {
                'é«˜ç¢ºä¿¡åº¦äº‹å®Ÿ': [fact for facts in mece_facts.values() for fact in facts if 'CV=' in fact or 'äºº' in fact],
                'ä¸­ç¢ºä¿¡åº¦äº‹å®Ÿ': [fact for facts in mece_facts.values() for fact in facts if 'ãƒ‘ã‚¿ãƒ¼ãƒ³' in fact or 'æ™‚é–“' in fact],
                'è¦æ¤œè¨¼äº‹å®Ÿ': [fact for facts in mece_facts.values() for fact in facts if 'ã‚¨ãƒ©ãƒ¼' in fact or 'æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ' in fact]
            }
        }
    
    def _generate_machine_readable_constraints(self, mece_facts: Dict[str, List[str]], long_df: pd.DataFrame) -> Dict[str, Any]:
        """æ©Ÿæ¢°å¯èª­å½¢å¼ã®åˆ¶ç´„ç”Ÿæˆ"""
        
        hard_constraints = []
        soft_constraints = []
        preferences = []
        
        # MECEã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥åˆ¶ç´„åˆ†é¡
        for category, facts in mece_facts.items():
            for i, fact in enumerate(facts):
                constraint_id = f"axis4_{category.lower().replace('åˆ¶ç´„', '')}_{i+1}"
                
                # åˆ¶ç´„ã®å¼·åº¦åˆ¤å®š
                if any(keyword in fact for keyword in ['å¿…è¦', 'æœ€å¤§', 'æœ€å°', 'ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£']):
                    hard_constraints.append({
                        'id': constraint_id,
                        'type': 'demand_load',
                        'category': category,
                        'description': fact,
                        'priority': 'high',
                        'confidence': 0.8
                    })
                elif any(keyword in fact for keyword in ['æ”¹å–„', 'æœ€é©åŒ–', 'åŠ¹ç‡']):
                    soft_constraints.append({
                        'id': constraint_id,
                        'type': 'demand_load',
                        'category': category,
                        'description': fact,
                        'priority': 'medium',
                        'confidence': 0.6
                    })
                else:
                    preferences.append({
                        'id': constraint_id,
                        'type': 'demand_load',
                        'category': category,
                        'description': fact,
                        'priority': 'low',
                        'confidence': 0.4
                    })
        
        return {
            'hard_constraints': hard_constraints,
            'soft_constraints': soft_constraints,
            'preferences': preferences,
            'constraint_relationships': [],
            'validation_rules': [
                {
                    'rule_id': 'axis4_demand_capacity_check',
                    'description': 'éœ€è¦ãŒã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ã‚’è¶…ãˆãªã„ã“ã¨ã‚’ç¢ºèª',
                    'validation_type': 'capacity_constraint'
                },
                {
                    'rule_id': 'axis4_load_distribution_check',
                    'description': 'è² è·åˆ†æ•£ãŒé©åˆ‡ã«è¡Œã‚ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª',
                    'validation_type': 'load_balancing'
                }
            ]
        }
    
    def _generate_extraction_metadata(self, long_df: pd.DataFrame, wt_df: pd.DataFrame, 
                                     mece_facts: Dict[str, List[str]]) -> Dict[str, Any]:
        """æŠ½å‡ºãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
        
        # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®è¨ˆç®—
        date_range = {}
        if 'ds' in long_df.columns:
            dates = pd.to_datetime(long_df['ds'])
            date_range = {
                'start_date': dates.min().isoformat(),
                'end_date': dates.max().isoformat(),
                'total_days': (dates.max() - dates.min()).days
            }
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ªæŒ‡æ¨™
        data_quality = {
            'completeness': 1.0 - (long_df.isnull().sum().sum() / (len(long_df) * len(long_df.columns))),
            'record_count': len(long_df),
            'unique_staff_count': long_df['staff'].nunique() if 'staff' in long_df.columns else 0,
            'unique_roles_count': long_df['role'].nunique() if 'role' in long_df.columns else 0,
            'demand_coverage_ratio': len([f for facts in mece_facts.values() for f in facts if 'äºº' in f or 'CV=' in f]) / sum(len(facts) for facts in mece_facts.values()) if sum(len(facts) for facts in mece_facts.values()) > 0 else 0
        }
        
        return {
            'extraction_timestamp': datetime.now().isoformat(),
            'axis_info': {
                'axis_number': self.axis_number,
                'axis_name': self.axis_name,
                'mece_categories': list(mece_facts.keys())
            },
            'data_period': date_range,
            'data_quality': data_quality,
            'extraction_statistics': {
                'total_facts_extracted': sum(len(facts) for facts in mece_facts.values()),
                'high_confidence_facts': len([f for facts in mece_facts.values() for f in facts if 'CV=' in f or 'äºº' in f]),
                'categories_with_facts': len([cat for cat, facts in mece_facts.items() if facts and not any('æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ' in f for f in facts)])
            }
        }