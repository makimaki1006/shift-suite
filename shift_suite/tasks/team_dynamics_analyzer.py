"""
ãƒãƒ¼ãƒ ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ãƒ»ç›¸æ€§åˆ†æã‚¨ãƒ³ã‚¸ãƒ³

ã‚¹ã‚¿ãƒƒãƒ•é–“ã®ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ç›¸æ€§ã€å­¦ç¿’åŠ¹æœã€ç·Šæ€¥å¯¾å¿œèƒ½åŠ›ã‚’åˆ†æã—ã€
æœ€é©ãªãƒãƒ¼ãƒ ç·¨æˆã¨ã‚·ãƒ•ãƒˆé…ç½®ã‚’æ”¯æ´ã—ã¾ã™ã€‚

Author: Claude Code Assistant
Created: 2025-01-14
"""

from __future__ import annotations

import logging
from dataclasses import dataclass
from typing import Dict, List, Tuple, Set, Optional
from collections import defaultdict, Counter
from itertools import combinations

import numpy as np
import pandas as pd
from scipy import stats
from scipy.spatial.distance import cosine
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

from .constants import TEAM_DYNAMICS_PARAMETERS

log = logging.getLogger(__name__)

@dataclass
class TeamCompatibility:
    """ãƒãƒ¼ãƒ ç›¸æ€§åˆ†æçµæœ"""
    staff_pair: Tuple[str, str]
    compatibility_score: float  # 0.0-1.0
    collaboration_frequency: float
    performance_impact: float
    risk_factors: List[str]
    synergy_factors: List[str]
    recommendation: str

@dataclass
class LearningPattern:
    """å­¦ç¿’ãƒ»æˆé•·ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æçµæœ"""
    staff_name: str
    experience_level: str  # æ–°äººã€ä¸­å …ã€ãƒ™ãƒ†ãƒ©ãƒ³
    learning_speed: float
    skill_growth_areas: List[str]
    mentoring_capacity: float
    optimal_mentors: List[str]
    recommended_tasks: List[str]

@dataclass
class EmergencyCapacity:
    """ç·Šæ€¥å¯¾å¿œèƒ½åŠ›åˆ†æçµæœ"""
    staff_name: str
    flexibility_score: float  # 0.0-1.0
    cross_training_level: float
    stress_resilience: float
    emergency_availability: float
    backup_roles: List[str]
    response_time_category: str

class TeamDynamicsAnalyzer:
    """ãƒãƒ¼ãƒ ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ãƒ»ç›¸æ€§åˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.compatibility_threshold = TEAM_DYNAMICS_PARAMETERS["compatibility_threshold_good"]  # ç›¸æ€§è‰¯å¥½ã®é–¾å€¤
        self.emergency_score_threshold = TEAM_DYNAMICS_PARAMETERS["emergency_score_threshold"]  # ç·Šæ€¥å¯¾å¿œå¯èƒ½ã®é–¾å€¤
        
    def analyze_team_dynamics(self, long_df: pd.DataFrame) -> Dict[str, any]:
        """ãƒãƒ¼ãƒ ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã®åŒ…æ‹¬åˆ†æ"""
        
        if long_df.empty:
            return {}
            
        log.info("ğŸ¤ ãƒãƒ¼ãƒ ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹åˆ†æã‚’é–‹å§‹...")
        
        # 1. ã‚¹ã‚¿ãƒƒãƒ•é–“ç›¸æ€§åˆ†æ
        compatibility_results = self._analyze_staff_compatibility(long_df)
        
        # 2. å­¦ç¿’ãƒ»æˆé•·ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        learning_patterns = self._analyze_learning_patterns(long_df)
        
        # 3. ç·Šæ€¥å¯¾å¿œèƒ½åŠ›åˆ†æ
        emergency_capacity = self._analyze_emergency_capacity(long_df)
        
        # 4. æœ€é©ãƒãƒ¼ãƒ ç·¨æˆææ¡ˆ
        optimal_teams = self._generate_optimal_teams(
            compatibility_results, learning_patterns, emergency_capacity
        )
        
        # 5. ã‚¹ãƒˆãƒ¬ã‚¹è€æ€§åˆ†æ
        stress_analysis = self._analyze_stress_resilience(long_df)
        
        return {
            'staff_compatibility': compatibility_results,
            'learning_patterns': learning_patterns,
            'emergency_capacity': emergency_capacity,
            'optimal_teams': optimal_teams,
            'stress_resilience': stress_analysis,
            'team_recommendations': self._generate_team_recommendations(
                compatibility_results, learning_patterns, emergency_capacity
            )
        }
    
    def _analyze_staff_compatibility(self, long_df: pd.DataFrame) -> List[TeamCompatibility]:
        """ã‚¹ã‚¿ãƒƒãƒ•é–“ç›¸æ€§åˆ†æ"""
        
        working_df = long_df[long_df['parsed_slots_count'] > 0]
        compatibility_results = []
        
        # åŒæ—¥å‹¤å‹™ã®åˆ†æ
        daily_teams = working_df.groupby(['ds', 'code'])['staff'].apply(list).reset_index()
        
        # ãƒšã‚¢å…±èµ·çµ±è¨ˆ
        pair_stats = defaultdict(lambda: {
            'co_occurrences': 0,
            'total_opportunities': 0,
            'performance_indicators': []
        })
        
        staff_list = list(working_df['staff'].unique())
        
        for staff1, staff2 in combinations(staff_list, 2):
            # å…±èµ·å›æ•°ã®è¨ˆç®—
            staff1_days = set(working_df[working_df['staff'] == staff1]['ds'].dt.date)
            staff2_days = set(working_df[working_df['staff'] == staff2]['ds'].dt.date)
            
            co_occurrence_days = staff1_days.intersection(staff2_days)
            total_opportunity_days = staff1_days.union(staff2_days)
            
            if len(total_opportunity_days) > 0:
                collaboration_freq = len(co_occurrence_days) / len(total_opportunity_days)
                
                # ç›¸æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
                compatibility_score = self._calculate_compatibility_score(
                    staff1, staff2, working_df, collaboration_freq
                )
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å½±éŸ¿ã®åˆ†æ
                performance_impact = self._analyze_performance_impact(
                    staff1, staff2, working_df, co_occurrence_days
                )
                
                # ãƒªã‚¹ã‚¯ãƒ»ã‚·ãƒŠã‚¸ãƒ¼è¦å› ã®ç‰¹å®š
                risk_factors, synergy_factors = self._identify_compatibility_factors(
                    staff1, staff2, working_df
                )
                
                # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
                recommendation = self._generate_compatibility_recommendation(
                    compatibility_score, collaboration_freq, performance_impact
                )
                
                compatibility_results.append(TeamCompatibility(
                    staff_pair=(staff1, staff2),
                    compatibility_score=compatibility_score,
                    collaboration_frequency=collaboration_freq,
                    performance_impact=performance_impact,
                    risk_factors=risk_factors,
                    synergy_factors=synergy_factors,
                    recommendation=recommendation
                ))
        
        # ç›¸æ€§ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        compatibility_results.sort(key=lambda x: x.compatibility_score, reverse=True)
        
        return compatibility_results
    
    def _analyze_learning_patterns(self, long_df: pd.DataFrame) -> List[LearningPattern]:
        """å­¦ç¿’ãƒ»æˆé•·ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        
        working_df = long_df[long_df['parsed_slots_count'] > 0]
        learning_patterns = []
        
        for staff in working_df['staff'].unique():
            staff_df = working_df[working_df['staff'] == staff]
            
            # çµŒé¨“ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š
            experience_level = self._assess_experience_level(staff_df)
            
            # å­¦ç¿’é€Ÿåº¦ã®åˆ†æ
            learning_speed = self._calculate_learning_speed(staff_df)
            
            # ã‚¹ã‚­ãƒ«æˆé•·é ˜åŸŸã®ç‰¹å®š
            skill_growth_areas = self._identify_skill_growth_areas(staff_df)
            
            # ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°èƒ½åŠ›ã®è©•ä¾¡
            mentoring_capacity = self._assess_mentoring_capacity(staff_df, experience_level)
            
            # æœ€é©ãƒ¡ãƒ³ã‚¿ãƒ¼ã®ææ¡ˆ
            optimal_mentors = self._identify_optimal_mentors(
                staff, working_df, experience_level
            )
            
            # æ¨å¥¨ã‚¿ã‚¹ã‚¯ã®ç”Ÿæˆ
            recommended_tasks = self._generate_task_recommendations(
                experience_level, skill_growth_areas
            )
            
            learning_patterns.append(LearningPattern(
                staff_name=staff,
                experience_level=experience_level,
                learning_speed=learning_speed,
                skill_growth_areas=skill_growth_areas,
                mentoring_capacity=mentoring_capacity,
                optimal_mentors=optimal_mentors,
                recommended_tasks=recommended_tasks
            ))
        
        return learning_patterns
    
    def _analyze_emergency_capacity(self, long_df: pd.DataFrame) -> List[EmergencyCapacity]:
        """ç·Šæ€¥å¯¾å¿œèƒ½åŠ›åˆ†æ"""
        
        working_df = long_df[long_df['parsed_slots_count'] > 0]
        emergency_capacity = []
        
        for staff in working_df['staff'].unique():
            staff_df = working_df[working_df['staff'] == staff]
            
            # æŸ”è»Ÿæ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
            flexibility_score = self._calculate_flexibility_score(staff_df)
            
            # ã‚¯ãƒ­ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¬ãƒ™ãƒ«ã®è©•ä¾¡
            cross_training_level = self._assess_cross_training_level(staff_df)
            
            # ã‚¹ãƒˆãƒ¬ã‚¹è€æ€§ã®è©•ä¾¡
            stress_resilience = self._assess_stress_resilience(staff_df)
            
            # ç·Šæ€¥æ™‚å¯¾å¿œå¯èƒ½æ€§ã®è¨ˆç®—
            emergency_availability = self._calculate_emergency_availability(staff_df)
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯èƒ½å½¹å‰²ã®ç‰¹å®š
            backup_roles = self._identify_backup_roles(staff_df)
            
            # å¯¾å¿œæ™‚é–“ã‚«ãƒ†ã‚´ãƒªã®åˆ†é¡
            response_time_category = self._categorize_response_time(
                flexibility_score, emergency_availability
            )
            
            emergency_capacity.append(EmergencyCapacity(
                staff_name=staff,
                flexibility_score=flexibility_score,
                cross_training_level=cross_training_level,
                stress_resilience=stress_resilience,
                emergency_availability=emergency_availability,
                backup_roles=backup_roles,
                response_time_category=response_time_category
            ))
        
        # ç·Šæ€¥å¯¾å¿œèƒ½åŠ›é †ã§ã‚½ãƒ¼ãƒˆ
        emergency_capacity.sort(key=lambda x: x.flexibility_score, reverse=True)
        
        return emergency_capacity
    
    def _analyze_stress_resilience(self, long_df: pd.DataFrame) -> Dict[str, any]:
        """ã‚¹ãƒˆãƒ¬ã‚¹è€æ€§ã®è©³ç´°åˆ†æ"""
        
        working_df = long_df[long_df['parsed_slots_count'] > 0]
        stress_analysis = {}
        
        for staff in working_df['staff'].unique():
            staff_df = working_df[working_df['staff'] == staff]
            
            # 1. è² è·å¤‰å‹•ã¸ã®é©å¿œæ€§
            workload_variance = staff_df['parsed_slots_count'].var()
            adaptation_score = min(1.0, 1.0 / (1.0 + workload_variance))
            
            # 2. é€£ç¶šå‹¤å‹™è€æ€§
            consecutive_tolerance = self._assess_consecutive_tolerance(staff_df)
            
            # 3. ç¹å¿™æœŸå¯¾å¿œåŠ›
            peak_period_performance = self._assess_peak_period_performance(staff_df)
            
            # 4. ç·åˆã‚¹ãƒˆãƒ¬ã‚¹è€æ€§ã‚¹ã‚³ã‚¢
            overall_resilience = (
                adaptation_score * TEAM_DYNAMICS_PARAMETERS["adaptation_weight"] +
                consecutive_tolerance * TEAM_DYNAMICS_PARAMETERS["consecutive_tolerance_weight"] +
                peak_period_performance * TEAM_DYNAMICS_PARAMETERS["peak_performance_weight"]
            )
            
            stress_analysis[staff] = {
                'adaptation_score': adaptation_score,
                'consecutive_tolerance': consecutive_tolerance,
                'peak_period_performance': peak_period_performance,
                'overall_resilience': overall_resilience,
                'stress_category': self._categorize_stress_level(overall_resilience)
            }
        
        return stress_analysis
    
    def _generate_optimal_teams(self, compatibility_results: List[TeamCompatibility],
                              learning_patterns: List[LearningPattern],
                              emergency_capacity: List[EmergencyCapacity]) -> List[Dict[str, any]]:
        """æœ€é©ãƒãƒ¼ãƒ ç·¨æˆã®ææ¡ˆ"""
        
        optimal_teams = []
        
        # é«˜ç›¸æ€§ãƒšã‚¢ã®æŠ½å‡º
        high_compatibility_pairs = [
            comp for comp in compatibility_results 
            if comp.compatibility_score >= self.compatibility_threshold
        ]
        
        # çµŒé¨“ãƒ¬ãƒ™ãƒ«åˆ¥ã‚¹ã‚¿ãƒƒãƒ•åˆ†é¡
        experience_groups = defaultdict(list)
        for pattern in learning_patterns:
            experience_groups[pattern.experience_level].append(pattern.staff_name)
        
        # ç·Šæ€¥å¯¾å¿œå¯èƒ½ã‚¹ã‚¿ãƒƒãƒ•ã®ç‰¹å®š
        emergency_responders = [
            cap.staff_name for cap in emergency_capacity 
            if cap.flexibility_score >= self.emergency_score_threshold
        ]
        
        # ãƒãƒ¼ãƒ ç·¨æˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
        team_id = 1
        used_staff = set()
        
        for pair in high_compatibility_pairs:
            staff1, staff2 = pair.staff_pair
            
            if staff1 not in used_staff and staff2 not in used_staff:
                # çµŒé¨“ãƒãƒ©ãƒ³ã‚¹ã®ç¢ºèª
                exp1 = next((p.experience_level for p in learning_patterns if p.staff_name == staff1), "ä¸æ˜")
                exp2 = next((p.experience_level for p in learning_patterns if p.staff_name == staff2), "ä¸æ˜")
                
                # ãƒãƒ¼ãƒ ç‰¹æ€§ã®åˆ†æ
                team_characteristics = {
                    'compatibility_score': pair.compatibility_score,
                    'experience_balance': self._assess_experience_balance(exp1, exp2),
                    'emergency_coverage': any(staff in emergency_responders for staff in [staff1, staff2]),
                    'learning_potential': self._assess_learning_potential(staff1, staff2, learning_patterns),
                    'synergy_factors': pair.synergy_factors
                }
                
                optimal_teams.append({
                    'team_id': f"Team_{team_id:02d}",
                    'members': [staff1, staff2],
                    'characteristics': team_characteristics,
                    'recommendation_reason': f"é«˜ç›¸æ€§ãƒšã‚¢ï¼ˆç›¸æ€§åº¦{pair.compatibility_score:.2f}ï¼‰",
                    'optimal_scenarios': self._identify_optimal_scenarios(pair, team_characteristics)
                })
                
                used_staff.add(staff1)
                used_staff.add(staff2)
                team_id += 1
        
        return optimal_teams
    
    def _generate_team_recommendations(self, compatibility_results: List[TeamCompatibility],
                                     learning_patterns: List[LearningPattern],
                                     emergency_capacity: List[EmergencyCapacity]) -> List[str]:
        """ãƒãƒ¼ãƒ ç·¨æˆã«é–¢ã™ã‚‹æ¨å¥¨äº‹é …"""
        
        recommendations = []
        
        # 1. é«˜ç›¸æ€§ãƒšã‚¢ã®æ´»ç”¨æ¨å¥¨
        excellent_pairs = [c for c in compatibility_results if c.compatibility_score >= TEAM_DYNAMICS_PARAMETERS["compatibility_threshold_excellent"]]
        if excellent_pairs:
            recommendations.append(
                f"å„ªç§€ãªç›¸æ€§ãƒšã‚¢{len(excellent_pairs)}çµ„ã®ç©æ¥µæ´»ç”¨ã‚’æ¨å¥¨"
            )
        
        # 2. çµŒé¨“ãƒãƒ©ãƒ³ã‚¹æ”¹å–„
        newcomers = [p.staff_name for p in learning_patterns if p.experience_level == "æ–°äºº"]
        veterans = [p.staff_name for p in learning_patterns if p.experience_level == "ãƒ™ãƒ†ãƒ©ãƒ³"]
        
        if len(newcomers) > len(veterans):
            recommendations.append(
                f"æ–°äºº{len(newcomers)}åã«å¯¾ã—ãƒ™ãƒ†ãƒ©ãƒ³{len(veterans)}åã§ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°ä½“åˆ¶å¼·åŒ–ãŒå¿…è¦"
            )
        
        # 3. ç·Šæ€¥å¯¾å¿œä½“åˆ¶ã®ææ¡ˆ
        emergency_ready = [e.staff_name for e in emergency_capacity if e.flexibility_score >= TEAM_DYNAMICS_PARAMETERS["emergency_ready_threshold"]]
        if len(emergency_ready) < 3:
            recommendations.append(
                "ç·Šæ€¥å¯¾å¿œå¯èƒ½ã‚¹ã‚¿ãƒƒãƒ•ãŒä¸è¶³ã€‚ã‚¯ãƒ­ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿæ–½ã‚’æ¨å¥¨"
            )
        
        # 4. ãƒªã‚¹ã‚¯ãƒšã‚¢ã®è­¦å‘Š
        risky_pairs = [c for c in compatibility_results if c.compatibility_score < TEAM_DYNAMICS_PARAMETERS["compatibility_threshold_risky"]]
        if risky_pairs:
            recommendations.append(
                f"ç›¸æ€§ã«èª²é¡Œã®ã‚ã‚‹ãƒšã‚¢{len(risky_pairs)}çµ„ã«ã¤ã„ã¦é…ç½®æ³¨æ„ãŒå¿…è¦"
            )
        
        return recommendations
    
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    def _calculate_compatibility_score(self, staff1: str, staff2: str, 
                                     working_df: pd.DataFrame, collaboration_freq: float) -> float:
        """ç›¸æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        
        # åŸºæœ¬è¦å› 
        freq_score = min(collaboration_freq * 2, 1.0)  # å”åƒé »åº¦
        
        # å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é¡ä¼¼æ€§
        pattern_similarity = self._calculate_pattern_similarity(staff1, staff2, working_df)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        performance_score = TEAM_DYNAMICS_PARAMETERS["performance_default_score"]  # å®Ÿéš›ã®å®Ÿè£…ã§ã¯å…·ä½“çš„ãªKPIã‚’ä½¿ç”¨
        
        # é‡ã¿ä»˜ãåˆæˆ
        compatibility_score = (
            freq_score * TEAM_DYNAMICS_PARAMETERS["frequency_weight"] +
            pattern_similarity * TEAM_DYNAMICS_PARAMETERS["pattern_weight"] +
            performance_score * TEAM_DYNAMICS_PARAMETERS["performance_weight"]
        )
        
        return min(compatibility_score, 1.0)
    
    def _calculate_pattern_similarity(self, staff1: str, staff2: str, working_df: pd.DataFrame) -> float:
        """å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é¡ä¼¼æ€§è¨ˆç®—"""
        
        staff1_df = working_df[working_df['staff'] == staff1]
        staff2_df = working_df[working_df['staff'] == staff2]
        
        # æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é¡ä¼¼æ€§
        weekday1 = staff1_df.groupby(staff1_df['ds'].dt.dayofweek).size()
        weekday2 = staff2_df.groupby(staff2_df['ds'].dt.dayofweek).size()
        
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§è¨ˆç®—
        weekday1_norm = weekday1.reindex(range(7), fill_value=0).values
        weekday2_norm = weekday2.reindex(range(7), fill_value=0).values
        
        if np.sum(weekday1_norm) > 0 and np.sum(weekday2_norm) > 0:
            similarity = 1 - cosine(weekday1_norm, weekday2_norm)
        else:
            similarity = 0.0
            
        return max(0.0, similarity)
    
    def _analyze_performance_impact(self, staff1: str, staff2: str, 
                                  working_df: pd.DataFrame, co_occurrence_days: Set) -> float:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å½±éŸ¿ã®åˆ†æ"""
        
        # ç°¡æ˜“å®Ÿè£…ï¼šå…±èµ·æ—¥æ•°ã«åŸºã¥ãå½±éŸ¿åº¦
        impact_score = min(len(co_occurrence_days) / TEAM_DYNAMICS_PARAMETERS["impact_normalization_days"], 1.0)  # æŒ‡å®šæ—¥æ•°ã‚’ä¸Šé™ã¨ã—ã¦æ­£è¦åŒ–
        
        return impact_score
    
    def _identify_compatibility_factors(self, staff1: str, staff2: str, 
                                      working_df: pd.DataFrame) -> Tuple[List[str], List[str]]:
        """ç›¸æ€§è¦å› ã®ç‰¹å®š"""
        
        risk_factors = []
        synergy_factors = []
        
        staff1_df = working_df[working_df['staff'] == staff1]
        staff2_df = working_df[working_df['staff'] == staff2]
        
        # å‹¤å‹™æ™‚é–“ã®é‡è¤‡åº¦
        overlap_ratio = len(set(staff1_df['ds'].dt.date).intersection(set(staff2_df['ds'].dt.date))) / \
                       len(set(staff1_df['ds'].dt.date).union(set(staff2_df['ds'].dt.date)))
        
        if overlap_ratio > TEAM_DYNAMICS_PARAMETERS["overlap_ratio_high"]:
            synergy_factors.append("é«˜ã„å‹¤å‹™æ™‚é–“é‡è¤‡")
        elif overlap_ratio < TEAM_DYNAMICS_PARAMETERS["overlap_ratio_low"]:
            risk_factors.append("å‹¤å‹™æ™‚é–“é‡è¤‡ãŒå°‘ãªã„")
        
        # è·ç¨®ã®çµ„ã¿åˆã‚ã›
        roles1 = set(staff1_df['role'].unique())
        roles2 = set(staff2_df['role'].unique())
        
        if len(roles1.intersection(roles2)) > 0:
            synergy_factors.append("åŒè·ç¨®ã§ã®é€£æºå¯èƒ½")
        else:
            synergy_factors.append("ç•°è·ç¨®ã§ã®è£œå®Œé–¢ä¿‚")
        
        return risk_factors, synergy_factors
    
    def _generate_compatibility_recommendation(self, compatibility_score: float,
                                             collaboration_freq: float,
                                             performance_impact: float) -> str:
        """ç›¸æ€§ã«åŸºã¥ãæ¨å¥¨äº‹é …"""
        
        if compatibility_score >= TEAM_DYNAMICS_PARAMETERS["compatibility_threshold_high"]:
            return "ç©æ¥µçš„ãªãƒšã‚¢é…ç½®ã‚’æ¨å¥¨"
        elif compatibility_score >= TEAM_DYNAMICS_PARAMETERS["compatibility_threshold_decent"]:
            return "æ¡ä»¶ãŒåˆãˆã°ãƒšã‚¢é…ç½®å¯èƒ½"
        elif compatibility_score >= TEAM_DYNAMICS_PARAMETERS["compatibility_threshold_acceptable"]:
            return "çŸ­æ™‚é–“ã§ã®çµ„ã¿åˆã‚ã›ã¯å¯èƒ½"
        else:
            return "ãƒšã‚¢é…ç½®ã¯é¿ã‘ã‚‹ã“ã¨ã‚’æ¨å¥¨"
    
    def _assess_experience_level(self, staff_df: pd.DataFrame) -> str:
        """çµŒé¨“ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š"""
        
        total_days = len(staff_df['ds'].dt.date.unique())
        data_span = (staff_df['ds'].max() - staff_df['ds'].min()).days
        
        if total_days < TEAM_DYNAMICS_PARAMETERS["experience_newcomer_days"] or data_span < TEAM_DYNAMICS_PARAMETERS["experience_newcomer_span"]:
            return "æ–°äºº"
        elif total_days < TEAM_DYNAMICS_PARAMETERS["experience_midlevel_days"] or data_span < TEAM_DYNAMICS_PARAMETERS["experience_midlevel_span"]:
            return "ä¸­å …"
        else:
            return "ãƒ™ãƒ†ãƒ©ãƒ³"
    
    def _calculate_learning_speed(self, staff_df: pd.DataFrame) -> float:
        """å­¦ç¿’é€Ÿåº¦ã®è¨ˆç®—"""
        
        # å‹¤å‹™åŒºåˆ†ã®å¤šæ§˜æ€§å¢—åŠ ç‡ã§å­¦ç¿’é€Ÿåº¦ã‚’æ¨å®š
        codes_over_time = []
        for week in staff_df['ds'].dt.isocalendar().week.unique():
            week_df = staff_df[staff_df['ds'].dt.isocalendar().week == week]
            codes_over_time.append(len(week_df['code'].unique()))
        
        if len(codes_over_time) > 1:
            # ç·šå½¢å›å¸°ã§å¢—åŠ ç‡ã‚’è¨ˆç®—
            x = np.arange(len(codes_over_time))
            slope, _, _, _, _ = stats.linregress(x, codes_over_time)
            learning_speed = max(0.0, min(slope / TEAM_DYNAMICS_PARAMETERS["slope_normalization_factor"], 1.0))  # æ­£è¦åŒ–
        else:
            learning_speed = TEAM_DYNAMICS_PARAMETERS["learning_default_speed"]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
        return learning_speed
    
    def _identify_skill_growth_areas(self, staff_df: pd.DataFrame) -> List[str]:
        """ã‚¹ã‚­ãƒ«æˆé•·é ˜åŸŸã®ç‰¹å®š"""
        
        # ä½¿ç”¨é »åº¦ã®ä½ã„å‹¤å‹™åŒºåˆ†ã‚’æˆé•·é ˜åŸŸã¨ã—ã¦ç‰¹å®š
        code_counts = staff_df['code'].value_counts()
        growth_areas = code_counts[code_counts <= TEAM_DYNAMICS_PARAMETERS["skill_growth_min_frequency"]].index.tolist()
        
        return growth_areas[:TEAM_DYNAMICS_PARAMETERS["max_growth_areas"]]  # ä¸Šä½æŒ‡å®šæ•°ã¾ã§
    
    def _assess_mentoring_capacity(self, staff_df: pd.DataFrame, experience_level: str) -> float:
        """ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°èƒ½åŠ›ã®è©•ä¾¡"""
        
        if experience_level == "ãƒ™ãƒ†ãƒ©ãƒ³":
            # å‹¤å‹™åŒºåˆ†ã®å¤šæ§˜æ€§ã‚’ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°èƒ½åŠ›ã®æŒ‡æ¨™ã¨ã™ã‚‹
            code_diversity = len(staff_df['code'].unique())
            mentoring_capacity = min(code_diversity / TEAM_DYNAMICS_PARAMETERS["mentoring_diversity_factor"], 1.0)
        elif experience_level == "ä¸­å …":
            mentoring_capacity = TEAM_DYNAMICS_PARAMETERS["mentoring_capacity_default"]
        else:
            mentoring_capacity = TEAM_DYNAMICS_PARAMETERS["mentoring_capacity_low"]
            
        return mentoring_capacity
    
    def _identify_optimal_mentors(self, staff: str, working_df: pd.DataFrame, 
                                experience_level: str) -> List[str]:
        """æœ€é©ãƒ¡ãƒ³ã‚¿ãƒ¼ã®ç‰¹å®š"""
        
        if experience_level == "ãƒ™ãƒ†ãƒ©ãƒ³":
            return []  # ãƒ™ãƒ†ãƒ©ãƒ³ã«ã¯ãƒ¡ãƒ³ã‚¿ãƒ¼ã¯ä¸è¦
        
        # åŒã˜è·ç¨®ã®ãƒ™ãƒ†ãƒ©ãƒ³ã‚’æ¢ã™
        staff_role = working_df[working_df['staff'] == staff]['role'].iloc[0] if not working_df[working_df['staff'] == staff].empty else None
        
        potential_mentors = []
        for mentor_candidate in working_df['staff'].unique():
            if mentor_candidate != staff:
                mentor_df = working_df[working_df['staff'] == mentor_candidate]
                mentor_exp_level = self._assess_experience_level(mentor_df)
                mentor_role = mentor_df['role'].iloc[0] if not mentor_df.empty else None
                
                if (mentor_exp_level == "ãƒ™ãƒ†ãƒ©ãƒ³" and 
                    mentor_role == staff_role):
                    potential_mentors.append(mentor_candidate)
        
        return potential_mentors[:TEAM_DYNAMICS_PARAMETERS["max_mentors_per_person"]]  # æœ€å¤§æŒ‡å®šäººæ•°
    
    def _generate_task_recommendations(self, experience_level: str, 
                                     skill_growth_areas: List[str]) -> List[str]:
        """æ¨å¥¨ã‚¿ã‚¹ã‚¯ã®ç”Ÿæˆ"""
        
        if experience_level == "æ–°äºº":
            return ["åŸºæœ¬æ¥­å‹™ã®ç¿’å¾—", "ãƒ¡ãƒ³ã‚¿ãƒ¼åŒè¡Œ", "å®‰å…¨æ‰‹é †ã®ç¢ºèª"]
        elif experience_level == "ä¸­å …":
            return ["æ–°äººæŒ‡å°", "å°‚é–€ã‚¹ã‚­ãƒ«å‘ä¸Š", "ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—ç™ºæ®"]
        else:
            return ["ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°", "å“è³ªç®¡ç†", "æ¥­å‹™æ”¹å–„ææ¡ˆ"]
    
    def _calculate_flexibility_score(self, staff_df: pd.DataFrame) -> float:
        """æŸ”è»Ÿæ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        
        # å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¤‰å‹•æ€§ã‚’æŸ”è»Ÿæ€§ã®æŒ‡æ¨™ã¨ã™ã‚‹
        weekday_variance = staff_df.groupby(staff_df['ds'].dt.dayofweek).size().var()
        code_diversity = len(staff_df['code'].unique())
        
        flexibility = min((code_diversity / TEAM_DYNAMICS_PARAMETERS["flexibility_code_factor"] + 1 / (1 + weekday_variance)) / TEAM_DYNAMICS_PARAMETERS["flexibility_variance_weight"], 1.0)
        
        return flexibility
    
    def _assess_cross_training_level(self, staff_df: pd.DataFrame) -> float:
        """ã‚¯ãƒ­ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¬ãƒ™ãƒ«ã®è©•ä¾¡"""
        
        # è¤‡æ•°è·ç¨®ãƒ»è¤‡æ•°å‹¤å‹™åŒºåˆ†ã¸ã®å¯¾å¿œåº¦
        role_count = len(staff_df['role'].unique())
        code_count = len(staff_df['code'].unique())
        
        cross_training_level = min((role_count + code_count) / TEAM_DYNAMICS_PARAMETERS["cross_training_normalization_factor"], 1.0)
        
        return cross_training_level
    
    def _assess_stress_resilience(self, staff_df: pd.DataFrame) -> float:
        """ã‚¹ãƒˆãƒ¬ã‚¹è€æ€§ã®è©•ä¾¡"""
        
        # é€£ç¶šå‹¤å‹™æ—¥æ•°ã¨å‹¤å‹™æ™‚é–“ã®å¤‰å‹•ã¸ã®é©å¿œæ€§
        consecutive_days = self._calculate_max_consecutive(staff_df)
        hours_variance = staff_df['parsed_slots_count'].var()
        
        resilience = min(consecutive_days / TEAM_DYNAMICS_PARAMETERS["stress_consecutive_days_factor"] + 1 / (1 + hours_variance), 1.0)
        
        return resilience
    
    def _calculate_emergency_availability(self, staff_df: pd.DataFrame) -> float:
        """ç·Šæ€¥æ™‚å¯¾å¿œå¯èƒ½æ€§ã®è¨ˆç®—"""
        
        # å‹¤å‹™é »åº¦ã¨æŸ”è»Ÿæ€§ã‹ã‚‰ç·Šæ€¥å¯¾å¿œå¯èƒ½æ€§ã‚’æ¨å®š
        total_days = len(staff_df['ds'].dt.date.unique())
        data_span = (staff_df['ds'].max() - staff_df['ds'].min()).days
        
        availability = min(total_days / max(data_span, 1) * TEAM_DYNAMICS_PARAMETERS["emergency_availability_factor"], 1.0)
        
        return availability
    
    def _identify_backup_roles(self, staff_df: pd.DataFrame) -> List[str]:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯èƒ½å½¹å‰²ã®ç‰¹å®š"""
        
        return staff_df['role'].unique().tolist()
    
    def _categorize_response_time(self, flexibility_score: float, 
                                emergency_availability: float) -> str:
        """å¯¾å¿œæ™‚é–“ã‚«ãƒ†ã‚´ãƒªã®åˆ†é¡"""
        
        combined_score = (flexibility_score + emergency_availability) / 2
        
        if combined_score >= TEAM_DYNAMICS_PARAMETERS["response_time_instant_threshold"]:
            return "å³åº§å¯¾å¿œå¯èƒ½"
        elif combined_score >= TEAM_DYNAMICS_PARAMETERS["response_time_quick_threshold"]:
            return "çŸ­æ™‚é–“ã§å¯¾å¿œå¯èƒ½"
        elif combined_score >= TEAM_DYNAMICS_PARAMETERS["response_time_adjusted_threshold"]:
            return "èª¿æ•´å¾Œå¯¾å¿œå¯èƒ½"
        else:
            return "å¯¾å¿œå›°é›£"
    
    def _calculate_max_consecutive(self, staff_df: pd.DataFrame) -> int:
        """æœ€å¤§é€£ç¶šå‹¤å‹™æ—¥æ•°ã®è¨ˆç®—"""
        
        dates = sorted(staff_df['ds'].dt.date.unique())
        max_consecutive = 1
        current_consecutive = 1
        
        for i in range(1, len(dates)):
            if (dates[i] - dates[i-1]).days == 1:
                current_consecutive += 1
                max_consecutive = max(max_consecutive, current_consecutive)
            else:
                current_consecutive = 1
                
        return max_consecutive
    
    def _assess_consecutive_tolerance(self, staff_df: pd.DataFrame) -> float:
        """é€£ç¶šå‹¤å‹™è€æ€§ã®è©•ä¾¡"""
        
        max_consecutive = self._calculate_max_consecutive(staff_df)
        tolerance = min(max_consecutive / TEAM_DYNAMICS_PARAMETERS["consecutive_tolerance_factor"], 1.0)  # æŒ‡å®šæ—¥æ•°ã‚’ä¸Šé™ã¨ã—ã¦æ­£è¦åŒ–
        
        return tolerance
    
    def _assess_peak_period_performance(self, staff_df: pd.DataFrame) -> float:
        """ç¹å¿™æœŸå¯¾å¿œåŠ›ã®è©•ä¾¡"""
        
        # æœˆæœ«ï¼ˆæŒ‡å®šæ—¥ä»¥é™ï¼‰ã®å‹¤å‹™é »åº¦ã§ç¹å¿™æœŸå¯¾å¿œåŠ›ã‚’è©•ä¾¡
        month_end_days = staff_df[staff_df['ds'].dt.day >= TEAM_DYNAMICS_PARAMETERS["month_end_threshold"]]
        total_month_end_possible = len(staff_df[staff_df['ds'].dt.day >= TEAM_DYNAMICS_PARAMETERS["month_end_threshold"]]['ds'].dt.date.unique())
        
        if total_month_end_possible > 0:
            peak_performance = len(month_end_days) / total_month_end_possible
        else:
            peak_performance = 0.5
            
        return min(peak_performance, 1.0)
    
    def _categorize_stress_level(self, overall_resilience: float) -> str:
        """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«ã®ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
        
        if overall_resilience >= TEAM_DYNAMICS_PARAMETERS["stress_high_threshold"]:
            return "é«˜ã‚¹ãƒˆãƒ¬ã‚¹è€æ€§"
        elif overall_resilience >= TEAM_DYNAMICS_PARAMETERS["stress_medium_threshold"]:
            return "ä¸­ã‚¹ãƒˆãƒ¬ã‚¹è€æ€§"
        elif overall_resilience >= TEAM_DYNAMICS_PARAMETERS["stress_low_threshold"]:
            return "ä½ã‚¹ãƒˆãƒ¬ã‚¹è€æ€§"
        else:
            return "ã‚¹ãƒˆãƒ¬ã‚¹æ³¨æ„"
    
    def _assess_experience_balance(self, exp1: str, exp2: str) -> str:
        """çµŒé¨“ãƒãƒ©ãƒ³ã‚¹ã®è©•ä¾¡"""
        
        if exp1 == exp2:
            return f"åŒãƒ¬ãƒ™ãƒ«ï¼ˆ{exp1}ï¼‰"
        elif (exp1 == "ãƒ™ãƒ†ãƒ©ãƒ³" and exp2 == "æ–°äºº") or (exp1 == "æ–°äºº" and exp2 == "ãƒ™ãƒ†ãƒ©ãƒ³"):
            return "ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°é–¢ä¿‚"
        else:
            return "ãƒãƒ©ãƒ³ã‚¹è‰¯å¥½"
    
    def _assess_learning_potential(self, staff1: str, staff2: str, 
                                 learning_patterns: List[LearningPattern]) -> float:
        """å­¦ç¿’ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã®è©•ä¾¡"""
        
        pattern1 = next((p for p in learning_patterns if p.staff_name == staff1), None)
        pattern2 = next((p for p in learning_patterns if p.staff_name == staff2), None)
        
        if pattern1 and pattern2:
            learning_potential = (pattern1.learning_speed + pattern2.learning_speed) / 2
        else:
            learning_potential = 0.5
            
        return learning_potential
    
    def _identify_optimal_scenarios(self, pair: TeamCompatibility, 
                                  team_characteristics: Dict[str, any]) -> List[str]:
        """æœ€é©ã‚·ãƒŠãƒªã‚ªã®ç‰¹å®š"""
        
        scenarios = []
        
        if team_characteristics['emergency_coverage']:
            scenarios.append("ç·Šæ€¥æ™‚å¯¾å¿œ")
        
        if team_characteristics['experience_balance'] == "ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°é–¢ä¿‚":
            scenarios.append("æ–°äººæŒ‡å°")
        
        if pair.compatibility_score >= TEAM_DYNAMICS_PARAMETERS["compatibility_threshold_excellent"]:
            scenarios.append("é‡è¦æ¥­å‹™æ‹…å½“")
        
        if not scenarios:
            scenarios.append("é€šå¸¸æ¥­å‹™")
        
        return scenarios


def analyze_team_dynamics(long_df: pd.DataFrame) -> Dict[str, any]:
    """
    ãƒãƒ¼ãƒ ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹åˆ†æã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
    
    Args:
        long_df: å‹¤å‹™ãƒ‡ãƒ¼ã‚¿
        
    Returns:
        ãƒãƒ¼ãƒ ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹åˆ†æçµæœ
    """
    analyzer = TeamDynamicsAnalyzer()
    return analyzer.analyze_team_dynamics(long_df)