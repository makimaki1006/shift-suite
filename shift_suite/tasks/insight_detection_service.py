"""
ç–çµåˆãªæ´å¯Ÿæ¤œå‡ºã‚µãƒ¼ãƒ“ã‚¹
æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’å¤‰æ›´ã›ãšã«ã€å¤–éƒ¨ã‹ã‚‰æ´å¯Ÿæ¤œå‡ºã‚’å®Ÿè¡Œ
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Callable
from pathlib import Path
import json
from datetime import datetime
from dataclasses import dataclass
from abc import ABC, abstractmethod
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import yaml

logger = logging.getLogger(__name__)


class InsightDetectionService:
    """
    ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ã®æ´å¯Ÿæ¤œå‡ºã‚µãƒ¼ãƒ“ã‚¹
    æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã«ã¯ä¸€åˆ‡æ‰‹ã‚’åŠ ãˆãšã«å‹•ä½œ
    """
    
    def __init__(self):
        """æ´å¯Ÿæ¤œå‡ºã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–"""
        self.logger = logging.getLogger(__name__)
        self.plugins: List[InsightPlugin] = []
        self.hooks = {}  # ãƒ•ãƒƒã‚¯æ©Ÿèƒ½ã®åˆæœŸåŒ–
        self.config = {
            'parallel_execution': False,
            'max_workers': 4
        }
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®ç™»éŒ²
        # æ³¨æ„: EmploymentConstraintPluginã¯æ„å›³çš„ã«é™¤å¤–
        # ï¼ˆãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒä¸é©åˆã®ãŸã‚ï¼‰
        self.register_plugin(EmploymentConstraintPlugin())  # ç„¡åŠ¹åŒ–æ¸ˆã¿
        self.register_plugin(TimeMismatchPlugin())
        self.register_plugin(WorkloadImbalancePlugin())
        self.register_plugin(FatigueRiskPlugin())
        self.register_plugin(CostAnomalyPlugin())
        self.register_plugin(FairnessPlugin())
        
        # ç¾å®Ÿæ€§æ¤œè¨¼ã®é–¾å€¤
        self.REALISTIC_HOURS_MIN = 50    # æœˆ50æ™‚é–“æœªæº€ã¯å°‘ãªã™ã
        self.REALISTIC_HOURS_MAX = 250   # æœˆ250æ™‚é–“è¶…ã¯å¤šã™ã
        self.REALISTIC_DAILY_MAX = 12    # æ—¥12æ™‚é–“è¶…ã¯ç•°å¸¸
        
    def _load_config(self, config_path: Optional[Path]) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if config_path and config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                if config_path.suffix == '.yaml':
                    return yaml.safe_load(f)
                else:
                    return json.load(f)
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        return {
            'enabled_plugins': ['all'],
            'output_format': ['json', 'html', 'csv'],
            'auto_detect': True,
            'parallel_execution': True,
            'max_workers': 4,
            'thresholds': {
                'cost_waste': 10,
                'workload_imbalance': 2.0,
                'fatigue_hours': 200
            }
        }
    
    def _load_plugins(self):
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’å‹•çš„ã«ãƒ­ãƒ¼ãƒ‰"""
        # åŸºæœ¬ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ç™»éŒ²
        self.register_plugin(EmploymentConstraintPlugin())
        self.register_plugin(TimeMismatchPlugin())
        self.register_plugin(WorkloadImbalancePlugin())
        self.register_plugin(FatigueRiskPlugin())
        self.register_plugin(CostAnomalyPlugin())
        self.register_plugin(FairnessPlugin())
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å‹•çš„ãƒ­ãƒ¼ãƒ‰
        plugin_dir = Path(__file__).parent / 'insight_plugins'
        if plugin_dir.exists():
            for plugin_file in plugin_dir.glob('*.py'):
                try:
                    # å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå®Ÿè£…ã¯çœç•¥ï¼‰
                    pass
                except Exception as e:
                    logger.warning(f"ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ {plugin_file} ã®ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
    
    def register_plugin(self, plugin: 'InsightPlugin'):
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ç™»éŒ²"""
        self.plugins.append(plugin)
        logger.info(f"ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ç™»éŒ²: {plugin.name}")
    
    def register_hook(self, event: str, callback: Callable):
        """ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ãƒƒã‚¯ã‚’ç™»éŒ²"""
        if event not in self.hooks:
            self.hooks[event] = []
        self.hooks[event].append(callback)
    
    def _trigger_hook(self, event: str, data: Any):
        """ãƒ•ãƒƒã‚¯ã‚’ãƒˆãƒªã‚¬ãƒ¼"""
        if event in self.hooks:
            for callback in self.hooks[event]:
                try:
                    callback(data)
                except Exception as e:
                    logger.error(f"ãƒ•ãƒƒã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ ({event}): {e}")
    
    def analyze_directory(self, analysis_dir: Path) -> 'InsightReport':
        """
        åˆ†æãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æ´å¯Ÿã‚’æ¤œå‡ºï¼ˆéä¾µè¥²çš„ï¼‰
        
        Args:
            analysis_dir: åˆ†æçµæœãŒæ ¼ç´ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            æ´å¯Ÿãƒ¬ãƒãƒ¼ãƒˆ
        """
        logger.info(f"æ´å¯Ÿæ¤œå‡ºé–‹å§‹: {analysis_dir}")
        
        # å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        data_context = self._load_analysis_data(analysis_dir)
        
        if not data_context:
            logger.warning("åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return InsightReport(insights=[], metadata={})
        
        # æ¤œå‡ºé–‹å§‹ã‚’ãƒ•ãƒƒã‚¯
        self._trigger_hook('detection_started', data_context)
        
        all_insights = []
        
        if self.config['parallel_execution']:
            # ä¸¦åˆ—å®Ÿè¡Œ
            with ThreadPoolExecutor(max_workers=self.config['max_workers']) as executor:
                futures = {
                    executor.submit(plugin.detect, data_context): plugin
                    for plugin in self.plugins
                    if self._is_plugin_enabled(plugin)
                }
                
                for future in as_completed(futures):
                    plugin = futures[future]
                    try:
                        insights = future.result(timeout=30)
                        all_insights.extend(insights)
                        logger.info(f"{plugin.name}: {len(insights)}å€‹ã®æ´å¯Ÿã‚’æ¤œå‡º")
                    except Exception as e:
                        logger.error(f"{plugin.name} ã§ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            # é †æ¬¡å®Ÿè¡Œ
            for plugin in self.plugins:
                if self._is_plugin_enabled(plugin):
                    try:
                        insights = plugin.detect(data_context)
                        all_insights.extend(insights)
                        logger.info(f"{plugin.name}: {len(insights)}å€‹ã®æ´å¯Ÿã‚’æ¤œå‡º")
                    except Exception as e:
                        logger.error(f"{plugin.name} ã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ç¾å®Ÿæ€§æ¤œè¨¼ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        validated_insights = []
        for insight in all_insights:
            if self._validate_insight_realism(insight):
                validated_insights.append(insight)
            else:
                logger.warning(f"éç¾å®Ÿçš„ãªæ´å¯Ÿã‚’é™¤å¤–: {insight.title}")
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = InsightReport(
            insights=validated_insights,
            metadata={
                'analysis_dir': str(analysis_dir),
                'detection_time': datetime.now().isoformat(),
                'plugin_count': len(self.plugins),
                'total_insights': len(validated_insights),
                'filtered_count': len(all_insights) - len(validated_insights)
            }
        )
        
        # æ¤œå‡ºå®Œäº†ã‚’ãƒ•ãƒƒã‚¯
        self._trigger_hook('detection_completed', report)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        self._save_report(report, analysis_dir)
        
        return report
    
    def _load_analysis_data(self, analysis_dir: Path) -> Optional[Dict]:
        """åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã®ã¾ã¾åˆ©ç”¨ï¼‰"""
        data_context = {}
        
        # å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«
        required_files = {
            'intermediate_data': 'intermediate_data.parquet',
            'shortage_role': 'shortage_role_summary.parquet',
            'shortage_employment': 'shortage_employment_summary.parquet'
        }
        
        for key, filename in required_files.items():
            file_path = analysis_dir / filename
            if file_path.exists():
                try:
                    data_context[key] = pd.read_parquet(file_path)
                except Exception as e:
                    logger.warning(f"{filename} ã®èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«
        optional_files = {
            'need_data': 'need_per_date_slot.parquet',
            'meta': 'heatmap.meta.json'
        }
        
        for key, filename in optional_files.items():
            file_path = analysis_dir / filename
            if file_path.exists():
                try:
                    if filename.endswith('.json'):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data_context[key] = json.load(f)
                    else:
                        data_context[key] = pd.read_parquet(file_path)
                except Exception:
                    pass
        
        return data_context if data_context else None
    
    def _is_plugin_enabled(self, plugin: 'InsightPlugin') -> bool:
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãŒæœ‰åŠ¹ã‹åˆ¤å®š"""
        enabled = self.config.get('enabled_plugins', ['all'])
        if 'all' in enabled:
            return True
        return plugin.name in enabled
    
    def _save_report(self, report: 'InsightReport', output_dir: Path):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜"""
        output_formats = self.config.get('output_format', ['json'])
        
        if 'json' in output_formats:
            json_path = output_dir / 'insights_detected.json'
            report.save_json(json_path)
            logger.info(f"JSONãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {json_path}")
        
        if 'html' in output_formats:
            html_path = output_dir / 'insights_report.html'
            report.save_html(html_path)
            logger.info(f"HTMLãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {html_path}")
        
        if 'csv' in output_formats:
            csv_path = output_dir / 'insights_table.csv'
            report.save_csv(csv_path)
            logger.info(f"CSVãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {csv_path}")

    def _validate_insight_realism(self, insight: 'Insight') -> bool:
        """
        æ´å¯Ÿã®ç¾å®Ÿæ€§ã‚’æ¤œè¨¼
        
        éç¾å®Ÿçš„ãªå€¤ã‚’æ¤œå‡ºã—ã¦ãƒ­ã‚°ã«è¨˜éŒ²ã—ã€
        å¿…è¦ã«å¿œã˜ã¦æ´å¯Ÿã‚’é™¤å¤–ã™ã‚‹
        """
        # æ™‚é–“é–¢é€£ã®æ¤œè¨¼
        if 'hours' in insight.evidence:
            hours = insight.evidence['hours']
            if not (self.REALISTIC_HOURS_MIN <= hours <= self.REALISTIC_HOURS_MAX):
                self.logger.warning(
                    f"éç¾å®Ÿçš„ãªæ™‚é–“ã‚’æ¤œå‡º: {hours}h/æœˆ "
                    f"(ãƒ—ãƒ©ã‚°ã‚¤ãƒ³: {insight.plugin}, ã‚¿ã‚¤ãƒˆãƒ«: {insight.title})"
                )
                return False
                
        if 'avg_hours' in insight.evidence:
            avg_hours = insight.evidence['avg_hours']
            if avg_hours > self.REALISTIC_HOURS_MAX:
                self.logger.error(
                    f"éç¾å®Ÿçš„ãªå¹³å‡æ™‚é–“: {avg_hours}h/æœˆ "
                    f"(ãƒ—ãƒ©ã‚°ã‚¤ãƒ³: {insight.plugin})"
                )
                return False
                
        # è²¡å‹™å½±éŸ¿ã®æ¤œè¨¼ï¼ˆ1å„„å††è¶…ã¯è¦ç¢ºèªï¼‰
        if insight.impact > 10000:
            self.logger.warning(
                f"ç•°å¸¸ã«å¤§ãã„è²¡å‹™å½±éŸ¿: {insight.impact}ä¸‡å††/æœˆ "
                f"(ãƒ—ãƒ©ã‚°ã‚¤ãƒ³: {insight.plugin})"
            )
            
        return True


class InsightPlugin(ABC):
    """æ´å¯Ÿæ¤œå‡ºãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.name = self.__class__.__name__
        self.enabled = True
    
    @abstractmethod
    def detect(self, data_context: Dict) -> List['Insight']:
        """
        æ´å¯Ÿã‚’æ¤œå‡º
        
        Args:
            data_context: åˆ†æãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            æ¤œå‡ºã•ã‚ŒãŸæ´å¯Ÿã®ãƒªã‚¹ãƒˆ
        """
        pass


@dataclass
class Insight:
    """æ¤œå‡ºã•ã‚ŒãŸæ´å¯Ÿ"""
    plugin: str
    severity: str  # critical, high, medium, low
    category: str
    title: str
    description: str
    evidence: Dict[str, Any]
    impact: Optional[float] = None
    recommendation: Optional[str] = None
    confidence: float = 0.8


class InsightReport:
    """æ´å¯Ÿãƒ¬ãƒãƒ¼ãƒˆ"""
    
    def __init__(self, insights: List[Insight], metadata: Dict):
        self.insights = insights
        self.metadata = metadata
        self._sort_by_severity()
    
    def _sort_by_severity(self):
        """é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ"""
        severity_order = {'critical': 0, 'high': 1, 'medium': 2, 'low': 3, 'info': 4}
        self.insights.sort(key=lambda x: (severity_order.get(x.severity, 99), -x.confidence))
    
    def get_summary(self) -> Dict:
        """ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        severity_counts = {}
        for insight in self.insights:
            severity_counts[insight.severity] = severity_counts.get(insight.severity, 0) + 1
        
        total_impact = sum(i.impact for i in self.insights if i.impact)
        
        return {
            'total': len(self.insights),
            'by_severity': severity_counts,
            'financial_impact': total_impact,
            'top_insights': self.insights[:5]
        }
    
    def save_json(self, path: Path):
        """JSONå½¢å¼ã§ä¿å­˜"""
        data = {
            'metadata': self.metadata,
            'summary': self.get_summary(),
            'insights': [
                {
                    'plugin': i.plugin,
                    'severity': i.severity,
                    'category': i.category,
                    'title': i.title,
                    'description': i.description,
                    'evidence': i.evidence,
                    'impact': i.impact,
                    'recommendation': i.recommendation,
                    'confidence': i.confidence
                }
                for i in self.insights
            ]
        }
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2, default=str)
    
    def save_html(self, path: Path):
        """HTMLå½¢å¼ã§ä¿å­˜"""
        html = self._generate_html()
        with open(path, 'w', encoding='utf-8') as f:
            f.write(html)
    
    def save_csv(self, path: Path):
        """CSVå½¢å¼ã§ä¿å­˜"""
        import csv
        
        with open(path, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=[
                'severity', 'category', 'title', 'description', 
                'impact', 'recommendation', 'confidence', 'plugin'
            ])
            writer.writeheader()
            
            for insight in self.insights:
                writer.writerow({
                    'severity': insight.severity,
                    'category': insight.category,
                    'title': insight.title,
                    'description': insight.description,
                    'impact': insight.impact,
                    'recommendation': insight.recommendation,
                    'confidence': insight.confidence,
                    'plugin': insight.plugin
                })
    
    def _generate_html(self) -> str:
        """HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        summary = self.get_summary()
        
        html = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>æ´å¯Ÿæ¤œå‡ºãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ background: linear-gradient(135deg, #667eea, #764ba2); color: white; padding: 20px; border-radius: 10px; }}
        .summary {{ display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; margin: 20px 0; }}
        .metric {{ background: #f8f9fa; padding: 15px; border-radius: 8px; text-align: center; }}
        .metric-value {{ font-size: 2em; font-weight: bold; color: #333; }}
        .insight {{ background: white; border-left: 4px solid #667eea; padding: 15px; margin: 15px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .critical {{ border-left-color: #dc2626; }}
        .high {{ border-left-color: #ea580c; }}
        .medium {{ border-left-color: #ca8a04; }}
        .low {{ border-left-color: #16a34a; }}
        .badge {{ display: inline-block; padding: 3px 10px; border-radius: 15px; font-size: 0.8em; font-weight: bold; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ” æ´å¯Ÿæ¤œå‡ºãƒ¬ãƒãƒ¼ãƒˆ</h1>
        <p>ç”Ÿæˆæ—¥æ™‚: {self.metadata.get('detection_time', '')}</p>
    </div>
    
    <div class="summary">
        <div class="metric">
            <div class="metric-value">{summary['total']}</div>
            <div>æ¤œå‡ºã•ã‚ŒãŸæ´å¯Ÿ</div>
        </div>
        <div class="metric">
            <div class="metric-value">{summary['by_severity'].get('critical', 0)}</div>
            <div>ç·Šæ€¥å¯¾å¿œ</div>
        </div>
        <div class="metric">
            <div class="metric-value">{summary['by_severity'].get('high', 0)}</div>
            <div>é«˜å„ªå…ˆåº¦</div>
        </div>
        <div class="metric">
            <div class="metric-value">{summary['financial_impact']:.0f}ä¸‡å††</div>
            <div>è²¡å‹™å½±éŸ¿</div>
        </div>
    </div>
    
    <h2>æ¤œå‡ºã•ã‚ŒãŸæ´å¯Ÿ</h2>
"""
        
        for insight in self.insights[:20]:  # ä¸Šä½20å€‹
            severity_class = insight.severity
            html += f"""
    <div class="insight {severity_class}">
        <h3>
            <span class="badge" style="background: {'#dc2626' if insight.severity == 'critical' else '#ea580c' if insight.severity == 'high' else '#ca8a04' if insight.severity == 'medium' else '#16a34a'}; color: white;">
                {insight.severity.upper()}
            </span>
            {insight.title}
        </h3>
        <p>{insight.description}</p>
        {f'<p><strong>è²¡å‹™å½±éŸ¿:</strong> {insight.impact:.1f}ä¸‡å††/æœˆ</p>' if insight.impact else ''}
        {f'<p><strong>æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:</strong> {insight.recommendation}</p>' if insight.recommendation else ''}
        <p style="font-size: 0.9em; color: #666;">æ¤œå‡º: {insight.plugin} | ç¢ºä¿¡åº¦: {insight.confidence*100:.0f}%</p>
    </div>
"""
        
        html += """
</body>
</html>
"""
        return html


# =====================================
# ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å®Ÿè£…ä¾‹
# =====================================

class EmploymentConstraintPlugin(InsightPlugin):
    """é›‡ç”¨å¥‘ç´„åˆ¶ç´„ã‚’æ¤œå‡º"""
    
    def detect(self, data_context: Dict) -> List[Insight]:
        """
        é›‡ç”¨å¥‘ç´„åˆ¶ç´„ã®æ¤œå‡º
        
        æ³¨æ„: intermediate_data.parquetã¯ã‚·ãƒ•ãƒˆå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã§ã‚ã‚Šã€
        é›‡ç”¨å¥‘ç´„ã®æœ€ä½ä¿è¨¼æ™‚é–“åˆ†æã«ã¯é©ã•ãªã„ãŸã‚ã€
        ã“ã®åˆ†æã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚
        """
        insights = []
        
        # ã“ã®åˆ†æã¯ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã§ã¯é©åˆ‡ã§ãªã„ãŸã‚ç„¡åŠ¹åŒ–
        # ç†ç”±:
        # 1. intermediate_data.parquetã¯ã‚·ãƒ•ãƒˆå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿
        # 2. é›‡ç”¨å¥‘ç´„ã®æœ€ä½ä¿è¨¼æ™‚é–“ã¯åˆ¥é€”å¥‘ç´„ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦
        # 3. ç¾åœ¨ã®è¨ˆç®—ã§ã¯éç¾å®Ÿçš„ãªçµæœï¼ˆæœˆ2000æ™‚é–“è¶…ï¼‰ãŒç™ºç”Ÿ
        
        return insights


class TimeMismatchPlugin(InsightPlugin):
    """æ™‚é–“å¸¯ãƒŸã‚¹ãƒãƒƒãƒã‚’æ¤œå‡º"""
    
    def detect(self, data_context: Dict) -> List[Insight]:
        insights = []
        
        if 'intermediate_data' not in data_context:
            return insights
        
        df = data_context['intermediate_data']
        
        if 'slot' in df.columns:
            slot_counts = df.groupby('slot').size()
            
            morning = slot_counts[12:20].sum() if len(slot_counts) > 20 else 0
            afternoon = slot_counts[28:36].sum() if len(slot_counts) > 36 else 0
            
            if afternoon > morning * 1.5 and morning > 0:
                excess = afternoon - morning
                impact = excess * 0.5 * 2000 / 10000
                
                insights.append(Insight(
                    plugin=self.name,
                    severity='high',
                    category='efficiency',
                    title="æœã®ä¸è¶³ã¨åˆå¾Œã®éå‰°",
                    description=f"æœã«æ¯”ã¹ã¦åˆå¾Œã«{excess}ã‚¹ãƒ­ãƒƒãƒˆåˆ†ã®éå‰°é…ç½®",
                    evidence={'morning': morning, 'afternoon': afternoon},
                    impact=impact,
                    recommendation="ã‚·ãƒ•ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¦‹ç›´ã—",
                    confidence=0.9
                ))
        
        return insights


class WorkloadImbalancePlugin(InsightPlugin):
    """ä½œæ¥­è² è·ã®ä¸å‡è¡¡ã‚’æ¤œå‡º"""
    
    def detect(self, data_context: Dict) -> List[Insight]:
        insights = []
        
        if 'intermediate_data' not in data_context:
            return insights
        
        df = data_context['intermediate_data']
        
        if 'staff' in df.columns:
            staff_loads = df.groupby('staff').size()
            mean_load = staff_loads.mean()
            std_load = staff_loads.std()
            
            for staff, load in staff_loads.items():
                if load > mean_load + 2 * std_load:
                    insights.append(Insight(
                        plugin=self.name,
                        severity='critical' if load > mean_load * 3 else 'high',
                        category='risk',
                        title=f"{staff}ã®éè² è·",
                        description=f"å‹¤å‹™æ™‚é–“ãŒå¹³å‡ã®{load/mean_load:.1f}å€",
                        evidence={'staff': staff, 'hours': load * 0.5},
                        impact=None,
                        recommendation="è² è·åˆ†æ•£ã¨ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å°å…¥",
                        confidence=0.95
                    ))
        
        return insights


class FatigueRiskPlugin(InsightPlugin):
    """ç–²åŠ´ãƒªã‚¹ã‚¯ã‚’æ¤œå‡º"""
    
    def detect(self, data_context: Dict) -> List[Insight]:
        insights = []
        
        if 'intermediate_data' not in data_context:
            return insights
        
        df = data_context['intermediate_data']
        
        if 'staff' in df.columns:
            staff_hours = df.groupby('staff').size() * 0.5
            
            for staff, hours in staff_hours.items():
                if hours > 200:
                    insights.append(Insight(
                        plugin=self.name,
                        severity='critical',
                        category='risk',
                        title=f"{staff}ã®ç–²åŠ´è“„ç©ãƒªã‚¹ã‚¯",
                        description=f"æœˆ{hours:.0f}æ™‚é–“å‹¤å‹™ã§é›¢è·ãƒªã‚¹ã‚¯é«˜",
                        evidence={'staff': staff, 'hours': hours},
                        impact=100,  # æ¡ç”¨ã‚³ã‚¹ãƒˆ
                        recommendation="å³åº§ã«ä¼‘æš‡ä»˜ä¸ã¨è² è·è»½æ¸›",
                        confidence=0.9
                    ))
        
        return insights


class CostAnomalyPlugin(InsightPlugin):
    """ã‚³ã‚¹ãƒˆç•°å¸¸ã‚’æ¤œå‡º"""
    
    def detect(self, data_context: Dict) -> List[Insight]:
        insights = []
        
        if 'intermediate_data' not in data_context:
            return insights
        
        df = data_context['intermediate_data']
        
        if 'ds' in df.columns:
            df['weekday'] = pd.to_datetime(df['ds']).dt.dayofweek
            weekday_counts = df.groupby('weekday').size()
            
            avg_count = weekday_counts.mean()
            
            for day, count in weekday_counts.items():
                if count > avg_count * 1.3:
                    excess = count - avg_count
                    impact = excess * 0.5 * 2000 * 4 / 10000
                    
                    day_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
                    
                    insights.append(Insight(
                        plugin=self.name,
                        severity='high' if impact > 20 else 'medium',
                        category='anomaly',
                        title=f"{day_names[day]}æ›œæ—¥ã®éå‰°é…ç½®",
                        description=f"å¹³å‡ã‚ˆã‚Š{excess:.0f}ã‚¹ãƒ­ãƒƒãƒˆå¤šã„é…ç½®",
                        evidence={'weekday': day, 'excess': excess},
                        impact=impact,
                        recommendation="é…ç½®ç†ç”±ã®èª¿æŸ»ã¨é©æ­£åŒ–",
                        confidence=0.85
                    ))
        
        return insights


class FairnessPlugin(InsightPlugin):
    """å…¬å¹³æ€§å•é¡Œã‚’æ¤œå‡º"""
    
    def detect(self, data_context: Dict) -> List[Insight]:
        insights = []
        
        if 'intermediate_data' not in data_context:
            return insights
        
        df = data_context['intermediate_data']
        
        if 'staff' in df.columns:
            staff_loads = df.groupby('staff').size()
            
            # ã‚¸ãƒ‹ä¿‚æ•°è¨ˆç®—
            sorted_loads = np.sort(staff_loads.values)
            n = len(sorted_loads)
            cumsum = np.cumsum(sorted_loads)
            gini = (2 * np.sum((np.arange(1, n + 1)) * sorted_loads)) / (n * cumsum[-1]) - (n + 1) / n
            
            if gini > 0.3:
                min_staff = staff_loads.idxmin()
                max_staff = staff_loads.idxmax()
                ratio = staff_loads[max_staff] / staff_loads[min_staff]
                
                insights.append(Insight(
                    plugin=self.name,
                    severity='high' if ratio > 3 else 'medium',
                    category='fairness',
                    title="ã‚·ãƒ•ãƒˆé…åˆ†ã®ä¸å…¬å¹³",
                    description=f"ã‚¹ã‚¿ãƒƒãƒ•é–“ã§{ratio:.1f}å€ã®è² è·å·®",
                    evidence={'gini': gini, 'min_staff': min_staff, 'max_staff': max_staff},
                    impact=None,
                    recommendation="é…åˆ†ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®è¦‹ç›´ã—",
                    confidence=0.85
                ))
        
        return insights


# =====================================
# ä½¿ç”¨ä¾‹
# =====================================

def run_insight_detection(analysis_dir: Path):
    """
    ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ã§æ´å¯Ÿæ¤œå‡ºã‚’å®Ÿè¡Œ
    
    ä½¿ç”¨ä¾‹:
        from pathlib import Path
        from insight_detection_service import run_insight_detection
        
        # æ—¢å­˜ã®åˆ†æçµæœã‹ã‚‰æ´å¯Ÿã‚’æ¤œå‡º
        analysis_dir = Path("output/analysis_20240101")
        report = run_insight_detection(analysis_dir)
    """
    
    # ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–
    service = InsightDetectionService()
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ•ãƒƒã‚¯ã‚’ç™»éŒ²ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    def on_detection_completed(report):
        print(f"æ¤œå‡ºå®Œäº†: {len(report.insights)}å€‹ã®æ´å¯Ÿ")
        
    service.register_hook('detection_completed', on_detection_completed)
    
    # æ´å¯Ÿã‚’æ¤œå‡º
    report = service.analyze_directory(analysis_dir)
    
    # ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    summary = report.get_summary()
    print(f"åˆè¨ˆ: {summary['total']}å€‹ã®æ´å¯Ÿ")
    print(f"è²¡å‹™å½±éŸ¿: {summary['financial_impact']:.0f}ä¸‡å††/æœˆ")
    
    return report


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    import sys
    if len(sys.argv) > 1:
        analysis_dir = Path(sys.argv[1])
        if analysis_dir.exists():
            report = run_insight_detection(analysis_dir)
            print(f"ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {analysis_dir}/insights_detected.json")