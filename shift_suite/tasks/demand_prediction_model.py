"""
éœ€è¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
MT2.1: AI/MLæ©Ÿèƒ½ - éœ€è¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º
"""

import os
import json
import datetime
import math
from typing import Dict, List, Any, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

class DemandPredictionModel:
    """éœ€è¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.model_name = "DemandPredictionModel_v1.0"
        self.version = "1.0"
        self.last_trained = None
        self.model_params = {
            'trend_weight': 0.3,
            'seasonal_weight': 0.4,
            'cyclical_weight': 0.2,
            'noise_weight': 0.1,
            'prediction_horizon': 30,  # 30æ—¥å…ˆã¾ã§äºˆæ¸¬
            'confidence_level': 0.95
        }
        
        # æ›œæ—¥ãƒ»æ™‚é–“å¸¯ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.day_patterns = {
            0: 1.2,  # æœˆæ›œæ—¥ï¼ˆé«˜éœ€è¦ï¼‰
            1: 1.0,  # ç«æ›œæ—¥
            2: 1.0,  # æ°´æ›œæ—¥
            3: 1.0,  # æœ¨æ›œæ—¥
            4: 1.1,  # é‡‘æ›œæ—¥
            5: 0.8,  # åœŸæ›œæ—¥ï¼ˆä½éœ€è¦ï¼‰
            6: 0.7   # æ—¥æ›œæ—¥ï¼ˆæœ€ä½éœ€è¦ï¼‰
        }
        
        self.hour_patterns = {
            0: 0.3, 1: 0.2, 2: 0.2, 3: 0.2, 4: 0.3, 5: 0.4,
            6: 0.7, 7: 1.0, 8: 1.2, 9: 1.1, 10: 1.0, 11: 1.0,
            12: 0.9, 13: 1.0, 14: 1.1, 15: 1.0, 16: 0.9, 17: 0.8,
            18: 0.7, 19: 0.6, 20: 0.5, 21: 0.4, 22: 0.4, 23: 0.3
        }
    
    def train_model(self, historical_data: List[Dict]) -> Dict:
        """ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        try:
            print("ğŸ¤– éœ€è¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹...")
            
            # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
            processed_data = self._preprocess_data(historical_data)
            
            # ç‰¹å¾´é‡æŠ½å‡º
            features = self._extract_features(processed_data)
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            trend_analysis = self._analyze_trend(processed_data)
            
            # å­£ç¯€æ€§åˆ†æ
            seasonal_analysis = self._analyze_seasonality(processed_data)
            
            # å‘¨æœŸæ€§åˆ†æ
            cyclical_analysis = self._analyze_cyclical_patterns(processed_data)
            
            # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
            self._update_model_parameters(trend_analysis, seasonal_analysis, cyclical_analysis)
            
            self.last_trained = datetime.datetime.now()
            
            training_results = {
                'success': True,
                'model_version': self.version,
                'training_timestamp': self.last_trained.isoformat(),
                'data_points_used': len(processed_data),
                'features_extracted': len(features),
                'trend_strength': trend_analysis['strength'],
                'seasonal_strength': seasonal_analysis['strength'],
                'cyclical_strength': cyclical_analysis['strength'],
                'model_accuracy': self._calculate_model_accuracy(processed_data),
                'training_summary': {
                    'trend_analysis': trend_analysis,
                    'seasonal_analysis': seasonal_analysis,
                    'cyclical_analysis': cyclical_analysis
                }
            }
            
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº† - ç²¾åº¦: {training_results['model_accuracy']:.2f}%")
            return training_results
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'model_version': self.version
            }
    
    def predict_demand(self, target_date: str, hours_ahead: int = 24) -> Dict:
        """éœ€è¦äºˆæ¸¬å®Ÿè¡Œ"""
        try:
            target_dt = datetime.datetime.strptime(target_date, '%Y-%m-%d')
            predictions = []
            
            for hour_offset in range(hours_ahead):
                prediction_time = target_dt + datetime.timedelta(hours=hour_offset)
                
                # åŸºæœ¬éœ€è¦é‡è¨ˆç®—
                base_demand = self._calculate_base_demand(prediction_time)
                
                # ãƒˆãƒ¬ãƒ³ãƒ‰èª¿æ•´
                trend_adjusted = self._apply_trend_adjustment(base_demand, prediction_time)
                
                # å­£ç¯€æ€§èª¿æ•´
                seasonal_adjusted = self._apply_seasonal_adjustment(trend_adjusted, prediction_time)
                
                # å‘¨æœŸæ€§èª¿æ•´
                cyclical_adjusted = self._apply_cyclical_adjustment(seasonal_adjusted, prediction_time)
                
                # ä¿¡é ¼åŒºé–“è¨ˆç®—
                confidence_interval = self._calculate_confidence_interval(cyclical_adjusted)
                
                prediction = {
                    'timestamp': prediction_time.isoformat(),
                    'hour': prediction_time.hour,
                    'day_of_week': prediction_time.weekday(),
                    'predicted_demand': round(cyclical_adjusted, 2),
                    'confidence_interval': {
                        'lower': round(confidence_interval[0], 2),
                        'upper': round(confidence_interval[1], 2)
                    },
                    'demand_level': self._classify_demand_level(cyclical_adjusted),
                    'factors': {
                        'base_demand': round(base_demand, 2),
                        'trend_factor': round(trend_adjusted / base_demand, 3) if base_demand > 0 else 1.0,
                        'seasonal_factor': round(seasonal_adjusted / trend_adjusted, 3) if trend_adjusted > 0 else 1.0,
                        'cyclical_factor': round(cyclical_adjusted / seasonal_adjusted, 3) if seasonal_adjusted > 0 else 1.0
                    }
                }
                
                predictions.append(prediction)
            
            # äºˆæ¸¬ã‚µãƒãƒªãƒ¼
            demand_values = [p['predicted_demand'] for p in predictions]
            prediction_summary = {
                'average_demand': round(sum(demand_values) / len(demand_values), 2),
                'peak_demand': max(demand_values),
                'peak_time': predictions[demand_values.index(max(demand_values))]['timestamp'],
                'min_demand': min(demand_values),
                'min_time': predictions[demand_values.index(min(demand_values))]['timestamp'],
                'demand_variance': round(self._calculate_variance(demand_values), 2),
                'high_demand_periods': len([p for p in predictions if p['demand_level'] == 'high']),
                'medium_demand_periods': len([p for p in predictions if p['demand_level'] == 'medium']),
                'low_demand_periods': len([p for p in predictions if p['demand_level'] == 'low'])
            }
            
            return {
                'success': True,
                'model_version': self.version,
                'prediction_date': target_date,
                'hours_predicted': hours_ahead,
                'predictions': predictions,
                'summary': prediction_summary,
                'generated_at': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'prediction_date': target_date
            }
    
    def _preprocess_data(self, data: List[Dict]) -> List[Dict]:
        """ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†"""
        processed = []
        
        for item in data:
            if self._validate_data_item(item):
                processed_item = {
                    'timestamp': item.get('timestamp', datetime.datetime.now().isoformat()),
                    'demand': float(item.get('demand', 0)),
                    'date': item.get('date', '2025-01-01'),
                    'hour': item.get('hour', 0),
                    'day_of_week': item.get('day_of_week', 0),
                    'month': item.get('month', 1),
                    'is_holiday': item.get('is_holiday', False),
                    'weather_factor': item.get('weather_factor', 1.0),
                    'special_events': item.get('special_events', [])
                }
                processed.append(processed_item)
        
        return sorted(processed, key=lambda x: x['timestamp'])
    
    def _validate_data_item(self, item: Dict) -> bool:
        """ãƒ‡ãƒ¼ã‚¿é …ç›®æ¤œè¨¼"""
        required_fields = ['demand']
        return all(field in item for field in required_fields) and isinstance(item.get('demand'), (int, float))
    
    def _extract_features(self, data: List[Dict]) -> Dict:
        """ç‰¹å¾´é‡æŠ½å‡º"""
        if not data:
            return {}
        
        demands = [item['demand'] for item in data]
        
        features = {
            'mean_demand': sum(demands) / len(demands),
            'max_demand': max(demands),
            'min_demand': min(demands),
            'demand_std': self._calculate_std(demands),
            'demand_range': max(demands) - min(demands),
            'data_points': len(data),
            'time_span_days': self._calculate_time_span(data),
            'hourly_patterns': self._extract_hourly_patterns(data),
            'daily_patterns': self._extract_daily_patterns(data),
            'monthly_patterns': self._extract_monthly_patterns(data)
        }
        
        return features
    
    def _calculate_std(self, values: List[float]) -> float:
        """æ¨™æº–åå·®è¨ˆç®—"""
        if len(values) < 2:
            return 0.0
        
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / (len(values) - 1)
        return math.sqrt(variance)
    
    def _calculate_variance(self, values: List[float]) -> float:
        """åˆ†æ•£è¨ˆç®—"""
        if len(values) < 2:
            return 0.0
        
        mean = sum(values) / len(values)
        return sum((x - mean) ** 2 for x in values) / len(values)
    
    def _calculate_time_span(self, data: List[Dict]) -> int:
        """ãƒ‡ãƒ¼ã‚¿æœŸé–“è¨ˆç®—"""
        if len(data) < 2:
            return 1
        
        start_time = datetime.datetime.fromisoformat(data[0]['timestamp'])
        end_time = datetime.datetime.fromisoformat(data[-1]['timestamp'])
        return (end_time - start_time).days + 1
    
    def _extract_hourly_patterns(self, data: List[Dict]) -> Dict:
        """æ™‚é–“åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        hourly_demands = {}
        
        for item in data:
            hour = item.get('hour', 0)
            if hour not in hourly_demands:
                hourly_demands[hour] = []
            hourly_demands[hour].append(item['demand'])
        
        patterns = {}
        for hour, demands in hourly_demands.items():
            patterns[hour] = {
                'average': sum(demands) / len(demands),
                'count': len(demands),
                'peak_ratio': (sum(demands) / len(demands)) / (sum(d['demand'] for d in data) / len(data)) if data else 1.0
            }
        
        return patterns
    
    def _extract_daily_patterns(self, data: List[Dict]) -> Dict:
        """æ—¥åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        daily_demands = {}
        
        for item in data:
            day = item.get('day_of_week', 0)
            if day not in daily_demands:
                daily_demands[day] = []
            daily_demands[day].append(item['demand'])
        
        patterns = {}
        for day, demands in daily_demands.items():
            patterns[day] = {
                'average': sum(demands) / len(demands),
                'count': len(demands),
                'day_name': ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'][day] if 0 <= day <= 6 else 'ä¸æ˜'
            }
        
        return patterns
    
    def _extract_monthly_patterns(self, data: List[Dict]) -> Dict:
        """æœˆåˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        monthly_demands = {}
        
        for item in data:
            month = item.get('month', 1)
            if month not in monthly_demands:
                monthly_demands[month] = []
            monthly_demands[month].append(item['demand'])
        
        patterns = {}
        for month, demands in monthly_demands.items():
            patterns[month] = {
                'average': sum(demands) / len(demands),
                'count': len(demands)
            }
        
        return patterns
    
    def _analyze_trend(self, data: List[Dict]) -> Dict:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        if len(data) < 3:
            return {'strength': 0.0, 'direction': 'stable', 'slope': 0.0}
        
        # å˜ç´”ç·šå½¢å›å¸°ã§ãƒˆãƒ¬ãƒ³ãƒ‰ç®—å‡º
        n = len(data)
        x_values = list(range(n))
        y_values = [item['demand'] for item in data]
        
        x_mean = sum(x_values) / n
        y_mean = sum(y_values) / n
        
        numerator = sum((x_values[i] - x_mean) * (y_values[i] - y_mean) for i in range(n))
        denominator = sum((x_values[i] - x_mean) ** 2 for i in range(n))
        
        slope = numerator / denominator if denominator != 0 else 0
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦è¨ˆç®—
        y_pred = [slope * x + (y_mean - slope * x_mean) for x in x_values]
        ss_res = sum((y_values[i] - y_pred[i]) ** 2 for i in range(n))
        ss_tot = sum((y_values[i] - y_mean) ** 2 for i in range(n))
        
        r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
        
        return {
            'strength': max(0, min(1, abs(r_squared))),
            'direction': 'increasing' if slope > 0.1 else 'decreasing' if slope < -0.1 else 'stable',
            'slope': slope,
            'r_squared': r_squared
        }
    
    def _analyze_seasonality(self, data: List[Dict]) -> Dict:
        """å­£ç¯€æ€§åˆ†æ"""
        if len(data) < 7:
            return {'strength': 0.0, 'dominant_pattern': 'none'}
        
        # æ›œæ—¥åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¼·åº¦è¨ˆç®—
        daily_patterns = self._extract_daily_patterns(data)
        
        if len(daily_patterns) < 2:
            return {'strength': 0.0, 'dominant_pattern': 'none'}
        
        daily_averages = [pattern['average'] for pattern in daily_patterns.values()]
        overall_average = sum(daily_averages) / len(daily_averages)
        
        # å­£ç¯€æ€§å¼·åº¦ï¼ˆæ¨™æº–åå·®ãƒ™ãƒ¼ã‚¹ï¼‰
        variance = sum((avg - overall_average) ** 2 for avg in daily_averages) / len(daily_averages)
        strength = min(1.0, math.sqrt(variance) / overall_average) if overall_average > 0 else 0
        
        # ä¸»è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ç‰¹å®š
        max_day = max(daily_patterns.keys(), key=lambda k: daily_patterns[k]['average'])
        min_day = min(daily_patterns.keys(), key=lambda k: daily_patterns[k]['average'])
        
        return {
            'strength': strength,
            'dominant_pattern': 'weekly',
            'peak_day': max_day,
            'low_day': min_day,
            'daily_patterns': daily_patterns
        }
    
    def _analyze_cyclical_patterns(self, data: List[Dict]) -> Dict:
        """å‘¨æœŸæ€§åˆ†æ"""
        if len(data) < 24:
            return {'strength': 0.0, 'cycle_length': 24}
        
        # æ™‚é–“åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‘¨æœŸæ€§åˆ†æ
        hourly_patterns = self._extract_hourly_patterns(data)
        
        if len(hourly_patterns) < 2:
            return {'strength': 0.0, 'cycle_length': 24}
        
        hourly_averages = [hourly_patterns.get(h, {'average': 0})['average'] for h in range(24)]
        overall_average = sum(hourly_averages) / len(hourly_averages)
        
        # å‘¨æœŸæ€§å¼·åº¦è¨ˆç®—
        variance = sum((avg - overall_average) ** 2 for avg in hourly_averages) / len(hourly_averages)
        strength = min(1.0, math.sqrt(variance) / overall_average) if overall_average > 0 else 0
        
        # ãƒ”ãƒ¼ã‚¯æ™‚é–“ç‰¹å®š
        peak_hour = hourly_averages.index(max(hourly_averages))
        low_hour = hourly_averages.index(min(hourly_averages))
        
        return {
            'strength': strength,
            'cycle_length': 24,
            'peak_hour': peak_hour,
            'low_hour': low_hour,
            'hourly_patterns': hourly_patterns
        }
    
    def _update_model_parameters(self, trend_analysis: Dict, seasonal_analysis: Dict, cyclical_analysis: Dict):
        """ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°"""
        # åˆ†æçµæœã«åŸºã¥ãé‡ã¿èª¿æ•´
        total_strength = trend_analysis['strength'] + seasonal_analysis['strength'] + cyclical_analysis['strength']
        
        if total_strength > 0:
            self.model_params['trend_weight'] = trend_analysis['strength'] / total_strength * 0.8
            self.model_params['seasonal_weight'] = seasonal_analysis['strength'] / total_strength * 0.8
            self.model_params['cyclical_weight'] = cyclical_analysis['strength'] / total_strength * 0.8
            self.model_params['noise_weight'] = 1.0 - (self.model_params['trend_weight'] + 
                                                       self.model_params['seasonal_weight'] + 
                                                       self.model_params['cyclical_weight'])
    
    def _calculate_model_accuracy(self, data: List[Dict]) -> float:
        """ãƒ¢ãƒ‡ãƒ«ç²¾åº¦è¨ˆç®—"""
        if len(data) < 10:
            return 85.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç²¾åº¦
        
        # å¾ŒåŠãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ç²¾åº¦ãƒ†ã‚¹ãƒˆ
        train_size = int(len(data) * 0.8)
        train_data = data[:train_size]
        test_data = data[train_size:]
        
        errors = []
        for item in test_data:
            # ç°¡æ˜“äºˆæ¸¬å®Ÿè¡Œ
            prediction_time = datetime.datetime.fromisoformat(item['timestamp'])
            predicted = self._calculate_base_demand(prediction_time)
            actual = item['demand']
            
            if actual > 0:
                error = abs(predicted - actual) / actual
                errors.append(error)
        
        if not errors:
            return 85.0
        
        mean_error = sum(errors) / len(errors)
        accuracy = max(0, min(100, (1 - mean_error) * 100))
        
        return accuracy
    
    def _calculate_base_demand(self, prediction_time: datetime.datetime) -> float:
        """åŸºæœ¬éœ€è¦é‡è¨ˆç®—"""
        # åŸºæº–éœ€è¦é‡
        base = 100.0
        
        # æ›œæ—¥èª¿æ•´
        day_factor = self.day_patterns.get(prediction_time.weekday(), 1.0)
        
        # æ™‚é–“èª¿æ•´
        hour_factor = self.hour_patterns.get(prediction_time.hour, 1.0)
        
        return base * day_factor * hour_factor
    
    def _apply_trend_adjustment(self, base_demand: float, prediction_time: datetime.datetime) -> float:
        """ãƒˆãƒ¬ãƒ³ãƒ‰èª¿æ•´é©ç”¨"""
        # ç°¡æ˜“ãƒˆãƒ¬ãƒ³ãƒ‰èª¿æ•´ï¼ˆæ™‚é–“çµŒéã«å¿œã˜ãŸç·šå½¢èª¿æ•´ï¼‰
        days_from_base = (prediction_time - datetime.datetime(2025, 1, 1)).days
        trend_factor = 1.0 + (days_from_base * 0.001)  # 1æ—¥ã‚ãŸã‚Š0.1%ã®æˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰
        
        return base_demand * trend_factor
    
    def _apply_seasonal_adjustment(self, demand: float, prediction_time: datetime.datetime) -> float:
        """å­£ç¯€æ€§èª¿æ•´é©ç”¨"""
        # æœˆåˆ¥å­£ç¯€èª¿æ•´
        month_factors = {
            1: 0.9, 2: 0.9, 3: 1.0, 4: 1.1, 5: 1.1, 6: 1.2,
            7: 1.2, 8: 1.1, 9: 1.0, 10: 1.0, 11: 0.95, 12: 0.85
        }
        
        month_factor = month_factors.get(prediction_time.month, 1.0)
        return demand * month_factor
    
    def _apply_cyclical_adjustment(self, demand: float, prediction_time: datetime.datetime) -> float:
        """å‘¨æœŸæ€§èª¿æ•´é©ç”¨"""
        # é€±å†…ã‚µã‚¤ã‚¯ãƒ«èª¿æ•´ï¼ˆè¿½åŠ ã®å¾®èª¿æ•´ï¼‰
        week_progress = prediction_time.weekday() / 7.0
        cyclical_factor = 1.0 + 0.05 * math.sin(2 * math.pi * week_progress)
        
        return demand * cyclical_factor
    
    def _calculate_confidence_interval(self, predicted_demand: float) -> Tuple[float, float]:
        """ä¿¡é ¼åŒºé–“è¨ˆç®—"""
        # ç°¡æ˜“ä¿¡é ¼åŒºé–“ï¼ˆÂ±20%ï¼‰
        margin = predicted_demand * 0.2
        return (predicted_demand - margin, predicted_demand + margin)
    
    def _classify_demand_level(self, demand: float) -> str:
        """éœ€è¦ãƒ¬ãƒ™ãƒ«åˆ†é¡"""
        if demand >= 120:
            return 'high'
        elif demand >= 80:
            return 'medium'
        else:
            return 'low'
    
    def get_model_info(self) -> Dict:
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—"""
        return {
            'model_name': self.model_name,
            'version': self.version,
            'last_trained': self.last_trained.isoformat() if self.last_trained else None,
            'parameters': self.model_params,
            'capabilities': [
                'æ™‚é–“åˆ¥éœ€è¦äºˆæ¸¬',
                'æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ',
                'å­£ç¯€æ€§åˆ†æ',
                'ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ',
                'ä¿¡é ¼åŒºé–“è¨ˆç®—'
            ],
            'prediction_horizon': f"{self.model_params['prediction_horizon']}æ—¥",
            'confidence_level': f"{self.model_params['confidence_level']*100}%"
        }

# ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
def generate_sample_data(days: int = 30) -> List[Dict]:
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    sample_data = []
    start_date = datetime.datetime(2025, 1, 1)
    
    for day in range(days):
        current_date = start_date + datetime.timedelta(days=day)
        
        for hour in range(24):
            current_time = current_date + datetime.timedelta(hours=hour)
            
            # åŸºæœ¬éœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³
            base_demand = 80 + 20 * math.sin(2 * math.pi * hour / 24)  # æ—¥å†…å¤‰å‹•
            base_demand += 10 * math.sin(2 * math.pi * day / 7)        # é€±å†…å¤‰å‹•
            base_demand += 5 * math.sin(2 * math.pi * day / 30)        # æœˆå†…å¤‰å‹•
            
            # ãƒã‚¤ã‚ºè¿½åŠ 
            import random
            noise = random.uniform(-10, 10)
            final_demand = max(10, base_demand + noise)
            
            sample_data.append({
                'timestamp': current_time.isoformat(),
                'demand': round(final_demand, 1),
                'date': current_time.strftime('%Y-%m-%d'),
                'hour': hour,
                'day_of_week': current_time.weekday(),
                'month': current_time.month,
                'is_holiday': False,
                'weather_factor': random.uniform(0.8, 1.2),
                'special_events': []
            })
    
    return sample_data

if __name__ == "__main__":
    # éœ€è¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("ğŸ¤– éœ€è¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    model = DemandPredictionModel()
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    sample_data = generate_sample_data(30)
    print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(sample_data)}ä»¶")
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    print("\nğŸ¯ ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Ÿè¡Œ...")
    training_result = model.train_model(sample_data)
    
    if training_result['success']:
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«è¨“ç·´æˆåŠŸ!")
        print(f"   â€¢ ç²¾åº¦: {training_result['model_accuracy']:.2f}%")
        print(f"   â€¢ ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {training_result['data_points_used']}")
        print(f"   â€¢ ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦: {training_result['trend_strength']:.3f}")
        print(f"   â€¢ å­£ç¯€æ€§å¼·åº¦: {training_result['seasonal_strength']:.3f}")
        print(f"   â€¢ å‘¨æœŸæ€§å¼·åº¦: {training_result['cyclical_strength']:.3f}")
    else:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«è¨“ç·´å¤±æ•—: {training_result['error']}")
        exit(1)
    
    # éœ€è¦äºˆæ¸¬å®Ÿè¡Œ
    print("\nğŸ”® éœ€è¦äºˆæ¸¬å®Ÿè¡Œ...")
    prediction_result = model.predict_demand('2025-02-01', 48)  # 48æ™‚é–“äºˆæ¸¬
    
    if prediction_result['success']:
        print(f"âœ… éœ€è¦äºˆæ¸¬æˆåŠŸ!")
        summary = prediction_result['summary']
        print(f"   â€¢ äºˆæ¸¬æœŸé–“: {prediction_result['hours_predicted']}æ™‚é–“")
        print(f"   â€¢ å¹³å‡éœ€è¦: {summary['average_demand']}")
        print(f"   â€¢ ãƒ”ãƒ¼ã‚¯éœ€è¦: {summary['peak_demand']} ({summary['peak_time']})")
        print(f"   â€¢ æœ€å°éœ€è¦: {summary['min_demand']} ({summary['min_time']})")
        print(f"   â€¢ é«˜éœ€è¦æœŸé–“: {summary['high_demand_periods']}æ™‚é–“")
        print(f"   â€¢ ä¸­éœ€è¦æœŸé–“: {summary['medium_demand_periods']}æ™‚é–“")
        print(f"   â€¢ ä½éœ€è¦æœŸé–“: {summary['low_demand_periods']}æ™‚é–“")
        
        # æœ€åˆã®12æ™‚é–“ã®è©³ç´°äºˆæ¸¬è¡¨ç¤º
        print(f"\nğŸ“ˆ è©³ç´°äºˆæ¸¬çµæœï¼ˆæœ€åˆã®12æ™‚é–“ï¼‰:")
        for i, pred in enumerate(prediction_result['predictions'][:12]):
            time = datetime.datetime.fromisoformat(pred['timestamp'])
            print(f"   {time.strftime('%m/%d %H:%M')}: {pred['predicted_demand']:5.1f} ({pred['demand_level']}) "
                  f"[{pred['confidence_interval']['lower']:.1f}-{pred['confidence_interval']['upper']:.1f}]")
    else:
        print(f"âŒ éœ€è¦äºˆæ¸¬å¤±æ•—: {prediction_result['error']}")
    
    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
    print(f"\nğŸ“‹ ãƒ¢ãƒ‡ãƒ«æƒ…å ±:")
    model_info = model.get_model_info()
    print(f"   â€¢ ãƒ¢ãƒ‡ãƒ«å: {model_info['model_name']}")
    print(f"   â€¢ ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {model_info['version']}")
    print(f"   â€¢ äºˆæ¸¬æœŸé–“: {model_info['prediction_horizon']}")
    print(f"   â€¢ ä¿¡é ¼åº¦: {model_info['confidence_level']}")
    
    # çµæœä¿å­˜
    result_data = {
        'model_info': model_info,
        'training_result': training_result,
        'prediction_result': prediction_result,
        'test_timestamp': datetime.datetime.now().isoformat()
    }
    
    result_filename = f"demand_prediction_test_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    result_filepath = os.path.join(os.path.dirname(__file__), '..', '..', result_filename)
    
    with open(result_filepath, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ãƒ†ã‚¹ãƒˆçµæœä¿å­˜: {result_filename}")
    print("ğŸ‰ éœ€è¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«é–‹ç™ºå®Œäº†!")