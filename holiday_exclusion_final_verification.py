#!/usr/bin/env python3
"""
ä¼‘æ—¥é™¤å¤–å®Ÿè£…ã®æœ€çµ‚æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
============================

app.py ã®ä¿®æ­£å®Ÿè£…ã¨ dash_app.py ã®æ—¢å­˜ãƒ•ã‚£ãƒ«ã‚¿ãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.abspath('.'))

def check_data_consistency():
    """ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ã‚’ç¢ºèªã™ã‚‹"""
    print("=" * 60)
    print("ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯")
    print("=" * 60)
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
    test_files = [
        "ãƒ‡ã‚¤_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿_ä¼‘æ—¥ç²¾ç·».xlsx",
        "ã‚·ãƒ§ãƒ¼ãƒˆ_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿.xlsx",
    ]
    
    for test_file in test_files:
        if Path(test_file).exists():
            print(f"âœ… ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {test_file}")
            return test_file
    
    print("âŒ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return None

def analyze_excel_structure(excel_path: str):
    """Excelãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’åˆ†æ"""
    print(f"\nğŸ“Š Excelãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ åˆ†æ: {excel_path}")
    print("-" * 40)
    
    try:
        # å„ã‚·ãƒ¼ãƒˆã®å†…å®¹ã‚’ç¢ºèª
        xl = pd.ExcelFile(excel_path)
        print(f"ã‚·ãƒ¼ãƒˆæ•°: {len(xl.sheet_names)}")
        print(f"ã‚·ãƒ¼ãƒˆå: {xl.sheet_names}")
        
        # æœ€åˆã®ã‚·ãƒ¼ãƒˆã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º
        if xl.sheet_names:
            sample_df = pd.read_excel(excel_path, sheet_name=xl.sheet_names[0], nrows=10)
            print(f"\nã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ (æœ€åˆã®10è¡Œ):")
            print(sample_df.to_string())
            
            # ã‚¹ã‚¿ãƒƒãƒ•åã«ä¼‘æš‡ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãªã„ã‹ç¢ºèª
            if 'Båˆ—' in sample_df.columns or len(sample_df.columns) > 1:
                staff_col = sample_df.columns[1]  # é€šå¸¸Båˆ—ãŒã‚¹ã‚¿ãƒƒãƒ•å
                unique_values = sample_df[staff_col].dropna().unique()
                print(f"\n{staff_col}åˆ—ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ (æœ€åˆã®20å€‹):")
                for i, val in enumerate(unique_values[:20]):
                    print(f"  {i+1}. '{val}'")
                    
                # ä¼‘æš‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œç´¢
                rest_patterns = ['Ã—', 'X', 'x', 'ä¼‘', 'OFF', 'off', 'æœ‰', 'ç‰¹', 'ä»£', 'æŒ¯']
                found_patterns = []
                for pattern in rest_patterns:
                    matches = [val for val in unique_values if isinstance(val, str) and pattern in val]
                    if matches:
                        found_patterns.append((pattern, matches[:3]))  # æœ€åˆã®3ã¤ã‚’è¡¨ç¤º
                
                if found_patterns:
                    print(f"\nğŸ” ä¼‘æš‡ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º:")
                    for pattern, matches in found_patterns:
                        print(f"  '{pattern}': {matches}")
                else:
                    print(f"\nâœ… ä¼‘æš‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        return True
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def check_filter_implementations():
    """ãƒ•ã‚£ãƒ«ã‚¿å®Ÿè£…ã®ç¢ºèª"""
    print("\nğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿å®Ÿè£…ç¢ºèª")
    print("-" * 40)
    
    # 1. heatmap.py ã® _filter_work_records ç¢ºèª
    heatmap_path = Path("shift_suite/tasks/heatmap.py")
    if heatmap_path.exists():
        with open(heatmap_path, 'r', encoding='utf-8') as f:
            content = f.read()
            if '_filter_work_records' in content:
                print("âœ… heatmap.py: _filter_work_records é–¢æ•°ãŒå­˜åœ¨")
                if 'holiday_type.*é€šå¸¸å‹¤å‹™' in content or 'DEFAULT_HOLIDAY_TYPE' in content:
                    print("âœ… heatmap.py: holiday_type ã«ã‚ˆã‚‹ä¼‘æš‡é™¤å¤–ãŒå®Ÿè£…æ¸ˆã¿")
                if 'parsed_slots_count.*> 0' in content:
                    print("âœ… heatmap.py: parsed_slots_count ã«ã‚ˆã‚‹0ã‚¹ãƒ­ãƒƒãƒˆé™¤å¤–ãŒå®Ÿè£…æ¸ˆã¿")
            else:
                print("âŒ heatmap.py: _filter_work_records é–¢æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        print("âŒ heatmap.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # 2. utils.py ã® apply_rest_exclusion_filter ç¢ºèª
    utils_path = Path("shift_suite/tasks/utils.py")
    if utils_path.exists():
        with open(utils_path, 'r', encoding='utf-8') as f:
            content = f.read()
            if 'apply_rest_exclusion_filter' in content:
                print("âœ… utils.py: apply_rest_exclusion_filter é–¢æ•°ãŒå­˜åœ¨")
                if 'rest_patterns' in content:
                    print("âœ… utils.py: ä¼‘æš‡ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ãŒå®Ÿè£…æ¸ˆã¿")
            else:
                print("âŒ utils.py: apply_rest_exclusion_filter é–¢æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        print("âŒ utils.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # 3. app.py ã®ä¿®æ­£ç¢ºèª
    app_path = Path("app.py")
    if app_path.exists():
        with open(app_path, 'r', encoding='utf-8') as f:
            content = f.read()
            if 'working_long_df' in content:
                print("âœ… app.py: working_long_df ã«ã‚ˆã‚‹äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãŒå®Ÿè£…æ¸ˆã¿")
                if 'holiday_type.*é€šå¸¸å‹¤å‹™' in content:
                    print("âœ… app.py: holiday_type é™¤å¤–ãŒå®Ÿè£…æ¸ˆã¿")
                if 'parsed_slots_count.*> 0' in content:
                    print("âœ… app.py: parsed_slots_count é™¤å¤–ãŒå®Ÿè£…æ¸ˆã¿")
            else:
                print("âŒ app.py: working_long_df ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        print("âŒ app.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # 4. dash_app.py ã®ç¢ºèª
    dash_path = Path("dash_app.py")
    if dash_path.exists():
        with open(dash_path, 'r', encoding='utf-8') as f:
            content = f.read()
            if 'pre_aggregated_data.*apply_rest_exclusion_filter' in content:
                print("âœ… dash_app.py: pre_aggregated_data ã« apply_rest_exclusion_filter ãŒé©ç”¨æ¸ˆã¿")
            elif "key in ['pre_aggregated_data'" in content:
                print("âœ… dash_app.py: data_get() ã§ pre_aggregated_data ã« ãƒ•ã‚£ãƒ«ã‚¿ãŒé©ç”¨ã•ã‚Œã‚‹")
            else:
                print("âŒ dash_app.py: pre_aggregated_data ã®ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        print("âŒ dash_app.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

def check_existing_analysis_results():
    """æ—¢å­˜ã®åˆ†æçµæœã‚’ç¢ºèª"""
    print("\nğŸ“‚ æ—¢å­˜åˆ†æçµæœç¢ºèª")
    print("-" * 40)
    
    # åˆ†æçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ã™
    analysis_dirs = []
    for item in Path('.').iterdir():
        if item.is_dir() and ('analysis' in item.name.lower() or 'results' in item.name.lower() or 'out_' in item.name):
            analysis_dirs.append(item)
    
    if not analysis_dirs:
        print("âŒ åˆ†æçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"âœ… åˆ†æçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {len(analysis_dirs)}å€‹")
    for dir_path in analysis_dirs[:5]:  # æœ€åˆã®5ã¤ã‚’è¡¨ç¤º
        print(f"  ğŸ“ {dir_path.name}")
        
        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        key_files = ['heat_ALL.parquet', 'pre_aggregated_data.parquet', 'intermediate_data.parquet']
        for key_file in key_files:
            file_path = dir_path / key_file
            if file_path.exists():
                print(f"    âœ… {key_file}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚‚ç¢ºèª
                try:
                    df = pd.read_parquet(file_path)
                    print(f"      ğŸ“Š Shape: {df.shape}")
                    
                    if key_file == 'pre_aggregated_data.parquet':
                        # staff_count ã®åˆ†å¸ƒã‚’ç¢ºèª
                        if 'staff_count' in df.columns:
                            non_zero = (df['staff_count'] > 0).sum()
                            total = len(df)
                            print(f"      ğŸ‘¥ éã‚¼ãƒ­ãƒ¬ã‚³ãƒ¼ãƒ‰: {non_zero}/{total} ({non_zero/total:.1%})")
                            
                            # æ—¥åˆ¥ã‚µãƒãƒªãƒ¼
                            if 'date_lbl' in df.columns:
                                daily_totals = df.groupby('date_lbl')['staff_count'].sum()
                                working_days = (daily_totals > 0).sum()
                                print(f"      ğŸ“… ç¨¼åƒæ—¥: {working_days}/{len(daily_totals)}")
                    
                except Exception as e:
                    print(f"      âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                print(f"    âŒ {key_file} (ãªã—)")

def generate_validation_report():
    """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    print("\nğŸ“‹ æ¤œè¨¼ã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    
    # å®Ÿè£…çŠ¶æ³ã®è©•ä¾¡
    implementation_score = 0
    total_checks = 6
    
    checks = [
        ("heatmap.py _filter_work_records", Path("shift_suite/tasks/heatmap.py").exists()),
        ("utils.py apply_rest_exclusion_filter", Path("shift_suite/tasks/utils.py").exists()),
        ("app.py working_long_df", Path("app.py").exists()),
        ("dash_app.py data_get ãƒ•ã‚£ãƒ«ã‚¿", Path("dash_app.py").exists()),
        ("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨", any(Path(f).exists() for f in ["ãƒ‡ã‚¤_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿_ä¼‘æ—¥ç²¾ç·».xlsx", "ã‚·ãƒ§ãƒ¼ãƒˆ_ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿.xlsx"])),
        ("åˆ†æçµæœã®å­˜åœ¨", any(Path('.').glob('*analysis*')) or any(Path('.').glob('out_*')))
    ]
    
    for check_name, passed in checks:
        if passed:
            print(f"âœ… {check_name}")
            implementation_score += 1
        else:
            print(f"âŒ {check_name}")
    
    print(f"\nğŸ¯ å®Ÿè£…å®Œæˆåº¦: {implementation_score}/{total_checks} ({implementation_score/total_checks:.1%})")
    
    # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    print(f"\nğŸš€ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
    if implementation_score >= 5:
        print("  1. å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§app.pyã‚’å®Ÿè¡Œã—ã¦æ¤œè¨¼")
        print("  2. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ (dash_app.py) ã§çµæœã‚’ç¢ºèª")
        print("  3. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã§é™¤å¤–å‡¦ç†ã®å®Ÿè¡Œã‚’ç¢ºèª")
    elif implementation_score >= 3:
        print("  1. ä¸è¶³ã—ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª")
        print("  2. åŸºæœ¬çš„ãªå‹•ä½œãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ")
    else:
        print("  1. ã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‹ã‚‰ç¢ºèª")
        print("  2. å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å¾©å…ƒ")
    
    # ãƒ†ã‚¹ãƒˆæ‰‹é †
    print(f"\nğŸ§ª ãƒ†ã‚¹ãƒˆæ‰‹é †:")
    print("  1. ãƒ†ã‚¹ãƒˆExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™")
    print("  2. Streamlit app.py ã‚’å®Ÿè¡Œ")
    print("  3. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ä¼‘æ—¥ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºçŠ¶æ³ã‚’ç¢ºèª")
    print("  4. shift_suite.log ã§é™¤å¤–å‡¦ç†ã®å®Ÿè¡Œã‚’ç¢ºèª")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ” shift_suite ä¼‘æ—¥é™¤å¤–å®Ÿè£… - æœ€çµ‚æ¤œè¨¼")
    print("=" * 60)
    
    # 1. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç¢ºèª
    test_file = check_data_consistency()
    if test_file:
        analyze_excel_structure(test_file)
    
    # 2. å®Ÿè£…ç¢ºèª
    check_filter_implementations()
    
    # 3. æ—¢å­˜çµæœç¢ºèª
    check_existing_analysis_results()
    
    # 4. æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ
    generate_validation_report()
    
    print(f"\nğŸ‰ æ¤œè¨¼å®Œäº†!")
    print("è©³ç´°ãªå•é¡Œèª¿æŸ»ãŒå¿…è¦ãªå ´åˆã¯ holiday_exclusion_investigation_summary.md ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()