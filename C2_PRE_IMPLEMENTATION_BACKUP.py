"""
C2å®Ÿè£…å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚·ã‚¹ãƒ†ãƒ 
å®‰å…¨æ€§åˆ†æçµæœï¼ˆ100/100ï¼‰ã‚’å—ã‘ã¦ã€æ…é‡ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥ã‚’å®Ÿè¡Œ
"""

import os
import shutil
import json
import hashlib
from datetime import datetime
from pathlib import Path
import zipfile
import tempfile

class C2PreImplementationBackup:
    """C2å®Ÿè£…å‰å°‚ç”¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.base_path = "/mnt/c/Users/fuji1/OneDrive/ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/ã‚·ãƒ•ãƒˆåˆ†æ"
        self.backup_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.backup_dir = f"C2_PRE_IMPLEMENTATION_BACKUP_{self.backup_timestamp}"
        self.backup_full_path = os.path.join(self.base_path, self.backup_dir)
        
        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå®‰å…¨æ€§åˆ†æã§ç¢ºèªæ¸ˆã¿ï¼‰
        self.critical_files = [
            "app.py",
            "dash_app.py",
            "shift_suite/__init__.py",
            "shift_suite/tasks/utils.py", 
            "shift_suite/tasks/shortage.py",
            "shift_suite/tasks/fact_extractor_prototype.py",  # Phase 2
            "shift_suite/tasks/lightweight_anomaly_detector.py"  # Phase 3.1
        ]
        
        # ãƒ¢ãƒã‚¤ãƒ«é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ—¢å­˜å®Ÿè£…ä¿è­·ï¼‰
        self.mobile_files = [
            "dash_components/visualization_engine.py",
            "improved_ui_components.py",
            "dash_app_backup.py"
        ]
        
        # è¨­å®šãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
        self.config_files = [
            "requirements.txt",
            "shift_suite/config.json"
        ]
        
        # æœ€è¿‘ã®å®Ÿè£…æˆæœç‰©
        self.recent_implementations = [
            "C1_FEATURE_EXPANSION_LITE.py",
            "C1_implementation_summary.json",
            "C2_SAFETY_ANALYSIS.py",
            "C2_safety_analysis_report_20250803_223812.json"
        ]
        
    def create_comprehensive_backup(self):
        """åŒ…æ‹¬çš„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        print(f"ğŸ›¡ï¸ C2å®Ÿè£…å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹...")
        print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å…ˆ: {self.backup_dir}")
        
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            os.makedirs(self.backup_full_path, exist_ok=True)
            
            backup_report = {
                'timestamp': datetime.now().isoformat(),
                'backup_type': 'c2_pre_implementation',
                'backup_directory': self.backup_dir,
                'safety_analysis_passed': True,
                'safety_score': 100,
                'files_backed_up': {},
                'verification': {},
                'summary': {}
            }
            
            # 1. é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            print("\\nğŸ“‹ é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—...")
            critical_results = self._backup_critical_files()
            backup_report['files_backed_up']['critical'] = critical_results
            
            # 2. ãƒ¢ãƒã‚¤ãƒ«é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            print("\\nğŸ“± ãƒ¢ãƒã‚¤ãƒ«é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—...")
            mobile_results = self._backup_mobile_files()
            backup_report['files_backed_up']['mobile'] = mobile_results
            
            # 3. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            print("\\nâš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—...")
            config_results = self._backup_config_files()
            backup_report['files_backed_up']['config'] = config_results
            
            # 4. æœ€è¿‘ã®å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            print("\\nğŸš€ æœ€è¿‘å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—...")
            recent_results = self._backup_recent_implementations()
            backup_report['files_backed_up']['recent'] = recent_results
            
            # 5. shift_suiteãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå…¨ä½“ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            print("\\nğŸ“¦ shift_suiteãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—...")
            suite_results = self._backup_shift_suite_directory()
            backup_report['files_backed_up']['shift_suite'] = suite_results
            
            # 6. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼
            print("\\nâœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼...")
            verification_results = self._verify_backup()
            backup_report['verification'] = verification_results
            
            # 7. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µãƒãƒªãƒ¼
            backup_report['summary'] = self._generate_backup_summary(backup_report)
            
            # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
            report_file = os.path.join(self.backup_full_path, 'backup_report.json')
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(backup_report, f, ensure_ascii=False, indent=2)
            
            # åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆ
            print("\\nğŸ“¦ åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆ...")
            archive_path = self._create_compressed_archive()
            backup_report['archive_path'] = archive_path
            
            print(f"\\nğŸ¯ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†!")
            print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å ´æ‰€: {self.backup_full_path}")
            print(f"ğŸ“¦ åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {archive_path}")
            print(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
            
            return backup_report
            
        except Exception as e:
            error_report = {
                'timestamp': datetime.now().isoformat(),
                'backup_type': 'c2_pre_implementation_error',
                'error': str(e),
                'status': 'failed'
            }
            print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return error_report
    
    def _backup_critical_files(self):
        """é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        results = {}
        critical_dir = os.path.join(self.backup_full_path, 'critical_files')
        os.makedirs(critical_dir, exist_ok=True)
        
        for file_path in self.critical_files:
            source_path = os.path.join(self.base_path, file_path)
            
            if os.path.exists(source_path):
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä¿æŒã—ã¦ã‚³ãƒ”ãƒ¼
                dest_path = os.path.join(critical_dir, file_path)
                dest_dir = os.path.dirname(dest_path)
                os.makedirs(dest_dir, exist_ok=True)
                
                shutil.copy2(source_path, dest_path)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
                file_hash = self._calculate_file_hash(source_path)
                file_size = os.path.getsize(source_path)
                
                results[file_path] = {
                    'status': 'backed_up',
                    'source_size': file_size,
                    'hash': file_hash,
                    'backup_path': dest_path
                }
                
                print(f"  âœ… {file_path} ({file_size} bytes)")
            else:
                results[file_path] = {
                    'status': 'not_found',
                    'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“'
                }
                print(f"  âŒ {file_path} (è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
        
        return results
    
    def _backup_mobile_files(self):
        """ãƒ¢ãƒã‚¤ãƒ«é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        results = {}
        mobile_dir = os.path.join(self.backup_full_path, 'mobile_files')
        os.makedirs(mobile_dir, exist_ok=True)
        
        for file_path in self.mobile_files:
            source_path = os.path.join(self.base_path, file_path)
            
            if os.path.exists(source_path):
                dest_path = os.path.join(mobile_dir, file_path)
                dest_dir = os.path.dirname(dest_path)
                os.makedirs(dest_dir, exist_ok=True)
                
                shutil.copy2(source_path, dest_path)
                
                file_hash = self._calculate_file_hash(source_path)
                file_size = os.path.getsize(source_path)
                
                results[file_path] = {
                    'status': 'backed_up',
                    'source_size': file_size,
                    'hash': file_hash,
                    'backup_path': dest_path
                }
                
                print(f"  âœ… {file_path} ({file_size} bytes)")
            else:
                results[file_path] = {
                    'status': 'not_found',
                    'note': 'ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå­˜åœ¨ã—ãªãã¦ã‚‚å•é¡Œãªã—ï¼‰'
                }
                print(f"  âšª {file_path} (ã‚ªãƒ—ã‚·ãƒ§ãƒ³ - å­˜åœ¨ã›ãš)")
        
        return results
    
    def _backup_config_files(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        results = {}
        config_dir = os.path.join(self.backup_full_path, 'config_files')
        os.makedirs(config_dir, exist_ok=True)
        
        for file_path in self.config_files:
            source_path = os.path.join(self.base_path, file_path)
            
            if os.path.exists(source_path):
                dest_path = os.path.join(config_dir, os.path.basename(file_path))
                shutil.copy2(source_path, dest_path)
                
                file_hash = self._calculate_file_hash(source_path)
                file_size = os.path.getsize(source_path)
                
                results[file_path] = {
                    'status': 'backed_up',
                    'source_size': file_size,
                    'hash': file_hash,
                    'backup_path': dest_path
                }
                
                print(f"  âœ… {file_path} ({file_size} bytes)")
        
        return results
    
    def _backup_recent_implementations(self):
        """æœ€è¿‘ã®å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        results = {}
        recent_dir = os.path.join(self.backup_full_path, 'recent_implementations')
        os.makedirs(recent_dir, exist_ok=True)
        
        for file_path in self.recent_implementations:
            source_path = os.path.join(self.base_path, file_path)
            
            if os.path.exists(source_path):
                dest_path = os.path.join(recent_dir, os.path.basename(file_path))
                shutil.copy2(source_path, dest_path)
                
                file_hash = self._calculate_file_hash(source_path)
                file_size = os.path.getsize(source_path)
                
                results[file_path] = {
                    'status': 'backed_up',
                    'source_size': file_size,
                    'hash': file_hash,
                    'backup_path': dest_path
                }
                
                print(f"  âœ… {file_path} ({file_size} bytes)")
        
        return results
    
    def _backup_shift_suite_directory(self):
        """shift_suiteãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        source_dir = os.path.join(self.base_path, 'shift_suite')
        dest_dir = os.path.join(self.backup_full_path, 'shift_suite_complete')
        
        if os.path.exists(source_dir):
            shutil.copytree(source_dir, dest_dir, ignore=shutil.ignore_patterns('__pycache__', '*.pyc'))
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚ºè¨ˆç®—
            total_size = sum(
                os.path.getsize(os.path.join(dirpath, filename))
                for dirpath, dirnames, filenames in os.walk(dest_dir)
                for filename in filenames
            )
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚«ã‚¦ãƒ³ãƒˆ
            file_count = sum(
                len(filenames)
                for dirpath, dirnames, filenames in os.walk(dest_dir)
            )
            
            print(f"  âœ… shift_suiteãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— ({file_count}ãƒ•ã‚¡ã‚¤ãƒ«, {total_size} bytes)")
            
            return {
                'status': 'backed_up',
                'total_size': total_size,
                'file_count': file_count,
                'backup_path': dest_dir
            }
        else:
            print(f"  âŒ shift_suiteãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {
                'status': 'not_found',
                'error': 'shift_suiteãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“'
            }
    
    def _verify_backup(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼"""
        verification = {
            'critical_files_verified': 0,
            'hash_mismatches': [],
            'missing_backups': [],
            'verification_passed': True
        }
        
        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
        for file_path in self.critical_files:
            source_path = os.path.join(self.base_path, file_path)
            backup_path = os.path.join(self.backup_full_path, 'critical_files', file_path)
            
            if os.path.exists(source_path) and os.path.exists(backup_path):
                source_hash = self._calculate_file_hash(source_path)
                backup_hash = self._calculate_file_hash(backup_path)
                
                if source_hash == backup_hash:
                    verification['critical_files_verified'] += 1
                    print(f"  âœ… {file_path} æ¤œè¨¼æˆåŠŸ")
                else:
                    verification['hash_mismatches'].append(file_path)
                    verification['verification_passed'] = False
                    print(f"  âŒ {file_path} ãƒãƒƒã‚·ãƒ¥ä¸ä¸€è‡´")
            elif os.path.exists(source_path):
                verification['missing_backups'].append(file_path)
                verification['verification_passed'] = False
                print(f"  âŒ {file_path} ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¬ æ")
        
        return verification
    
    def _calculate_file_hash(self, file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        hash_sha256 = hashlib.sha256()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_sha256.update(chunk)
        return hash_sha256.hexdigest()
    
    def _generate_backup_summary(self, backup_report):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        files_backed_up = backup_report['files_backed_up']
        
        total_files = 0
        total_size = 0
        successful_backups = 0
        
        for category, files in files_backed_up.items():
            if isinstance(files, dict):
                if category == 'shift_suite':
                    if files.get('status') == 'backed_up':
                        total_files += files.get('file_count', 0)
                        total_size += files.get('total_size', 0)
                        successful_backups += 1
                else:
                    for file_path, file_info in files.items():
                        total_files += 1
                        if file_info.get('status') == 'backed_up':
                            total_size += file_info.get('source_size', 0)
                            successful_backups += 1
        
        verification = backup_report.get('verification', {})
        
        return {
            'total_files_attempted': total_files,
            'successful_backups': successful_backups,
            'total_backup_size': total_size,
            'verification_passed': verification.get('verification_passed', False),
            'critical_files_verified': verification.get('critical_files_verified', 0),
            'backup_integrity': 'excellent' if verification.get('verification_passed') else 'warning'
        }
    
    def _create_compressed_archive(self):
        """åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆ"""
        archive_name = f"{self.backup_dir}.zip"
        archive_path = os.path.join(self.base_path, archive_name)
        
        with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(self.backup_full_path):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, self.backup_full_path)
                    zipf.write(file_path, arcname)
        
        archive_size = os.path.getsize(archive_path)
        print(f"  âœ… åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆå®Œäº† ({archive_size} bytes)")
        
        return archive_path

def main():
    """C2å®Ÿè£…å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ›¡ï¸ C2å®Ÿè£…å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹...")
    print("ğŸ“Š å®‰å…¨æ€§åˆ†æçµæœ: 100/100 - å®Ÿè£…æº–å‚™è‰¯å¥½")
    
    backup_system = C2PreImplementationBackup()
    result = backup_system.create_comprehensive_backup()
    
    if 'error' in result:
        print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—: {result['error']}")
        return result
    
    # æˆåŠŸã‚µãƒãƒªãƒ¼è¡¨ç¤º
    summary = result.get('summary', {})
    
    print(f"\\nğŸ“Š ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µãƒãƒªãƒ¼:")
    print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«: {summary.get('successful_backups', 0)}ä»¶")
    print(f"ğŸ“¦ ç·ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚º: {summary.get('total_backup_size', 0):,} bytes")
    print(f"âœ… æ¤œè¨¼çµæœ: {summary.get('backup_integrity', 'unknown')}")
    print(f"ğŸ”’ é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼: {summary.get('critical_files_verified', 0)}ä»¶æˆåŠŸ")
    
    verification = result.get('verification', {})
    if verification.get('verification_passed'):
        print(f"\\nğŸ¯ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼æˆåŠŸ - C2å®Ÿè£…æº–å‚™å®Œäº†")
    else:
        print(f"\\nâš ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼ã«è­¦å‘Šã‚ã‚Š - æ…é‡ã«é€²è¡Œ")
    
    print(f"\\nğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"  1. C2.3 æ®µéšçš„å®Ÿè£…è¨ˆç”»ç­–å®š")
    print(f"  2. C2.4 ãƒ¢ãƒã‚¤ãƒ«UI/UXæ”¹å–„å®Ÿè£…")
    print(f"  3. C2.5 ç·åˆãƒ†ã‚¹ãƒˆãƒ»æ¤œè¨¼")
    
    return result

if __name__ == "__main__":
    result = main()