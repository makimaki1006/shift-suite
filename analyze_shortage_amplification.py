#!/usr/bin/env python3
"""
ä¸è¶³æ™‚é–“ã®ç•°å¸¸æ”¾å¤§ï¼ˆ8.6æ™‚é–“/æ—¥ï¼‰ã®æ ¹æœ¬åŸå› åˆ†æ
27,486.5æ™‚é–“å•é¡Œã®çœŸã®è§£æ±ºã«å‘ã‘ãŸå¾¹åº•èª¿æŸ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import pandas as pd
import numpy as np
from pathlib import Path
import json
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
log = logging.getLogger(__name__)

def analyze_shortage_calculation_amplification():
    """ä¸è¶³æ™‚é–“è¨ˆç®—ã®ç•°å¸¸æ”¾å¤§ã‚’è©³ç´°åˆ†æ"""
    
    print("=" * 80)
    print("ğŸ” ä¸è¶³æ™‚é–“ç•°å¸¸æ”¾å¤§ï¼ˆ8.6æ™‚é–“/æ—¥ï¼‰ã®æ ¹æœ¬åŸå› åˆ†æ")
    print("=" * 80)
    
    # åˆ†æå¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
    analysis_dirs = [
        "./extracted_test/out_median_based",
        "./extracted_test/out_mean_based", 
        "./extracted_test/out_p25_based",
        "./temp_analysis_check/out_median_based"
    ]
    
    results = {}
    
    for dir_path in analysis_dirs:
        dir_path = Path(dir_path)
        if not dir_path.exists():
            continue
            
        print(f"\nğŸ“ åˆ†æå¯¾è±¡: {dir_path}")
        
        try:
            # 1. shortage_time.parquet ã®è©³ç´°åˆ†æ
            shortage_file = dir_path / "shortage_time.parquet"
            need_file = dir_path / "need_per_date_slot.parquet"
            heat_all_file = dir_path / "heat_ALL.parquet"
            meta_file = dir_path / "heatmap.meta.json"
            
            analysis_result = {
                'directory': str(dir_path),
                'files_found': {},
                'shortage_analysis': {},
                'need_analysis': {},
                'amplification_factors': {},
                'root_causes': []
            }
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            for file_name, file_path in [
                ('shortage_time', shortage_file),
                ('need_per_date_slot', need_file),
                ('heat_ALL', heat_all_file),
                ('meta', meta_file)
            ]:
                analysis_result['files_found'][file_name] = file_path.exists()
                if file_path.exists():
                    print(f"  âœ“ {file_name}: å­˜åœ¨")
                else:
                    print(f"  âœ— {file_name}: ä¸å­˜åœ¨")
            
            # 2. shortage_time.parquet ã®è©³ç´°åˆ†æ
            if shortage_file.exists():
                shortage_df = pd.read_parquet(shortage_file)
                print(f"\n  ğŸ“Š Shortage Time åˆ†æ:")
                print(f"    å½¢çŠ¶: {shortage_df.shape} (æ™‚é–“å¸¯ Ã— æ—¥ä»˜)")
                
                # çµ±è¨ˆå€¤è¨ˆç®—
                total_shortage_slots = shortage_df.sum().sum()
                period_days = len(shortage_df.columns)
                time_slots = len(shortage_df.index)
                
                # ã‚¹ãƒ­ãƒƒãƒˆæ™‚é–“ã‚’æ¨å®šï¼ˆé€šå¸¸ã¯30åˆ†=0.5æ™‚é–“ï¼‰
                slot_hours = 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                
                total_shortage_hours = total_shortage_slots * slot_hours
                avg_shortage_per_day = total_shortage_hours / max(period_days, 1)
                
                print(f"    æœŸé–“: {period_days}æ—¥")
                print(f"    æ™‚é–“å¸¯æ•°: {time_slots}")
                print(f"    ç·ä¸è¶³ã‚¹ãƒ­ãƒƒãƒˆæ•°: {total_shortage_slots:.1f}")
                print(f"    ç·ä¸è¶³æ™‚é–“: {total_shortage_hours:.1f}æ™‚é–“")
                print(f"    1æ—¥å¹³å‡ä¸è¶³: {avg_shortage_per_day:.2f}æ™‚é–“/æ—¥")
                
                # ğŸ¯ ç•°å¸¸å€¤æ¤œå‡º
                if avg_shortage_per_day > 5:
                    print(f"    âš ï¸ ç•°å¸¸: 1æ—¥{avg_shortage_per_day:.1f}æ™‚é–“ã¯éå¤§ï¼ˆæ­£å¸¸: 1-3æ™‚é–“/æ—¥ï¼‰")
                    analysis_result['root_causes'].append(f"Daily average {avg_shortage_per_day:.1f}h exceeds normal range")
                
                # æ—¥åˆ¥ãƒ»æ™‚é–“å¸¯åˆ¥ã®è©³ç´°åˆ†æ
                daily_shortage = shortage_df.sum(axis=0)  # æ—¥åˆ¥åˆè¨ˆ
                hourly_shortage = shortage_df.sum(axis=1)  # æ™‚é–“å¸¯åˆ¥åˆè¨ˆ
                
                print(f"    æ—¥åˆ¥ä¸è¶³ - æœ€å¤§: {daily_shortage.max():.1f}ã‚¹ãƒ­ãƒƒãƒˆ, æœ€å°: {daily_shortage.min():.1f}ã‚¹ãƒ­ãƒƒãƒˆ")
                print(f"    æ™‚é–“å¸¯åˆ¥ä¸è¶³ - æœ€å¤§: {hourly_shortage.max():.1f}ã‚¹ãƒ­ãƒƒãƒˆ")
                
                # æœ€ã‚‚ä¸è¶³ã®å¤šã„æ™‚é–“å¸¯TOP5
                top_shortage_times = hourly_shortage.nlargest(5)
                print(f"    æœ€å¤§ä¸è¶³æ™‚é–“å¸¯TOP5:")
                for time_slot, shortage_count in top_shortage_times.items():
                    print(f"      {time_slot}: {shortage_count:.1f}ã‚¹ãƒ­ãƒƒãƒˆ ({shortage_count * slot_hours:.1f}æ™‚é–“)")
                
                analysis_result['shortage_analysis'] = {
                    'total_slots': float(total_shortage_slots),
                    'total_hours': float(total_shortage_hours),
                    'period_days': period_days,
                    'avg_per_day': float(avg_shortage_per_day),
                    'max_daily': float(daily_shortage.max()),
                    'min_daily': float(daily_shortage.min()),
                    'top_shortage_times': {str(k): float(v) for k, v in top_shortage_times.items()}
                }
            
            # 3. need_per_date_slot.parquet ã®è©³ç´°åˆ†æ
            if need_file.exists():
                need_df = pd.read_parquet(need_file)
                print(f"\n  ğŸ“ˆ Need Data åˆ†æ:")
                print(f"    å½¢çŠ¶: {need_df.shape}")
                
                total_need = need_df.sum().sum()
                max_need = need_df.max().max()
                mean_need = need_df.mean().mean()
                
                print(f"    ç·Needå€¤: {total_need:.1f}")
                print(f"    æœ€å¤§Needå€¤: {max_need:.1f}")
                print(f"    å¹³å‡Needå€¤: {mean_need:.2f}")
                
                # ğŸ¯ Needå€¤ã®ç•°å¸¸æ¤œå‡º
                if max_need > 10:
                    print(f"    âš ï¸ ç•°å¸¸: æœ€å¤§Needå€¤{max_need:.1f}ã¯éå¤§ï¼ˆæ­£å¸¸: 1-5äºº/ã‚¹ãƒ­ãƒƒãƒˆï¼‰")
                    analysis_result['root_causes'].append(f"Max Need value {max_need:.1f} exceeds normal range")
                
                if mean_need > 3:
                    print(f"    âš ï¸ ç•°å¸¸: å¹³å‡Needå€¤{mean_need:.2f}ã¯éå¤§ï¼ˆæ­£å¸¸: 0.5-2äºº/ã‚¹ãƒ­ãƒƒãƒˆï¼‰")
                    analysis_result['root_causes'].append(f"Mean Need value {mean_need:.2f} exceeds normal range")
                
                analysis_result['need_analysis'] = {
                    'total_need': float(total_need),
                    'max_need': float(max_need),
                    'mean_need': float(mean_need)
                }
            
            # 4. heat_ALL.parquet ã¨ã®æ¯”è¼ƒåˆ†æ
            if heat_all_file.exists():
                heat_all_df = pd.read_parquet(heat_all_file)
                print(f"\n  ğŸ”¥ Heat ALL åˆ†æ:")
                print(f"    å½¢çŠ¶: {heat_all_df.shape}")
                
                # å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
                date_columns = [col for col in heat_all_df.columns if pd.api.types.is_datetime64_any_dtype(pd.to_datetime(col, errors='coerce', infer_datetime_format=True))]
                if not date_columns:
                    # æ–‡å­—åˆ—ã®æ—¥ä»˜åˆ—ã‚’æ¢ã™
                    date_columns = [col for col in heat_all_df.columns if isinstance(col, str) and ('2024' in col or '2025' in col)]
                
                if date_columns:
                    actual_data = heat_all_df[date_columns]
                    total_actual = actual_data.sum().sum()
                    print(f"    ç·å®Ÿç¸¾å€¤: {total_actual:.1f}")
                    
                    # Need vs å®Ÿç¸¾ã®æ¯”è¼ƒ
                    if need_file.exists() and total_need > 0:
                        need_vs_actual_ratio = total_need / max(total_actual, 1)
                        print(f"    Need/å®Ÿç¸¾æ¯”ç‡: {need_vs_actual_ratio:.2f}")
                        
                        if need_vs_actual_ratio > 2.0:
                            print(f"    âš ï¸ ç•°å¸¸: Needå€¤ãŒå®Ÿç¸¾ã®{need_vs_actual_ratio:.1f}å€ï¼ˆæ­£å¸¸: 1.0-1.5å€ï¼‰")
                            analysis_result['root_causes'].append(f"Need/Actual ratio {need_vs_actual_ratio:.2f} is excessive")
                        
                        analysis_result['amplification_factors']['need_vs_actual_ratio'] = float(need_vs_actual_ratio)
            
            # 5. meta.json ã‹ã‚‰ã®çµ±è¨ˆæ‰‹æ³•ç¢ºèª
            if meta_file.exists():
                with open(meta_file, 'r', encoding='utf-8') as f:
                    meta_data = json.load(f)
                    
                print(f"\n  âš™ï¸ Meta Data åˆ†æ:")
                
                # çµ±è¨ˆæ‰‹æ³•ã®ç¢ºèª
                statistic_method = meta_data.get('statistic_method', 'Unknown')
                print(f"    çµ±è¨ˆæ‰‹æ³•: {statistic_method}")
                
                if '75ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«' in statistic_method or '90ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«' in statistic_method:
                    print(f"    âš ï¸ é«˜ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«æ¤œå‡º: {statistic_method}ãŒéœ€è¦ã‚’éå¤§è©•ä¾¡ã—ã¦ã„ã‚‹å¯èƒ½æ€§")
                    analysis_result['root_causes'].append(f"High percentile method '{statistic_method}' may inflate demand")
                
                # èª¿æ•´ä¿‚æ•°ã®ç¢ºèª
                adjustment_factor = meta_data.get('adjustment_factor', 1.0)
                if adjustment_factor > 1.2:
                    print(f"    âš ï¸ é«˜ã„èª¿æ•´ä¿‚æ•°: {adjustment_factor}")
                    analysis_result['root_causes'].append(f"High adjustment factor {adjustment_factor}")
                
                analysis_result['amplification_factors'].update({
                    'statistic_method': statistic_method,
                    'adjustment_factor': adjustment_factor
                })
            
            results[str(dir_path)] = analysis_result
            
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            results[str(dir_path)] = {'error': str(e)}
    
    # 6. å…¨ä½“ã‚µãƒãƒªãƒ¼ã¨æ ¹æœ¬åŸå› ã®ç‰¹å®š
    print(f"\n" + "=" * 80)
    print("ğŸ¯ æ ¹æœ¬åŸå› åˆ†æã‚µãƒãƒªãƒ¼")
    print("=" * 80)
    
    all_root_causes = []
    all_avg_shortages = []
    
    for dir_name, result in results.items():
        if 'error' in result:
            continue
            
        shortage_analysis = result.get('shortage_analysis', {})
        avg_shortage = shortage_analysis.get('avg_per_day', 0)
        
        if avg_shortage > 0:
            all_avg_shortages.append(avg_shortage)
            print(f"\nğŸ“Š {Path(dir_name).name}: {avg_shortage:.2f}æ™‚é–“/æ—¥")
            
            for cause in result.get('root_causes', []):
                all_root_causes.append(cause)
                print(f"  ğŸ” {cause}")
    
    # æœ€çµ‚åˆ¤å®š
    if all_avg_shortages:
        avg_of_avgs = np.mean(all_avg_shortages)
        print(f"\nğŸ” å…¨ä½“å¹³å‡ä¸è¶³æ™‚é–“: {avg_of_avgs:.2f}æ™‚é–“/æ—¥")
        
        if avg_of_avgs > 5:
            print(f"âŒ çµè«–: {avg_of_avgs:.1f}æ™‚é–“/æ—¥ã¯ä¾ç„¶ã¨ã—ã¦ç•°å¸¸ã«é«˜ã„")
            print("ğŸ¯ æ®‹å­˜ã™ã‚‹ä¸»ãªå•é¡Œ:")
            
            # æ ¹æœ¬åŸå› ã®åˆ†é¡
            cause_categories = {
                'statistical_amplification': [],
                'need_overestimation': [],
                'period_dependency': [],
                'calculation_error': []
            }
            
            for cause in set(all_root_causes):
                if 'percentile' in cause.lower() or 'adjustment' in cause.lower():
                    cause_categories['statistical_amplification'].append(cause)
                elif 'need' in cause.lower() and 'exceeds' in cause.lower():
                    cause_categories['need_overestimation'].append(cause)
                elif 'ratio' in cause.lower() and 'excessive' in cause.lower():
                    cause_categories['calculation_error'].append(cause)
                else:
                    cause_categories['period_dependency'].append(cause)
            
            for category, causes in cause_categories.items():
                if causes:
                    print(f"\n  ğŸ“‹ {category.replace('_', ' ').title()}:")
                    for cause in causes:
                        print(f"    â€¢ {cause}")
        else:
            print(f"âœ… çµè«–: {avg_of_avgs:.1f}æ™‚é–“/æ—¥ã¯è¨±å®¹ç¯„å›²å†…")
    
    # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_file = Path("shortage_amplification_analysis_results.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ’¾ è©³ç´°çµæœã‚’ä¿å­˜: {output_file}")
    
    return results

if __name__ == "__main__":
    analyze_shortage_calculation_amplification()