# dash_app.py - Shift-Suiteé«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢ (app.pyæ©Ÿèƒ½å®Œå…¨å†ç¾ç‰ˆ)
import base64
import io
import json
import logging
import tempfile
import zipfile
from functools import lru_cache
from pathlib import Path
from typing import Dict, List, Tuple
import unicodedata

import dash
import dash_cytoscape as cyto
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from dash import dash_table, dcc, html
from dash.dependencies import Input, Output, State, ALL
from dash.exceptions import PreventUpdate
from shift_suite.tasks.utils import safe_read_excel, gen_labels
from shift_suite.tasks.shortage_factor_analyzer import ShortageFactorAnalyzer
from shift_suite.tasks import over_shortage_log
from shift_suite.tasks.daily_cost import calculate_daily_cost
from shift_suite.tasks import leave_analyzer
from shift_suite.tasks.analyzers.synergy import analyze_synergy
from shift_suite.tasks.analyzers.team_dynamics import analyze_team_dynamics
from shift_suite.tasks.blueprint_analyzer import (
    create_scored_blueprint,
    analyze_tradeoffs,
)
from shift_suite.tasks.integrated_creation_logic_viewer import (
    create_creation_logic_analysis_tab,
)
from shift_suite.tasks.quick_logic_analysis import (
    get_basic_shift_stats,
    get_quick_patterns,
    run_optimized_analysis,
    create_stats_cards,
    create_pattern_list,
    create_deep_analysis_display,
)
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

# ãƒ­ã‚¬ãƒ¼è¨­å®š
LOG_LEVEL = logging.DEBUG
log_stream = io.StringIO()

logging.basicConfig(
    level=LOG_LEVEL,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.StreamHandler(stream=log_stream)
    ],
    force=True
)
log = logging.getLogger(__name__)

# Dashã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
app = dash.Dash(__name__, suppress_callback_exceptions=True)
server = app.server
app.title = "Shift-Suite é«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢"

# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹
# ``DATA_CACHE`` lazily holds loaded DataFrames for the active scenario.
DATA_CACHE: dict[str, object] = {}
# Path to the currently selected scenario directory.
CURRENT_SCENARIO_DIR: Path | None = None
# Temporary directory object for uploaded scenarios
TEMP_DIR_OBJ: tempfile.TemporaryDirectory | None = None

# ``LOGIC_ANALYSIS_CACHE`` stores results keyed by dataframe hash
LOGIC_ANALYSIS_CACHE: dict[int, dict[str, object]] = {}

def get_cached_analysis(df_hash: int):
    """Return cached analysis results for the given hash."""
    return LOGIC_ANALYSIS_CACHE.get(df_hash)


def cache_analysis(df_hash: int, results: dict) -> None:
    """Cache analysis results keeping at most 3 entries."""
    if len(LOGIC_ANALYSIS_CACHE) >= 3:
        oldest_key = next(iter(LOGIC_ANALYSIS_CACHE))
        del LOGIC_ANALYSIS_CACHE[oldest_key]
    LOGIC_ANALYSIS_CACHE[df_hash] = results

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
def safe_filename(name: str) -> str:
    """Normalize and sanitize strings for file keys"""
    name = unicodedata.normalize("NFKC", name)
    for ch in ["/", "\\", ":", "*", "?", "\"", "<", ">", "|", "ãƒ»", "ï¼", "ï¼¼"]:
        name = name.replace(ch, "_")
    return name

def date_with_weekday(date_str: str) -> str:
    """æ—¥ä»˜æ–‡å­—åˆ—ã«æ›œæ—¥ã‚’è¿½åŠ """
    try:  # noqa: E722
        date = pd.to_datetime(date_str)
        weekdays = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
        return f"{date.strftime('%m/%d')}({weekdays[date.weekday()]})"
    except Exception:
        return str(date_str)


@lru_cache(maxsize=8)
def safe_read_parquet(filepath: Path) -> pd.DataFrame:
    """Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã¿çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    try:
        return pd.read_parquet(filepath)  # type: ignore
    except Exception as e:
        log.warning(f"Failed to read {filepath}: {e}")
        return pd.DataFrame()


@lru_cache(maxsize=8)
def safe_read_csv(filepath: Path) -> pd.DataFrame:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã¿çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    try:
        return pd.read_csv(filepath)  # type: ignore
    except Exception as e:
        log.warning(f"Failed to read {filepath}: {e}")
        return pd.DataFrame()


def clear_data_cache() -> None:
    """Clear cached data when the scenario changes."""
    global DATA_CACHE
    DATA_CACHE.clear()
    safe_read_parquet.cache_clear()
    safe_read_csv.cache_clear()


def data_get(key: str, default=None):
    """Load a data asset lazily from the current scenario directory."""
    log.debug(f"data_get('{key}'): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¤œç´¢ä¸­...")
    if key in DATA_CACHE:
        log.debug(f"data_get('{key}'): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§ç™ºè¦‹ã€‚")
        return DATA_CACHE[key]

    log.debug(f"data_get('{key}'): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã€‚ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚’é–‹å§‹...")

    if CURRENT_SCENARIO_DIR is None:
        log.warning("CURRENT_SCENARIO_DIRãŒæœªè¨­å®šã®ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return default

    search_dirs = [CURRENT_SCENARIO_DIR, CURRENT_SCENARIO_DIR.parent]
    log.debug(f"Searching {search_dirs} for key {key}")

    # Special file names
    special = {
        "long_df": ["intermediate_data.parquet"],
        "daily_cost": ["daily_cost.parquet", "daily_cost.xlsx"],
    }

    filenames = special.get(key, [f"{key}.parquet", f"{key}.csv", f"{key}.xlsx"])

    for name in filenames:
        for directory in search_dirs:
            fp = directory / name
            log.debug(f"Checking {fp}")
            if fp.suffix == ".parquet" and fp.exists():
                df = safe_read_parquet(fp)
                if not df.empty:
                    DATA_CACHE[key] = df
                    log.debug(f"Loaded {fp} into cache for {key}")
                return DATA_CACHE.get(key, default)
            if fp.suffix == ".csv" and fp.exists():
                df = safe_read_csv(fp)
                if not df.empty:
                    DATA_CACHE[key] = df
                    log.debug(f"Loaded {fp} into cache for {key}")
                return DATA_CACHE.get(key, default)
            if fp.suffix == ".xlsx" and fp.exists():
                df = safe_read_excel(fp)
                if not df.empty:
                    DATA_CACHE[key] = df
                    log.debug(f"Loaded {fp} into cache for {key}")
                return DATA_CACHE.get(key, default)

    if key == "summary_report":
        files = sorted(CURRENT_SCENARIO_DIR.glob("OverShortage_SummaryReport_*.md"))
        if files:
            text = files[-1].read_text(encoding="utf-8")
            DATA_CACHE[key] = text
            log.debug(f"Loaded summary report {files[-1]}")
            return text
    if key in {"roles", "employments"}:
        roles, employments = load_shortage_meta(CURRENT_SCENARIO_DIR)
        DATA_CACHE["roles"] = roles
        DATA_CACHE["employments"] = employments
        return DATA_CACHE.get(key, default)

    if key == "shortage_events":
        df_events = over_shortage_log.list_events(CURRENT_SCENARIO_DIR)
        DATA_CACHE[key] = df_events
        DATA_CACHE["shortage_log_path"] = str(Path(CURRENT_SCENARIO_DIR) / "over_shortage_log.csv")
        return DATA_CACHE.get(key, default)

    log.debug(f"ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼ '{key}' ã«å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    DATA_CACHE[key] = default
    return default


def _valid_df(df: pd.DataFrame) -> bool:
    """Return True if ``df`` is a non-empty :class:`~pandas.DataFrame`."""
    return isinstance(df, pd.DataFrame) and not df.empty


def calc_ratio_from_heatmap(df: pd.DataFrame) -> pd.DataFrame:
    """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸è¶³ç‡ã‚’è¨ˆç®—"""
    if df.empty or "need" not in df.columns:
        return pd.DataFrame()

    date_cols = [c for c in df.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    if not date_cols:
        return pd.DataFrame()

    need_series = df["need"].fillna(0)
    need_df = pd.DataFrame(
        np.repeat(need_series.values[:, np.newaxis], len(date_cols), axis=1),
        index=need_series.index,
        columns=date_cols
    )
    staff_df = df[date_cols].fillna(0)
    ratio_df = ((need_df - staff_df) / need_df.replace(0, np.nan)).clip(lower=0).fillna(0)
    return ratio_df


def load_shortage_meta(data_dir: Path) -> Tuple[List[str], List[str]]:
    """è·ç¨®ã¨é›‡ç”¨å½¢æ…‹ã®ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    roles = []
    employments = []
    meta_fp = data_dir / "shortage.meta.json"
    if meta_fp.exists():
        try:
            with open(meta_fp, 'r', encoding='utf-8') as f:
                meta = json.load(f)
            roles = meta.get("roles", [])
            employments = meta.get("employments", [])
        except Exception as e:
            log.debug(f"Failed to load shortage meta: {e}")
    return roles, employments



def load_and_sum_heatmaps(data_dir: Path, keys: List[str]) -> pd.DataFrame:
    """Load multiple heatmap files and aggregate them."""
    dfs = []
    for key in keys:
        df = data_get(key)
        if df is None and data_dir:
            fp = Path(data_dir) / f"{key}.parquet"
            if fp.exists():
                df = safe_read_parquet(fp)
                if not df.empty:
                    DATA_CACHE[key] = df
        if isinstance(df, pd.DataFrame) and not df.empty:
            dfs.append(df)

    if not dfs:
        return pd.DataFrame()

    total = dfs[0].copy()
    for df in dfs[1:]:
        total = total.add(df, fill_value=0)

    if {"need", "staff"}.issubset(total.columns):
        total["lack"] = (total["need"] - total["staff"]).clip(lower=0)
    if {"staff", "upper"}.issubset(total.columns):
        total["excess"] = (total["staff"] - total["upper"]).clip(lower=0)

    return total


def generate_heatmap_figure(df_heat: pd.DataFrame, title: str) -> go.Figure:
    """æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã™ã‚‹"""
    if df_heat is None or df_heat.empty:
        return go.Figure().update_layout(title_text=f"{title}: ãƒ‡ãƒ¼ã‚¿ãªã—", height=300)

    date_cols = [c for c in df_heat.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    if not date_cols:
        return go.Figure().update_layout(title_text=f"{title}: è¡¨ç¤ºå¯èƒ½ãªæ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãªã—", height=300)

    display_df = df_heat[date_cols]
    time_labels = gen_labels(30)
    display_df = display_df.reindex(time_labels, fill_value=0)
    display_df_renamed = display_df.copy()
    display_df_renamed.columns = [date_with_weekday(c) for c in display_df.columns]

    fig = px.imshow(
        display_df_renamed,
        aspect='auto',
        color_continuous_scale=px.colors.sequential.Viridis,
        title=title,
        labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'}
    )
    fig.update_xaxes(tickvals=list(range(len(display_df.columns))))
    return fig


def create_knowledge_network_graph(network_data: Dict) -> cyto.Cytoscape:
    """Return an interactive network graph of implicit knowledge."""
    nodes = [
        {"data": {"id": n["id"], "label": n["label"]}}
        for n in network_data.get("nodes", [])
    ]
    edges = [
        {
            "data": {
                "source": e.get("from"),
                "target": e.get("to"),
                "label": e.get("label", ""),
            }
        }
        for e in network_data.get("edges", [])
    ]

    return cyto.Cytoscape(
        id="knowledge-network-graph",
        elements=nodes + edges,
        style={"width": "100%", "height": "500px"},
        layout={"name": "cose"},
        stylesheet=[
            {"selector": "node", "style": {"content": "data(label)", "font-size": "10px"}},
            {
                "selector": "edge",
                "style": {
                    "label": "data(label)",
                    "font-size": "8px",
                    "curve-style": "bezier",
                },
            },
        ],
    )

# --- UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç”Ÿæˆé–¢æ•° ---
def create_metric_card(label: str, value: str, color: str = "#1f77b4") -> html.Div:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆ"""
    return html.Div([
        html.Div(label, style={  # type: ignore
            'fontSize': '14px',
            'color': '#666',
            'marginBottom': '5px'
        }),
        html.Div(value, style={  # type: ignore
            'fontSize': '24px',
            'fontWeight': 'bold',
            'color': color
        })
    ], style={
        'padding': '15px',
        'backgroundColor': 'white',
        'borderRadius': '8px',
        'boxShadow': '0 2px 4px rgba(0,0,0,0.1)',
        'textAlign': 'center',
        'minHeight': '80px'
    })


def create_overview_tab() -> html.Div:
    """æ¦‚è¦ã‚¿ãƒ–ã‚’ä½œæˆ"""
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame())
    df_fairness = data_get('fairness_before', pd.DataFrame())
    df_staff = data_get('staff_stats', pd.DataFrame())
    df_alerts = data_get('stats_alerts', pd.DataFrame())

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    lack_h = df_shortage_role['lack_h'].sum() if 'lack_h' in df_shortage_role.columns else 0
    excess_cost = df_shortage_role['estimated_excess_cost'].sum() if 'estimated_excess_cost' in df_shortage_role.columns else 0
    lack_temp_cost = df_shortage_role['estimated_lack_cost_if_temporary_staff'].sum() if 'estimated_lack_cost_if_temporary_staff' in df_shortage_role.columns else 0
    lack_penalty_cost = df_shortage_role['estimated_lack_penalty_cost'].sum() if 'estimated_lack_penalty_cost' in df_shortage_role.columns else 0

    jain_index = "N/A"
    if not df_fairness.empty and 'metric' in df_fairness.columns:
        jain_row = df_fairness[df_fairness['metric'] == 'jain_index']
        if not jain_row.empty:
            jain_index = f"{float(jain_row['value'].iloc[0]):.3f}"

    staff_count = len(df_staff) if not df_staff.empty else 0
    avg_night_ratio = df_staff['night_ratio'].mean() if 'night_ratio' in df_staff.columns else 0
    alerts_count = len(df_alerts) if not df_alerts.empty else 0

    return html.Div([
        html.Div(id='overview-insights', style={  # type: ignore
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("åˆ†ææ¦‚è¦", style={'marginBottom': '20px'}),  # type: ignore
        html.Div([  # type: ignore
            html.Div([
                create_metric_card("ç·ä¸è¶³æ™‚é–“(h)", f"{lack_h:.1f}"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("å¤œå‹¤ JainæŒ‡æ•°", jain_index),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("ç·ã‚¹ã‚¿ãƒƒãƒ•æ•°", str(staff_count)),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("å¹³å‡å¤œå‹¤æ¯”ç‡", f"{avg_night_ratio:.3f}"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("ã‚¢ãƒ©ãƒ¼ãƒˆæ•°", str(alerts_count), "#ff7f0e" if alerts_count > 0 else "#1f77b4"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("ç·éå‰°ã‚³ã‚¹ãƒˆ(Â¥)", f"{excess_cost:,.0f}"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("ä¸è¶³ã‚³ã‚¹ãƒˆ(æ´¾é£)(Â¥)", f"{lack_temp_cost:,.0f}"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£(Â¥)", f"{lack_penalty_cost:,.0f}"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
        ], style={'marginBottom': '20px'}),
    ])


def create_heatmap_tab() -> html.Div:
    """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚¿ãƒ–ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚ä¸Šä¸‹2ã¤ã®æ¯”è¼ƒã‚¨ãƒªã‚¢ã‚’æŒã¡ã¾ã™ã€‚"""
    roles = data_get('roles', [])
    employments = data_get('employments', [])

    # æ¯”è¼ƒã‚¨ãƒªã‚¢ã‚’1ã¤ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    def create_comparison_area(area_id: int):
        return html.Div([  # type: ignore
            html.H4(f"æ¯”è¼ƒã‚¨ãƒªã‚¢ {area_id}", style={'marginTop': '20px', 'borderTop': '2px solid #ddd', 'paddingTop': '20px'}),  # type: ignore

            # --- å„ã‚¨ãƒªã‚¢ã«è·ç¨®ã¨é›‡ç”¨å½¢æ…‹ã®ä¸¡æ–¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’è¨­ç½® ---
            html.Div([  # type: ignore
                html.Div([  # type: ignore
                    html.Label("è·ç¨®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"),  # type: ignore
                    dcc.Dropdown(
                        id={'type': 'heatmap-filter-role', 'index': area_id},
                        options=[{'label': 'ã™ã¹ã¦', 'value': 'all'}] + [{'label': r, 'value': r} for r in roles],
                        value='all',
                        clearable=False
                    )
                ], style={'width': '48%', 'display': 'inline-block', 'marginRight': '4%'}),

                html.Div([  # type: ignore
                    html.Label("é›‡ç”¨å½¢æ…‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"),  # type: ignore
                    dcc.Dropdown(
                        id={'type': 'heatmap-filter-employment', 'index': area_id},
                        options=[{'label': 'ã™ã¹ã¦', 'value': 'all'}] + [{'label': e, 'value': e} for e in employments],
                        value='all',
                        clearable=False
                    )
                ], style={'width': '48%', 'display': 'inline-block'}),
            ], style={'marginBottom': '10px'}),

            # --- ã‚°ãƒ©ãƒ•æç”»é ˜åŸŸ ---
            dcc.Loading(
                id={'type': 'loading-heatmap', 'index': area_id},
                children=html.Div(id={'type': 'graph-output-heatmap', 'index': area_id})
            )
        ], style={'padding': '10px', 'backgroundColor': '#f9f9f9', 'borderRadius': '5px', 'marginBottom': '10px'})

    return html.Div([
        html.H3("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æ¯”è¼ƒåˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
        html.P("ä¸Šä¸‹ã®ã‚¨ãƒªã‚¢ã§ãã‚Œãã‚Œã€Œè·ç¨®ã€ã¨ã€Œé›‡ç”¨å½¢æ…‹ã€ã®çµ„ã¿åˆã‚ã›ã‚’é¸æŠã—ã€ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚"),  # type: ignore
        create_comparison_area(1),
        create_comparison_area(2)
    ])


def create_shortage_tab() -> html.Div:
    """ä¸è¶³åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame())
    df_shortage_emp = data_get('shortage_employment_summary', pd.DataFrame())

    content = [html.Div(id='shortage-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("ä¸è¶³åˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
        html.Div(  # type: ignore
            dcc.Markdown(
                "\n".join(
                    [
                        "### è¨ˆç®—ã«ä½¿ç”¨ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
                        f"- Needç®—å‡ºæ–¹æ³•: {data_get('need_method', 'N/A')}",
                        f"- Upperç®—å‡ºæ–¹æ³•: {data_get('upper_method', 'N/A')}",
                        f"- ç›´æ¥é›‡ç”¨å˜ä¾¡: Â¥{data_get('wage_direct', 0):,.0f}/h",
                        f"- æ´¾é£å˜ä¾¡: Â¥{data_get('wage_temp', 0):,.0f}/h",
                        f"- æ¡ç”¨ã‚³ã‚¹ãƒˆ: Â¥{data_get('hiring_cost', 0):,}/äºº",
                        f"- ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£: Â¥{data_get('penalty_cost', 0):,.0f}/h",
                    ]
                )
            ),
            style={
                'backgroundColor': '#e9f2fa',
                'padding': '10px',
                'borderRadius': '8px',
                'border': '1px solid #cce5ff',
                'marginBottom': '20px'
            },
        )]

    # è·ç¨®åˆ¥ä¸è¶³åˆ†æ
    if not df_shortage_role.empty:
        content.append(html.H4("è·ç¨®åˆ¥ä¸è¶³æ™‚é–“"))  # type: ignore

        # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        total_lack = df_shortage_role['lack_h'].sum() if 'lack_h' in df_shortage_role.columns else 0
        if total_lack > 0:
            top_roles = df_shortage_role.nlargest(3, 'lack_h')[['role', 'lack_h']]
            metrics = [
                html.Div([
                    create_metric_card("ç·ä¸è¶³æ™‚é–“", f"{total_lack:.1f}h")
                ], style={'width': '25%', 'display': 'inline-block', 'padding': '5px'})
            ]
            for i, row in enumerate(top_roles.itertuples(index=False)):
                metrics.append(
                    html.Div([
                        create_metric_card(f"ä¸è¶³Top{i+1}", f"{row.role}: {row.lack_h:.1f}h")  # type: ignore
                    ], style={'width': '25%', 'display': 'inline-block', 'padding': '5px'})
                )
            content.append(html.Div(metrics, style={'marginBottom': '20px'}))

        # è·ç¨®åˆ¥ä¸è¶³æ™‚é–“ã‚°ãƒ©ãƒ•
        fig_role_lack = px.bar(
            df_shortage_role,
            x='role',
            y='lack_h',
            title='è·ç¨®åˆ¥ä¸è¶³æ™‚é–“',
            labels={'role': 'è·ç¨®', 'lack_h': 'ä¸è¶³æ™‚é–“(h)'},
            color_discrete_sequence=['#FFA500']
        )
        content.append(dcc.Graph(figure=fig_role_lack))

        # è·ç¨®åˆ¥éå‰°æ™‚é–“ã‚°ãƒ©ãƒ•
        if 'excess_h' in df_shortage_role.columns:
            fig_role_excess = px.bar(
                df_shortage_role,
                x='role',
                y='excess_h',
                title='è·ç¨®åˆ¥éå‰°æ™‚é–“',
                labels={'role': 'è·ç¨®', 'excess_h': 'éå‰°æ™‚é–“(h)'},
                color_discrete_sequence=['#00BFFF']
            )
            content.append(dcc.Graph(figure=fig_role_excess))

    # é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³åˆ†æ
    if not df_shortage_emp.empty:
        content.append(html.H4("é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³æ™‚é–“", style={'marginTop': '30px'}))  # type: ignore

        fig_emp_lack = px.bar(
            df_shortage_emp,
            x='employment',
            y='lack_h',
            title='é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³æ™‚é–“',
            labels={'employment': 'é›‡ç”¨å½¢æ…‹', 'lack_h': 'ä¸è¶³æ™‚é–“(h)'},
            color_discrete_sequence=['#2ca02c']
        )
        content.append(dcc.Graph(figure=fig_emp_lack))

    # ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    content.append(html.Div([
        html.H4("ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", style={'marginTop': '30px'}),  # type: ignore
        html.P("å„æ™‚é–“å¸¯ã§å¿…è¦äººæ•°ã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„ã®å‰²åˆã§äººå“¡ãŒä¸è¶³ã—ã¦ã„ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚"),  # type: ignore
        html.Div([  # type: ignore
            html.Label("è¡¨ç¤ºç¯„å›²"),  # type: ignore
            dcc.Dropdown(
                id='shortage-heatmap-scope',
                options=[
                    {'label': 'å…¨ä½“', 'value': 'overall'},
                    {'label': 'è·ç¨®åˆ¥', 'value': 'role'},
                    {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'employment'}
                ],
                value='overall',
                style={'width': '200px'}
            ),
        ], style={'marginBottom': '10px'}),
        html.Div(id='shortage-heatmap-detail-container'),
        html.Div(id='shortage-ratio-heatmap')
    ]))

    # Factor Analysis section
    content.append(html.Hr())
    content.append(html.H4('è¦å› åˆ†æ (AI)', style={'marginTop': '30px'}))  # type: ignore
    content.append(html.Button('è¦å› åˆ†æãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’', id='factor-train-button', n_clicks=0))  # type: ignore
    content.append(html.Div(id='factor-output'))  # type: ignore

    # Over/Short Log section
    events_df = data_get('shortage_events', pd.DataFrame())
    if not events_df.empty:
        content.append(html.Hr())  # type: ignore
        content.append(html.H4('éä¸è¶³æ‰‹å‹•ãƒ­ã‚°', style={'marginTop': '30px'}))  # type: ignore
        content.append(dash_table.DataTable(
            id='over-shortage-table',
            data=events_df.to_dict('records'),
            columns=[{'name': c, 'id': c, 'presentation': 'input'} for c in events_df.columns],
            editable=True,
        ))
        content.append(dcc.RadioItems(
            id='log-save-mode',
            options=[{'label': 'è¿½è¨˜', 'value': 'append'}, {'label': 'ä¸Šæ›¸ã', 'value': 'overwrite'}],
            value='è¿½è¨˜',
            inline=True,
            style={'marginTop': '10px'}
        ))
        content.append(html.Button('ãƒ­ã‚°ã‚’ä¿å­˜', id='save-log-button', n_clicks=0, style={'marginTop': '10px'}))  # type: ignore
        content.append(html.Div(id='save-log-msg'))  # type: ignore

    return html.Div(content)


def create_optimization_tab() -> html.Div:
    """æœ€é©åŒ–åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    return html.Div([  # type: ignore
        html.Div(id='optimization-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("æœ€é©åŒ–åˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
        html.Div([  # type: ignore
            html.Label("è¡¨ç¤ºç¯„å›²"),  # type: ignore
            dcc.Dropdown(
                id='opt-scope',
                options=[
                    {'label': 'å…¨ä½“', 'value': 'overall'},
                    {'label': 'è·ç¨®åˆ¥', 'value': 'role'},
                    {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'employment'}
                ],
                value='overall',
                clearable=False
            ),
        ], style={'width': '30%', 'marginBottom': '20px'}),
        html.Div(id='opt-detail-container'),  # type: ignore
        html.Div(id='optimization-content')  # type: ignore
    ])


def create_leave_analysis_tab() -> html.Div:
    """ä¼‘æš‡åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='leave-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("ä¼‘æš‡åˆ†æ", style={'marginBottom': '20px'})]  # type: ignore

    df_staff_balance = data_get('staff_balance_daily', pd.DataFrame())
    df_daily_summary = data_get('daily_summary', pd.DataFrame())
    df_concentration = data_get('concentration_requested', pd.DataFrame())
    df_ratio_breakdown = data_get('leave_ratio_breakdown', pd.DataFrame())

    if not df_staff_balance.empty:
        fig_balance = px.line(
            df_staff_balance,
            x='date',
            y=['total_staff', 'leave_applicants_count', 'non_leave_staff'],
            title='å‹¤å‹™äºˆå®šäººæ•°ã¨å…¨ä¼‘æš‡å–å¾—è€…æ•°ã®æ¨ç§»',
            labels={'value': 'äººæ•°', 'variable': 'é …ç›®', 'date': 'æ—¥ä»˜'},
            markers=True
        )
        fig_balance.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_balance))
        content.append(dash_table.DataTable(
            data=df_staff_balance.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_staff_balance.columns]
        ))

    if not df_daily_summary.empty:
        fig_breakdown = px.bar(
            df_daily_summary,
            x='date',
            y='total_leave_days',
            color='leave_type',
            barmode='stack',
            title='æ—¥åˆ¥ ä¼‘æš‡å–å¾—è€…æ•°ï¼ˆå†…è¨³ï¼‰',
            labels={'date': 'æ—¥ä»˜', 'total_leave_days': 'ä¼‘æš‡å–å¾—è€…æ•°', 'leave_type': 'ä¼‘æš‡ã‚¿ã‚¤ãƒ—'}
        )
        fig_breakdown.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_breakdown))

    if not df_ratio_breakdown.empty:
        fig_ratio_break = px.bar(
            df_ratio_breakdown,
            x='dayofweek',
            y='leave_ratio',
            color='leave_type',
            facet_col='month_period',
            category_orders={
                'dayofweek': ['æœˆæ›œæ—¥', 'ç«æ›œæ—¥', 'æ°´æ›œæ—¥', 'æœ¨æ›œæ—¥', 'é‡‘æ›œæ—¥', 'åœŸæ›œæ—¥', 'æ—¥æ›œæ—¥'],
                'month_period': ['æœˆåˆ(1-10æ—¥)', 'æœˆä¸­(11-20æ—¥)', 'æœˆæœ«(21-æœ«æ—¥)'],
            },
            labels={'dayofweek': 'æ›œæ—¥', 'leave_ratio': 'å‰²åˆ', 'leave_type': 'ä¼‘æš‡ã‚¿ã‚¤ãƒ—', 'month_period': 'æœˆæœŸé–“'},
            title='æ›œæ—¥ãƒ»æœˆæœŸé–“åˆ¥ä¼‘æš‡å–å¾—ç‡'
        )
        content.append(dcc.Graph(figure=fig_ratio_break))

    if not df_concentration.empty:
        fig_conc = go.Figure()
        fig_conc.add_trace(go.Scatter(
            x=df_concentration['date'],
            y=df_concentration['leave_applicants_count'],
            mode='lines+markers',
            name='ä¼‘æš‡ç”³è«‹è€…æ•°',
            line=dict(shape='spline', smoothing=0.5),
            marker=dict(size=6)
        ))
        if 'is_concentrated' in df_concentration.columns:
            concentrated = df_concentration[df_concentration['is_concentrated']]
            if not concentrated.empty:
                fig_conc.add_trace(go.Scatter(
                    x=concentrated['date'],
                    y=concentrated['leave_applicants_count'],
                    mode='markers',
                    marker=dict(color='red', size=12, symbol='diamond'),
                    name='é–¾å€¤è¶…éæ—¥',
                    hovertemplate='<b>%{x|%Y-%m-%d}</b><br>ç”³è«‹è€…æ•°: %{y}äºº<extra></extra>'
                ))

        fig_conc.update_layout(
            title='å¸Œæœ›ä¼‘ ç”³è«‹è€…æ•°ã®æ¨ç§»ã¨é›†ä¸­æ—¥',
            xaxis_title='æ—¥ä»˜',
            yaxis_title='ç”³è«‹è€…æ•°'
        )
        fig_conc.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_conc))

    return html.Div(content)


def create_cost_analysis_tab() -> html.Div:
    """ã‚³ã‚¹ãƒˆåˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    return html.Div([
        html.Div(id='cost-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("äººä»¶è²»åˆ†æ", style={'marginBottom': '20px'}),

        html.H4("å‹•çš„ã‚³ã‚¹ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", style={'marginTop': '30px'}),
        dcc.RadioItems(
            id='cost-by-radio',
            options=[
                {'label': 'è·ç¨®åˆ¥', 'value': 'role'},
                {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'employment'},
                {'label': 'ã‚¹ã‚¿ãƒƒãƒ•åˆ¥', 'value': 'staff'},
            ],
            value='role',
            inline=True,
            style={'marginBottom': '10px'},
        ),
        html.Div(id='wage-input-container'),

        dcc.Loading(
            id="loading-cost-analysis",
            type="circle",
            children=html.Div(id='cost-analysis-content')
        )
    ])


def create_hire_plan_tab() -> html.Div:
    """æ¡ç”¨è¨ˆç”»ã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='hire-plan-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("æ¡ç”¨è¨ˆç”»", style={'marginBottom': '20px'})]  # type: ignore

    df_hire = data_get('hire_plan', pd.DataFrame())
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame())
    df_work_patterns = data_get('work_patterns', pd.DataFrame())
    if not df_hire.empty:
        content.append(html.H4("å¿…è¦FTEï¼ˆè·ç¨®åˆ¥ï¼‰"))  # type: ignore

        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        content.append(dash_table.DataTable(
            data=df_hire.to_dict('records'),
            columns=[{'name': col, 'id': col} for col in df_hire.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'}
        ))

        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
        if 'role' in df_hire.columns and 'hire_fte' in df_hire.columns:
            fig_hire = px.bar(
                df_hire,
                x='role',
                y='hire_fte',
                title='è·ç¨®åˆ¥å¿…è¦FTE',
                labels={'role': 'è·ç¨®', 'hire_fte': 'å¿…è¦FTE'},
                color_discrete_sequence=['#1f77b4']
            )
            content.append(dcc.Graph(figure=fig_hire))

    if not df_hire.empty and not df_shortage_role.empty:
        content.append(html.Div([
            html.H4("What-if æ¡ç”¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", style={'marginTop': '30px'}),  # type: ignore
            html.P("ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’å‹•ã‹ã—ã¦ã€è¿½åŠ æ¡ç”¨ã«ã‚ˆã‚‹ä¸è¶³æ™‚é–“ã®å‰Šæ¸›åŠ¹æœã¨ã‚³ã‚¹ãƒˆã®å¤‰åŒ–ã‚’ç¢ºèªã§ãã¾ã™ã€‚"),  # type: ignore
            dcc.Dropdown(
                id='sim-work-pattern-dropdown',
                options=[{'label': i, 'value': i} for i in df_work_patterns['code'].unique()] if not df_work_patterns.empty else [],
                value=df_work_patterns['code'].iloc[0] if not df_work_patterns.empty else None,
                clearable=False,
            ),
            dcc.Slider(
                id='sim-hire-fte-slider',
                min=0,
                max=10,
                step=1,
                value=0,
                marks={i: str(i) for i in range(11)},
            ),
        ], style={'padding': '20px', 'backgroundColor': '#f0f0f0', 'borderRadius': '8px'}))
        content.append(dcc.Graph(id='sim-shortage-graph'))
        content.append(html.Div(id='sim-cost-text'))  # type: ignore

    # æœ€é©æ¡ç”¨è¨ˆç”»
    df_optimal = data_get('optimal_hire_plan', pd.DataFrame())
    if not df_optimal.empty:
        content.append(html.H4("æœ€é©æ¡ç”¨è¨ˆç”»", style={'marginTop': '30px'}))  # type: ignore
        content.append(html.P("åˆ†æã®çµæœã€ä»¥ä¸‹ã®å…·ä½“çš„ãªæ¡ç”¨è¨ˆç”»ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"))
        content.append(dash_table.DataTable(
            data=df_optimal.to_dict('records'),
            columns=[{'name': col, 'id': col} for col in df_optimal.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'}
        ))

    return html.Div(content)


def create_fatigue_tab() -> html.Div:
    """ç–²åŠ´åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    explanation = """
    #### ç–²åŠ´åˆ†æã®è©•ä¾¡æ–¹æ³•
    ã‚¹ã‚¿ãƒƒãƒ•ã®ç–²åŠ´ã‚¹ã‚³ã‚¢ã¯ã€ä»¥ä¸‹ã®è¦ç´ ã‚’ç·åˆçš„ã«è©•ä¾¡ã—ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚å„è¦ç´ ã¯ã€å…¨ã‚¹ã‚¿ãƒƒãƒ•å†…ã§ã®ç›¸å¯¾çš„ãªä½ç½®ï¼ˆåå·®ï¼‰ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢åŒ–ã•ã‚Œã€é‡ã¿ä»˜ã‘ã•ã‚Œã¦åˆè¨ˆã•ã‚Œã¾ã™ã€‚
    - **å‹¤å‹™é–‹å§‹æ™‚åˆ»ã®ã°ã‚‰ã¤ã:** å‡ºå‹¤æ™‚åˆ»ãŒä¸è¦å‰‡ã§ã‚ã‚‹ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **æ¥­å‹™ã®å¤šæ§˜æ€§:** æ‹…å½“ã™ã‚‹æ¥­å‹™ï¼ˆå‹¤å‹™ã‚³ãƒ¼ãƒ‰ï¼‰ã®ç¨®é¡ãŒå¤šã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **åŠ´åƒæ™‚é–“ã®ã°ã‚‰ã¤ã:** æ—¥ã€…ã®åŠ´åƒæ™‚é–“ãŒä¸è¦å‰‡ã§ã‚ã‚‹ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **çŸ­ã„ä¼‘æ¯æœŸé–“:** å‹¤å‹™é–“ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«ãŒçŸ­ã„é »åº¦ãŒé«˜ã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **é€£å‹¤:** 3é€£å‹¤ä»¥ä¸Šã®é€£ç¶šå‹¤å‹™ãŒå¤šã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **å¤œå‹¤æ¯”ç‡:** å…¨å‹¤å‹™ã«å ã‚ã‚‹å¤œå‹¤ã®å‰²åˆãŒé«˜ã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚

    *ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€ã“ã‚Œã‚‰ã®è¦ç´ ã¯å‡ç­‰ãªé‡ã¿ï¼ˆå„1.0ï¼‰ã§è©•ä¾¡ã•ã‚Œã¾ã™ã€‚*
    """
    content = [
        html.Div(  # type: ignore
            dcc.Markdown(explanation),
            style={
                'padding': '15px',
                'backgroundColor': '#e9f2fa',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #cce5ff',
            },
        ),
        html.H3("ç–²åŠ´åˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
    ]
    df_fatigue = data_get('fatigue_score', pd.DataFrame())

    if not df_fatigue.empty:
        df_fatigue_for_plot = df_fatigue.reset_index().rename(columns={'index': 'staff'})
        fig = px.bar(
            df_fatigue_for_plot,
            x='staff',
            y='fatigue_score',
            title='ã‚¹ã‚¿ãƒƒãƒ•åˆ¥ç–²åŠ´ã‚¹ã‚³ã‚¢',
            labels={'staff': 'ã‚¹ã‚¿ãƒƒãƒ•', 'fatigue_score': 'ç–²åŠ´ã‚¹ã‚³ã‚¢'}
        )
        content.append(dcc.Graph(figure=fig))
        content.append(dash_table.DataTable(
            data=df_fatigue_for_plot.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_fatigue_for_plot.columns]
        ))
    else:
        content.append(html.P("ç–²åŠ´åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))  # type: ignore

    return html.Div(content)


def create_forecast_tab() -> html.Div:
    """éœ€è¦äºˆæ¸¬ã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='forecast-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("éœ€è¦äºˆæ¸¬", style={'marginBottom': '20px'})]  # type: ignore
    df_fc = data_get('forecast', pd.DataFrame())
    df_actual = data_get('demand_series', pd.DataFrame())

    if not df_fc.empty:
        fig = go.Figure()
        if {'ds', 'yhat'}.issubset(df_fc.columns):
            fig.add_trace(go.Scatter(x=df_fc['ds'], y=df_fc['yhat'], mode='lines+markers', name='äºˆæ¸¬'))
        if not df_actual.empty and {'ds', 'y'}.issubset(df_actual.columns):
            fig.add_trace(go.Scatter(x=df_actual['ds'], y=df_actual['y'], mode='lines', name='å®Ÿç¸¾', line=dict(dash='dash')))
        fig.update_layout(title='éœ€è¦äºˆæ¸¬ã¨å®Ÿç¸¾', xaxis_title='æ—¥ä»˜', yaxis_title='éœ€è¦')
        content.append(dcc.Graph(figure=fig))
        content.append(dash_table.DataTable(
            data=df_fc.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_fc.columns]
        ))
    else:
        content.append(html.P("éœ€è¦äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))  # type: ignore

    return html.Div(content)


def create_fairness_tab() -> html.Div:
    """å…¬å¹³æ€§ã‚¿ãƒ–ã‚’ä½œæˆ"""
    explanation = """
    #### å…¬å¹³æ€§åˆ†æã®è©•ä¾¡æ–¹æ³•
    ã‚¹ã‚¿ãƒƒãƒ•é–“ã®ã€Œä¸å…¬å¹³æ„Ÿã€ã¯ã€å„å€‹äººã®åƒãæ–¹ãŒå…¨ä½“ã®å¹³å‡ã‹ã‚‰ã©ã‚Œã ã‘ä¹–é›¢ã—ã¦ã„ã‚‹ã‹ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢åŒ–ã•ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®è¦ç´ ã®ä¹–é›¢åº¦ã‚’å‡ç­‰ã«è©•ä¾¡ã—ã€ãã®å¹³å‡å€¤ã‚’ã€Œä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢ã€ã¨ã—ã¦ã„ã¾ã™ã€‚
    - **å¤œå‹¤æ¯”ç‡ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€å¤œå‹¤ã®å‰²åˆãŒæ¥µç«¯ã«å¤šã„ã€ã¾ãŸã¯å°‘ãªã„ã€‚
    - **ç·åŠ´åƒæ™‚é–“ï¼ˆã‚¹ãƒ­ãƒƒãƒˆæ•°ï¼‰ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€ç·åŠ´åƒæ™‚é–“ãŒæ¥µç«¯ã«å¤šã„ã€ã¾ãŸã¯å°‘ãªã„ã€‚
    - **å¸Œæœ›ä¼‘ã®æ‰¿èªç‡ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€å¸Œæœ›ä¼‘ã®é€šã‚Šã‚„ã™ã•ã«å·®ãŒã‚ã‚‹ã€‚
    - **é€£ä¼‘å–å¾—é »åº¦ã®ä¹–ãƒª:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€é€£ä¼‘ã®å–å¾—ã—ã‚„ã™ã•ã«å·®ãŒã‚ã‚‹ã€‚

    *ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©ã€ã“ã‚Œã‚‰ã®è¦ç´ ã«ãŠã„ã¦å¹³å‡ã‹ã‚‰ã®ä¹–é›¢ãŒå¤§ãã„ï¼ˆï¼ä¸å…¬å¹³æ„Ÿã‚’æ„Ÿã˜ã‚„ã™ã„å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚*
    """
    content = [
        html.Div(  # type: ignore
            dcc.Markdown(explanation),
            style={
                'padding': '15px',
                'backgroundColor': '#f0f0f0',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #ddd',
            },
        ),
        html.H3("å…¬å¹³æ€§ (ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢)", style={'marginBottom': '20px'}),  # type: ignore
    ]
    df_fair = data_get('fairness_after', pd.DataFrame())

    if not df_fair.empty:
        metric_col = (
            'unfairness_score'
            if 'unfairness_score' in df_fair.columns
            else ('fairness_score' if 'fairness_score' in df_fair.columns else 'night_ratio')
        )
        fig_bar = px.bar(
            df_fair,
            x='staff',
            y=metric_col,
            labels={'staff': 'ã‚¹ã‚¿ãƒƒãƒ•', metric_col: 'ã‚¹ã‚³ã‚¢'},
            color_discrete_sequence=['#FF8C00']
        )
        avg_val = df_fair[metric_col].mean()
        fig_bar.add_hline(y=avg_val, line_dash='dash', line_color='red')
        content.append(dcc.Graph(figure=fig_bar))

        fig_hist = px.histogram(
            df_fair,
            x=metric_col,
            nbins=20,
            title="å…¬å¹³æ€§ã‚¹ã‚³ã‚¢åˆ†å¸ƒ",
            labels={metric_col: 'ã‚¹ã‚³ã‚¢'}
        )
        fig_hist.update_layout(yaxis_title="äººæ•°")
        fig_hist.add_vline(x=avg_val, line_dash='dash', line_color='red')
        content.append(dcc.Graph(figure=fig_hist))

        if 'unfairness_score' in df_fair.columns:
            ranking = df_fair.sort_values('unfairness_score', ascending=False)[['staff', 'unfairness_score']]
            ranking.index += 1
            content.append(html.H4('ä¸å…¬å¹³æ„Ÿãƒ©ãƒ³ã‚­ãƒ³ã‚°'))  # type: ignore
            content.append(dash_table.DataTable(
                data=ranking.to_dict('records'),
                columns=[{'name': i, 'id': i} for i in ranking.columns]
            ))
        content.append(dash_table.DataTable(
            data=df_fair.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_fair.columns]
        ))
    else:
        content.append(html.P("å…¬å¹³æ€§ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

    return html.Div(content)


def create_gap_analysis_tab() -> html.Div:
    """åŸºæº–ä¹–é›¢åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='gap-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("åŸºæº–ä¹–é›¢åˆ†æ", style={'marginBottom': '20px'})]  # type: ignore
    df_summary = data_get('gap_summary', pd.DataFrame())
    df_heat = data_get('gap_heatmap', pd.DataFrame())

    if not df_summary.empty:
        content.append(dash_table.DataTable(
            data=df_summary.to_dict('records'),
            columns=[{'name': c, 'id': c} for c in df_summary.columns]
        ))
    if not df_heat.empty:
        fig = px.imshow(
            df_heat,
            aspect='auto',
            color_continuous_scale='RdBu_r',
            labels={'x': 'æ™‚é–“å¸¯', 'y': 'è·ç¨®', 'color': 'ä¹–é›¢'}
        )
        content.append(dcc.Graph(figure=fig))
    if df_summary.empty and df_heat.empty:
        content.append(html.P("åŸºæº–ä¹–é›¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))  # type: ignore

    return html.Div(content)


def create_summary_report_tab() -> html.Div:
    """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='summary-report-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ", style={'marginBottom': '20px'})]  # type: ignore
    report_text = data_get('summary_report')
    if report_text:
        content.append(dcc.Markdown(report_text))
    else:
        content.append(html.P("ãƒ¬ãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))
    return html.Div(content)


def create_ppt_report_tab() -> html.Div:
    """PowerPointãƒ¬ãƒãƒ¼ãƒˆã‚¿ãƒ–ã‚’ä½œæˆ"""
    return html.Div([  # type: ignore
        html.Div(id='ppt-report-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("PowerPointãƒ¬ãƒãƒ¼ãƒˆ", style={'marginBottom': '20px'}),  # type: ignore
        html.P("ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦PowerPointãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"),  # type: ignore
        html.Button('PPTãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ', id='ppt-generate', n_clicks=0)  # type: ignore
    ])


def create_individual_analysis_tab() -> html.Div:
    """è·å“¡å€‹åˆ¥åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    long_df = data_get('long_df', pd.DataFrame())

    if long_df.empty:
        return html.Div("åˆ†æã®å…ƒã¨ãªã‚‹å‹¤å‹™ãƒ‡ãƒ¼ã‚¿ (long_df) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    staff_list = sorted(long_df['staff'].unique())

    return html.Div([
        html.H3("è·å“¡å€‹åˆ¥åˆ†æ", style={'marginBottom': '20px'}),
        html.P("åˆ†æã—ãŸã„è·å“¡ã‚’ä»¥ä¸‹ã‹ã‚‰é¸æŠã—ã¦ãã ã•ã„ã€‚"),
        dcc.Dropdown(
            id='individual-staff-dropdown',
            options=[{'label': staff, 'value': staff} for staff in staff_list],
            value=staff_list[0] if staff_list else None,
            clearable=False,
            style={'width': '50%', 'marginBottom': '20px'}
        ),
        dcc.Loading(
            id="loading-individual-analysis",
            type="circle",
            children=html.Div(id='individual-analysis-content')
        )
    ])


def create_team_analysis_tab() -> html.Div:
    """ãƒãƒ¼ãƒ åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty:
        return html.Div("åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    filterable_cols = ['role', 'code', 'employment']

    return html.Div([
        html.H3("ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ»ãƒãƒ¼ãƒ åˆ†æ"),
        html.P("åˆ†æã—ãŸã„ãƒãƒ¼ãƒ ã®æ¡ä»¶ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"),
        html.Div([
            dcc.Dropdown(
                id='team-criteria-key-dropdown',
                options=[{'label': col, 'value': col} for col in filterable_cols],
                value='code',
                style={'width': '200px', 'display': 'inline-block'}
            ),
            dcc.Dropdown(
                id='team-criteria-value-dropdown',
                style={
                    'width': '300px',
                    'display': 'inline-block',
                    'marginLeft': '10px'
                }
            )
        ]),
        dcc.Loading(children=html.Div(id='team-analysis-content'))
    ])


def create_blueprint_analysis_tab() -> html.Div:
    """ã‚·ãƒ•ãƒˆä½œæˆãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆåˆ†æã‚¿ãƒ–ã‚’ä½œæˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    return html.Div([
        html.H3("ã‚·ãƒ•ãƒˆä½œæˆãƒ—ãƒ­ã‚»ã‚¹ã®\u300cæš—é»™çŸ¥\u300dåˆ†æ", style={'marginBottom': '20px'}),
        html.P(
            "éå»ã®ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ç†Ÿç·´è€…ãŒç„¡æ„è­˜ã«è¡Œã£ã¦ã„ã‚‹\u300cã‚·ãƒ•ãƒˆã®çµ„ã¿æ–¹ã®ã‚»ã‚ªãƒªãƒ¼\u300dã‚’6ã¤ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã€æŠ½å‡ºã—ã¾ã™ã€‚",
            style={'marginBottom': '10px'}
        ),

        # åˆ†æè¦³ç‚¹ã®èª¬æ˜
        html.Details([
            html.Summary('ğŸ“Š åˆ†æã®6ã¤ã®è¦³ç‚¹ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§è©³ç´°ï¼‰', style={'cursor': 'pointer', 'fontWeight': 'bold'}),
            html.Div([
                html.Ul([
                    html.Li("ğŸ¤ ã‚¹ã‚­ãƒ«ç›¸æ€§: èª°ã¨èª°ã‚’çµ„ã¾ã›ã‚‹ã¨ä¸Šæ‰‹ãã„ãã‹ã€é€†ã«é¿ã‘ã¦ã„ã‚‹ã‹"),
                    html.Li("âš–ï¸ è² è·åˆ†æ•£æˆ¦ç•¥: ç¹å¿™æ™‚é–“å¸¯ã«ã©ã‚“ãªæˆ¦ç•¥ã§äººã‚’é…ç½®ã—ã¦ã„ã‚‹ã‹"),
                    html.Li("ğŸ‘¤ å€‹äººé…æ…®: ç‰¹å®šè·å“¡ã®å€‹äººäº‹æƒ…ã¸ã®é…æ…®ãƒ‘ã‚¿ãƒ¼ãƒ³"),
                    html.Li("ğŸ”„ ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: å…¬å¹³æ€§ã‚’ä¿ã¤ãŸã‚ã®è¤‡é›‘ãªãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ«"),
                    html.Li("ğŸš¨ ãƒªã‚¹ã‚¯å›é¿: ãƒˆãƒ©ãƒ–ãƒ«é˜²æ­¢ã®ãŸã‚ã®æš—é»™ã®é…ç½®ãƒ«ãƒ¼ãƒ«"),
                    html.Li("ğŸ“… æ™‚ç³»åˆ—æˆ¦ç•¥: æœˆåˆãƒ»æœˆæœ«ã€æ›œæ—¥ã«ã‚ˆã‚‹é…ç½®æˆ¦ç•¥ã®å¤‰åŒ–"),
                ])
            ], style={'padding': '10px', 'backgroundColor': '#f0f0f0', 'borderRadius': '5px', 'marginTop': '10px'})
        ], style={'marginBottom': '20px'}),

        html.Button(
            "ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆã‚’ç”Ÿæˆ",
            id="generate-blueprint-button",
            n_clicks=0,
            style={
                "marginTop": "10px",
                "marginBottom": "20px",
                "padding": "10px 30px",
                "fontSize": "16px",
                "backgroundColor": "#1f77b4",
                "color": "white",
                "border": "none",
                "borderRadius": "5px",
                "cursor": "pointer"
            },
        ),
        dcc.Loading(
            id="loading-blueprint",
            type="default",
            children=html.Div(id="blueprint-analysis-content")
        ),
    ])

# --- ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
app.layout = html.Div([
    dcc.Store(id='kpi-data-store', storage_type='memory'),
    dcc.Store(id='data-loaded', storage_type='memory'),
    dcc.Store(id='full-analysis-store', storage_type='memory'),
    dcc.Store(id='creation-logic-results-store', storage_type='memory'),
    dcc.Store(id='logic-analysis-progress', storage_type='memory'),
    dcc.Interval(id='logic-analysis-interval', interval=500, disabled=True),

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    html.Div([  # type: ignore
        html.H1("ğŸ—‚ï¸ Shift-Suite é«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢", style={
            'textAlign': 'center',
            'color': 'white',
            'margin': '0',
            'padding': '20px'
        })
    ], style={
        'backgroundColor': '#2c3e50',
        'boxShadow': '0 2px 4px rgba(0,0,0,0.1)'
    }),

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢
    html.Div([  # type: ignore
        dcc.Upload(
            id='upload-data',
            children=html.Div([
                'åˆ†æçµæœã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ— ã¾ãŸã¯ ',
                html.A('ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠ', style={'textDecoration': 'underline'})
            ]),
            style={
                'width': '100%',
                'height': '100px',
                'lineHeight': '100px',
                'borderWidth': '2px',
                'borderStyle': 'dashed',
                'borderRadius': '10px',
                'textAlign': 'center',
                'margin': '20px 0',
                'backgroundColor': '#f8f9fa',
                'cursor': 'pointer'
            },
            multiple=False
        ),
    ], style={'padding': '0 20px'}),

    html.Div([  # type: ignore
        html.H3("åˆ†æã‚·ãƒŠãƒªã‚ªé¸æŠ", style={'textAlign': 'center'}),
        dcc.Dropdown(
            id='scenario-dropdown',
            placeholder="ã¾ãšåˆ†æçµæœã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            style={'width': '60%', 'margin': 'auto'}
        )
    ], id='scenario-selector-div', style={'display': 'none'}),

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    html.Div(id='main-content', style={'padding': '20px'}),  # type: ignore

    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ãƒ“ãƒ¥ãƒ¼ã‚¢
    html.Details([
        html.Summary('ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ã‚’è¡¨ç¤º/éè¡¨ç¤º'),
        dcc.Textarea(id='log-viewer', style={'width': '100%', 'height': 300}, readOnly=True)
    ], style={'padding': '0 20px'}),
    dcc.Interval(id='log-interval', interval=1000),

], style={'backgroundColor': '#f5f5f5', 'minHeight': '100vh'})

# --- ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•° ---
@app.callback(
    Output('data-loaded', 'data'),
    Output('scenario-dropdown', 'options'),
    Output('scenario-dropdown', 'value'),
    Output('scenario-selector-div', 'style'),
    Input('upload-data', 'contents'),
    State('upload-data', 'filename')
)
def process_upload(contents, filename):
    """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚·ãƒŠãƒªã‚ªã‚’æ¤œå‡º"""
    if contents is None:
        raise PreventUpdate

    global TEMP_DIR_OBJ

    log.info(f"Received upload: {filename}")

    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    if TEMP_DIR_OBJ:
        TEMP_DIR_OBJ.cleanup()

    TEMP_DIR_OBJ = tempfile.TemporaryDirectory(prefix="shift_suite_dash_")
    temp_dir_path = Path(TEMP_DIR_OBJ.name)
    log.debug(f"Created temp dir {temp_dir_path}")

    # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)

    try:
        with zipfile.ZipFile(io.BytesIO(decoded)) as zf:
            zf.extractall(temp_dir_path)
        log.info(f"Extracted ZIP to {temp_dir_path}")

        scenarios = [d.name for d in temp_dir_path.iterdir() if d.is_dir() and d.name.startswith('out_')]
        if not scenarios:
            return {'error': 'åˆ†æã‚·ãƒŠãƒªã‚ªã®ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}, [], None, {'display': 'none'}

        log.debug(f"Found scenarios: {scenarios}")

        # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ç”¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        scenario_name_map = {
            'out_median_based': 'ä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹',
            'out_mean_based': 'å¹³å‡å€¤ãƒ™ãƒ¼ã‚¹',
            'out_p25_based': '25ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹',
        }

        scenario_options = [
            {'label': scenario_name_map.get(s, s.replace('out_', '')), 'value': s}
            for s in scenarios
        ]
        first_scenario = scenarios[0]
        scenario_paths = {d.name: str(d) for d in temp_dir_path.iterdir() if d.is_dir()}
        return {
            'success': True,
            'scenarios': scenario_paths,
        }, scenario_options, first_scenario, {'display': 'block'}

    except Exception as e:
        log.error(f"Error processing ZIP: {e}", exc_info=True)
        return {'error': str(e)}, [], None, {'display': 'none'}


@app.callback(
    Output('kpi-data-store', 'data'),
    Output('main-content', 'children'),
    Input('scenario-dropdown', 'value'),
    State('data-loaded', 'data')
)
def update_main_content(selected_scenario, data_status):
    """ã‚·ãƒŠãƒªã‚ªé¸æŠã«å¿œã˜ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¡ã‚¤ãƒ³UIã‚’æ›´æ–°"""
    if (
        not selected_scenario
        or not data_status
        or 'success' not in data_status
        or 'scenarios' not in data_status
    ):
        raise PreventUpdate

    data_dir = Path(data_status['scenarios'].get(selected_scenario, ''))
    if not data_dir.exists():
        raise PreventUpdate

    log.info(f"Switching to scenario {selected_scenario} at {data_dir}")

    # Scenario has changed; reset caches and store new directory
    global CURRENT_SCENARIO_DIR
    CURRENT_SCENARIO_DIR = data_dir
    clear_data_cache()

    pre_aggr = data_get('pre_aggregated_data')
    if pre_aggr is None or (isinstance(pre_aggr, pd.DataFrame) and pre_aggr.empty):
        return {}, html.Div(f"ã‚¨ãƒ©ãƒ¼: {(data_dir / 'pre_aggregated_data.parquet').name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")  # type: ignore

    kpi_data = {}

    tabs = dcc.Tabs(id='main-tabs', value='overview', children=[
        dcc.Tab(label='æ¦‚è¦', value='overview'),
        dcc.Tab(label='ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', value='heatmap'),
        dcc.Tab(label='ä¸è¶³åˆ†æ', value='shortage'),
        dcc.Tab(label='æœ€é©åŒ–åˆ†æ', value='optimization'),
        dcc.Tab(label='ä¼‘æš‡åˆ†æ', value='leave'),
        dcc.Tab(label='ã‚³ã‚¹ãƒˆåˆ†æ', value='cost'),
        dcc.Tab(label='æ¡ç”¨è¨ˆç”»', value='hire_plan'),
        dcc.Tab(label='ç–²åŠ´åˆ†æ', value='fatigue'),
        dcc.Tab(label='éœ€è¦äºˆæ¸¬', value='forecast'),
        dcc.Tab(label='å…¬å¹³æ€§', value='fairness'),
        dcc.Tab(label='åŸºæº–ä¹–é›¢åˆ†æ', value='gap'),
        dcc.Tab(label='ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ', value='summary_report'),
        dcc.Tab(label='PPTãƒ¬ãƒãƒ¼ãƒˆ', value='ppt_report'),
        dcc.Tab(label='è·å“¡å€‹åˆ¥åˆ†æ', value='individual_analysis'),
        dcc.Tab(label='ãƒãƒ¼ãƒ åˆ†æ', value='team_analysis'),
        dcc.Tab(label='ä½œæˆãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆ', value='blueprint_analysis'),
        dcc.Tab(label='ãƒ­ã‚¸ãƒƒã‚¯è§£æ˜', value='logic_analysis'),
    ])

    main_layout = html.Div([
        tabs,
        html.Div(id='tab-content', style={'marginTop': '20px'})
    ])

    return kpi_data, main_layout


@app.callback(
    Output('tab-content', 'children'),
    Input('main-tabs', 'value'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
def update_tab_content(active_tab, selected_scenario, data_status):
    """ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›´æ–°"""
    if not selected_scenario or not data_status:
        raise PreventUpdate
    if active_tab == 'overview':
        return create_overview_tab()
    elif active_tab == 'heatmap':
        return create_heatmap_tab()
    elif active_tab == 'shortage':
        return create_shortage_tab()
    elif active_tab == 'optimization':
        return create_optimization_tab()
    elif active_tab == 'leave':
        return create_leave_analysis_tab()
    elif active_tab == 'cost':
        return create_cost_analysis_tab()
    elif active_tab == 'hire_plan':
        return create_hire_plan_tab()
    elif active_tab == 'fatigue':
        return create_fatigue_tab()
    elif active_tab == 'forecast':
        return create_forecast_tab()
    elif active_tab == 'fairness':
        return create_fairness_tab()
    elif active_tab == 'gap':
        return create_gap_analysis_tab()
    elif active_tab == 'summary_report':
        return create_summary_report_tab()
    elif active_tab == 'ppt_report':
        return create_ppt_report_tab()  # type: ignore
    elif active_tab == 'individual_analysis':
        return create_individual_analysis_tab()
    elif active_tab == 'team_analysis':
        return create_team_analysis_tab()
    elif active_tab == 'blueprint_analysis':
        return create_blueprint_analysis_tab()
    elif active_tab == 'logic_analysis':
        return create_creation_logic_analysis_tab()
    else:
        return html.Div("ã‚¿ãƒ–ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“")


@app.callback(
    Output({'type': 'heatmap-filter-employment', 'index': ALL}, 'options'),
    Output({'type': 'heatmap-filter-employment', 'index': ALL}, 'value'),
    Input({'type': 'heatmap-filter-role', 'index': ALL}, 'value'),
)
def update_employment_options(selected_roles):
    """è·ç¨®é¸æŠã«å¿œã˜ã¦é›‡ç”¨å½¢æ…‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’æ›´æ–°"""
    aggregated_df = data_get('pre_aggregated_data')
    if aggregated_df is None or aggregated_df.empty:
        default_options = [{'label': 'ã™ã¹ã¦', 'value': 'all'}]
        return [default_options, default_options], ['all', 'all']

    output_options = []
    for role in selected_roles:
        if role and role != 'all':
            employments = aggregated_df[aggregated_df['role'] == role][
                'employment'
            ].unique()
            new_options = (
                [{'label': 'ã™ã¹ã¦', 'value': 'all'}]
                + [{'label': emp, 'value': emp} for emp in sorted(employments)]
            )
        else:
            all_employments = aggregated_df['employment'].unique()
            new_options = (
                [{'label': 'ã™ã¹ã¦', 'value': 'all'}]
                + [{'label': emp, 'value': emp} for emp in sorted(all_employments)]
            )
        output_options.append(new_options)

    return output_options, ['all', 'all']


@app.callback(
    Output({'type': 'graph-output-heatmap', 'index': 1}, 'children'),
    Output({'type': 'graph-output-heatmap', 'index': 2}, 'children'),
    Input({'type': 'heatmap-filter-role', 'index': 1}, 'value'),
    Input({'type': 'heatmap-filter-employment', 'index': 1}, 'value'),
    Input({'type': 'heatmap-filter-role', 'index': 2}, 'value'),
    Input({'type': 'heatmap-filter-employment', 'index': 2}, 'value'),
)
def update_comparison_heatmaps(role1, emp1, role2, emp2):
    """äº‹å‰é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‹•çš„ã«ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã€2ã‚¨ãƒªã‚¢ã‚’æ›´æ–°"""

    aggregated_df = data_get('pre_aggregated_data')
    if aggregated_df is None or aggregated_df.empty:
        error_message = html.Div("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®å…ƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")  # type: ignore
        return error_message, error_message

    def generate_dynamic_heatmap(selected_role, selected_emp):
        """é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§äº‹å‰é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ã—ãƒ”ãƒœãƒƒãƒˆåŒ–"""

        filtered_df = aggregated_df.copy()
        title_parts = []

        # é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«åˆã‚ã›ã¦ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã‚€
        if selected_role and selected_role != 'all':
            filtered_df = filtered_df[filtered_df['role'] == selected_role]
            title_parts.append(f"è·ç¨®: {selected_role}")

        if selected_emp and selected_emp != 'all':
            filtered_df = filtered_df[filtered_df['employment'] == selected_emp]
            title_parts.append(f"é›‡ç”¨å½¢æ…‹: {selected_emp}")

        title = " AND ".join(title_parts) if title_parts else "å…¨ä½“"

        if filtered_df.empty:
            time_labels = gen_labels(30)
            all_dates = sorted(aggregated_df['date_lbl'].unique())
            empty_heatmap = pd.DataFrame(index=time_labels, columns=all_dates).fillna(0)
            fig_empty = generate_heatmap_figure(empty_heatmap, f"{title} (å‹¤å‹™ãƒ‡ãƒ¼ã‚¿ãªã—)")
            return dcc.Graph(figure=fig_empty)

        # æ—¥ä»˜é †ã«ä¸¦ã³æ›¿ãˆã¦ã‹ã‚‰ãƒ”ãƒœãƒƒãƒˆ
        dynamic_heatmap_df = filtered_df.sort_values('date_lbl').pivot_table(
            index='time',
            columns='date_lbl',
            values='staff_count',
            aggfunc='sum',
            fill_value=0,
        )

        time_labels = gen_labels(30)
        all_dates = sorted(aggregated_df['date_lbl'].unique())
        dynamic_heatmap_df = dynamic_heatmap_df.reindex(index=time_labels, columns=all_dates, fill_value=0)

        fig = generate_heatmap_figure(dynamic_heatmap_df, title)
        return dcc.Graph(figure=fig)

    output1 = generate_dynamic_heatmap(role1, emp1)
    output2 = generate_dynamic_heatmap(role2, emp2)

    return output1, output2


@app.callback(
    Output('shortage-heatmap-detail-container', 'children'),
    Input('shortage-heatmap-scope', 'value')
)
def update_shortage_heatmap_detail(scope):
    """ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®è©³ç´°é¸æŠã‚’æ›´æ–°"""
    if scope == 'overall':
        return None
    elif scope == 'role':
        roles = data_get('roles', [])
        return html.Div([  # type: ignore
            html.Label("è·ç¨®é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'shortage-detail', 'index': 'role'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': r, 'value': r} for r in roles],
                value='ALL',
                style={'width': '200px'}
            )
        ], style={'marginBottom': '10px'})
    elif scope == 'employment':
        employments = data_get('employments', [])
        return html.Div([  # type: ignore
            html.Label("é›‡ç”¨å½¢æ…‹é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'shortage-detail', 'index': 'employment'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': e, 'value': e} for e in employments],
                value='ALL',
                style={'width': '200px'}
            )
        ], style={'marginBottom': '10px'})
    return None


@app.callback(
    Output('shortage-ratio-heatmap', 'children'),
    Input('shortage-heatmap-scope', 'value'),
    Input({'type': 'shortage-detail', 'index': ALL}, 'value')
)
def update_shortage_ratio_heatmap(scope, detail_values):
    """ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ›´æ–°"""
    # é¸æŠå†…å®¹ã‹ã‚‰ã‚­ãƒ¼ã‚’çµ„ã¿ç«‹ã¦ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    key_suffix = ''
    if scope == 'role' and detail_values and detail_values[0] != 'ALL':
        key_suffix = f"role_{safe_filename(detail_values[0])}"
    elif scope == 'employment' and detail_values and detail_values[0] != 'ALL':
        key_suffix = f"emp_{safe_filename(detail_values[0])}"

    heat_key = f"heat_{key_suffix}" if key_suffix else "heat_all"
    df_heat = data_get(heat_key, pd.DataFrame())

    if df_heat.empty:
        return html.Div("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")  # type: ignore

    date_cols = [c for c in df_heat.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    staff_df = df_heat[date_cols]
    need_df = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                           index=df_heat.index, columns=date_cols)
    upper_df = pd.DataFrame(np.repeat(df_heat['upper'].values[:, np.newaxis], len(date_cols), axis=1),
                            index=df_heat.index, columns=date_cols)

    lack_count_df = (need_df - staff_df).clip(lower=0).fillna(0)
    excess_count_df = (staff_df - upper_df).clip(lower=0).fillna(0)
    ratio_df = calc_ratio_from_heatmap(df_heat)
    lack_count_df_renamed = lack_count_df.copy()
    lack_count_df_renamed.columns = [date_with_weekday(c) for c in lack_count_df_renamed.columns]
    fig_lack = px.imshow(
        lack_count_df_renamed,
        aspect='auto',
        color_continuous_scale='Oranges',
        title='ä¸è¶³äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
        labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'},
    )
    fig_lack.update_xaxes(tickvals=list(range(len(lack_count_df.columns))))

    fig_excess = go.Figure()
    if not excess_count_df.empty:
        excess_count_df_renamed = excess_count_df.copy()
        excess_count_df_renamed.columns = [date_with_weekday(c) for c in excess_count_df_renamed.columns]
        fig_excess = px.imshow(
            excess_count_df_renamed,
            aspect='auto',
            color_continuous_scale='Blues',
            title='éå‰°äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
            labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'},
        )
        fig_excess.update_xaxes(tickvals=list(range(len(excess_count_df.columns))))

    fig_ratio = go.Figure()
    if not ratio_df.empty:
        ratio_df_renamed = ratio_df.copy()
        ratio_df_renamed.columns = [date_with_weekday(c) for c in ratio_df_renamed.columns]
        fig_ratio = px.imshow(
            ratio_df_renamed,
            aspect='auto',
            color_continuous_scale='RdBu_r',
            title='ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
            labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ä¸è¶³ç‡'},
        )
        fig_ratio.update_xaxes(tickvals=list(range(len(ratio_df.columns))))

    return html.Div([  # type: ignore
        html.H4('ä¸è¶³äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—'),
        dcc.Graph(figure=fig_lack),
        html.H4('éå‰°äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', style={'marginTop': '30px'}),
        dcc.Graph(figure=fig_excess),
        html.H4('ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', style={'marginTop': '30px'}),
        dcc.Graph(figure=fig_ratio),
    ])


@app.callback(
    Output('opt-detail-container', 'children'),
    Input('opt-scope', 'value')
)
def update_opt_detail(scope):
    """æœ€é©åŒ–åˆ†æã®è©³ç´°é¸æŠã‚’æ›´æ–°"""
    if scope == 'overall':
        return None
    elif scope == 'role':
        roles = data_get('roles', [])
        return html.Div([  # type: ignore
            html.Label("è·ç¨®é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'opt-detail', 'index': 'role'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': r, 'value': r} for r in roles],
                value='ALL',
                style={'width': '300px', 'marginBottom': '20px'}
            )
        ])
    elif scope == 'employment':
        employments = data_get('employments', [])
        return html.Div([  # type: ignore
            html.Label("é›‡ç”¨å½¢æ…‹é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'opt-detail', 'index': 'employment'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': e, 'value': e} for e in employments],
                value='ALL',
                style={'width': '300px', 'marginBottom': '20px'}
            )
        ])
    return None

@app.callback(
    Output('optimization-content', 'children'),
    Input('opt-scope', 'value'),
    Input({'type': 'opt-detail', 'index': ALL}, 'value')
)
def update_optimization_content(scope, detail_values):
    """æœ€é©åŒ–åˆ†æã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›´æ–°"""
    # é¸æŠå†…å®¹ã‹ã‚‰ã‚­ãƒ¼ã‚’çµ„ã¿ç«‹ã¦ã¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’å–å¾—
    key_suffix = ''
    if scope == 'role' and detail_values and detail_values[0] != 'ALL':
        key_suffix = f"role_{safe_filename(detail_values[0])}"
    elif scope == 'employment' and detail_values and detail_values[0] != 'ALL':
        key_suffix = f"emp_{safe_filename(detail_values[0])}"

    heat_key = f"heat_{key_suffix}" if key_suffix else "heat_all"
    df_heat = data_get(heat_key, pd.DataFrame())

    if df_heat.empty:
        return html.Div("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã®æœ€é©åŒ–åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    date_cols = [c for c in df_heat.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    staff_df = df_heat[date_cols]
    need_df = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                           index=df_heat.index, columns=date_cols)
    upper_df = pd.DataFrame(np.repeat(df_heat['upper'].values[:, np.newaxis], len(date_cols), axis=1),
                            index=df_heat.index, columns=date_cols)

    # ä¸è¶³ç‡ãƒ»éå‰°ç‡ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    lack_ratio = ((need_df - staff_df) / need_df.replace(0, np.nan)).clip(lower=0).fillna(0)
    excess_ratio = ((staff_df - upper_df) / upper_df.replace(0, np.nan)).clip(lower=0).fillna(0)

    df_surplus = (staff_df - need_df).clip(lower=0).fillna(0)
    df_margin = (upper_df - staff_df).clip(lower=0).fillna(0)
    df_score = 1 - (0.6 * lack_ratio + 0.4 * excess_ratio).clip(0, 1)

    if not (_valid_df(df_surplus) and _valid_df(df_margin) and _valid_df(df_score)):
        return html.Div("æœ€é©åŒ–åˆ†æãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    surplus_df_renamed = df_surplus.copy()
    surplus_df_renamed.columns = [date_with_weekday(c) for c in surplus_df_renamed.columns]

    margin_df_renamed = df_margin.copy()
    margin_df_renamed.columns = [date_with_weekday(c) for c in margin_df_renamed.columns]

    score_df_renamed = df_score.copy()
    score_df_renamed.columns = [date_with_weekday(c) for c in score_df_renamed.columns]

    content = [
        html.Div([
            html.H4("1. å¿…è¦äººæ•°ã«å¯¾ã™ã‚‹ä½™å‰° (Surplus vs Need)"),
            html.P("å„æ™‚é–“å¸¯ã§å¿…è¦äººæ•°ï¼ˆneedï¼‰ã«å¯¾ã—ã¦ä½•äººå¤šãã‚¹ã‚¿ãƒƒãƒ•ãŒã„ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚"),
            dcc.Graph(
                figure=px.imshow(
                    surplus_df_renamed,
                    aspect='auto',
                    color_continuous_scale='Blues',
                    title='å¿…è¦äººæ•°ã«å¯¾ã™ã‚‹ä½™å‰°äººå“¡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
                    labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ä½™å‰°äººæ•°'},
                ).update_xaxes(tickvals=list(range(len(df_surplus.columns))))
            ),
        ]),
        html.Div([
            html.H4("2. ä¸Šé™ã«å¯¾ã™ã‚‹ä½™ç™½ (Margin to Upper)", style={'marginTop': '30px'}),
            html.P("å„æ™‚é–“å¸¯ã§é…ç½®äººæ•°ã®ä¸Šé™ï¼ˆupperï¼‰ã¾ã§ã‚ã¨ä½•äººã®ä½™è£•ãŒã‚ã£ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚"),
            dcc.Graph(
                figure=px.imshow(
                    margin_df_renamed,
                    aspect='auto',
                    color_continuous_scale='Greens',
                    title='ä¸Šé™äººæ•°ã¾ã§ã®ä½™ç™½ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
                    labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ä½™ç™½äººæ•°'},
                ).update_xaxes(tickvals=list(range(len(df_margin.columns))))
            ),
        ]),
        html.Div([
            html.H4("3. äººå“¡é…ç½® æœ€é©åŒ–ã‚¹ã‚³ã‚¢", style={'marginTop': '30px'}),
            html.P("äººå“¡é…ç½®ã®åŠ¹ç‡æ€§ã‚’0ã‹ã‚‰1ã®ã‚¹ã‚³ã‚¢ã§ç¤ºã—ã¾ã™ï¼ˆ1ãŒæœ€ã‚‚è‰¯ã„ï¼‰ã€‚"),
            dcc.Graph(
                figure=px.imshow(
                    score_df_renamed,
                    aspect='auto',
                    color_continuous_scale='RdYlGn',
                    zmin=0,
                    zmax=1,
                    title='æœ€é©åŒ–ã‚¹ã‚³ã‚¢ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
                    labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ã‚¹ã‚³ã‚¢'},
                ).update_xaxes(tickvals=list(range(len(df_score.columns))))
            ),
        ]),
    ]

    return html.Div(content)


@app.callback(
    Output('overview-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_overview_insights(kpi_data):
    if not kpi_data:
        return ""

    total_lack_h = kpi_data.get('total_lack_h', 0)

    if total_lack_h > 0:
        most_lacking_role = kpi_data.get('most_lacking_role_name', 'N/A')
        most_lacking_hours = kpi_data.get('most_lacking_role_hours', 0)
        insight_text = f"""
        #### ğŸ“ˆ åˆ†æãƒã‚¤ãƒ©ã‚¤ãƒˆ
        - **ç·ä¸è¶³æ™‚é–“:** {total_lack_h:.1f} æ™‚é–“
        - **æœ€é‡è¦èª²é¡Œ:** **{most_lacking_role}** ã®ä¸è¶³ãŒ **{most_lacking_hours:.1f}æ™‚é–“** ã¨æœ€ã‚‚æ·±åˆ»ã§ã™ã€‚ã“ã®è·ç¨®ã®æ¡ç”¨ã¾ãŸã¯é…ç½®è»¢æ›ãŒæ€¥å‹™ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚
        """
        return dcc.Markdown(insight_text)
    return html.P(
        "ğŸ‘ äººå“¡ä¸è¶³ã¯ç™ºç”Ÿã—ã¦ã„ã¾ã›ã‚“ã€‚ç´ æ™´ã‚‰ã—ã„å‹¤å‹™ä½“åˆ¶ã§ã™ï¼",
        style={'fontWeight': 'bold'},  # type: ignore
    )


@app.callback(
    Output('shortage-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_shortage_insights(kpi_data):
    explanation = """
    #### ä¸è¶³åˆ†æã®è©•ä¾¡æ–¹æ³•
    - **ä¸è¶³ (Shortage):** `ä¸è¶³äººæ•° = å¿…è¦äººæ•° (Need) - å®Ÿç¸¾äººæ•°` ã§è¨ˆç®—ã•ã‚Œã¾ã™ã€‚å€¤ãŒãƒ—ãƒ©ã‚¹ã®å ´åˆã€ãã®æ™‚é–“å¸¯ã¯äººå“¡ãŒä¸è¶³ã—ã¦ã„ãŸã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
    - **éå‰° (Excess):** `éå‰°äººæ•° = å®Ÿç¸¾äººæ•° - ä¸Šé™äººæ•° (Upper)` ã§è¨ˆç®—ã•ã‚Œã¾ã™ã€‚å€¤ãŒãƒ—ãƒ©ã‚¹ã®å ´åˆã€éå‰°ãªäººå“¡ãŒé…ç½®ã•ã‚Œã¦ã„ãŸã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚

    *ã€Œå¿…è¦äººæ•°ã€ã¨ã€Œä¸Šé™äººæ•°ã€ã¯ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œåˆ†æåŸºæº–è¨­å®šã€ã§æŒ‡å®šã—ãŸæ–¹æ³•ï¼ˆéå»å®Ÿç¸¾ã®çµ±è¨ˆã€ã¾ãŸã¯äººå“¡é…ç½®åŸºæº–ï¼‰ã«åŸºã¥ã„ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚*
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('hire-plan-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_hire_plan_insights(kpi_data):
    if not kpi_data:
        return ""
    total_lack_h = kpi_data.get('total_lack_h', 0)
    if total_lack_h == 0:
        return html.P("è¿½åŠ æ¡ç”¨ã®å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    role = kpi_data.get('most_lacking_role_name', 'N/A')
    return dcc.Markdown(
        f"æœ€ã‚‚ä¸è¶³ã—ã¦ã„ã‚‹ **{role}** ã®è£œå……ã‚’å„ªå…ˆçš„ã«æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
    )


@app.callback(
    Output('optimization-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_optimization_insights(kpi_data):
    explanation = """
    #### æœ€é©åŒ–åˆ†æã®è©•ä¾¡æ–¹æ³•
    äººå“¡é…ç½®ã®åŠ¹ç‡æ€§ã¯ã€ä»¥ä¸‹ã®2ã¤ã®è¦³ç‚¹ã‹ã‚‰ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’è¨ˆç®—ã—ã€æœ€çµ‚çš„ãªã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—ã¾ã™ã€‚
    - **ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ (é‡ã¿: 60%):** `(å¿…è¦äººæ•° - å®Ÿç¸¾äººæ•°) / å¿…è¦äººæ•°`
    - **éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£ (é‡ã¿: 40%):** `(å®Ÿç¸¾äººæ•° - ä¸Šé™äººæ•°) / ä¸Šé™äººæ•°`

    **æœ€é©åŒ–ã‚¹ã‚³ã‚¢ = 1 - (ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ Ã— 0.6 + éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£ Ã— 0.4)**

    *ã‚¹ã‚³ã‚¢ãŒ1ã«è¿‘ã„ã»ã©ã€ä¸è¶³ã‚‚éå‰°ã‚‚ãªãã€åŠ¹ç‡çš„ãªäººå“¡é…ç½®ãŒã§ãã¦ã„ã‚‹çŠ¶æ…‹ã‚’ç¤ºã—ã¾ã™ã€‚*
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('leave-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_leave_insights(kpi_data):
    explanation = """
    #### ä¼‘æš‡åˆ†æã®è©•ä¾¡æ–¹æ³•
    - **ä¼‘æš‡å–å¾—è€…æ•°:** `holiday_type`ãŒä¼‘æš‡é–¢é€£ï¼ˆå¸Œæœ›ä¼‘ã€æœ‰çµ¦ãªã©ï¼‰ã«è¨­å®šã•ã‚Œã€ã‹ã¤å‹¤å‹™æ™‚é–“ãŒãªã„ï¼ˆ`parsed_slots_count = 0`ï¼‰å ´åˆã«ã€Œ1æ—¥ã€ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã¾ã™ã€‚
    - **é›†ä¸­æ—¥:** ã€Œå¸Œæœ›ä¼‘ã€ã®å–å¾—è€…æ•°ãŒã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ãŸé–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3äººï¼‰ä»¥ä¸Šã«ãªã£ãŸæ—¥ã‚’ã€Œé›†ä¸­æ—¥ã€ã¨ã—ã¦ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¾ã™ã€‚
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('cost-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_cost_insights(kpi_data):
    explanation = """
    #### ã‚³ã‚¹ãƒˆåˆ†æã®è©•ä¾¡æ–¹æ³•
    æ—¥ã€…ã®äººä»¶è²»ã¯ã€å„ã‚¹ã‚¿ãƒƒãƒ•ã®å‹¤å‹™æ™‚é–“ï¼ˆã‚¹ãƒ­ãƒƒãƒˆæ•° Ã— ã‚¹ãƒ­ãƒƒãƒˆé•·ï¼‰ã«ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ãŸå˜ä¾¡åŸºæº–ï¼ˆè·ç¨®åˆ¥ã€é›‡ç”¨å½¢æ…‹åˆ¥ãªã©ï¼‰ã®æ™‚çµ¦ã‚’ä¹—ã˜ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('wage-input-container', 'children'),
    Input('cost-by-radio', 'value')
)
def update_wage_inputs(by_key):
    """å˜ä¾¡å…¥åŠ›æ¬„ã‚’ç”Ÿæˆ"""
    long_df = data_get('long_df')
    if long_df is None or long_df.empty or by_key not in long_df.columns:
        return html.P("å˜ä¾¡è¨­å®šã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    unique_keys: list[str] = sorted(long_df[by_key].dropna().unique())
    inputs = []
    for key in unique_keys:
        inputs.append(html.Div([
            html.Label(f'æ™‚çµ¦: {key}'),
            dcc.Input(
                id={'type': 'wage-input', 'index': key},
                value=1500,
                type='number',
                debounce=True,
            )
        ], style={'padding': '5px', 'display': 'inline-block'}))
    return inputs


@app.callback(
    Output('cost-analysis-content', 'children'),
    Input('cost-by-radio', 'value'),
    Input({'type': 'wage-input', 'index': ALL}, 'value'),
    State({'type': 'wage-input', 'index': ALL}, 'id'),
)
def update_cost_analysis_content(by_key, all_wages, all_wage_ids):
    """å˜ä¾¡å¤‰æ›´ã«å¿œã˜ã¦ã‚³ã‚¹ãƒˆåˆ†æã‚¿ãƒ–ã®å…¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å‹•çš„ã«æ›´æ–°ã™ã‚‹"""
    long_df = data_get('long_df')
    if long_df is None or long_df.empty or not all_wages:
        raise PreventUpdate

    wages = {
        wage_id['index']: (wage_val or 0) for wage_id, wage_val in zip(all_wage_ids, all_wages)
    }

    df_cost = calculate_daily_cost(long_df, wages, by=by_key)
    if df_cost.empty:
        return html.P("ã‚³ã‚¹ãƒˆè¨ˆç®—çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    df_cost['date'] = pd.to_datetime(df_cost['date'])

    if not {'day_of_week', 'total_staff', 'role_breakdown'}.issubset(df_cost.columns):
        details = (
            long_df[long_df.get('parsed_slots_count', 1) > 0]
            .assign(date=lambda x: pd.to_datetime(x['ds']).dt.normalize())
            .groupby('date')
            .agg(
                day_of_week=('ds', lambda x: ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'][x.iloc[0].weekday()]),
                total_staff=('staff', 'nunique'),
                role_breakdown=('role', lambda s: ', '.join(f"{r}:{c}" for r, c in s.value_counts().items())),
            )
            .reset_index()
        )
        df_cost = pd.merge(df_cost, details, on='date', how='left')

    df_cost = df_cost.sort_values('date')

    content = []

    total_cost = df_cost['cost'].sum()
    avg_daily_cost = df_cost['cost'].mean()
    max_cost_day = df_cost.loc[df_cost['cost'].idxmax()]
    summary_cards = html.Div([
        create_metric_card("ç·ã‚³ã‚¹ãƒˆ", f"Â¥{total_cost:,.0f}"),
        create_metric_card("æ—¥å¹³å‡ã‚³ã‚¹ãƒˆ", f"Â¥{avg_daily_cost:,.0f}"),
        create_metric_card("æœ€é«˜ã‚³ã‚¹ãƒˆæ—¥", f"{max_cost_day['date'].strftime('%m/%d')}<br>Â¥{max_cost_day['cost']:,.0f}"),
    ], style={'display': 'flex', 'justifyContent': 'space-around', 'marginBottom': '20px'})
    content.append(summary_cards)

    df_cost['cumulative_cost'] = df_cost['cost'].cumsum()
    fig_cumulative = px.area(df_cost, x='date', y='cumulative_cost', title='ç´¯è¨ˆäººä»¶è²»ã®æ¨ç§»')
    fig_cumulative.update_xaxes(tickformat="%m/%d(%a)")
    content.append(dcc.Graph(figure=fig_cumulative))

    fig_daily = px.bar(df_cost, x='date', y='cost', title='æ—¥åˆ¥ç™ºç”Ÿäººä»¶è²»ï¼ˆç·é¡ï¼‰')
    fig_daily.update_xaxes(tickformat="%m/%d(%a)")
    content.append(dcc.Graph(figure=fig_daily))

    if 'role_breakdown' in df_cost.columns and by_key == 'role':
        role_data = []
        for _, row in df_cost.iterrows():
            if pd.notna(row.get('role_breakdown')):
                date_total_cost = row['cost']
                role_counts = {r.split(':')[0]: int(r.split(':')[1]) for r in row['role_breakdown'].split(', ') if ':' in r}
                total_count = sum(role_counts.values())

                for role, count in role_counts.items():
                    role_cost = (count / total_count) * date_total_cost if total_count > 0 else 0
                    role_data.append({'date': row['date'], 'role': role, 'count': count, 'cost': role_cost})

        if role_data:
            role_df = pd.DataFrame(role_data)

            fig_stacked = px.bar(role_df, x='date', y='cost', color='role', title='æ—¥åˆ¥äººä»¶è²»ï¼ˆè·ç¨®åˆ¥å†…è¨³ï¼‰')
            fig_stacked.update_xaxes(tickformat="%m/%d(%a)")
            content.append(dcc.Graph(figure=fig_stacked))

            role_df['month'] = pd.to_datetime(role_df['date']).dt.to_period('M').astype(str)
            monthly_role = role_df.groupby(['month', 'role'])['cost'].sum().reset_index()
            fig_monthly = px.bar(monthly_role, x='month', y='cost', color='role', title='æœˆæ¬¡äººä»¶è²»ï¼ˆè·ç¨®åˆ¥å†…è¨³ï¼‰')
            content.append(dcc.Graph(figure=fig_monthly))

            total_by_role = role_df.groupby('role')['cost'].sum().reset_index()
            fig_pie = px.pie(total_by_role, values='cost', names='role', title='è·ç¨®åˆ¥ã‚³ã‚¹ãƒˆæ§‹æˆæ¯”ï¼ˆå…¨æœŸé–“ï¼‰')
            fig_pie.update_traces(textposition='inside', textinfo='percent+label')
            content.append(dcc.Graph(figure=fig_pie))

    return html.Div(content)


@app.callback(
    Output('individual-analysis-content', 'children'),
    Input('individual-staff-dropdown', 'value')
)
def update_individual_analysis_content(selected_staff):
    """è·å“¡é¸æŠã«å¿œã˜ã¦åˆ†æã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›´æ–°ã™ã‚‹"""
    if not selected_staff:
        raise PreventUpdate

    # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬ã§èª­ã¿è¾¼ã‚€
    long_df = data_get('long_df', pd.DataFrame())
    fatigue_df = data_get('fatigue_score', pd.DataFrame())
    fairness_df = data_get('fairness_after', pd.DataFrame())
    shortage_df = data_get('shortage_time', pd.DataFrame())
    excess_df = data_get('excess_time', pd.DataFrame())

    if long_df.empty:
        return html.P("å‹¤å‹™ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    staff_df = long_df[long_df['staff'] == selected_staff].copy()

    # --- 1. å‹¤å‹™åŒºåˆ†ã”ã¨ã®å æœ‰å‰²åˆ ---
    work_dist_fig = go.Figure(layout={'title': {'text': f'{selected_staff}ã•ã‚“ã®å‹¤å‹™å‰²åˆ'}})
    if not staff_df.empty and 'code' in staff_df.columns:
        work_records = staff_df[staff_df.get('parsed_slots_count', 1) > 0]
        if not work_records.empty:
            code_counts = work_records['code'].value_counts()
            work_dist_fig = px.pie(
                values=code_counts.values, names=code_counts.index,
                title=f'{selected_staff}ã•ã‚“ã®å‹¤å‹™å‰²åˆ', hole=.3
            )
            work_dist_fig.update_traces(textposition='inside', textinfo='percent+label')

    # --- 2. ä¸å…¬å¹³ãƒ»ç–²åŠ´åº¦ã®è©³ç´°ã‚¹ã‚³ã‚¢ ---
    fatigue_score, unfairness_score = "ãƒ‡ãƒ¼ã‚¿ãªã—", "ãƒ‡ãƒ¼ã‚¿ãªã—"
    score_details_df = pd.DataFrame()
    if not fatigue_df.empty:
        fatigue_df_indexed = fatigue_df.set_index('staff') if 'staff' in fatigue_df.columns else fatigue_df
        if selected_staff in fatigue_df_indexed.index:
            fatigue_score = f"{fatigue_df_indexed.loc[selected_staff, 'fatigue_score']:.1f}"
    if not fairness_df.empty and 'staff' in fairness_df.columns:
        staff_fairness = fairness_df[fairness_df['staff'] == selected_staff]
        if not staff_fairness.empty:
            row = staff_fairness.iloc[0]
            unfairness_score = f"{row.get('unfairness_score', 0):.2f}"
            details_data = {
                "æŒ‡æ¨™": ["å¤œå‹¤æ¯”ç‡ã®ä¹–é›¢", "ç·åŠ´åƒæ™‚é–“ã®ä¹–é›¢", "å¸Œæœ›ä¼‘æ‰¿èªç‡ã®ä¹–é›¢", "é€£ä¼‘å–å¾—é »åº¦ã®ä¹–é›¢"],
                "ã‚¹ã‚³ã‚¢": [f"{row.get(col, 0):.2f}" for col in ['dev_night_ratio', 'dev_work_slots', 'dev_approval_rate', 'dev_consecutive']]
            }
            score_details_df = pd.DataFrame(details_data)

    # --- 3. å…±åƒã—ãŸè·å“¡ãƒ©ãƒ³ã‚­ãƒ³ã‚° ---
    coworker_ranking_df = pd.DataFrame()
    my_slots = staff_df[['ds']].drop_duplicates()
    coworkers = long_df[long_df['ds'].isin(my_slots['ds']) & (long_df['staff'] != selected_staff)]
    if not coworkers.empty:
        coworker_counts = coworkers['staff'].value_counts().reset_index()
        coworker_counts.columns = ['è·å“¡', 'å…±åƒå›æ•°']
        coworker_ranking_df = coworker_counts.head(5)

    # --- 4. äººå“¡ä¸è¶³/éå‰°ã¸ã®è²¢çŒ®åº¦åˆ†æ ---
    slot_hours = 0.5
    shortage_contribution_h, excess_contribution_h = 0, 0
    staff_work_slots = staff_df[staff_df.get('parsed_slots_count', 0) > 0][['ds']].copy()
    staff_work_slots['date_str'] = staff_work_slots['ds'].dt.strftime('%Y-%m-%d')
    staff_work_slots['time'] = staff_work_slots['ds'].dt.strftime('%H:%M')
    if not shortage_df.empty:
        shortage_long = shortage_df.melt(var_name='date_str', value_name='shortage_count', ignore_index=False).reset_index().rename(columns={'index':'time'})
        merged_shortage = pd.merge(staff_work_slots, shortage_long, on=['date_str', 'time'])
        shortage_contribution_h = merged_shortage[merged_shortage['shortage_count'] > 0].shape[0] * slot_hours
    if not excess_df.empty:
        excess_long = excess_df.melt(var_name='date_str', value_name='excess_count', ignore_index=False).reset_index().rename(columns={'index':'time'})
        merged_excess = pd.merge(staff_work_slots, excess_long, on=['date_str', 'time'])
        excess_contribution_h = merged_excess[merged_excess['excess_count'] > 0].shape[0] * slot_hours

    # --- 5. å€‹äººã®ä¼‘æš‡å–å¾—å‚¾å‘ ---
    leave_by_dow_fig = go.Figure(layout={'title': {'text': 'æ›œæ—¥åˆ¥ã®ä¼‘æš‡å–å¾—æ—¥æ•°'}})
    staff_leave_df = staff_df[staff_df.get('holiday_type', 'é€šå¸¸å‹¤å‹™') != 'é€šå¸¸å‹¤å‹™']
    if not staff_leave_df.empty:
        daily_leave = leave_analyzer.get_daily_leave_counts(staff_leave_df)
        if not daily_leave.empty:
            dow_summary = leave_analyzer.summarize_leave_by_day_count(daily_leave, period='dayofweek')
            if not dow_summary.empty:
                leave_by_dow_fig = px.bar(dow_summary, x='period_unit', y='total_leave_days', color='leave_type', title=f'{selected_staff}ã•ã‚“ã®æ›œæ—¥åˆ¥ä¼‘æš‡å–å¾—æ—¥æ•°')
                leave_by_dow_fig.update_xaxes(title_text="æ›œæ—¥").update_yaxes(title_text="æ—¥æ•°")

    # --- 6. è·å“¡é–“ã®ã€ŒåŒ–å­¦åå¿œã€åˆ†æ ---
    synergy_fig = go.Figure(layout={'title': {'text': f'{selected_staff}ã•ã‚“ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼åˆ†æ'}})
    if not shortage_df.empty:  # ä¸è¶³ãƒ‡ãƒ¼ã‚¿ãŒãªã„ã¨è¨ˆç®—ã§ããªã„ãŸã‚ã‚¬ãƒ¼ãƒ‰
        synergy_df = analyze_synergy(long_df, shortage_df, selected_staff)
        if not synergy_df.empty:
            synergy_df_top5 = synergy_df.head(5)
            synergy_df_worst5 = synergy_df.tail(5).sort_values("ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢", ascending=True)
            synergy_display_df = pd.concat([synergy_df_top5, synergy_df_worst5])
            synergy_fig = px.bar(
                synergy_display_df, x="ç›¸æ‰‹ã®è·å“¡", y="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢", color="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢",
                color_continuous_scale='RdYlGn', title=f"{selected_staff}ã•ã‚“ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ (Top5 & Worst5)"
            )
            synergy_fig.update_layout(xaxis_title="ç›¸æ‰‹ã®è·å“¡", yaxis_title="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰")

    # --- 7 & 8. åƒãæ–¹ã®ã‚¯ã‚»åˆ†æ ---
    mannelido_score, rhythm_score = "è¨ˆç®—ä¸å¯", "è¨ˆç®—ä¸å¯"
    work_records_for_role = staff_df[staff_df.get('parsed_slots_count', 0) > 0]
    if not work_records_for_role.empty:
        role_per_day = work_records_for_role[['ds', 'role']].copy()
        role_per_day['date'] = role_per_day['ds'].dt.date
        role_counts = role_per_day.drop_duplicates(subset=['date', 'role'])['role'].value_counts(normalize=True)
        if not role_counts.empty:
            mannelido_score = f"{role_counts.max():.2f}"

        daily_starts = work_records_for_role.groupby(work_records_for_role['ds'].dt.date)['ds'].min()
        if len(daily_starts) > 1:
            start_hours = daily_starts.dt.hour + daily_starts.dt.minute / 60.0
            rhythm_score = f"{start_hours.std():.2f}"
        else:
            rhythm_score = "0.00"

    # --- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®çµ„ã¿ç«‹ã¦ ---
    layout = html.Div([
        html.Div([
            html.Div([
                html.H4("ç–²åŠ´åº¦ãƒ»ä¸å…¬å¹³æ„Ÿãƒ»åƒãæ–¹ã®ã‚¯ã‚»"),
                create_metric_card("ç–²åŠ´ã‚¹ã‚³ã‚¢", fatigue_score, color="#ff7f0e"),
                create_metric_card("ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢", unfairness_score, color="#d62728"),
                create_metric_card("æ¥­å‹™ãƒãƒ³ãƒãƒªåº¦", mannelido_score, color="#9467bd"),
                create_metric_card("ç”Ÿæ´»ãƒªã‚ºãƒ ç ´å£Šåº¦", rhythm_score, color="#8c564b"),
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top', 'paddingRight': '1%'}),
            html.Div([
                html.H5("ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢ã®å†…è¨³"),
                dash_table.DataTable(
                    data=score_details_df.to_dict('records'),
                    columns=[{'name': i, 'id': i} for i in score_details_df.columns],
                ) if not score_details_df.empty else html.P("è©³ç´°ãƒ‡ãƒ¼ã‚¿ãªã—")
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top', 'paddingRight': '1%'}),
            html.Div([
                html.H5("å…±åƒãƒ©ãƒ³ã‚­ãƒ³ã‚° Top 5"),
                dash_table.DataTable(
                    data=coworker_ranking_df.to_dict('records'),
                    columns=[{'name': i, 'id': i} for i in coworker_ranking_df.columns],
                ) if not coworker_ranking_df.empty else html.P("å…±åƒãƒ‡ãƒ¼ã‚¿ãªã—"),
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top', 'paddingRight': '1%'}),
            html.Div([
                html.H5("ä¸è¶³/éå‰°ã¸ã®è²¢çŒ®åº¦"),
                create_metric_card("ä¸è¶³æ™‚é–“å¸¯ã§ã®å‹¤å‹™ (h)", f"{shortage_contribution_h:.1f}", color="#c53d40"),
                create_metric_card("éå‰°æ™‚é–“å¸¯ã§ã®å‹¤å‹™ (h)", f"{excess_contribution_h:.1f}", color="#1f77b4"),
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top'}),
        ], style={'marginBottom': '20px'}),
        html.Div([
            html.Div([dcc.Graph(figure=work_dist_fig)], style={'width': '49%', 'display': 'inline-block'}),
            html.Div([dcc.Graph(figure=leave_by_dow_fig)], style={'width': '49%', 'display': 'inline-block'}),
        ]),
        html.Div([
            html.H4("è·å“¡é–“ã®\u300cåŒ–å­¦åå¿œ\u300dåˆ†æ", style={'marginTop': '20px'}),
            html.P("ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ã¯ã€ãã®ãƒšã‚¢ãŒä¸€ç·’ã«å‹¤å‹™ã—ãŸéš›ã®\u300cäººå“¡ä¸è¶³ã®èµ·ã“ã‚Šã«ãã•\u300dã‚’ç¤ºã—ã¾ã™ã€‚ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©ã€ä¸è¶³ãŒå°‘ãªããªã‚‹è‰¯ã„çµ„ã¿åˆã‚ã›ã§ã™ã€‚"),
            dcc.Graph(figure=synergy_fig)
        ])
    ])

    return layout


@app.callback(
    Output('team-criteria-value-dropdown', 'options'),
    Input('team-criteria-key-dropdown', 'value')
)
def update_team_value_options(selected_key):
    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty or not selected_key:
        return []
    options = sorted(long_df[selected_key].unique())
    return [{'label': opt, 'value': opt} for opt in options]


@app.callback(
    Output('team-analysis-content', 'children'),
    Input('team-criteria-value-dropdown', 'value'),
    State('team-criteria-key-dropdown', 'value')
)
def update_team_analysis_graphs(selected_value, selected_key):
    if not selected_value or not selected_key:
        raise PreventUpdate

    long_df = data_get('long_df', pd.DataFrame())
    fatigue_df = data_get('fatigue_score', pd.DataFrame())
    fairness_df = data_get('fairness_after', pd.DataFrame())

    team_criteria = {selected_key: selected_value}
    team_df = analyze_team_dynamics(long_df, fatigue_df, fairness_df, team_criteria)

    if team_df.empty:
        return html.P("ã“ã®æ¡ä»¶ã«åˆè‡´ã™ã‚‹ãƒãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    fig_fatigue = px.line(
        team_df,
        y=['avg_fatigue', 'std_fatigue'],
        title=f"ãƒãƒ¼ãƒ ã€Œ{selected_value}ã€ã®ç–²åŠ´åº¦ã‚¹ã‚³ã‚¢æ¨ç§»"
    )
    fig_fairness = px.line(
        team_df,
        y=['avg_unfairness', 'std_unfairness'],
        title=f"ãƒãƒ¼ãƒ ã€Œ{selected_value}ã€ã®ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢æ¨ç§»"
    )

    return html.Div([
        html.H4(f"ãƒãƒ¼ãƒ ã€Œ{selected_value}ã€ã®åˆ†æçµæœ"),
        dcc.Graph(figure=fig_fatigue),
        dcc.Graph(figure=fig_fairness)
    ])


@app.callback(
    Output('blueprint-analysis-content', 'children'),
    Input('generate-blueprint-button', 'n_clicks')
)
def update_blueprint_analysis_content(n_clicks):
    if n_clicks == 0:
        raise PreventUpdate

    long_df = data_get('long_df', pd.DataFrame())

    if long_df.empty:
        return html.Div([
            html.H4("ã‚¨ãƒ©ãƒ¼", style={'color': 'red'}),
            html.P("åˆ†æã«å¿…è¦ãªå‹¤å‹™ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        ])

    score_df = create_scored_blueprint(long_df)
    tradeoff_info = analyze_tradeoffs(score_df)

    if score_df.empty:
        return html.Div([html.P("åˆ†æã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")])

    scatter_df = pd.DataFrame(tradeoff_info.get("scatter_data", []))
    fig = px.scatter(
        scatter_df,
        x="fairness_score",
        y="cost_score",
        hover_data=["date"],
        title="Fairness vs Cost"
    )

    corr_df = pd.DataFrame(tradeoff_info.get("correlation_matrix", {}))
    corr_table = dash_table.DataTable(
        data=corr_df.round(2).reset_index().rename(columns={"index": "score"}).to_dict("records"),
        columns=[{"name": c, "id": c} for c in corr_df.reset_index().rename(columns={"index": "score"}).columns],
    ) if not corr_df.empty else html.P("ç›¸é–¢ãƒ‡ãƒ¼ã‚¿ãªã—")

    tradeoff_div = html.Div([
        dcc.Graph(figure=fig),
        html.H4("Correlation Matrix"),
        corr_table,
    ])

    summary_items = [html.Li(f"{k}: {v:.2f}") for k, v in tradeoff_info.get("strongest_tradeoffs", {}).items()]
    summary_div = html.Div([
        html.H4("Strongest Trade-offs"),
        html.Ul(summary_items) if summary_items else html.P("ãªã—")
    ])

    return html.Div([
        tradeoff_div,
        html.Hr(),
        summary_div
    ])


@app.callback(
    Output('sim-shortage-graph', 'figure'),
    Output('sim-cost-text', 'children'),
    Input('sim-work-pattern-dropdown', 'value'),
    Input('sim-hire-fte-slider', 'value'),
    State('kpi-data-store', 'data'),
)
def update_hire_simulation(selected_pattern, added_fte, kpi_data):
    if not kpi_data or not selected_pattern:
        raise PreventUpdate

    from shift_suite.tasks.h2hire import (
        AVG_HOURLY_WAGE,
        RECRUIT_COST_PER_HIRE,
    )

    df_work_patterns = data_get('work_patterns', pd.DataFrame())
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame()).copy()

    pattern_info = df_work_patterns[df_work_patterns['code'] == selected_pattern]
    if pattern_info.empty:
        raise PreventUpdate
    slots_per_day = pattern_info['parsed_slots_count'].iloc[0]
    hours_per_day = slots_per_day * 0.5
    reduction_hours = added_fte * hours_per_day * 20

    if not df_shortage_role.empty:
        most_lacking_role_index = df_shortage_role['lack_h'].idxmax()
        original_hours = df_shortage_role.loc[most_lacking_role_index, 'lack_h']
        df_shortage_role.loc[most_lacking_role_index, 'lack_h'] = max(0, original_hours - reduction_hours)

    fig = px.bar(
        df_shortage_role,
        x='role',
        y='lack_h',
        title=f'ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¾Œ: {selected_pattern}å‹¤å‹™è€…ã‚’{added_fte}äººè¿½åŠ æ¡ç”¨ã—ãŸå ´åˆã®æ®‹å­˜ä¸è¶³æ™‚é–“',
        labels={'lack_h': 'æ®‹å­˜ä¸è¶³æ™‚é–“(h)'},
    )

    new_total_lack_h = df_shortage_role['lack_h'].sum()
    original_total_lack_h = kpi_data.get('total_lack_h', 0)

    cost_before = original_total_lack_h * 2200
    cost_after_temp = new_total_lack_h * 2200

    added_labor_cost = reduction_hours * AVG_HOURLY_WAGE
    added_recruit_cost = added_fte * RECRUIT_COST_PER_HIRE
    cost_after_hire = cost_after_temp + added_labor_cost + added_recruit_cost

    cost_text = f"""
    #### ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
    - **æ¡ç”¨ã‚³ã‚¹ãƒˆ:** {added_recruit_cost:,.0f} å†† (ä¸€æ™‚)
    - **è¿½åŠ äººä»¶è²»:** {added_labor_cost:,.0f} å†† (æœŸé–“ä¸­)
    - **ç·ã‚³ã‚¹ãƒˆ (æ¡ç”¨ã‚·ãƒŠãƒªã‚ª):** {cost_after_hire:,.0f} å††
    - **æ¯”è¼ƒ (å…¨ã¦æ´¾é£ã§è£œå¡«ã—ãŸå ´åˆ):** {cost_before:,.0f} å††
    """

    return fig, dcc.Markdown(cost_text)


@app.callback(
    Output('factor-output', 'children'),
    Input('factor-train-button', 'n_clicks')
)
def run_factor_analysis(n_clicks):
    if not n_clicks:
        raise PreventUpdate

    heat_df = data_get('heat_ALL')
    short_df = data_get('shortage_time')
    leave_df = data_get('leave_analysis')

    if heat_df is None or heat_df.empty or short_df is None or short_df.empty:
        return html.Div('å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“')

    analyzer = ShortageFactorAnalyzer()
    feat_df = analyzer.generate_features(pd.DataFrame(), heat_df, short_df, leave_df, set())
    model, fi_df = analyzer.train_and_get_feature_importance(feat_df)
    DATA_CACHE['factor_features'] = feat_df
    DATA_CACHE['factor_importance'] = fi_df

    table = dash_table.DataTable(
        data=fi_df.head(5).to_dict('records'),
        columns=[{'name': c, 'id': c} for c in fi_df.columns]
    )
    return html.Div([html.H5('å½±éŸ¿åº¦ã®é«˜ã„è¦å›  ãƒˆãƒƒãƒ—5'), table])  # type: ignore


def generate_lightweight_tree_visualization(tree_model):
    """Generate a small decision tree visualisation."""
    if not tree_model or not hasattr(tree_model, 'tree_'):
        return html.P('æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚')

    try:
        buf = io.BytesIO()
        fig, ax = plt.subplots(figsize=(12, 6))
        plot_tree(
            tree_model,
            filled=True,
            feature_names=tree_model.feature_names_in_[:20],
            max_depth=2,
            fontsize=8,
            ax=ax,
            impurity=False,
            proportion=True,
        )
        fig.savefig(buf, format='png', dpi=72, bbox_inches='tight')
        plt.close(fig)
        buf.seek(0)
        encoded = base64.b64encode(buf.getvalue()).decode()
        return html.Img(
            src=f"data:image/png;base64,{encoded}",
            style={'width': '100%', 'maxWidth': '1000px'},
        )
    except Exception as exc:  # noqa: BLE001
        log.error(f'æ±ºå®šæœ¨å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {exc}')
        return html.P(f'æ±ºå®šæœ¨ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}')


def generate_results_display(full_results):
    """Create the final display for logic analysis results."""
    mind_results = full_results.get('mind_reading', {})

    if 'error' in mind_results:
        return html.Div(f"åˆ†æã‚¨ãƒ©ãƒ¼: {mind_results['error']}", style={'color': 'red'})

    importance_df = pd.DataFrame(mind_results.get('feature_importance', []))
    fig_bar = px.bar(
        importance_df.sort_values('importance', ascending=False).head(15),
        x='importance',
        y='feature',
        orientation='h',
        title='åˆ¤æ–­åŸºæº–ã®é‡è¦åº¦ï¼ˆTOP15ï¼‰',
    )

    tree_content = generate_lightweight_tree_visualization(
        mind_results.get('thinking_process_tree')
    )

    return html.Div([
        html.H4('åˆ†æå®Œäº†ï¼'),
        html.Hr(),
        html.H4('åˆ¤æ–­åŸºæº–ã®é‡è¦åº¦'),
        html.P('ä½œæˆè€…ãŒã©ã®è¦ç´ ã‚’é‡è¦–ã—ã¦ã„ã‚‹ã‹ã‚’æ•°å€¤åŒ–ã—ãŸã‚‚ã®ã§ã™ã€‚'),
        dcc.Graph(figure=fig_bar),
        html.H4('æ€è€ƒãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ', style={'marginTop': '30px'}),
        html.P('é…ç½®ã‚’æ±ºå®šã™ã‚‹éš›ã®æ€è€ƒã®åˆ†å²ã‚’æ¨¡å€£ã—ãŸã‚‚ã®ã§ã™ã€‚'),
        tree_content,
    ])


@app.callback(
    Output('save-log-msg', 'children'),
    Input('save-log-button', 'n_clicks'),
    State('over-shortage-table', 'data'),
    State('log-save-mode', 'value')
)
def save_over_shortage_log(n_clicks, table_data, mode):
    if not n_clicks:
        raise PreventUpdate

    log_path = data_get('shortage_log_path')
    if not log_path:
        return 'ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'  # type: ignore

    df = pd.DataFrame(table_data)
    over_shortage_log.save_log(df, log_path, mode=mode)
    return 'ãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ'


@app.callback(Output('log-viewer', 'value'), Input('log-interval', 'n_intervals'))
def update_log_viewer(n):
    """ãƒ­ã‚°ãƒãƒƒãƒ•ã‚¡ã®å†…å®¹ã‚’å®šæœŸçš„ã«æ›´æ–°"""
    log_stream.seek(0)
    return log_stream.read()


@app.callback(
    Output('creation-logic-results', 'children'),
    Output('full-analysis-store', 'data'),
    Input('analyze-creation-logic-button', 'n_clicks'),
    State('analysis-detail-level', 'value'),
    prevent_initial_call=True,
)
def update_logic_analysis_immediate(n_clicks, detail_level):
    """Show basic results immediately and start deep analysis."""

    if not n_clicks:
        raise PreventUpdate

    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty:
        return html.Div('åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚', style={'color': 'red'}), None

    basic_stats = get_basic_shift_stats(long_df)
    quick_patterns = get_quick_patterns(long_df.head(500))

    immediate_results = html.Div([
        html.H4('âœ… åŸºæœ¬åˆ†æå®Œäº†ï¼ˆè©³ç´°åˆ†æå®Ÿè¡Œä¸­...ï¼‰', style={'color': 'green'}),
        html.Hr(),
        html.Div([
            html.H5('ğŸ“Š ã‚·ãƒ•ãƒˆã®åŸºæœ¬çµ±è¨ˆ'),
            create_stats_cards(basic_stats),
        ]),
        html.Div([
            html.H5('ğŸ” ç™ºè¦‹ã•ã‚ŒãŸä¸»è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆç°¡æ˜“ç‰ˆï¼‰'),
            create_pattern_list(quick_patterns),
        ], style={'marginTop': '20px'}),
        html.Div([
            html.H5('ğŸ§  AIã«ã‚ˆã‚‹æ·±å±¤åˆ†æ'),
            dcc.Loading(id='deep-analysis-loading', children=html.Div(id='deep-analysis-results'), type='circle'),
        ], style={'marginTop': '30px'}),
        dcc.Interval(id='background-trigger', interval=100, n_intervals=0, max_intervals=1),
    ])

    return immediate_results, {'status': 'pending', 'level': detail_level}


@app.callback(
    Output('deep-analysis-results', 'children'),
    Input('background-trigger', 'n_intervals'),
    State('analysis-detail-level', 'value'),
    prevent_initial_call=True,
)
def run_deep_analysis_background(n_intervals, detail_level):
    """Run deeper analysis in the background."""

    if n_intervals == 0:
        raise PreventUpdate

    long_df = data_get('long_df', pd.DataFrame())
    results = run_optimized_analysis(long_df, detail_level)

    return create_deep_analysis_display(results)


@app.callback(
    Output('progress-bar', 'figure'),
    Output('progress-message', 'children'),
    Input('logic-analysis-interval', 'n_intervals'),
    State('logic-analysis-progress', 'data'),
    prevent_initial_call=True,
)
def update_progress_bar(n_intervals, progress_data):
    """Update the progress bar display."""
    if not progress_data:
        raise PreventUpdate

    progress = progress_data.get('progress', 0)
    stage = progress_data.get('stage', 'loading')

    messages = {
        'loading': 'ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...',
        'analyzing': 'ã‚·ãƒ•ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã¦ã„ã¾ã™...',
        'visualizing': 'çµæœã‚’å¯è¦–åŒ–ã—ã¦ã„ã¾ã™...',
    }

    figure = {
        'data': [{
            'x': [progress],
            'y': ['Progress'],
            'type': 'bar',
            'orientation': 'h',
            'marker': {'color': '#1f77b4'},
        }],
        'layout': {
            'xaxis': {'range': [0, 100], 'title': 'é€²æ—ç‡ (%)'},
            'yaxis': {'visible': False},
            'height': 100,
            'margin': {'l': 0, 'r': 0, 't': 30, 'b': 30},
        },
    }

    return figure, messages.get(stage, 'å‡¦ç†ä¸­...')



# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹• ---
if __name__ == '__main__':
    app.run_server(debug=True, port=8050, host='127.0.0.1')
