# dash_app.py - Shift-Suiteé«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢ (app.pyæ©Ÿèƒ½å®Œå…¨å†ç¾ç‰ˆ)
import base64
import io
import json
import logging
import tempfile
import zipfile
import threading
import time
import weakref
import psutil
import os
from functools import lru_cache, wraps
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from collections import OrderedDict
import unicodedata

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ©Ÿèƒ½åˆ‡ã‚Šåˆ†ã‘è¨­å®š
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# True: é«˜åº¦æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–, False: åŸºæœ¬æ©Ÿèƒ½ã®ã¿
ENABLE_ADVANCED_FEATURES = True  # é«˜åº¦äºˆæ¸¬ãƒ»å­£ç¯€æ€§åˆ†æãƒ»ç–²åŠ´äºˆæ¸¬ãƒ»é›¢è·äºˆæ¸¬ã‚’æœ‰åŠ¹åŒ–

import dash
import dash_cytoscape as cyto
import numpy as np
import pandas as pd
import pyarrow.parquet as pq

import plotly.express as px
import plotly.graph_objects as go
from dash import dash_table, dcc, html
from dash.dependencies import Input, Output, State, ALL
from dash.exceptions import PreventUpdate
from flask import jsonify
import traceback
import gc
from shift_suite.tasks.utils import safe_read_excel, gen_labels
from shift_suite.tasks.shortage_factor_analyzer import ShortageFactorAnalyzer
from shift_suite.tasks import over_shortage_log
from shift_suite.tasks.daily_cost import calculate_daily_cost
from shift_suite.tasks import leave_analyzer
try:
    from shift_suite.tasks.analyzers.synergy_enhanced import (
        analyze_synergy, analyze_team_synergy, analyze_synergy_by_role, 
        analyze_all_roles_synergy, create_synergy_correlation_matrix, 
        create_synergy_correlation_matrix_optimized
    )
except ImportError:
    from shift_suite.tasks.analyzers.synergy import analyze_synergy
    analyze_team_synergy = None
    analyze_synergy_by_role = None
    analyze_all_roles_synergy = None
    create_synergy_correlation_matrix = None
    create_synergy_correlation_matrix_optimized = None
from shift_suite.tasks.analyzers.team_dynamics import analyze_team_dynamics
from shift_suite.tasks.blueprint_analyzer import create_blueprint_list
from shift_suite.tasks.integrated_creation_logic_viewer import (
    create_creation_logic_analysis_tab,
)
from shift_suite.tasks.quick_logic_analysis import (
    get_basic_shift_stats,
    get_quick_patterns,
    run_optimized_analysis,
    create_stats_cards,
    create_pattern_list,
    create_deep_analysis_display,
)
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

def create_shortage_from_heat_all(heat_all_df: pd.DataFrame) -> pd.DataFrame:
    """
    heat_ALLãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸è¶³ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹
    """
    if heat_all_df.empty:
        return pd.DataFrame()
    
    # æ—¥ä»˜åˆ—ã‚’ç‰¹å®šï¼ˆæ•°å€¤ã§ãªã„åˆ—ã¯é™¤å¤–ï¼‰
    date_columns = [col for col in heat_all_df.columns if col not in ['staff', 'role', 'code', 'sum', 'max', 'min', 'avg', 'need']]
    
    if not date_columns:
        return pd.DataFrame()
    
    # æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    time_index = heat_all_df.index
    
    # å„æ—¥ä»˜ãƒ»æ™‚é–“å¸¯ã®ä¸è¶³ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    shortage_data = {}
    for date_col in date_columns:
        if date_col in heat_all_df.columns:
            # å®Ÿéš›ã®äººæ•°ã‹ã‚‰å¿…è¦äººæ•°ã‚’å¼•ã„ã¦ä¸è¶³ã‚’è¨ˆç®—
            # æ­£ã®å€¤ã¯ä¸è¶³ã€è² ã®å€¤ã¯éå‰°
            actual_staff = heat_all_df[date_col].fillna(0)
            if 'need' in heat_all_df.columns:
                need = heat_all_df['need'].fillna(0)
                shortage = need - actual_staff
            else:
                # needãŒãªã„å ´åˆã¯ã€å¹³å‡å€¤ã‚’åŸºæº–ã¨ã™ã‚‹
                avg_staff = actual_staff.mean()
                shortage = avg_staff - actual_staff
            
            # ä¸è¶³ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹ï¼ˆæ­£ã®å€¤ã®ã¿ï¼‰
            shortage = shortage.clip(lower=0)
            shortage_data[date_col] = shortage
    
    if not shortage_data:
        return pd.DataFrame()
    
    shortage_df = pd.DataFrame(shortage_data, index=time_index)
    return shortage_df

def simple_synergy_analysis(long_df: pd.DataFrame, target_staff: str) -> pd.DataFrame:
    """
    ã‚·ãƒ³ãƒ—ãƒ«ãªã‚·ãƒŠã‚¸ãƒ¼åˆ†æï¼ˆshortage_dfã‚’ä½¿ã‚ãªã„ç‰ˆï¼‰
    å…±åƒé »åº¦ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ç›¸é–¢ã«åŸºã¥ãåˆ†æ
    """
    if long_df.empty or not target_staff:
        return pd.DataFrame()
    
    # å¯¾è±¡è·å“¡ã®å‹¤å‹™è¨˜éŒ²
    target_work = long_df[long_df['staff'] == target_staff]
    if target_work.empty:
        return pd.DataFrame()
    
    # ä»–ã®è·å“¡ã¨ã®å…±åƒåˆ†æ
    synergy_scores = []
    other_staff = long_df[long_df['staff'] != target_staff]['staff'].unique()
    
    for coworker in other_staff:
        coworker_work = long_df[long_df['staff'] == coworker]
        if coworker_work.empty:
            continue
        
        # å…±åƒã—ãŸæ—¥æ™‚ã‚’ç‰¹å®š
        target_slots = set(target_work['ds'])
        coworker_slots = set(coworker_work['ds'])
        together_slots = target_slots & coworker_slots
        
        if len(together_slots) < 2:  # æœ€ä½é™ã®å…±åƒå›æ•°
            continue
        
        # å…±åƒé »åº¦ã®è¨ˆç®—
        total_target_slots = len(target_slots)
        together_ratio = len(together_slots) / total_target_slots if total_target_slots > 0 else 0
        
        # ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆå…±åƒé »åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
        # ã‚ˆã‚Šå¤šãä¸€ç·’ã«åƒã = ã‚ˆã‚Šè‰¯ã„ç›¸æ€§ã¨ä»®å®š
        synergy_score = together_ratio * 100  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸
        
        synergy_scores.append({
            "ç›¸æ‰‹ã®è·å“¡": coworker,
            "ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢": synergy_score,
            "å…±åƒã‚¹ãƒ­ãƒƒãƒˆæ•°": len(together_slots)
        })
    
    if not synergy_scores:
        return pd.DataFrame()
    
    result_df = pd.DataFrame(synergy_scores).sort_values("ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢", ascending=False).reset_index(drop=True)
    return result_df

# ãƒ­ã‚¬ãƒ¼è¨­å®š
LOG_LEVEL = logging.DEBUG
log_stream = io.StringIO()

logging.basicConfig(
    level=LOG_LEVEL,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.StreamHandler(stream=log_stream)
    ],
    force=True
)
log = logging.getLogger(__name__)

# Analysis logger configuration
analysis_logger = logging.getLogger('analysis')
analysis_logger.setLevel(logging.INFO)
analysis_logger.propagate = False
try:
    file_handler = logging.FileHandler('analysis_log.log', mode='a', encoding='utf-8')
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - [%(module)s.%(funcName)s] - %(message)s')
    file_handler.setFormatter(formatter)
    if not analysis_logger.handlers:
        analysis_logger.addHandler(file_handler)
except Exception as e:
    logging.error(f"\u5206\u6790\u30ed\u30b0\u30d5\u30a1\u30a4\u30eb\u306e\u8a2d\u5b9a\u306b\u5931\u6557\u3057\u307e\u3057\u305f: {e}")

# Dashã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
app = dash.Dash(__name__, suppress_callback_exceptions=True)
server = app.server
app.title = "Shift-Suite é«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢"

# Flask error handlers
@server.errorhandler(Exception)
def handle_exception(e):
    """Catch all unhandled exceptions."""
    log.exception("Unhandled exception in request:")
    error_info = {
        "error": str(e),
        "type": type(e).__name__,
        "traceback": traceback.format_exc(),
    }
    return jsonify(error_info), 200


@server.errorhandler(500)
def handle_500(e):
    log.error("500 error occurred")
    return jsonify({"error": "Internal server error", "message": str(e)}), 200

# === ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ç®¡ç†ï¼ˆå®‰å®šæ€§å‘ä¸Šç‰ˆï¼‰ ===
# ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªLRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å®Ÿè£…
class ThreadSafeLRUCache:
    """ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªLRUã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Ÿè£…"""
    def __init__(self, maxsize: int = 50):
        self._cache = OrderedDict()
        self._lock = threading.RLock()
        self._maxsize = maxsize
        self._hits = 0
        self._misses = 0
        
    def get(self, key: str, default=None):
        with self._lock:
            if key in self._cache:
                # LRU: æœ€è¿‘ä½¿ç”¨ã—ãŸã‚‚ã®ã‚’æœ«å°¾ã«ç§»å‹•
                self._cache.move_to_end(key)
                self._hits += 1
                return self._cache[key]
            self._misses += 1
            return default
            
    def set(self, key: str, value: Any):
        with self._lock:
            if key in self._cache:
                del self._cache[key]
            self._cache[key] = value
            # ã‚µã‚¤ã‚ºåˆ¶é™ã‚’è¶…ãˆãŸã‚‰æœ€ã‚‚å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
            if len(self._cache) > self._maxsize:
                oldest_key = next(iter(self._cache))
                del self._cache[oldest_key]
                log.debug(f"Cache evicted: {oldest_key}")
                
    def clear(self):
        with self._lock:
            self._cache.clear()
            self._hits = 0
            self._misses = 0
            
    def get_path(self, key: str):
        """ãƒ‘ã‚¹å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰"""
        return self.get(key)
    
    def get_stats(self):
        with self._lock:
            total = self._hits + self._misses
            hit_rate = self._hits / total if total > 0 else 0
            return {
                "size": len(self._cache),
                "hits": self._hits,
                "misses": self._misses,
                "hit_rate": hit_rate
            }
            
    def __contains__(self, key):
        with self._lock:
            return key in self._cache
            
    def keys(self):
        with self._lock:
            return list(self._cache.keys())

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ­ãƒƒã‚¯
DATA_CACHE = ThreadSafeLRUCache(maxsize=50)

# ã‚·ãƒŠã‚¸ãƒ¼åˆ†æçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
SYNERGY_CACHE = ThreadSafeLRUCache(maxsize=10)

def get_synergy_cache_key(long_df: pd.DataFrame, shortage_df: pd.DataFrame) -> str:
    """ã‚·ãƒŠã‚¸ãƒ¼åˆ†æçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
    try:
        # ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã¨ã™ã‚‹
        import hashlib
        long_hash = hashlib.md5(str(long_df.shape).encode() + str(long_df.columns.tolist()).encode()).hexdigest()[:8]
        shortage_hash = hashlib.md5(str(shortage_df.shape).encode() + str(shortage_df.columns.tolist()).encode()).hexdigest()[:8]
        return f"synergy_{long_hash}_{shortage_hash}"
    except:
        return "synergy_default"

def clear_synergy_cache():
    """ã‚·ãƒŠã‚¸ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
    global SYNERGY_CACHE
    SYNERGY_CACHE.clear()
    log.info("ã‚·ãƒŠã‚¸ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
LOADING_STATUS = {}  # èª­ã¿è¾¼ã¿ä¸­ã®ã‚­ãƒ¼ã‚’è¿½è·¡
LOADING_LOCK = threading.Lock()
# Path to the currently selected scenario directory.
CURRENT_SCENARIO_DIR: Path | None = None
# Temporary directory object for uploaded scenarios
TEMP_DIR_OBJ: tempfile.TemporaryDirectory | None = None

# ``LOGIC_ANALYSIS_CACHE`` stores results keyed by dataframe hash
LOGIC_ANALYSIS_CACHE: dict[int, dict[str, object]] = {}

def get_cached_analysis(df_hash: int):
    """Return cached analysis results for the given hash."""
    return LOGIC_ANALYSIS_CACHE.get(df_hash)


def cache_analysis(df_hash: int, results: dict) -> None:
    """Cache analysis results keeping at most 3 entries."""
    if len(LOGIC_ANALYSIS_CACHE) >= 3:
        oldest_key = next(iter(LOGIC_ANALYSIS_CACHE))
        del LOGIC_ANALYSIS_CACHE[oldest_key]
    LOGIC_ANALYSIS_CACHE[df_hash] = results

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
def safe_filename(name: str) -> str:
    """Normalize and sanitize strings for file keys"""
    name = unicodedata.normalize("NFKC", name)
    for ch in ["/", "\\", ":", "*", "?", "\"", "<", ">", "|", "ãƒ»", "ï¼", "ï¼¼"]:
        name = name.replace(ch, "_")
    return name


def calculate_role_dynamic_need(df_heat: pd.DataFrame, date_cols: List[str], heat_key: str) -> pd.DataFrame:
    """
    è·ç¨®åˆ¥ãƒ»é›‡ç”¨å½¢æ…‹åˆ¥ã®å‹•çš„needå€¤ã‚’æ­£ç¢ºã«è¨ˆç®—ã™ã‚‹å…±é€šé–¢æ•°
    
    Args:
        df_heat: è·ç¨®åˆ¥ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿
        date_cols: æ—¥ä»˜åˆ—ã®ãƒªã‚¹ãƒˆ
        heat_key: ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚­ãƒ¼ï¼ˆãƒ­ã‚°ç”¨ï¼‰
    
    Returns:
        è¨ˆç®—ã•ã‚ŒãŸå‹•çš„needå€¤ã®DataFrame
    """
    log.info(f"[ROLE_DYNAMIC_NEED] Calculating for {heat_key}")
    
    # â˜…â˜…â˜… ä¿®æ­£ï¼šè©³ç´°Needå€¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ä½¿ç”¨ â˜…â˜…â˜…
    # è·ç¨®åˆ¥ã¾ãŸã¯é›‡ç”¨å½¢æ…‹åˆ¥ã®è©³ç´°Needå€¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    detailed_need_key = None
    if heat_key.startswith('heat_emp_'):
        # é›‡ç”¨å½¢æ…‹åˆ¥
        emp_name = heat_key.replace('heat_emp_', '').replace('heat_', '')
        detailed_need_key = f"need_per_date_slot_emp_{emp_name}"
    elif heat_key.startswith('heat_') and heat_key not in ['heat_all', 'heat_ALL']:
        # è·ç¨®åˆ¥
        role_name = heat_key.replace('heat_', '')
        detailed_need_key = f"need_per_date_slot_role_{role_name}"
    
    # è©³ç´°Needå€¤ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ç›´æ¥ä½¿ç”¨
    if detailed_need_key:
        detailed_need_df = data_get(detailed_need_key, pd.DataFrame())
        if not detailed_need_df.empty:
            log.info(f"[ROLE_DYNAMIC_NEED] {heat_key}: Using detailed need file {detailed_need_key}")
            
            # æ—¥ä»˜åˆ—ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            available_date_cols = [col for col in date_cols if col in detailed_need_df.columns]
            if available_date_cols:
                filtered_need_df = detailed_need_df[available_date_cols].copy()
                filtered_need_df = filtered_need_df.reindex(index=df_heat.index, fill_value=0)
                log.info(f"[ROLE_DYNAMIC_NEED] {heat_key}: Successfully using detailed need values")
                return filtered_need_df
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®ãƒ­ã‚¸ãƒƒã‚¯
    log.warning(f"[ROLE_DYNAMIC_NEED] {heat_key}: Detailed need file not found, using fallback logic")
    
    # Step 1: need_per_date_slotã‹ã‚‰å…¨ä½“ã®å‹•çš„needå€¤ã‚’å–å¾—
    need_per_date_df = data_get('need_per_date_slot', pd.DataFrame())
    
    if need_per_date_df.empty or len(date_cols) == 0:
        log.warning(f"[ROLE_DYNAMIC_NEED] {heat_key}: Fallback to baseline need (no global data)")
        return pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                           index=df_heat.index, columns=date_cols)
    
    # Step 2: å…¨è·ç¨®ã®åŸºæº–needå€¤ã®åˆè¨ˆã‚’è¨ˆç®—
    # heat_ALLï¼ˆå…¨ä½“ï¼‰ã¨é›‡ç”¨å½¢æ…‹åˆ¥ï¼ˆheat_emp_ï¼‰ã‚’é™¤å¤–ã—ã¦å€‹åˆ¥è·ç¨®ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
    all_role_keys = [k for k in DATA_CACHE.keys() 
                    if k.startswith('heat_') 
                    and k not in ['heat_all', 'heat_ALL']
                    and not k.startswith('heat_emp_')]
    total_baseline_need = 0.0
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®å‡ºåŠ›
    all_heat_keys = [k for k in DATA_CACHE.keys() if k.startswith('heat_')]
    log.info(f"[ROLE_DYNAMIC_NEED] All heat keys: {all_heat_keys}")
    log.info(f"[ROLE_DYNAMIC_NEED] Filtered role keys: {all_role_keys}")
    
    for role_key in all_role_keys:
        role_heat = data_get(role_key, pd.DataFrame())
        if not role_heat.empty and 'need' in role_heat.columns:
            role_baseline = role_heat['need'].sum()
            total_baseline_need += role_baseline
            log.debug(f"[ROLE_DYNAMIC_NEED] {role_key}: baseline_need={role_baseline:.2f}")
    
    if total_baseline_need <= 0:
        log.warning(f"[ROLE_DYNAMIC_NEED] {heat_key}: Fallback to baseline need (no total baseline)")
        return pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                           index=df_heat.index, columns=date_cols)
    
    # Step 3: å½“å‰è·ç¨®ã®æ¯”ç‡ã‚’è¨ˆç®—
    current_role_total_baseline = df_heat['need'].sum() if 'need' in df_heat.columns else len(df_heat)
    role_ratio = current_role_total_baseline / total_baseline_need
    
    log.info(f"[ROLE_DYNAMIC_NEED] {heat_key}: role_ratio={role_ratio:.4f}, baseline_need={current_role_total_baseline}, total_baseline={total_baseline_need}")
    
    # Step 4: å…¨ä½“ã®å‹•çš„needå€¤ã«è·ç¨®æ¯”ç‡ã‚’é©ç”¨
    need_df = pd.DataFrame(index=df_heat.index, columns=date_cols)
    need_per_date_df.columns = [str(col) for col in need_per_date_df.columns]
    
    for date_col in date_cols:
        date_str = str(date_col)
        if date_str in need_per_date_df.columns:
            overall_need_series = need_per_date_df[date_str]
            
            # æ™‚é–“å¸¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆã‚ã›ã‚‹
            if len(overall_need_series) == len(df_heat):
                role_need_series = overall_need_series * role_ratio
                need_df[date_col] = role_need_series.values
            else:
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸ä¸€è‡´ã®å ´åˆã¯å¹³å‡å€¤ã‚’ä½¿ç”¨
                avg_need = overall_need_series.mean() * role_ratio
                need_df[date_col] = avg_need
        else:
            # è©²å½“æ—¥ä»˜ãŒãªã„å ´åˆã¯åŸºæº–å€¤ã‚’ä½¿ç”¨
            need_df[date_col] = df_heat['need'].values
    
    need_df = need_df.fillna(0)
    total_calculated_need = need_df.sum().sum()
    log.info(f"[ROLE_DYNAMIC_NEED] {heat_key}: Successfully calculated, total_need={total_calculated_need:.2f}")
    
    return need_df

def date_with_weekday(date_str: str) -> str:
    """æ—¥ä»˜æ–‡å­—åˆ—ã«æ›œæ—¥ã‚’è¿½åŠ """
    try:  # noqa: E722
        date = pd.to_datetime(date_str)
        weekdays = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
        return f"{date.strftime('%m/%d')}({weekdays[date.weekday()]})"
    except Exception:
        return str(date_str)


@lru_cache(maxsize=8)
def safe_read_parquet(filepath: Path) -> pd.DataFrame:
    """Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã¿çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    try:
        if not filepath.exists():
            log.debug(f"File does not exist: {filepath}")
            return pd.DataFrame()
        
        if filepath.stat().st_size == 0:
            log.warning(f"Empty file detected: {filepath}")
            return pd.DataFrame()
            
        df = pd.read_parquet(filepath)
        log.debug(f"Successfully loaded {filepath}: shape={df.shape}")
        return df
    except FileNotFoundError:
        log.debug(f"File not found: {filepath}")
        return pd.DataFrame()
    except pd.errors.EmptyDataError:
        log.warning(f"Empty data in file: {filepath}")
        return pd.DataFrame()
    except Exception as e:
        log.warning(f"Failed to read {filepath}: {type(e).__name__}: {e}")
        return pd.DataFrame()


@lru_cache(maxsize=8)
def safe_read_csv(filepath: Path) -> pd.DataFrame:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã¿çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    try:
        return pd.read_csv(filepath)  # type: ignore
    except Exception as e:
        log.warning(f"Failed to read {filepath}: {e}")
        return pd.DataFrame()


def clear_data_cache() -> None:
    """Clear cached data when the scenario changes with resource monitoring."""
    memory_before = get_memory_usage()
    log.info(f"Data cache clear started. Memory before: {memory_before['rss_mb']:.1f}MB")
    
    DATA_CACHE.clear()
    safe_read_parquet.cache_clear()
    safe_read_csv.cache_clear()
    
    # ç©æ¥µçš„ãªã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
    gc.collect()
    
    memory_after = get_memory_usage()
    memory_freed = memory_before['rss_mb'] - memory_after['rss_mb']
    log.info(f"Data cache cleared. Memory after: {memory_after['rss_mb']:.1f}MB (freed: {memory_freed:.1f}MB)")


# === ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–æ©Ÿèƒ½ï¼ˆå®‰å®šæ€§å‘ä¸Šã®ãŸã‚è¿½åŠ ï¼‰ ===
def get_memory_usage() -> Dict[str, float]:
    """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—"""
    try:
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        return {
            "rss_mb": memory_info.rss / 1024 / 1024,  # å®Ÿéš›ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
            "vms_mb": memory_info.vms / 1024 / 1024,  # ä»®æƒ³ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
            "percent": process.memory_percent(),       # ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã«å¯¾ã™ã‚‹å‰²åˆ
        }
    except Exception as e:
        log.warning(f"Memory usage monitoring failed: {e}")
        return {"rss_mb": 0, "vms_mb": 0, "percent": 0}

def check_memory_pressure() -> bool:
    """ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯"""
    memory_info = get_memory_usage()
    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡80%ä»¥ä¸Šã§è­¦å‘Š
    return memory_info["percent"] > 80

def emergency_cleanup():
    """ç·Šæ€¥ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    log.warning("ç·Šæ€¥ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œã—ã¾ã™")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
    DATA_CACHE.clear()
    safe_read_parquet.cache_clear()
    safe_read_csv.cache_clear()
    
    # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
    gc.collect()
    
    memory_after = get_memory_usage()
    log.info(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¾Œãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_after['rss_mb']:.1f}MB ({memory_after['percent']:.1f}%)")

# æ–°ã—ã„å®‰å®šæ€§å‘ä¸Šç‰ˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ©ãƒƒãƒ‘ãƒ¼
def safe_callback_enhanced(func):
    """Enhanced safe callback with resource monitoring and better error handling."""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        memory_start = get_memory_usage()
        
        try:
            # ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ãƒã‚§ãƒƒã‚¯
            if check_memory_pressure():
                log.warning(f"High memory usage before {func.__name__}: {memory_start['percent']:.1f}%")
                emergency_cleanup()
            
            # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªå®Ÿè¡Œ
            if gc.get_count()[0] > 700:
                gc.collect()
                
            # å®Ÿéš›ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
            result = func(*args, **kwargs)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°
            execution_time = time.time() - start_time
            memory_end = get_memory_usage()
            memory_delta = memory_end['rss_mb'] - memory_start['rss_mb']
            
            if execution_time > 5:  # 5ç§’ä»¥ä¸Šã®å‡¦ç†ã‚’è­¦å‘Š
                log.warning(f"Slow callback {func.__name__}: {execution_time:.2f}s, memory delta: {memory_delta:+.1f}MB")
            elif execution_time > 1:  # 1ç§’ä»¥ä¸Šã‚’æƒ…å ±ãƒ­ã‚°
                log.info(f"Callback {func.__name__}: {execution_time:.2f}s, memory delta: {memory_delta:+.1f}MB")
                
            return result
            
        except PreventUpdate:
            # PreventUpdateã¯æ­£å¸¸ãªãƒ•ãƒ­ãƒ¼ãªã®ã§å†ç™ºç”Ÿ
            raise
        except FileNotFoundError as e:
            log.error(f"File not found: {e}")
            return html.Div([
                html.H4("Error: File not found", style={'color': 'red'}),
                html.P(str(e)),
                html.P("Please check if the file was uploaded correctly.")
            ])
        except pd.errors.EmptyDataError:
            log.error("Empty dataframe")
            return html.Div([
                html.H4("Error: Data is empty", style={'color': 'orange'}),
                html.P("The data file may be empty or corrupted.")
            ])
        except MemoryError as e:
            log.error(f"Memory error: {e}")
            emergency_cleanup()
            return html.Div([
                html.H4("Memory Error", style={'color': 'red'}),
                html.P("Memory shortage occurred. Cache has been cleared."),
                html.P("Please refresh the browser or try with smaller dataset.")
            ])
        except TimeoutError as e:
            log.error(f"Timeout: {e}")
            return html.Div([
                html.H4("Processing Timeout", style={'color': 'orange'}),
                html.P("Processing is taking too long. Please reduce data size or wait.")
            ])
        except Exception as e:
            log.exception(f"Unexpected error in {func.__name__}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if check_memory_pressure():
                emergency_cleanup()
            
            # å˜ä¸€ã®å‡ºåŠ›ç”¨ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            error_div = html.Div([
                html.H4(f"Error occurred ({func.__name__})", style={'color': 'red'}),
                html.Details([
                    html.Summary("Show error details"),
                    html.Pre(str(e), style={'background': '#f0f0f0', 'padding': '10px', 'overflow': 'auto'})
                ]),
                html.P("Please refresh the browser if the problem persists.")
            ])
            
            # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’å–å¾—ã—ã¦ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆæ•°ã‚’åˆ¤å®š
            try:
                import inspect
                # é–¢æ•°ã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‹ã‚‰å‡ºåŠ›æƒ…å ±ã‚’å–å¾—
                # ã“ã‚Œã¯è¤‡é›‘ãªã®ã§ã€é–¢æ•°åã§åˆ¤å®šã™ã‚‹æ–¹æ³•ã‚’ä½¿ç”¨
                func_name = func.__name__
                
                # è¤‡æ•°å‡ºåŠ›ã‚’æŒã¤æ—¢çŸ¥ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
                # æ©Ÿèƒ½åˆ‡ã‚Šåˆ†ã‘ã«å¯¾å¿œã—ãŸå‡ºåŠ›æ•°è¨ˆç®—
                basic_tab_count = 14
                advanced_tab_count = 3 if ENABLE_ADVANCED_FEATURES else 0
                total_tab_count = basic_tab_count + advanced_tab_count
                
                multi_output_callbacks = {
                    'run_advanced_forecast': 3,
                    'update_tab_visibility': total_tab_count,  # å‹•çš„ã«è¨ˆç®—
                    'run_fatigue_prediction': 3,
                    'run_turnover_prediction': 3,
                    'run_seasonal_analysis': 6,  # å­£ç¯€æ€§åˆ†æã®6ã¤ã®å‡ºåŠ›
                    'update_individual_staff_analysis': 2,
                    'update_employment_options': 2
                }
                
                if func_name in multi_output_callbacks:
                    num_outputs = multi_output_callbacks[func_name]
                    return tuple([error_div] * num_outputs)
                else:
                    # å˜ä¸€å‡ºåŠ›ã¨ã—ã¦æ‰±ã†
                    return error_div
            except:
                # ã™ã¹ã¦å¤±æ•—ã—ãŸå ´åˆã¯å˜ä¸€å‡ºåŠ›ã¨ã—ã¦æ‰±ã†
                return error_div
    return wrapper

# çµ±ä¸€ã•ã‚ŒãŸsafe_callbacké–¢æ•°ï¼ˆEnhancedç‰ˆã‚’ä½¿ç”¨ï¼‰
safe_callback = safe_callback_enhanced


def data_get(key: str, default=None):
    """Load a data asset lazily from the current scenario directory with enhanced stability."""
    log.debug(f"data_get('{key}'): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¤œç´¢ä¸­...")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ï¼ˆThreadSafeLRUCacheã‚’ä½¿ç”¨ï¼‰
    cached_value = DATA_CACHE.get(key)
    if cached_value is not None:
        log.debug(f"data_get('{key}'): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ")
        return cached_value

    log.debug(f"data_get('{key}'): ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã€‚ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚’é–‹å§‹...")

    if CURRENT_SCENARIO_DIR is None:
        log.warning(f"CURRENT_SCENARIO_DIRãŒæœªè¨­å®šã®ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚key={key}")
        default_value = default if default is not None else pd.DataFrame()
        DATA_CACHE.set(key, default_value)
        return default_value

    search_dirs = [CURRENT_SCENARIO_DIR, CURRENT_SCENARIO_DIR.parent]
    log.debug(f"Searching {search_dirs} for key {key}")

    # Special file names
    special = {
        "long_df": ["intermediate_data.parquet"],
        "daily_cost": ["daily_cost.parquet", "daily_cost.xlsx"],
        "shortage_time": ["shortage_time_CORRECTED.parquet"],
        "need_per_date_slot": ["need_per_date_slot.parquet"],
    }
    
    # â˜…â˜…â˜… è·ç¨®åˆ¥ãƒ»é›‡ç”¨å½¢æ…‹åˆ¥è©³ç´°Needå€¤ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢å¯¾å¿œ â˜…â˜…â˜…
    if key.startswith("need_per_date_slot_role_") or key.startswith("need_per_date_slot_emp_"):
        filenames = [f"{key}.parquet"]
    else:
        filenames = special.get(key, [f"{key}.parquet", f"{key}.csv", f"{key}.xlsx"])

    # Special handling for need_per_date_slot
    if key == "need_per_date_slot":
        for directory in search_dirs:
            fp = directory / "need_per_date_slot.parquet"
            if fp.exists():
                try:
                    log.debug(f"Loading need_per_date_slot from {fp}")
                    
                    # è¤‡æ•°ã®æ–¹æ³•ã§datetimeå•é¡Œã‚’å›é¿
                    df = None
                    
                    # æ–¹æ³•1: PyArrowãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã—ã¦èª­ã¿è¾¼ã¿ã€ã‚«ãƒ©ãƒ åã‚’æ‰‹å‹•å‡¦ç†
                    try:
                        table = pq.read_table(fp)
                        # ã‚«ãƒ©ãƒ åã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                        new_columns = [str(col) for col in table.column_names]
                        
                        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ï¼ˆindexå‡¦ç†ï¼‰
                        df = table.to_pandas()
                        df.columns = new_columns
                        
                        log.debug(f"Method 1 success: PyArrow table conversion")
                        
                    except Exception as e1:
                        log.debug(f"Method 1 failed: {e1}")
                        
                        # æ–¹æ³•2: pandasç›´æ¥èª­ã¿è¾¼ã¿ï¼ˆtypes_mapperãªã—ï¼‰
                        try:
                            df = pd.read_parquet(fp, engine='pyarrow', 
                                               use_nullable_dtypes=False)
                            df.columns = [str(col) for col in df.columns]
                            log.debug(f"Method 2 success: Direct pandas read")
                            
                        except Exception as e2:
                            log.debug(f"Method 2 failed: {e2}")
                            
                            # æ–¹æ³•3: æœ€å¾Œã®æ‰‹æ®µ - ãƒ•ã‚¡ã‚¤ãƒ«å†ä½œæˆ
                            try:
                                # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’åˆ¥ã®æ–¹æ³•ã§èª­ã¿è¾¼ã¿
                                temp_table = pq.read_table(fp)
                                temp_df = temp_table.to_pandas(types_mapper=pd.ArrowDtype)
                                temp_df.columns = [str(col) for col in temp_df.columns]
                                
                                # ä¸€æ™‚çš„ã«CSVçµŒç”±ã§å¤‰æ›
                                temp_csv = fp.with_suffix('.temp.csv')
                                temp_df.to_csv(temp_csv)
                                df = pd.read_csv(temp_csv, index_col=0)
                                temp_csv.unlink()  # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                                
                                log.debug(f"Method 3 success: CSV conversion")
                                
                            except Exception as e3:
                                log.error(f"All methods failed: {e1}, {e2}, {e3}")
                                raise e3
                    
                    if df is not None:
                        DATA_CACHE.set(key, df)
                        log.info(f"Successfully loaded need_per_date_slot: {df.shape}")
                        return df
                    else:
                        raise ValueError("Failed to load parquet file with any method")
                except Exception as e:
                    log.warning(f"Failed to load {fp}: {e}")
                    continue
        log.warning("need_per_date_slot.parquet not found")
        empty_df = pd.DataFrame()
        DATA_CACHE.set(key, empty_df)
        return empty_df

    for name in filenames:
        for directory in search_dirs:
            fp = directory / name
            log.debug(f"Checking {fp}")
            if fp.suffix == ".parquet" and fp.exists():
                df = safe_read_parquet(fp)
                if not df.empty:
                    DATA_CACHE.set(key, df)
                    log.debug(f"Loaded {fp} into cache for {key}")
                    return df
                break
            if fp.suffix == ".csv" and fp.exists():
                df = safe_read_csv(fp)
                if not df.empty:
                    DATA_CACHE.set(key, df)
                    log.debug(f"Loaded {fp} into cache for {key}")
                    return df
                break
            if fp.suffix == ".xlsx" and fp.exists():
                df = safe_read_excel(fp)
                if not df.empty:
                    DATA_CACHE.set(key, df)
                    log.debug(f"Loaded {fp} into cache for {key}")
                    return df
                break

    if key == "summary_report":
        files = sorted(CURRENT_SCENARIO_DIR.glob("OverShortage_SummaryReport_*.md"))
        if files:
            text = files[-1].read_text(encoding="utf-8")
            DATA_CACHE.set(key, text)
            log.debug(f"Loaded summary report {files[-1]}")
            return text
    if key in {"roles", "employments"}:
        roles, employments = load_shortage_meta(CURRENT_SCENARIO_DIR)
        DATA_CACHE.set("roles", roles)
        DATA_CACHE.set("employments", employments)
        return DATA_CACHE.get(key, default)

    if key == "shortage_events":
        df_events = over_shortage_log.list_events(CURRENT_SCENARIO_DIR)
        DATA_CACHE.set(key, df_events)
        DATA_CACHE.set("shortage_log_path", str(Path(CURRENT_SCENARIO_DIR) / "over_shortage_log.csv"))
        return DATA_CACHE.get(key, default)

    log.debug(f"ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼ '{key}' ã«å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    DATA_CACHE.set(key, default)
    return default


def _valid_df(df: pd.DataFrame) -> bool:
    """Return True if ``df`` is a non-empty :class:`~pandas.DataFrame`."""
    return isinstance(df, pd.DataFrame) and not df.empty


def calc_ratio_from_heatmap(df: pd.DataFrame) -> pd.DataFrame:
    """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸è¶³ç‡ã‚’è¨ˆç®—ï¼ˆçµ±åˆã‚·ã‚¹ãƒ†ãƒ å¯¾å¿œï¼‰"""
    if df.empty:
        return pd.DataFrame()

    date_cols = [c for c in df.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    if not date_cols:
        return pd.DataFrame()

    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ : need_per_date_slotã‚’å„ªå…ˆä½¿ç”¨
    need_per_date_df = data_get('need_per_date_slot')
    
    if not need_per_date_df.empty:
        # need_per_date_slotã‹ã‚‰need_dfã‚’ä½œæˆ
        log.info(f"Using need_per_date_slot for accurate need calculation: {need_per_date_df.shape}")
        
        # æ—¥ä»˜åˆ—ã®äº¤é›†åˆã‚’å–å¾—
        available_dates = [col for col in date_cols if str(col) in need_per_date_df.columns]
        
        if available_dates:
            need_df = need_per_date_df[[str(col) for col in available_dates]].copy()
            need_df.columns = available_dates  # å…ƒã®åˆ—åã«æˆ»ã™
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¸€è‡´ã•ã›ã‚‹
            common_index = df.index.intersection(need_df.index)
            need_df = need_df.loc[common_index]
        else:
            log.warning("No matching dates in need_per_date_slot, falling back to average need")
            need_df = pd.DataFrame(0.0, index=df.index, columns=date_cols)
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®average needä½¿ç”¨
        if "need" in df.columns:
            log.warning("need_per_date_slot not available, using average need values")
            need_series = df["need"].fillna(0)
            need_df = pd.DataFrame(
                np.repeat(need_series.values[:, np.newaxis], len(date_cols), axis=1),
                index=need_series.index,
                columns=date_cols
            )
        else:
            need_df = pd.DataFrame(0.0, index=df.index, columns=date_cols)
    staff_df = df[date_cols].fillna(0)
    
    # ä¿®æ­£: æ—¥æ›œæ—¥ã®éå‰°è¡¨ç¤ºã‚’é˜²ããŸã‚ã€è¨ˆç®—ã‚’å¼·åŒ–
    # need_dfãŒ0ã®å ´åˆã®é©åˆ‡ãªå‡¦ç†
    valid_need_mask = need_df > 0
    ratio_df = pd.DataFrame(0.0, index=need_df.index, columns=need_df.columns)
    
    # éœ€è¦ãŒã‚ã‚‹å ´åˆã®ã¿ä¸è¶³ç‡ã‚’è¨ˆç®—
    ratio_df = ratio_df.where(~valid_need_mask, 
                             ((need_df - staff_df) / need_df).clip(lower=0))
    
    # æœ€çµ‚çš„ã«NaNå€¤ã‚’0ã§åŸ‹ã‚ã‚‹ï¼ˆæ—¥æ›œæ—¥å¯¾ç­–ï¼‰
    ratio_df = ratio_df.fillna(0)
    
    return ratio_df


def load_shortage_meta(data_dir: Path) -> Tuple[List[str], List[str]]:
    """è·ç¨®ã¨é›‡ç”¨å½¢æ…‹ã®ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    roles = []
    employments = []
    meta_fp = data_dir / "shortage.meta.json"
    if meta_fp.exists():
        try:
            with open(meta_fp, 'r', encoding='utf-8') as f:
                meta = json.load(f)
            roles = meta.get("roles", [])
            employments = meta.get("employments", [])
        except Exception as e:
            log.debug(f"Failed to load shortage meta: {e}")
    return roles, employments



def load_and_sum_heatmaps(data_dir: Path, keys: List[str]) -> pd.DataFrame:
    """Load multiple heatmap files and aggregate them."""
    dfs = []
    for key in keys:
        df = data_get(key)
        if df is None and data_dir:
            fp = Path(data_dir) / f"{key}.parquet"
            if fp.exists():
                df = safe_read_parquet(fp)
                if not df.empty:
                    DATA_CACHE.set(key, df)
        if isinstance(df, pd.DataFrame) and not df.empty:
            dfs.append(df)

    if not dfs:
        return pd.DataFrame()

    total = dfs[0].copy()
    for df in dfs[1:]:
        total = total.add(df, fill_value=0)

    if {"need", "staff"}.issubset(total.columns):
        total["lack"] = (total["need"] - total["staff"]).clip(lower=0)
    if {"staff", "upper"}.issubset(total.columns):
        total["excess"] = (total["staff"] - total["upper"]).clip(lower=0)

    return total


def generate_heatmap_figure(df_heat: pd.DataFrame, title: str) -> go.Figure:
    """æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã™ã‚‹"""
    if df_heat is None or df_heat.empty:
        return go.Figure().update_layout(title_text=f"{title}: ãƒ‡ãƒ¼ã‚¿ãªã—", height=300)

    date_cols = [c for c in df_heat.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    if not date_cols:
        return go.Figure().update_layout(title_text=f"{title}: è¡¨ç¤ºå¯èƒ½ãªæ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãªã—", height=300)

    display_df = df_heat[date_cols]
    # â˜…â˜…â˜… æ™‚é–“é–“éš”çµ±ä¸€: 30åˆ† â†’ 15åˆ† â˜…â˜…â˜…
    time_labels = gen_labels(15)  # 30åˆ†ã‹ã‚‰15åˆ†ã«å¤‰æ›´
    display_df = display_df.reindex(time_labels, fill_value=0)
    
    # ä¿®æ­£ç‚¹1: NaNå€¤ã‚’æ˜ç¤ºçš„ã«0ã§åŸ‹ã‚ã‚‹
    display_df = display_df.fillna(0)
    
    display_df_renamed = display_df.copy()
    display_df_renamed.columns = [date_with_weekday(c) for c in display_df.columns]

    # ä¿®æ­£ç‚¹2: text_autoã‚’è¿½åŠ ã—ã¦ã€0å€¤ã‚‚è¡¨ç¤ºã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
    fig = px.imshow(
        display_df_renamed,
        aspect='auto',
        color_continuous_scale=px.colors.sequential.Viridis,
        title=title,
        labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'},
        text_auto=True  # ã‚»ãƒ«ã«å€¤ã‚’è¡¨ç¤º
    )
    
    # â˜…â˜…â˜… é€£ç¶šå‹¤å‹™ã®è¦–è¦šåŒ–æ”¹å–„ â˜…â˜…â˜…
    # æ—¥ä»˜å¢ƒç•Œï¼ˆ0:00ï¼‰ã§ã®å¢ƒç•Œç·šã‚’è¿½åŠ 
    if '00:00' in display_df.index:
        midnight_row = list(display_df.index).index('00:00')
        fig.add_hline(
            y=midnight_row - 0.5,  # ã‚»ãƒ«ã®å¢ƒç•Œã«ç·šã‚’å¼•ã
            line_color="red",
            line_width=2,
            annotation_text="æ—¥ä»˜å¢ƒç•Œ (0:00) - æ˜ã‘ç•ªã‚·ãƒ•ãƒˆã®ç¶™ç¶šéƒ¨åˆ†",
            annotation_position="bottom left",
            annotation_font_color="red"
        )
    
    # æ˜ã‘ç•ªã‚·ãƒ•ãƒˆã®è¦–è¦šçš„å¼·èª¿ï¼ˆ6:00ã®å¢ƒç•Œç·šè¿½åŠ ï¼‰
    if '06:00' in display_df.index:
        morning_row = list(display_df.index).index('06:00')
        fig.add_hline(
            y=morning_row - 0.5,
            line_color="orange",
            line_width=1,
            line_dash="dash",
            annotation_text="æ˜ã‘ç•ªçµ‚äº†æ™‚åˆ»ç›®å®‰ (6:00)",
            annotation_position="bottom right",
            annotation_font_color="orange"
        )
    
    # ä¿®æ­£ç‚¹3: 0å€¤ã®è¡¨ç¤ºã‚¹ã‚¿ã‚¤ãƒ«ã‚’èª¿æ•´
    fig.update_traces(
        texttemplate='%{text}',
        textfont={"size": 10}
    )
    fig.update_xaxes(tickvals=list(range(len(display_df.columns))))
    return fig


def create_knowledge_network_graph(network_data: Dict) -> cyto.Cytoscape:
    """Return an interactive network graph of implicit knowledge."""
    nodes = [
        {"data": {"id": n["id"], "label": n["label"]}}
        for n in network_data.get("nodes", [])
    ]
    edges = [
        {
            "data": {
                "source": e.get("from"),
                "target": e.get("to"),
                "label": e.get("label", ""),
            }
        }
        for e in network_data.get("edges", [])
    ]

    return cyto.Cytoscape(
        id="knowledge-network-graph",
        elements=nodes + edges,
        style={"width": "100%", "height": "500px"},
        layout={"name": "cose"},
        stylesheet=[
            {"selector": "node", "style": {"content": "data(label)", "font-size": "10px"}},
            {
                "selector": "edge",
                "style": {
                    "label": "data(label)",
                    "font-size": "8px",
                    "curve-style": "bezier",
                },
            },
        ],
    )

# --- UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç”Ÿæˆé–¢æ•° ---
def create_metric_card(label: str, value: str, color: str = "#1f77b4") -> html.Div:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆ"""
    return html.Div([
        html.Div(label, style={  # type: ignore
            'fontSize': '14px',
            'color': '#666',
            'marginBottom': '5px'
        }),
        html.Div(value, style={  # type: ignore
            'fontSize': '24px',
            'fontWeight': 'bold',
            'color': color
        })
    ], style={
        'padding': '15px',
        'backgroundColor': 'white',
        'borderRadius': '8px',
        'boxShadow': '0 2px 4px rgba(0,0,0,0.1)',
        'textAlign': 'center',
        'minHeight': '80px'
    })


def create_overview_tab() -> html.Div:
    """æ¦‚è¦ã‚¿ãƒ–ã‚’ä½œæˆ"""
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame())
    df_fairness = data_get('fairness_before', pd.DataFrame())
    df_staff = data_get('staff_stats', pd.DataFrame())
    df_alerts = data_get('stats_alerts', pd.DataFrame())

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ï¼ˆé‡è¤‡ã‚«ã‚¦ãƒ³ãƒˆã‚’å›é¿ï¼‰
    # ç·ä¸è¶³æ™‚é–“ã®æ­£ã—ã„è¨ˆç®—
    lack_h = 0
    if not df_shortage_role.empty and 'lack_h' in df_shortage_role.columns:
        # ã€Œå…¨ä½“ã€ã€Œåˆè¨ˆã€ã€Œç·è¨ˆã€ã®è¡ŒãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        total_rows = df_shortage_role[df_shortage_role['role'].isin(['å…¨ä½“', 'åˆè¨ˆ', 'ç·è¨ˆ'])]
        if not total_rows.empty:
            lack_h = total_rows['lack_h'].iloc[0]
        else:
            # shortage_timeã‹ã‚‰ç›´æ¥è¨ˆç®—ã™ã‚‹æ–¹ãŒæ­£ç¢º
            shortage_time_df = data_get('shortage_time', pd.DataFrame())
            if not shortage_time_df.empty:
                # å„ã‚»ãƒ«ã®å€¤ã‚’åˆè¨ˆï¼ˆ30åˆ†å˜ä½ãªã®ã§0.5æ™‚é–“ï¼‰
                try:
                    shortage_values = shortage_time_df.select_dtypes(include=[np.number]).values
                    if shortage_values.size > 0:
                        total_slots = np.nansum(shortage_values)
                        if np.isfinite(total_slots):
                            lack_h = float(total_slots * 0.5)
                        else:
                            log.warning("shortage_timeè¨ˆç®—ã§ç„¡é™å€¤ã¾ãŸã¯NaNãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                            lack_h = df_shortage_role['lack_h'].sum()
                    else:
                        log.debug("shortage_time_dfã«æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                        lack_h = df_shortage_role['lack_h'].sum()
                except Exception as e:
                    log.debug(f"shortage_timeè¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼: {e}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šè·ç¨®åˆ¥ã®åˆè¨ˆï¼ˆé‡è¤‡ã®å¯èƒ½æ€§ã‚ã‚Šï¼‰
                    lack_h = df_shortage_role['lack_h'].sum()
            else:
                # æœ€çµ‚çš„ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                lack_h = df_shortage_role['lack_h'].sum()
    
    # ã‚³ã‚¹ãƒˆè¨ˆç®—ã‚‚åŒæ§˜ã«ä¿®æ­£
    excess_cost = 0
    lack_temp_cost = 0
    lack_penalty_cost = 0
    
    if not df_shortage_role.empty:
        # åˆè¨ˆè¡ŒãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        total_rows = df_shortage_role[df_shortage_role['role'].isin(['å…¨ä½“', 'åˆè¨ˆ', 'ç·è¨ˆ'])]
        if not total_rows.empty:
            excess_cost = total_rows['estimated_excess_cost'].iloc[0] if 'estimated_excess_cost' in total_rows.columns else 0
            lack_temp_cost = total_rows['estimated_lack_cost_if_temporary_staff'].iloc[0] if 'estimated_lack_cost_if_temporary_staff' in total_rows.columns else 0
            lack_penalty_cost = total_rows['estimated_lack_penalty_cost'].iloc[0] if 'estimated_lack_penalty_cost' in total_rows.columns else 0
        else:
            # åˆè¨ˆè¡ŒãŒãªã„å ´åˆã¯ã€é‡è¤‡ã‚’è€ƒæ…®ã›ãšã«åˆè¨ˆ
            excess_cost = df_shortage_role['estimated_excess_cost'].sum() if 'estimated_excess_cost' in df_shortage_role.columns else 0
            lack_temp_cost = df_shortage_role['estimated_lack_cost_if_temporary_staff'].sum() if 'estimated_lack_cost_if_temporary_staff' in df_shortage_role.columns else 0
            lack_penalty_cost = df_shortage_role['estimated_lack_penalty_cost'].sum() if 'estimated_lack_penalty_cost' in df_shortage_role.columns else 0

    # JainæŒ‡æ•°ã®å®‰å…¨ãªå–å¾—
    jain_index = "N/A"
    try:
        if not df_fairness.empty and 'metric' in df_fairness.columns:
            jain_row = df_fairness[df_fairness['metric'] == 'jain_index']
            if not jain_row.empty and 'value' in jain_row.columns:
                value = jain_row['value'].iloc[0]
                if pd.notna(value):
                    jain_index = f"{float(value):.3f}"
    except (ValueError, TypeError, IndexError) as e:
        log.debug(f"JainæŒ‡æ•°ã®è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼: {e}")
        jain_index = "ã‚¨ãƒ©ãƒ¼"

    # åŸºæœ¬çµ±è¨ˆã®å®‰å…¨ãªè¨ˆç®—
    staff_count = len(df_staff) if not df_staff.empty else 0
    avg_night_ratio = 0
    try:
        if not df_staff.empty and 'night_ratio' in df_staff.columns:
            night_ratios = df_staff['night_ratio'].dropna()
            avg_night_ratio = float(night_ratios.mean()) if len(night_ratios) > 0 else 0
    except (ValueError, TypeError) as e:
        log.debug(f"å¤œå‹¤æ¯”ç‡ã®è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼: {e}")
        avg_night_ratio = 0
    
    alerts_count = len(df_alerts) if not df_alerts.empty else 0

    return html.Div([
        html.Div(id='overview-insights', style={  # type: ignore
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("åˆ†ææ¦‚è¦", style={'marginBottom': '20px'}),  # type: ignore
        # ğŸ“Š é‡è¦æŒ‡æ¨™ã‚’å¤§ããè¡¨ç¤ºï¼ˆæœ€å„ªå…ˆï¼‰
        html.Div([  # type: ignore
            html.Div([
                html.Div([
                    html.H2(f"{lack_h:.1f}", style={
                        'margin': '0', 'color': '#d32f2f' if lack_h > 100 else '#2e7d32', 
                        'fontSize': '3rem', 'fontWeight': 'bold'
                    }),
                    html.P("ç·ä¸è¶³æ™‚é–“(h)", style={'margin': '5px 0', 'fontSize': '1.1rem', 'color': '#666'})
                ], style={
                    'textAlign': 'center', 'padding': '20px', 'backgroundColor': 'white',
                    'borderRadius': '12px', 'boxShadow': '0 4px 8px rgba(0,0,0,0.12)',
                    'border': f"3px solid {'#d32f2f' if lack_h > 100 else '#2e7d32'}"
                }),
            ], style={'width': '24%', 'display': 'inline-block', 'padding': '5px'}),
            
            html.Div([
                html.Div([
                    html.H3(f"{excess_cost:,.0f}", style={
                        'margin': '0', 'color': '#ff9800', 'fontSize': '2rem', 'fontWeight': 'bold'
                    }),
                    html.P("ç·éå‰°ã‚³ã‚¹ãƒˆ(Â¥)", style={'margin': '5px 0', 'fontSize': '1rem', 'color': '#666'})
                ], style={
                    'textAlign': 'center', 'padding': '15px', 'backgroundColor': 'white',
                    'borderRadius': '8px', 'boxShadow': '0 2px 4px rgba(0,0,0,0.1)',
                    'border': '2px solid #ff9800'
                }),
            ], style={'width': '24%', 'display': 'inline-block', 'padding': '5px'}),
            
            html.Div([
                html.Div([
                    html.H3(f"{lack_temp_cost:,.0f}", style={
                        'margin': '0', 'color': '#f44336', 'fontSize': '2rem', 'fontWeight': 'bold'
                    }),
                    html.P("ä¸è¶³ã‚³ã‚¹ãƒˆ(æ´¾é£)(Â¥)", style={'margin': '5px 0', 'fontSize': '1rem', 'color': '#666'})
                ], style={
                    'textAlign': 'center', 'padding': '15px', 'backgroundColor': 'white',
                    'borderRadius': '8px', 'boxShadow': '0 2px 4px rgba(0,0,0,0.1)',
                    'border': '2px solid #f44336'
                }),
            ], style={'width': '24%', 'display': 'inline-block', 'padding': '5px'}),
            
            html.Div([
                html.Div([
                    html.H3(str(alerts_count), style={
                        'margin': '0', 'color': '#ff7f0e' if alerts_count > 0 else '#1f77b4', 
                        'fontSize': '2rem', 'fontWeight': 'bold'
                    }),
                    html.P("ã‚¢ãƒ©ãƒ¼ãƒˆæ•°", style={'margin': '5px 0', 'fontSize': '1rem', 'color': '#666'})
                ], style={
                    'textAlign': 'center', 'padding': '15px', 'backgroundColor': 'white',
                    'borderRadius': '8px', 'boxShadow': '0 2px 4px rgba(0,0,0,0.1)',
                    'border': f"2px solid {'#ff7f0e' if alerts_count > 0 else '#1f77b4'}"
                }),
            ], style={'width': '24%', 'display': 'inline-block', 'padding': '5px'}),
        ], style={'marginBottom': '20px'}),
        
        # ğŸ“ˆ è©³ç´°æŒ‡æ¨™ã‚’å°ã•ãè¡¨ç¤ºï¼ˆè£œåŠ©æƒ…å ±ï¼‰
        html.Div([  # type: ignore
            html.Div([
                create_metric_card("å¤œå‹¤ JainæŒ‡æ•°", jain_index),
            ], style={'width': '20%', 'display': 'inline-block', 'padding': '3px'}),
            html.Div([
                create_metric_card("ç·ã‚¹ã‚¿ãƒƒãƒ•æ•°", str(staff_count)),
            ], style={'width': '20%', 'display': 'inline-block', 'padding': '3px'}),
            html.Div([
                create_metric_card("å¹³å‡å¤œå‹¤æ¯”ç‡", f"{avg_night_ratio:.3f}"),
            ], style={'width': '20%', 'display': 'inline-block', 'padding': '3px'}),
            html.Div([
                create_metric_card("ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£(Â¥)", f"{lack_penalty_cost:,.0f}"),
            ], style={'width': '20%', 'display': 'inline-block', 'padding': '3px'}),
            html.Div([
                html.Div([
                    html.P(f"ç·ä¸è¶³ç‡: {(lack_h / (lack_h + 100)) * 100:.1f}%" if lack_h > 0 else "ç·ä¸è¶³ç‡: 0%", 
                           style={'margin': '0', 'fontSize': '0.9rem', 'textAlign': 'center'})
                ], style={
                    'padding': '10px', 'backgroundColor': 'white', 'borderRadius': '8px',
                    'boxShadow': '0 2px 4px rgba(0,0,0,0.1)', 'minHeight': '60px', 'display': 'flex',
                    'alignItems': 'center', 'justifyContent': 'center'
                }),
            ], style={'width': '20%', 'display': 'inline-block', 'padding': '3px'}),
        ], style={'marginBottom': '30px'}),
    ])


def create_heatmap_tab() -> html.Div:
    """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚¿ãƒ–ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚ä¸Šä¸‹2ã¤ã®æ¯”è¼ƒã‚¨ãƒªã‚¢ã‚’æŒã¡ã¾ã™ã€‚"""
    roles = data_get('roles', [])
    employments = data_get('employments', [])

    # æ¯”è¼ƒã‚¨ãƒªã‚¢ã‚’1ã¤ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    def create_comparison_area(area_id: int):
        return html.Div([  # type: ignore
            html.H4(f"æ¯”è¼ƒã‚¨ãƒªã‚¢ {area_id}", style={'marginTop': '20px', 'borderTop': '2px solid #ddd', 'paddingTop': '20px'}),  # type: ignore

            # --- å„ã‚¨ãƒªã‚¢ã«è·ç¨®ã¨é›‡ç”¨å½¢æ…‹ã®ä¸¡æ–¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’è¨­ç½® ---
            html.Div([  # type: ignore
                html.Div([  # type: ignore
                    html.Label("è·ç¨®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"),  # type: ignore
                    dcc.Dropdown(
                        id={'type': 'heatmap-filter-role', 'index': area_id},
                        options=[{'label': 'ã™ã¹ã¦', 'value': 'all'}] + [{'label': r, 'value': r} for r in roles],
                        value='all',
                        clearable=False
                    )
                ], style={'width': '48%', 'display': 'inline-block', 'marginRight': '4%'}),

                html.Div([  # type: ignore
                    html.Label("é›‡ç”¨å½¢æ…‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"),  # type: ignore
                    dcc.Dropdown(
                        id={'type': 'heatmap-filter-employment', 'index': area_id},
                        options=[{'label': 'ã™ã¹ã¦', 'value': 'all'}] + [{'label': e, 'value': e} for e in employments],
                        value='all',
                        clearable=False
                    )
                ], style={'width': '48%', 'display': 'inline-block'}),
            ], style={'marginBottom': '10px'}),

            # --- ã‚°ãƒ©ãƒ•æç”»é ˜åŸŸ ---
            dcc.Loading(
                id={'type': 'loading-heatmap', 'index': area_id},
                children=html.Div(id={'type': 'graph-output-heatmap', 'index': area_id})
            )
        ], style={'padding': '10px', 'backgroundColor': '#f9f9f9', 'borderRadius': '5px', 'marginBottom': '10px'})

    return html.Div([
        html.H3("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æ¯”è¼ƒåˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
        html.P("ä¸Šä¸‹ã®ã‚¨ãƒªã‚¢ã§ãã‚Œãã‚Œã€Œè·ç¨®ã€ã¨ã€Œé›‡ç”¨å½¢æ…‹ã€ã®çµ„ã¿åˆã‚ã›ã‚’é¸æŠã—ã€ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚"),  # type: ignore
        create_comparison_area(1),
        create_comparison_area(2)
    ])


def create_shortage_tab() -> html.Div:
    """ä¸è¶³åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame())
    df_shortage_emp = data_get('shortage_employment_summary', pd.DataFrame())

    content = [html.Div(id='shortage-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("ä¸è¶³åˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
        html.Div(  # type: ignore
            dcc.Markdown(
                "\n".join(
                    [
                        "### è¨ˆç®—ã«ä½¿ç”¨ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
                        f"- Needç®—å‡ºæ–¹æ³•: {data_get('need_method', 'N/A')}",
                        f"- Upperç®—å‡ºæ–¹æ³•: {data_get('upper_method', 'N/A')}",
                        f"- ç›´æ¥é›‡ç”¨å˜ä¾¡: Â¥{data_get('wage_direct', 0):,.0f}/h",
                        f"- æ´¾é£å˜ä¾¡: Â¥{data_get('wage_temp', 0):,.0f}/h",
                        f"- æ¡ç”¨ã‚³ã‚¹ãƒˆ: Â¥{data_get('hiring_cost', 0):,}/äºº",
                        f"- ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£: Â¥{data_get('penalty_cost', 0):,.0f}/h",
                    ]
                )
            ),
            style={
                'backgroundColor': '#e9f2fa',
                'padding': '10px',
                'borderRadius': '8px',
                'border': '1px solid #cce5ff',
                'marginBottom': '20px'
            },
        )]

    # è·ç¨®åˆ¥ä¸è¶³åˆ†æ
    if not df_shortage_role.empty:
        content.append(html.H4("è·ç¨®åˆ¥ä¸è¶³æ™‚é–“"))  # type: ignore

        # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆé‡è¤‡ã‚«ã‚¦ãƒ³ãƒˆã‚’å›é¿ï¼‰
        total_lack = 0
        if 'lack_h' in df_shortage_role.columns:
            # ã€Œå…¨ä½“ã€ã€Œåˆè¨ˆã€ã€Œç·è¨ˆã€ã®è¡ŒãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
            total_rows = df_shortage_role[df_shortage_role['role'].isin(['å…¨ä½“', 'åˆè¨ˆ', 'ç·è¨ˆ'])]
            if not total_rows.empty:
                total_lack = total_rows['lack_h'].iloc[0]
            else:
                # ğŸ”§ ä¿®æ­£: é›‡ç”¨å½¢æ…‹ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã—ã¦ã‹ã‚‰åˆè¨ˆè¨ˆç®—
                role_only_df = df_shortage_role[~df_shortage_role['role'].str.startswith('emp_', na=False)]
                if not role_only_df.empty:
                    total_lack = role_only_df['lack_h'].sum()
                else:
                    # shortage_timeã‹ã‚‰ç›´æ¥è¨ˆç®—
                    shortage_time_df = data_get('shortage_time', pd.DataFrame())
                    if not shortage_time_df.empty:
                        try:
                            shortage_values = shortage_time_df.select_dtypes(include=[np.number]).values
                            total_lack = float(np.nansum(shortage_values) * 0.5)
                        except:
                            total_lack = df_shortage_role['lack_h'].sum()
                    else:
                        total_lack = df_shortage_role['lack_h'].sum()
        if total_lack > 0:
            top_roles = df_shortage_role.nlargest(3, 'lack_h')[['role', 'lack_h']]
            metrics = [
                html.Div([
                    create_metric_card("ç·ä¸è¶³æ™‚é–“", f"{total_lack:.1f}h")
                ], style={'width': '25%', 'display': 'inline-block', 'padding': '5px'})
            ]
            for i, row in enumerate(top_roles.itertuples(index=False)):
                metrics.append(
                    html.Div([
                        create_metric_card(f"ä¸è¶³Top{i+1}", f"{row.role}: {row.lack_h:.1f}h")  # type: ignore
                    ], style={'width': '25%', 'display': 'inline-block', 'padding': '5px'})
                )
            content.append(html.Div(metrics, style={'marginBottom': '20px'}))

        # è·ç¨®åˆ¥ä¸è¶³ãƒ»éå‰°æ™‚é–“çµ±åˆã‚°ãƒ©ãƒ•
        if 'excess_h' in df_shortage_role.columns:
            # ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆç”¨ã«å†æ•´å½¢
            shortage_data = []
            for _, row in df_shortage_role.iterrows():
                shortage_data.append({
                    'role': row['role'],
                    'type': 'ä¸è¶³æ™‚é–“',
                    'hours': row['lack_h']
                })
                shortage_data.append({
                    'role': row['role'], 
                    'type': 'éå‰°æ™‚é–“',
                    'hours': row['excess_h']
                })
            
            shortage_combined_df = pd.DataFrame(shortage_data)
            
            fig_role_combined = px.bar(
                shortage_combined_df,
                x='role',
                y='hours',
                color='type',
                title='è·ç¨®åˆ¥ä¸è¶³ãƒ»éå‰°æ™‚é–“',
                labels={'role': 'è·ç¨®', 'hours': 'æ™‚é–“(h)', 'type': 'ç¨®åˆ¥'},
                color_discrete_map={
                    'ä¸è¶³æ™‚é–“': '#FFA500',
                    'éå‰°æ™‚é–“': '#00BFFF'
                },
                barmode='group'
            )
            content.append(dcc.Graph(figure=fig_role_combined))
        else:
            # éå‰°æ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ä¸è¶³æ™‚é–“ã®ã¿
            fig_role_lack = px.bar(
                df_shortage_role,
                x='role',
                y='lack_h',
                title='è·ç¨®åˆ¥ä¸è¶³æ™‚é–“',
                labels={'role': 'è·ç¨®', 'lack_h': 'ä¸è¶³æ™‚é–“(h)'},
                color_discrete_sequence=['#FFA500']
            )
            content.append(dcc.Graph(figure=fig_role_lack))

    # é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³åˆ†æ
    if not df_shortage_emp.empty:
        content.append(html.H4("é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³æ™‚é–“", style={'marginTop': '30px'}))  # type: ignore

        fig_emp_lack = px.bar(
            df_shortage_emp,
            x='employment',
            y='lack_h',
            title='é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³æ™‚é–“',
            labels={'employment': 'é›‡ç”¨å½¢æ…‹', 'lack_h': 'ä¸è¶³æ™‚é–“(h)'},
            color_discrete_sequence=['#2ca02c']
        )
        content.append(dcc.Graph(figure=fig_emp_lack))

    # ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    content.append(html.Div([
        html.H4("ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", style={'marginTop': '30px'}),  # type: ignore
        html.P("å„æ™‚é–“å¸¯ã§å¿…è¦äººæ•°ã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„ã®å‰²åˆã§äººå“¡ãŒä¸è¶³ã—ã¦ã„ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚"),  # type: ignore
        html.Div([  # type: ignore
            html.Label("è¡¨ç¤ºç¯„å›²"),  # type: ignore
            dcc.Dropdown(
                id='shortage-heatmap-scope',
                options=[
                    {'label': 'å…¨ä½“', 'value': 'overall'},
                    {'label': 'è·ç¨®åˆ¥', 'value': 'role'},
                    {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'employment'}
                ],
                value='overall',
                style={'width': '200px'}
            ),
        ], style={'marginBottom': '10px'}),
        html.Div(id='shortage-heatmap-detail-container'),
        html.Div(id='shortage-ratio-heatmap')
    ]))

    # Factor Analysis section
    content.append(html.Hr())
    content.append(html.H4('è¦å› åˆ†æ (AI)', style={'marginTop': '30px'}))  # type: ignore
    content.append(html.Button('è¦å› åˆ†æãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’', id='factor-train-button', n_clicks=0))  # type: ignore
    content.append(html.Div(id='factor-output'))  # type: ignore

    # Over/Short Log section
    events_df = data_get('shortage_events', pd.DataFrame())
    if not events_df.empty:
        content.append(html.Hr())  # type: ignore
        content.append(html.H4('éä¸è¶³æ‰‹å‹•ãƒ­ã‚°', style={'marginTop': '30px'}))  # type: ignore
        content.append(dash_table.DataTable(
            id='over-shortage-table',
            data=events_df.to_dict('records'),
            columns=[{'name': c, 'id': c, 'presentation': 'input'} for c in events_df.columns],
            editable=True,
        ))
        content.append(dcc.RadioItems(
            id='log-save-mode',
            options=[{'label': 'è¿½è¨˜', 'value': 'append'}, {'label': 'ä¸Šæ›¸ã', 'value': 'overwrite'}],
            value='è¿½è¨˜',
            inline=True,
            style={'marginTop': '10px'}
        ))
        content.append(html.Button('ãƒ­ã‚°ã‚’ä¿å­˜', id='save-log-button', n_clicks=0, style={'marginTop': '10px'}))  # type: ignore
        content.append(html.Div(id='save-log-msg'))  # type: ignore

    return html.Div(content)


def generate_optimization_analysis(scope, detail_values):
    """æœ€é©åŒ–åˆ†æã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆã™ã‚‹å…±é€šé–¢æ•°"""
    try:
        # è©³ç´°å€¤ã®å‡¦ç†
        detail_values = detail_values or []
        if not detail_values:
            detail_values = ['ALL']
        
        # é©åˆ‡ãªãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚­ãƒ¼ã‚’æ±ºå®š
        key_suffix = ""
        if scope == 'role' and detail_values and detail_values[0] != 'ALL':
            # è·ç¨®åˆ¥: ç›´æ¥è·ç¨®åã‚’ä½¿ç”¨
            key_suffix = safe_filename(detail_values[0])
        elif scope == 'employment' and detail_values and detail_values[0] != 'ALL':
            # é›‡ç”¨å½¢æ…‹åˆ¥: emp_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãã§ä½¿ç”¨
            key_suffix = f"emp_{safe_filename(detail_values[0])}"

        heat_key = f"heat_{key_suffix}" if key_suffix else "heat_all"
        df_heat = data_get(heat_key, pd.DataFrame())
        
        if df_heat.empty:
            return [
                html.H4("æœ€é©åŒ–åˆ†æ", style={'marginTop': '20px'}),
                html.P(f"é¸æŠã•ã‚ŒãŸæ¡ä»¶ï¼ˆ{scope}ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            ]
        
        # æ—¥ä»˜åˆ—ã‚’ç‰¹å®š
        date_cols = [col for col in df_heat.columns 
                    if col not in ['staff', 'role', 'code', 'sum', 'max', 'min', 'avg', 'need', 'upper']]
        
        if not date_cols:
            return [
                html.H4("æœ€é©åŒ–åˆ†æ", style={'marginTop': '20px'}),
                html.P("åˆ†æã«å¿…è¦ãªæ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            ]
        
        # å®Ÿç¸¾äººæ•°ã€å¿…è¦äººæ•°ã€ä¸Šé™äººæ•°ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        staff_df = df_heat[date_cols].fillna(0)
        
        # needå€¤ã®è¨ˆç®—ï¼ˆä¸è¶³åˆ†æã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        if scope == 'overall':
            need_per_date_slot_df = data_get('need_per_date_slot', pd.DataFrame())
            if not need_per_date_slot_df.empty:
                need_per_date_slot_df.columns = [str(col) for col in need_per_date_slot_df.columns]
                common_cols = list(set(date_cols) & set(need_per_date_slot_df.columns))
                if common_cols:
                    need_df = need_per_date_slot_df[common_cols].fillna(0)
                    need_df.index = df_heat.index
                else:
                    need_df = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                                         index=df_heat.index, columns=date_cols)
            else:
                need_df = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                                     index=df_heat.index, columns=date_cols)
        else:
            # è·ç¨®åˆ¥ãƒ»é›‡ç”¨å½¢æ…‹åˆ¥ã®å ´åˆã¯ã€å…±é€šé–¢æ•°ã‚’ä½¿ç”¨
            need_df = calculate_role_dynamic_need(df_heat, date_cols, heat_key)
        
        upper_df = pd.DataFrame(np.repeat(df_heat['upper'].values[:, np.newaxis], len(date_cols), axis=1),
                               index=df_heat.index, columns=date_cols)

        # æœ€é©åŒ–ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        # ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£: (need - staff) / need (need > 0 ã®å ´åˆã®ã¿)
        lack_penalty_df = pd.DataFrame(0.0, index=need_df.index, columns=need_df.columns)
        valid_need_mask = need_df > 0
        lack_penalty_df = lack_penalty_df.where(~valid_need_mask, 
                                               ((need_df - staff_df) / need_df).clip(lower=0))
        
        # éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£: (staff - upper) / upper (upper > 0 ã®å ´åˆã®ã¿)
        excess_penalty_df = pd.DataFrame(0.0, index=upper_df.index, columns=upper_df.columns)
        valid_upper_mask = upper_df > 0
        excess_penalty_df = excess_penalty_df.where(~valid_upper_mask,
                                                   ((staff_df - upper_df) / upper_df).clip(lower=0))
        
        # æœ€é©åŒ–ã‚¹ã‚³ã‚¢ = 1 - (ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ Ã— 0.6 + éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£ Ã— 0.4)
        optimization_score_df = 1 - (lack_penalty_df * 0.6 + excess_penalty_df * 0.4)
        optimization_score_df = optimization_score_df.clip(lower=0, upper=1)
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ä½œæˆ
        content = [html.H4("æœ€é©åŒ–åˆ†æ", style={'marginTop': '20px'})]
        
        # æœ€é©åŒ–ã‚¹ã‚³ã‚¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        if not optimization_score_df.empty:
            score_renamed = optimization_score_df.copy()
            score_renamed.columns = [date_with_weekday(c) for c in score_renamed.columns]
            
            fig_score = px.imshow(
                score_renamed,
                aspect='auto',
                color_continuous_scale='RdYlGn',  # èµ¤ï¼ˆæ‚ªã„ï¼‰ã‹ã‚‰ç·‘ï¼ˆè‰¯ã„ï¼‰
                title='æœ€é©åŒ–ã‚¹ã‚³ã‚¢ï¼ˆ1.0ãŒæœ€è‰¯ã€0.0ãŒæœ€æ‚ªï¼‰',
                labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ã‚¹ã‚³ã‚¢'},
            )
            fig_score.update_xaxes(tickvals=list(range(len(score_renamed.columns))))
            content.append(dcc.Graph(figure=fig_score))
        
        # ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        if not lack_penalty_df.empty:
            lack_renamed = lack_penalty_df.copy()
            lack_renamed.columns = [date_with_weekday(c) for c in lack_renamed.columns]
            
            fig_lack = px.imshow(
                lack_renamed,
                aspect='auto',
                color_continuous_scale='Reds',
                title='ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆ0.0ãŒæœ€è‰¯ï¼‰',
                labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ãƒšãƒŠãƒ«ãƒ†ã‚£'},
            )
            fig_lack.update_xaxes(tickvals=list(range(len(lack_renamed.columns))))
            content.append(dcc.Graph(figure=fig_lack))
        
        # éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        if not excess_penalty_df.empty:
            excess_renamed = excess_penalty_df.copy()
            excess_renamed.columns = [date_with_weekday(c) for c in excess_renamed.columns]
            
            fig_excess = px.imshow(
                excess_renamed,
                aspect='auto',
                color_continuous_scale='Blues',
                title='éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆ0.0ãŒæœ€è‰¯ï¼‰',
                labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ãƒšãƒŠãƒ«ãƒ†ã‚£'},
            )
            fig_excess.update_xaxes(tickvals=list(range(len(excess_renamed.columns))))
            content.append(dcc.Graph(figure=fig_excess))
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        avg_score = optimization_score_df.mean().mean()
        min_score = optimization_score_df.min().min()
        max_score = optimization_score_df.max().max()
        
        content.append(html.Div([
            html.H5("æœ€é©åŒ–çµ±è¨ˆ", style={'marginTop': '20px'}),
            html.P(f"å¹³å‡æœ€é©åŒ–ã‚¹ã‚³ã‚¢: {avg_score:.3f}"),
            html.P(f"æœ€ä½ã‚¹ã‚³ã‚¢: {min_score:.3f}"),
            html.P(f"æœ€é«˜ã‚¹ã‚³ã‚¢: {max_score:.3f}"),
            html.P("ã‚¹ã‚³ã‚¢ãŒ1.0ã«è¿‘ã„ã»ã©æœ€é©ãªäººå“¡é…ç½®ã‚’ç¤ºã—ã¾ã™ã€‚")
        ], className="card p-3", style={'marginTop': '20px'}))
        
        return content
        
    except Exception as e:
        log.error(f"æœ€é©åŒ–åˆ†æã®ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return [
            html.H4("æœ€é©åŒ–åˆ†æ", style={'marginTop': '20px'}),
            html.P(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})
        ]


def create_optimization_tab() -> html.Div:
    """æœ€é©åŒ–åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    # åˆæœŸçŠ¶æ…‹ã§å…¨ä½“åˆ†æã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆ
    try:
        initial_content = generate_optimization_analysis('overall', ['ALL'])
    except:
        initial_content = [html.P("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")]
    
    return html.Div([  # type: ignore
        html.Div(id='optimization-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("æœ€é©åŒ–åˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
        html.Div([  # type: ignore
            html.Label("è¡¨ç¤ºç¯„å›²"),  # type: ignore
            dcc.Dropdown(
                id='opt-scope',
                options=[
                    {'label': 'å…¨ä½“', 'value': 'overall'},
                    {'label': 'è·ç¨®åˆ¥', 'value': 'role'},
                    {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'employment'}
                ],
                value='overall',
                clearable=False
            ),
        ], style={'width': '30%', 'marginBottom': '20px'}),
        html.Div(id='opt-detail-container'),  # type: ignore
        html.Div(id='optimization-content', children=initial_content)  # type: ignore
    ])


def create_leave_analysis_tab() -> html.Div:
    """ä¼‘æš‡åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='leave-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("ä¼‘æš‡åˆ†æ", style={'marginBottom': '20px'})]  # type: ignore

    df_staff_balance = data_get('staff_balance_daily', pd.DataFrame())
    df_daily_summary = data_get('daily_summary', pd.DataFrame())
    df_concentration = data_get('concentration_requested', pd.DataFrame())
    df_ratio_breakdown = data_get('leave_ratio_breakdown', pd.DataFrame())

    if not df_staff_balance.empty:
        fig_balance = px.line(
            df_staff_balance,
            x='date',
            y=['total_staff', 'leave_applicants_count', 'non_leave_staff'],
            title='å‹¤å‹™äºˆå®šäººæ•°ã¨å…¨ä¼‘æš‡å–å¾—è€…æ•°ã®æ¨ç§»',
            labels={'value': 'äººæ•°', 'variable': 'é …ç›®', 'date': 'æ—¥ä»˜'},
            markers=True
        )
        fig_balance.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_balance))
        content.append(dash_table.DataTable(
            data=df_staff_balance.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_staff_balance.columns]
        ))

    if not df_daily_summary.empty:
        fig_breakdown = px.bar(
            df_daily_summary,
            x='date',
            y='total_leave_days',
            color='leave_type',
            barmode='stack',
            title='æ—¥åˆ¥ ä¼‘æš‡å–å¾—è€…æ•°ï¼ˆå†…è¨³ï¼‰',
            labels={'date': 'æ—¥ä»˜', 'total_leave_days': 'ä¼‘æš‡å–å¾—è€…æ•°', 'leave_type': 'ä¼‘æš‡ã‚¿ã‚¤ãƒ—'}
        )
        fig_breakdown.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_breakdown))

    if not df_ratio_breakdown.empty:
        fig_ratio_break = px.bar(
            df_ratio_breakdown,
            x='dayofweek',
            y='leave_ratio',
            color='leave_type',
            facet_col='month_period',
            category_orders={
                'dayofweek': ['æœˆæ›œæ—¥', 'ç«æ›œæ—¥', 'æ°´æ›œæ—¥', 'æœ¨æ›œæ—¥', 'é‡‘æ›œæ—¥', 'åœŸæ›œæ—¥', 'æ—¥æ›œæ—¥'],
                'month_period': ['æœˆåˆ(1-10æ—¥)', 'æœˆä¸­(11-20æ—¥)', 'æœˆæœ«(21-æœ«æ—¥)'],
            },
            labels={'dayofweek': 'æ›œæ—¥', 'leave_ratio': 'å‰²åˆ', 'leave_type': 'ä¼‘æš‡ã‚¿ã‚¤ãƒ—', 'month_period': 'æœˆæœŸé–“'},
            title='æ›œæ—¥ãƒ»æœˆæœŸé–“åˆ¥ä¼‘æš‡å–å¾—ç‡'
        )
        content.append(dcc.Graph(figure=fig_ratio_break))

    if not df_concentration.empty:
        fig_conc = go.Figure()
        fig_conc.add_trace(go.Scatter(
            x=df_concentration['date'],
            y=df_concentration['leave_applicants_count'],
            mode='lines+markers',
            name='ä¼‘æš‡ç”³è«‹è€…æ•°',
            line=dict(shape='spline', smoothing=0.5),
            marker=dict(size=6)
        ))
        if 'is_concentrated' in df_concentration.columns:
            concentrated = df_concentration[df_concentration['is_concentrated']]
            if not concentrated.empty:
                fig_conc.add_trace(go.Scatter(
                    x=concentrated['date'],
                    y=concentrated['leave_applicants_count'],
                    mode='markers',
                    marker=dict(color='red', size=12, symbol='diamond'),
                    name='é–¾å€¤è¶…éæ—¥',
                    hovertemplate='<b>%{x|%Y-%m-%d}</b><br>ç”³è«‹è€…æ•°: %{y}äºº<extra></extra>'
                ))

        fig_conc.update_layout(
            title='å¸Œæœ›ä¼‘ ç”³è«‹è€…æ•°ã®æ¨ç§»ã¨é›†ä¸­æ—¥',
            xaxis_title='æ—¥ä»˜',
            yaxis_title='ç”³è«‹è€…æ•°'
        )
        fig_conc.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_conc))

    return html.Div(content)


def create_cost_analysis_tab() -> html.Div:
    """ã‚³ã‚¹ãƒˆåˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    return html.Div([
        html.Div(id='cost-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("äººä»¶è²»åˆ†æ", style={'marginBottom': '20px'}),

        html.H4("å‹•çš„ã‚³ã‚¹ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", style={'marginTop': '30px'}),
        dcc.RadioItems(
            id='cost-by-radio',
            options=[
                {'label': 'è·ç¨®åˆ¥', 'value': 'role'},
                {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'employment'},
                {'label': 'ã‚¹ã‚¿ãƒƒãƒ•åˆ¥', 'value': 'staff'},
            ],
            value='role',
            inline=True,
            style={'marginBottom': '10px'},
        ),
        html.Div(id='wage-input-container'),

        dcc.Loading(
            id="loading-cost-analysis",
            type="circle",
            children=html.Div(id='cost-analysis-content')
        )
    ])


def create_hire_plan_tab() -> html.Div:
    """æ¡ç”¨è¨ˆç”»ã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='hire-plan-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("æ¡ç”¨è¨ˆç”»", style={'marginBottom': '20px'})]  # type: ignore

    df_hire = data_get('hire_plan', pd.DataFrame())
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame())
    
    if not df_hire.empty:
        content.append(html.H4("å¿…è¦FTEï¼ˆè·ç¨®åˆ¥ï¼‰"))  # type: ignore

        # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«ç¿»è¨³
        df_hire_display = df_hire.copy()
        column_translations = {
            'role': 'è·ç¨®',
            'hire_fte': 'å¿…è¦FTE',
            'shortage_hours': 'ä¸è¶³æ™‚é–“',
            'current_fte': 'ç¾åœ¨FTE',
            'target_fte': 'ç›®æ¨™FTE',
            'priority': 'å„ªå…ˆåº¦',
            'cost_per_fte': 'FTEå˜ä¾¡',
            'total_cost': 'ç·ã‚³ã‚¹ãƒˆ'
        }
        df_hire_display.rename(columns=column_translations, inplace=True)

        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        content.append(dash_table.DataTable(
            data=df_hire_display.to_dict('records'),
            columns=[{'name': col, 'id': col} for col in df_hire_display.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'}
        ))

        # ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆå…ƒã®åˆ—åã‚’ä½¿ç”¨ï¼‰
        if 'role' in df_hire.columns and 'hire_fte' in df_hire.columns:
            fig_hire = px.bar(
                df_hire,
                x='role',
                y='hire_fte',
                title='è·ç¨®åˆ¥å¿…è¦FTE',
                labels={'role': 'è·ç¨®', 'hire_fte': 'å¿…è¦FTE'},
                color_discrete_sequence=['#1f77b4']
            )
            content.append(dcc.Graph(figure=fig_hire))

        # æ¡ç”¨æˆ¦ç•¥ææ¡ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
        content.append(html.Div([
            html.H4("æ¡ç”¨æˆ¦ç•¥ã®ææ¡ˆ", style={'marginTop': '30px'}),
            html.P("åˆ†æçµæœã«åŸºã¥ãæ¡ç”¨å„ªå…ˆåº¦ã¨æˆ¦ç•¥çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼š"),
            html.Ul([
                html.Li("æœ€ã‚‚ä¸è¶³ã®æ·±åˆ»ãªè·ç¨®ã‹ã‚‰å„ªå…ˆçš„ã«æ¡ç”¨ã‚’æ¤œè¨"),
                html.Li("å­£ç¯€æ€§ã‚’è€ƒæ…®ã—ãŸæ¡ç”¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®æœ€é©åŒ–"),
                html.Li("æ—¢å­˜è·å“¡ã®è² è·è»½æ¸›åŠ¹æœã®äºˆæ¸¬"),
                html.Li("ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®é«˜ã„æ¡ç”¨ãƒãƒ£ãƒãƒ«ã®æ´»ç”¨")
            ])
        ], style={'padding': '20px', 'backgroundColor': '#f8f9fa', 'borderRadius': '8px', 'marginTop': '20px'}))

    # æœ€é©æ¡ç”¨è¨ˆç”»
    df_optimal = data_get('optimal_hire_plan', pd.DataFrame())
    if not df_optimal.empty:
        content.append(html.H4("æœ€é©æ¡ç”¨è¨ˆç”»", style={'marginTop': '30px'}))  # type: ignore
        content.append(html.P("åˆ†æã®çµæœã€ä»¥ä¸‹ã®å…·ä½“çš„ãªæ¡ç”¨è¨ˆç”»ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"))
        
        # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«ç¿»è¨³
        df_optimal_display = df_optimal.copy()
        df_optimal_display.rename(columns=column_translations, inplace=True)
        
        content.append(dash_table.DataTable(
            data=df_optimal_display.to_dict('records'),
            columns=[{'name': col, 'id': col} for col in df_optimal_display.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'}
        ))

    return html.Div(content)


def create_fatigue_tab() -> html.Div:
    """ç–²åŠ´åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    explanation = """
    #### ç–²åŠ´åˆ†æã®è©•ä¾¡æ–¹æ³•
    ã‚¹ã‚¿ãƒƒãƒ•ã®ç–²åŠ´ã‚¹ã‚³ã‚¢ã¯ã€ä»¥ä¸‹ã®è¦ç´ ã‚’ç·åˆçš„ã«è©•ä¾¡ã—ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚å„è¦ç´ ã¯ã€å…¨ã‚¹ã‚¿ãƒƒãƒ•å†…ã§ã®ç›¸å¯¾çš„ãªä½ç½®ï¼ˆåå·®ï¼‰ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢åŒ–ã•ã‚Œã€é‡ã¿ä»˜ã‘ã•ã‚Œã¦åˆè¨ˆã•ã‚Œã¾ã™ã€‚
    - **å‹¤å‹™é–‹å§‹æ™‚åˆ»ã®ã°ã‚‰ã¤ã:** å‡ºå‹¤æ™‚åˆ»ãŒä¸è¦å‰‡ã§ã‚ã‚‹ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **æ¥­å‹™ã®å¤šæ§˜æ€§:** æ‹…å½“ã™ã‚‹æ¥­å‹™ï¼ˆå‹¤å‹™ã‚³ãƒ¼ãƒ‰ï¼‰ã®ç¨®é¡ãŒå¤šã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **åŠ´åƒæ™‚é–“ã®ã°ã‚‰ã¤ã:** æ—¥ã€…ã®åŠ´åƒæ™‚é–“ãŒä¸è¦å‰‡ã§ã‚ã‚‹ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **çŸ­ã„ä¼‘æ¯æœŸé–“:** å‹¤å‹™é–“ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«ãŒçŸ­ã„é »åº¦ãŒé«˜ã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **é€£å‹¤:** 3é€£å‹¤ä»¥ä¸Šã®é€£ç¶šå‹¤å‹™ãŒå¤šã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **å¤œå‹¤æ¯”ç‡:** å…¨å‹¤å‹™ã«å ã‚ã‚‹å¤œå‹¤ã®å‰²åˆãŒé«˜ã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚

    *ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€ã“ã‚Œã‚‰ã®è¦ç´ ã¯å‡ç­‰ãªé‡ã¿ï¼ˆå„1.0ï¼‰ã§è©•ä¾¡ã•ã‚Œã¾ã™ã€‚*
    """
    content = [
        html.Div(  # type: ignore
            dcc.Markdown(explanation),
            style={
                'padding': '15px',
                'backgroundColor': '#e9f2fa',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #cce5ff',
            },
        ),
        html.H3("ç–²åŠ´åˆ†æ", style={'marginBottom': '20px'}),  # type: ignore
    ]
    df_fatigue = data_get('fatigue_score', pd.DataFrame())

    if not df_fatigue.empty:
        # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«ç¿»è¨³
        df_fatigue_display = df_fatigue.reset_index().rename(columns={'index': 'staff'})
        column_translations = {
            'staff': 'è·å“¡å',
            'fatigue_score': 'ç–²åŠ´ã‚¹ã‚³ã‚¢',
            'work_start_variance': 'å‹¤å‹™é–‹å§‹æ™‚åˆ»ã®ã°ã‚‰ã¤ã',
            'work_diversity': 'æ¥­å‹™ã®å¤šæ§˜æ€§',
            'work_duration_variance': 'åŠ´åƒæ™‚é–“ã®ã°ã‚‰ã¤ã',
            'short_rest_frequency': 'çŸ­ã„ä¼‘æ¯æœŸé–“ã®é »åº¦',
            'consecutive_work_days': 'é€£å‹¤å›æ•°',
            'night_shift_ratio': 'å¤œå‹¤æ¯”ç‡'
        }
        df_fatigue_display.rename(columns=column_translations, inplace=True)

        # 1. å¾“æ¥ã®æ£’ã‚°ãƒ©ãƒ•
        fig_bar = px.bar(
            df_fatigue_display,
            x='è·å“¡å',
            y='ç–²åŠ´ã‚¹ã‚³ã‚¢',
            title='ã‚¹ã‚¿ãƒƒãƒ•åˆ¥ç–²åŠ´ã‚¹ã‚³ã‚¢',
            labels={'è·å“¡å': 'è·å“¡å', 'ç–²åŠ´ã‚¹ã‚³ã‚¢': 'ç–²åŠ´ã‚¹ã‚³ã‚¢'},
            color='ç–²åŠ´ã‚¹ã‚³ã‚¢',
            color_continuous_scale='Reds'
        )
        content.append(dcc.Graph(figure=fig_bar))

        # 2. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆç–²åŠ´è¦å› ã®è©³ç´°åˆ†æï¼‰
        fatigue_factors = ['å‹¤å‹™é–‹å§‹æ™‚åˆ»ã®ã°ã‚‰ã¤ã', 'æ¥­å‹™ã®å¤šæ§˜æ€§', 'åŠ´åƒæ™‚é–“ã®ã°ã‚‰ã¤ã', 
                         'çŸ­ã„ä¼‘æ¯æœŸé–“ã®é »åº¦', 'é€£å‹¤å›æ•°', 'å¤œå‹¤æ¯”ç‡']
        available_factors = [col for col in fatigue_factors if col in df_fatigue_display.columns]
        
        if len(df_fatigue_display) > 1 and available_factors:
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ï¼ˆ0-1ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
            factor_data = df_fatigue_display[available_factors].copy()
            for col in available_factors:
                if factor_data[col].max() != factor_data[col].min():
                    factor_data[col] = (factor_data[col] - factor_data[col].min()) / (factor_data[col].max() - factor_data[col].min())
            
            fig_heatmap = px.imshow(
                factor_data.T,
                x=df_fatigue_display['è·å“¡å'],
                y=available_factors,
                title='ç–²åŠ´è¦å› ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆè·å“¡åˆ¥è©³ç´°åˆ†æï¼‰',
                color_continuous_scale='Reds',
                aspect='auto'
            )
            fig_heatmap.update_layout(xaxis_title="è·å“¡å", yaxis_title="ç–²åŠ´è¦å› ")
            content.append(dcc.Graph(figure=fig_heatmap))

        # 3. æ•£å¸ƒå›³ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆç–²åŠ´è¦å› é–“ã®ç›¸é–¢ï¼‰
        if len(available_factors) >= 2:
            # 2ã¤ã®ä¸»è¦è¦å› ã®æ•£å¸ƒå›³
            fig_scatter = px.scatter(
                df_fatigue_display,
                x=available_factors[0],
                y=available_factors[1] if len(available_factors) > 1 else available_factors[0],
                size='ç–²åŠ´ã‚¹ã‚³ã‚¢',
                hover_name='è·å“¡å',
                title=f'{available_factors[0]} vs {available_factors[1] if len(available_factors) > 1 else available_factors[0]}',
                color='ç–²åŠ´ã‚¹ã‚³ã‚¢',
                color_continuous_scale='Reds'
            )
            content.append(dcc.Graph(figure=fig_scatter))

        # 4. ç–²åŠ´è¦å› ã®ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹
        if len(available_factors) >= 2:
            corr_matrix = df_fatigue_display[available_factors].corr()
            fig_corr = px.imshow(
                corr_matrix,
                text_auto=True,
                aspect="auto",
                title="ç–²åŠ´è¦å› é–“ã®ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹",
                color_continuous_scale='RdBu_r'
            )
            fig_corr.update_layout(
                xaxis_title="ç–²åŠ´è¦å› ",
                yaxis_title="ç–²åŠ´è¦å› "
            )
            content.append(dcc.Graph(figure=fig_corr))

        # 5. ç–²åŠ´ã‚¹ã‚³ã‚¢åˆ†å¸ƒã¨ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
        fig_box = px.box(
            df_fatigue_display,
            y='ç–²åŠ´ã‚¹ã‚³ã‚¢',
            title='ç–²åŠ´ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒï¼ˆãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆï¼‰',
            points="all"  # å…¨ãƒ‡ãƒ¼ã‚¿ç‚¹ã‚’è¡¨ç¤º
        )
        content.append(dcc.Graph(figure=fig_box))

        # 6. ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼ˆä¸Šä½3åã®è©³ç´°æ¯”è¼ƒï¼‰
        if len(df_fatigue_display) >= 3 and available_factors:
            top3 = df_fatigue_display.nlargest(3, 'ç–²åŠ´ã‚¹ã‚³ã‚¢')
            fig_radar = go.Figure()
            
            for _, row in top3.iterrows():
                factor_values = [row[factor] for factor in available_factors]
                # æ­£è¦åŒ–ï¼ˆ0-1ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
                max_val = max(factor_values) if max(factor_values) > 0 else 1
                min_val = min(factor_values)
                normalized_values = [(val - min_val) / (max_val - min_val) if max_val != min_val else 0.5 for val in factor_values]
                
                fig_radar.add_trace(go.Scatterpolar(
                    r=normalized_values,
                    theta=available_factors,
                    fill='toself',
                    name=row['è·å“¡å'],
                    opacity=0.7
                ))
            
            fig_radar.update_layout(
                polar=dict(
                    radialaxis=dict(visible=True, range=[0, 1])
                ),
                title="ç–²åŠ´åº¦ä¸Šä½3åã®è¦å› æ¯”è¼ƒï¼ˆãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼‰",
                showlegend=True
            )
            content.append(dcc.Graph(figure=fig_radar))

        # 7. ç–²åŠ´åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        if 'ç–²åŠ´ã‚¹ã‚³ã‚¢' in df_fatigue_display.columns:
            ranking = df_fatigue_display.sort_values('ç–²åŠ´ã‚¹ã‚³ã‚¢', ascending=False)[['è·å“¡å', 'ç–²åŠ´ã‚¹ã‚³ã‚¢']]
            ranking.index = range(1, len(ranking) + 1)
            ranking.index.name = 'é †ä½'
            ranking = ranking.reset_index()
            content.append(html.H4('ç–²åŠ´åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°'))
            content.append(dash_table.DataTable(
                data=ranking.to_dict('records'),
                columns=[{'name': i, 'id': i} for i in ranking.columns],
                style_cell={'textAlign': 'left'},
                style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},
                style_data_conditional=[
                    {
                        'if': {'row_index': 0},
                        'backgroundColor': '#ffebee',
                        'color': 'black',
                    },
                    {
                        'if': {'row_index': 1},
                        'backgroundColor': '#fff3e0',
                        'color': 'black',
                    },
                    {
                        'if': {'row_index': 2},
                        'backgroundColor': '#fff8e1',
                        'color': 'black',
                    }
                ]
            ))

        # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        content.append(html.H4("è©³ç´°ãƒ‡ãƒ¼ã‚¿", style={'marginTop': '30px'}))
        content.append(dash_table.DataTable(
            data=df_fatigue_display.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_fatigue_display.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},
            sort_action="native"
        ))
        
        # ç–²åŠ´åº¦äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        content.extend([
            html.Hr(style={'margin': '40px 0'}),
            html.H3("ç–²åŠ´åº¦äºˆæ¸¬ (AIäºˆæ¸¬)", style={'marginBottom': '20px', 'color': '#1976d2'}),
            
            html.Div([
                html.Div([
                    html.Label("äºˆæ¸¬æœŸé–“:", style={'fontWeight': 'bold', 'marginBottom': '5px'}),
                    dcc.Slider(
                        id='fatigue-forecast-days',
                        min=3,
                        max=14,
                        step=1,
                        value=7,
                        marks={i: f'{i}æ—¥' for i in [3, 7, 14]},
                        tooltip={"placement": "bottom", "always_visible": True}
                    ),
                ], style={'width': '48%', 'display': 'inline-block'}),
                
                html.Div([
                    html.Label("ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—:", style={'fontWeight': 'bold', 'marginBottom': '5px'}),
                    dcc.Dropdown(
                        id='fatigue-model-type',
                        options=[
                            {'label': 'LSTM (é•·çŸ­æœŸè¨˜æ†¶)', 'value': 'lstm'},
                            {'label': 'GRU (ã‚²ãƒ¼ãƒˆä»˜ãå›å¸°)', 'value': 'gru'},
                            {'label': 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰', 'value': 'hybrid'}
                        ],
                        value='lstm',
                        style={'marginBottom': '10px'}
                    ),
                ], style={'width': '48%', 'float': 'right', 'display': 'inline-block'}),
            ], style={'marginBottom': '20px'}),
            
            html.Div([
                dcc.Checklist(
                    id='fatigue-personal-models',
                    options=[{'label': 'å€‹äººåˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ã‚’æœ‰åŠ¹ã«ã™ã‚‹', 'value': 'personal'}],
                    value=['personal'],
                    style={'marginBottom': '15px'}
                ),
                
                html.Button('ç–²åŠ´åº¦äºˆæ¸¬ã‚’å®Ÿè¡Œ', id='run-fatigue-prediction-button', 
                           className='btn btn-primary',
                           style={'marginTop': '10px'}),
            ], style={'padding': '20px', 'backgroundColor': '#f5f5f5', 'borderRadius': '8px'}),
            
            # äºˆæ¸¬çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
            html.Div(id='fatigue-prediction-results', style={'marginTop': '30px'}),
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤ºã‚¨ãƒªã‚¢
            html.Div(id='fatigue-alerts', style={'marginTop': '30px'}),
            
            # æœ€é©åŒ–ææ¡ˆã‚¨ãƒªã‚¢
            html.Div(id='fatigue-optimization', style={'marginTop': '30px'})
        ])
    else:
        content.append(html.P("ç–²åŠ´åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))  # type: ignore

    return html.Div(content)






def create_advanced_forecast_tab() -> html.Div:
    """é«˜åº¦äºˆæ¸¬ã‚¿ãƒ–ã‚’ä½œæˆ"""
    from shift_suite.tasks.advanced_forecast import AdvancedForecastEngine
    
    content = [
        html.Div(
            dcc.Markdown("""
            #### é«˜åº¦äºˆæ¸¬åˆ†æ
            æœ¬ã‚¿ãƒ–ã§ã¯ã€SARIMAã€Prophetã€LSTMãªã©ã®æœ€å…ˆç«¯ã®äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€
            ã‚ˆã‚Šç²¾åº¦ã®é«˜ã„éœ€è¦äºˆæ¸¬ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
            
            **åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:**
            - **SARIMA**: å­£ç¯€æ€§ã‚’è€ƒæ…®ã—ãŸæ™‚ç³»åˆ—äºˆæ¸¬
            - **Prophet**: Facebooké–‹ç™ºã®é«˜åº¦ãªäºˆæ¸¬ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
            - **LSTM**: ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®é•·æœŸè¨˜æ†¶äºˆæ¸¬
            - **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«**: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®çµ±åˆã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š
            """),
            style={
                'padding': '15px',
                'backgroundColor': '#e3f2fd',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #90caf9'
            }
        ),
        html.H3("é«˜åº¦äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³", style={'marginBottom': '20px'}),
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        html.Div([
            html.Label("äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ:", style={'fontWeight': 'bold'}),
            dcc.Checklist(
                id='advanced-forecast-models',
                options=[
                    {'label': 'SARIMA (å­£ç¯€æ€§è‡ªå·±å›å¸°å’Œåˆ†ç§»å‹•å¹³å‡)', 'value': 'sarima'},
                    {'label': 'Prophet (Facebookäºˆæ¸¬)', 'value': 'prophet'},
                    {'label': 'LSTM (é•·çŸ­æœŸè¨˜æ†¶ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯)', 'value': 'lstm'},
                ],
                value=['sarima', 'prophet'],
                style={'marginBottom': '15px'}
            ),
            
            html.Label("äºˆæ¸¬æœŸé–“ï¼ˆæ—¥æ•°ï¼‰:", style={'fontWeight': 'bold', 'marginTop': '10px'}),
            dcc.Slider(
                id='advanced-forecast-periods',
                min=7,
                max=90,
                step=7,
                value=30,
                marks={i: f'{i}æ—¥' for i in [7, 14, 30, 60, 90]},
                tooltip={"placement": "bottom", "always_visible": True}
            ),
            
            dcc.Checklist(
                id='advanced-forecast-ensemble',
                options=[{'label': 'ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã‚’æœ‰åŠ¹ã«ã™ã‚‹', 'value': 'ensemble'}],
                value=['ensemble'],
                style={'marginTop': '15px', 'marginBottom': '15px'}
            ),
            
            html.Button('é«˜åº¦äºˆæ¸¬ã‚’å®Ÿè¡Œ', id='run-advanced-forecast-button', 
                       className='btn btn-primary',
                       style={'marginTop': '20px'}),
        ], style={'padding': '20px', 'backgroundColor': '#f5f5f5', 'borderRadius': '8px'}),
        
        # çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
        html.Div(id='advanced-forecast-results', style={'marginTop': '30px'}),
        
        # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
        html.Div(id='advanced-forecast-comparison', style={'marginTop': '30px'}),
        
        # äºˆæ¸¬ç²¾åº¦æŒ‡æ¨™
        html.Div(id='advanced-forecast-metrics', style={'marginTop': '30px'})
    ]
    
    return html.Div(content)


def create_seasonal_analysis_tab() -> html.Div:
    """å­£ç¯€æ€§åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    
    content = [
        html.Div(
            dcc.Markdown("""
            #### å­£ç¯€æ€§åˆ†æ
            æœ¬ã‚¿ãƒ–ã§ã¯ã€ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã€å¹´é–“ãƒ»æœˆé–“ãƒ»é€±é–“ãƒ»æ—¥å†…ã®
            å‘¨æœŸæ€§ã‚„å­£ç¯€æ€§ã‚’ç§‘å­¦çš„ã«è§£æ˜ã—ã¾ã™ã€‚
            
            **åˆ†æå†…å®¹:**
            - **æ™‚ç³»åˆ—åˆ†è§£**: å‚¾å‘ãƒ»å­£ç¯€ãƒ»æ®‹å·®æˆåˆ†ã¸ã®åˆ†é›¢
            - **ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æ**: FFTã«ã‚ˆã‚‹ä¸»è¦å‘¨æœŸã®ç‰¹å®š
            - **ç¥æ—¥åŠ¹æœ**: ä¼‘æ—¥ãƒ»ç¥æ—¥ãŒå‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸ãˆã‚‹å½±éŸ¿
            - **ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°**: é¡ä¼¼ã™ã‚‹å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            - **ç•°å¸¸å€¤æ¤œå‡º**: å­£ç¯€æ€§ã‹ã‚‰å¤–ã‚ŒãŸç•°å¸¸ãªå‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®š
            """),
            style={
                'padding': '15px',
                'backgroundColor': '#e8f5e8',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #4caf50'
            }
        ),
        html.H3("å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ", style={'marginBottom': '20px'}),
        
        # åˆ†æè¨­å®š
        html.Div([
            html.Label("åˆ†æå¯¾è±¡ã®é¸æŠ:", style={'fontWeight': 'bold'}),
            dcc.Checklist(
                id='seasonal-analysis-features',
                options=[
                    {'label': 'æ™‚ç³»åˆ—åˆ†è§£ï¼ˆSTLãƒ»å¤å…¸çš„åˆ†è§£ï¼‰', 'value': 'decomposition'},
                    {'label': 'ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æï¼ˆFFTãƒ»å‘¨æœŸæ¤œå‡ºï¼‰', 'value': 'spectral'},
                    {'label': 'ç¥æ—¥ãƒ»ä¼‘æ—¥åŠ¹æœã®åˆ†æ', 'value': 'holiday_effects'},
                    {'label': 'å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°', 'value': 'clustering'},
                ],
                value=['decomposition', 'spectral', 'holiday_effects'],
                style={'marginBottom': '15px'}
            ),
            
            html.Label("åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿:", style={'fontWeight': 'bold', 'marginTop': '10px'}),
            dcc.RadioItems(
                id='seasonal-analysis-scope',
                options=[
                    {'label': 'å…¨ä½“ï¼ˆå…¨è·ç¨®ãƒ»å…¨é›‡ç”¨å½¢æ…‹ï¼‰', 'value': 'overall'},
                    {'label': 'è·ç¨®åˆ¥', 'value': 'by_role'},
                    {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'by_employment'},
                    {'label': 'ã™ã¹ã¦ï¼ˆè©³ç´°åˆ†æï¼‰', 'value': 'all_detailed'}
                ],
                value='overall',
                style={'marginBottom': '15px'}
            ),
            
            html.Button('å­£ç¯€æ€§åˆ†æã‚’å®Ÿè¡Œ', id='run-seasonal-analysis-button', 
                       className='btn btn-success',
                       style={'marginTop': '20px'}),
        ], style={'padding': '20px', 'backgroundColor': '#f9f9f9', 'borderRadius': '8px'}),
        
        # çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
        html.Hr(style={'margin': '30px 0'}),
        html.H4("åˆ†æçµæœ", style={'marginBottom': '20px'}),
        
        # æ™‚ç³»åˆ—åˆ†è§£çµæœ
        html.Div(id='seasonal-decomposition-results', style={'marginBottom': '30px'}),
        
        # ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æçµæœ
        html.Div(id='seasonal-spectral-results', style={'marginBottom': '30px'}),
        
        # ç¥æ—¥åŠ¹æœçµæœ
        html.Div(id='seasonal-holiday-results', style={'marginBottom': '30px'}),
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ
        html.Div(id='seasonal-clustering-results', style={'marginBottom': '30px'}),
        
        # å­£ç¯€æ€§ç•°å¸¸å€¤çµæœ
        html.Div(id='seasonal-anomaly-results', style={'marginBottom': '30px'}),
        
        # äºˆæ¸¬çµæœ
        html.Div(id='seasonal-forecast-results', style={'marginBottom': '30px'})
    ]
    
    return html.Div(content)


def create_fairness_tab() -> html.Div:
    """å…¬å¹³æ€§ã‚¿ãƒ–ã‚’ä½œæˆ"""
    explanation = """
    #### å…¬å¹³æ€§åˆ†æã®è©•ä¾¡æ–¹æ³•
    ã‚¹ã‚¿ãƒƒãƒ•é–“ã®ã€Œä¸å…¬å¹³æ„Ÿã€ã¯ã€å„å€‹äººã®åƒãæ–¹ãŒå…¨ä½“ã®å¹³å‡ã‹ã‚‰ã©ã‚Œã ã‘ä¹–é›¢ã—ã¦ã„ã‚‹ã‹ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢åŒ–ã•ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®è¦ç´ ã®ä¹–é›¢åº¦ã‚’å‡ç­‰ã«è©•ä¾¡ã—ã€ãã®å¹³å‡å€¤ã‚’ã€Œä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢ã€ã¨ã—ã¦ã„ã¾ã™ã€‚
    - **å¤œå‹¤æ¯”ç‡ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€å¤œå‹¤ã®å‰²åˆãŒæ¥µç«¯ã«å¤šã„ã€ã¾ãŸã¯å°‘ãªã„ã€‚
    - **ç·åŠ´åƒæ™‚é–“ï¼ˆã‚¹ãƒ­ãƒƒãƒˆæ•°ï¼‰ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€ç·åŠ´åƒæ™‚é–“ãŒæ¥µç«¯ã«å¤šã„ã€ã¾ãŸã¯å°‘ãªã„ã€‚
    - **é€£ä¼‘å–å¾—é »åº¦ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€é€£ä¼‘ã®å–å¾—ã—ã‚„ã™ã•ã«å·®ãŒã‚ã‚‹ã€‚

    *ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©ã€ã“ã‚Œã‚‰ã®è¦ç´ ã«ãŠã„ã¦å¹³å‡ã‹ã‚‰ã®ä¹–é›¢ãŒå¤§ãã„ï¼ˆï¼ä¸å…¬å¹³æ„Ÿã‚’æ„Ÿã˜ã‚„ã™ã„å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚*
    """
    content = [
        html.Div(  # type: ignore
            dcc.Markdown(explanation),
            style={
                'padding': '15px',
                'backgroundColor': '#f0f0f0',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #ddd',
            },
        ),
        html.H3("å…¬å¹³æ€§ (ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢)", style={'marginBottom': '20px'}),  # type: ignore
    ]
    df_fair = data_get('fairness_after', pd.DataFrame())

    if not df_fair.empty:
        # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«ç¿»è¨³
        df_fair_display = df_fair.copy()
        column_translations = {
            'staff': 'è·å“¡å',
            'unfairness_score': 'ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢',
            'fairness_score': 'å…¬å¹³æ€§ã‚¹ã‚³ã‚¢',
            'night_ratio': 'å¤œå‹¤æ¯”ç‡',
            'dev_night_ratio': 'å¤œå‹¤æ¯”ç‡ã®ä¹–é›¢',
            'dev_work_slots': 'ç·åŠ´åƒæ™‚é–“ã®ä¹–é›¢',
            'dev_consecutive': 'é€£ä¼‘å–å¾—é »åº¦ã®ä¹–é›¢',
            'work_slots': 'ç·åŠ´åƒæ™‚é–“',
            'consecutive_holidays': 'é€£ä¼‘å–å¾—å›æ•°'
        }
        df_fair_display.rename(columns=column_translations, inplace=True)

        metric_col = (
            'ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢'
            if 'ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢' in df_fair_display.columns
            else ('å…¬å¹³æ€§ã‚¹ã‚³ã‚¢' if 'å…¬å¹³æ€§ã‚¹ã‚³ã‚¢' in df_fair_display.columns else 'å¤œå‹¤æ¯”ç‡')
        )

        # 1. å¾“æ¥ã®æ£’ã‚°ãƒ©ãƒ•ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        fig_bar = px.bar(
            df_fair_display,
            x='è·å“¡å',
            y=metric_col,
            labels={'è·å“¡å': 'è·å“¡å', metric_col: 'ã‚¹ã‚³ã‚¢'},
            color=metric_col,
            color_continuous_scale='RdYlBu_r',
            title='è·å“¡åˆ¥ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢'
        )
        avg_val = df_fair_display[metric_col].mean()
        fig_bar.add_hline(y=avg_val, line_dash='dash', line_color='red', annotation_text="å¹³å‡å€¤")
        content.append(dcc.Graph(figure=fig_bar))

        # 2. å…¬å¹³æ€§è¦å› ã®æ•£å¸ƒå›³ãƒãƒˆãƒªãƒƒã‚¯ã‚¹
        fairness_factors = ['å¤œå‹¤æ¯”ç‡ã®ä¹–é›¢', 'ç·åŠ´åƒæ™‚é–“ã®ä¹–é›¢', 'é€£ä¼‘å–å¾—é »åº¦ã®ä¹–é›¢']
        available_factors = [col for col in fairness_factors if col in df_fair_display.columns]
        
        if len(available_factors) >= 2:
            # æ•£å¸ƒå›³: 2ã¤ã®ä¸»è¦è¦å› ã®é–¢ä¿‚
            fig_scatter = px.scatter(
                df_fair_display,
                x=available_factors[0],
                y=available_factors[1],
                size=metric_col,
                hover_name='è·å“¡å',
                title=f'{available_factors[0]} vs {available_factors[1]}',
                color=metric_col,
                color_continuous_scale='RdYlBu_r'
            )
            content.append(dcc.Graph(figure=fig_scatter))

        # 3. å…¬å¹³æ€§è¦å› ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        if available_factors:
            factor_data = df_fair_display[available_factors].copy()
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
            for col in available_factors:
                if factor_data[col].max() != factor_data[col].min():
                    factor_data[col] = (factor_data[col] - factor_data[col].min()) / (factor_data[col].max() - factor_data[col].min())
            
            fig_heatmap = px.imshow(
                factor_data.T,
                x=df_fair_display['è·å“¡å'],
                y=available_factors,
                title='å…¬å¹³æ€§è¦å› ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆè·å“¡åˆ¥è©³ç´°åˆ†æï¼‰',
                color_continuous_scale='RdYlBu_r',
                aspect='auto'
            )
            fig_heatmap.update_layout(xaxis_title="è·å“¡å", yaxis_title="å…¬å¹³æ€§è¦å› ")
            content.append(dcc.Graph(figure=fig_heatmap))

        # 4. åˆ†å¸ƒå›³ã¨ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
        fig_hist = px.histogram(
            df_fair_display,
            x=metric_col,
            nbins=20,
            title="å…¬å¹³æ€§ã‚¹ã‚³ã‚¢åˆ†å¸ƒ",
            labels={metric_col: 'ã‚¹ã‚³ã‚¢'}
        )
        fig_hist.update_layout(yaxis_title="äººæ•°")
        fig_hist.add_vline(x=avg_val, line_dash='dash', line_color='red', annotation_text="å¹³å‡å€¤")
        content.append(dcc.Graph(figure=fig_hist))

        # 5. ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼ˆä¸å…¬å¹³æ„Ÿä¸Šä½3åï¼‰
        if len(df_fair_display) >= 3 and available_factors:
            top3 = df_fair_display.nlargest(3, metric_col)
            fig_radar = go.Figure()
            
            for _, row in top3.iterrows():
                factor_values = [abs(row[factor]) for factor in available_factors]  # çµ¶å¯¾å€¤ã§æ¯”è¼ƒ
                # æ­£è¦åŒ–
                max_val = max(factor_values) if max(factor_values) > 0 else 1
                normalized_values = [val/max_val for val in factor_values]
                
                fig_radar.add_trace(go.Scatterpolar(
                    r=normalized_values,
                    theta=available_factors,
                    fill='toself',
                    name=row['è·å“¡å']
                ))
            
            fig_radar.update_layout(
                polar=dict(
                    radialaxis=dict(visible=True, range=[0, 1])
                ),
                title="ä¸å…¬å¹³æ„Ÿä¸Šä½3åã®è¦å› æ¯”è¼ƒï¼ˆãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼‰"
            )
            content.append(dcc.Graph(figure=fig_radar))

        # 6. ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
        if 'ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢' in df_fair_display.columns:
            ranking = df_fair_display.sort_values('ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢', ascending=False)[['è·å“¡å', 'ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢']]
            ranking.index = range(1, len(ranking) + 1)
            ranking.index.name = 'é †ä½'
            ranking = ranking.reset_index()
            content.append(html.H4('ä¸å…¬å¹³æ„Ÿãƒ©ãƒ³ã‚­ãƒ³ã‚°'))  # type: ignore
            content.append(dash_table.DataTable(
                data=ranking.to_dict('records'),
                columns=[{'name': i, 'id': i} for i in ranking.columns],
                style_cell={'textAlign': 'left'},
                style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'}
            ))

        # è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        content.append(html.H4("è©³ç´°ãƒ‡ãƒ¼ã‚¿", style={'marginTop': '30px'}))
        content.append(dash_table.DataTable(
            data=df_fair_display.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_fair_display.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'},
            sort_action="native"
        ))
    else:
        content.append(html.P("å…¬å¹³æ€§ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

    return html.Div(content)


def create_gap_analysis_tab() -> html.Div:
    """åŸºæº–ä¹–é›¢åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='gap-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("åŸºæº–ä¹–é›¢åˆ†æ", style={'marginBottom': '20px'})]  # type: ignore
    df_summary = data_get('gap_summary', pd.DataFrame())
    df_heat = data_get('gap_heatmap', pd.DataFrame())

    if not df_summary.empty:
        content.append(dash_table.DataTable(
            data=df_summary.to_dict('records'),
            columns=[{'name': c, 'id': c} for c in df_summary.columns]
        ))
    if not df_heat.empty:
        fig = px.imshow(
            df_heat,
            aspect='auto',
            color_continuous_scale='RdBu_r',
            labels={'x': 'æ™‚é–“å¸¯', 'y': 'è·ç¨®', 'color': 'ä¹–é›¢'}
        )
        content.append(dcc.Graph(figure=fig))
    if df_summary.empty and df_heat.empty:
        content.append(html.P("åŸºæº–ä¹–é›¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))  # type: ignore

    return html.Div(content)


def create_summary_report_tab() -> html.Div:
    """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='summary-report-insights', style={  # type: ignore
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ", style={'marginBottom': '20px'})]  # type: ignore
    report_text = data_get('summary_report')
    if report_text:
        content.append(dcc.Markdown(report_text))
    else:
        content.append(html.P("ãƒ¬ãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))
    return html.Div(content)


def create_ppt_report_tab() -> html.Div:
    """PowerPointãƒ¬ãƒãƒ¼ãƒˆã‚¿ãƒ–ã‚’ä½œæˆ"""
    return html.Div([  # type: ignore
        html.Div(id='ppt-report-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("PowerPointãƒ¬ãƒãƒ¼ãƒˆ", style={'marginBottom': '20px'}),  # type: ignore
        html.P("ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦PowerPointãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"),  # type: ignore
        html.Button('PPTãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ', id='ppt-generate', n_clicks=0)  # type: ignore
    ])


def create_individual_analysis_tab() -> html.Div:
    """è·å“¡å€‹åˆ¥åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    long_df = data_get('long_df', pd.DataFrame())

    if long_df.empty:
        return html.Div("åˆ†æã®å…ƒã¨ãªã‚‹å‹¤å‹™ãƒ‡ãƒ¼ã‚¿ (long_df) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    staff_list = sorted(long_df['staff'].unique())

    return html.Div([
        html.Div(
            dcc.Markdown("""
            #### è·å“¡å€‹åˆ¥åˆ†æ
            ã“ã®ã‚¿ãƒ–ã§ã¯ã€å€‹ã€…ã®ã‚¹ã‚¿ãƒƒãƒ•ã®åƒãæ–¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ç–²åŠ´åº¦ã€å…¬å¹³æ€§ã€
            ãã—ã¦é›¢è·ãƒªã‚¹ã‚¯ã‚’ç·åˆçš„ã«åˆ†æã—ã¾ã™ã€‚
            """),
            style={
                'padding': '15px',
                'backgroundColor': '#f0f8ff',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #b3d9ff'
            }
        ),
        html.H3("è·å“¡å€‹åˆ¥åˆ†æ", style={'marginBottom': '20px'}),
        html.P("åˆ†æã—ãŸã„è·å“¡ã‚’ä»¥ä¸‹ã‹ã‚‰é¸æŠã—ã¦ãã ã•ã„ã€‚"),
        dcc.Dropdown(
            id='individual-staff-dropdown',
            options=[{'label': staff, 'value': staff} for staff in staff_list],
            value=None,  # åˆæœŸå€¤ã‚’Noneã«å¤‰æ›´
            placeholder="è·å“¡ã‚’é¸æŠã—ã¦ãã ã•ã„...",
            clearable=True,
            style={'width': '50%', 'marginBottom': '20px'}
        ),
        
        # ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚¿ã‚¤ãƒ—é¸æŠ
        html.Div([
            html.Label("ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚¿ã‚¤ãƒ—:", style={'fontWeight': 'bold', 'marginBottom': '10px'}),
            dcc.RadioItems(
                id='synergy-analysis-type',
                options=[
                    {'label': 'åŸºæœ¬åˆ†æï¼ˆå…¨è·å“¡å¯¾è±¡ï¼‰', 'value': 'basic'},
                    {'label': 'åŒè·ç¨®é™å®šåˆ†æ', 'value': 'same_role'},
                    {'label': 'å…¨è·ç¨®è©³ç´°åˆ†æ', 'value': 'all_roles'},
                    {'label': 'ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆå…¨ä½“ï¼‰', 'value': 'correlation_matrix'}
                ],
                value='basic',
                inline=True,
                style={'marginBottom': '20px'}
            ),
        ], style={'marginBottom': '20px', 'padding': '10px', 'backgroundColor': '#f8f9fa', 'borderRadius': '5px'}),
        
        # åˆ†æçµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
        html.Div(id='individual-analysis-content', children=[
            html.Div([
                html.H4("è·å“¡ã‚’é¸æŠã—ã¦ãã ã•ã„"),
                html.P("ä¸Šè¨˜ã®ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‹ã‚‰åˆ†æã—ãŸã„è·å“¡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚", style={'color': '#666'})
            ], style={'textAlign': 'center', 'marginTop': '50px', 'marginBottom': '50px'})
        ]),
        
        # é›¢è·ãƒªã‚¹ã‚¯äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        html.Hr(style={'margin': '40px 0'}),
        html.H3("é›¢è·ãƒªã‚¹ã‚¯äºˆæ¸¬ (AIåˆ†æ)", style={'marginBottom': '20px', 'color': '#d32f2f'}),
        
        html.Div([
            html.Div([
                html.Label("åˆ†ææœŸé–“:", style={'fontWeight': 'bold', 'marginBottom': '5px'}),
                dcc.Slider(
                    id='turnover-lookback-months',
                    min=3,
                    max=12,
                    step=1,
                    value=6,
                    marks={i: f'{i}ãƒ¶æœˆ' for i in [3, 6, 9, 12]},
                    tooltip={"placement": "bottom", "always_visible": True}
                ),
            ], style={'width': '48%', 'display': 'inline-block'}),
            
            html.Div([
                html.Label("ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—:", style={'fontWeight': 'bold', 'marginBottom': '5px'}),
                dcc.Dropdown(
                    id='turnover-model-type',
                    options=[
                        {'label': 'ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« (æ¨å¥¨)', 'value': 'ensemble'},
                        {'label': 'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ', 'value': 'random_forest'},
                        {'label': 'XGBoost', 'value': 'xgboost'},
                        {'label': 'ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°', 'value': 'logistic'}
                    ],
                    value='ensemble',
                    style={'marginBottom': '10px'}
                ),
            ], style={'width': '48%', 'float': 'right', 'display': 'inline-block'}),
        ], style={'marginBottom': '20px'}),
        
        html.Div([
            html.Button('é›¢è·ãƒªã‚¹ã‚¯åˆ†æã‚’å®Ÿè¡Œ', id='run-turnover-prediction-button', 
                       className='btn btn-danger',
                       style={'marginTop': '10px'}),
        ], style={'padding': '20px', 'backgroundColor': '#fff5f5', 'borderRadius': '8px'}),
        
        # é›¢è·ãƒªã‚¹ã‚¯çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
        html.Div(id='turnover-prediction-results', style={'marginTop': '30px'}),
        
        # é›¢è·é˜²æ­¢ææ¡ˆã‚¨ãƒªã‚¢
        html.Div(id='turnover-prevention-suggestions', style={'marginTop': '30px'}),
        
        # ãƒãƒ¼ãƒ é›¢è·ãƒªã‚¹ã‚¯ã‚¨ãƒªã‚¢
        html.Div(id='team-turnover-analysis', style={'marginTop': '30px'}),
        
        # å…¨ä½“ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚³ãƒ³ãƒ†ãƒŠï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
        html.Div(id='individual-analysis-content', style={'display': 'none'})
    ])


def create_team_analysis_tab() -> html.Div:
    """ãƒãƒ¼ãƒ åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty:
        return html.Div("åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    filterable_cols = ['role', 'code', 'employment']

    return html.Div([
        html.H3("ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ»ãƒãƒ¼ãƒ åˆ†æ"),
        html.Div([
            html.P("ãƒãƒ¼ãƒ åˆ†æã§ã¯ã€ç‰¹å®šã®æ¡ä»¶ã«è©²å½“ã™ã‚‹ã‚¹ã‚¿ãƒƒãƒ•ã‚°ãƒ«ãƒ¼ãƒ—ã®ç‰¹æ€§ã‚’åˆ†æã—ã¾ã™ã€‚"),
            html.Ul([
                html.Li("ãƒãƒ¼ãƒ æ§‹æˆ: é¸æŠã—ãŸæ¡ä»¶ã«è©²å½“ã™ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ã®ä¸€è¦§ã¨è©³ç´°"),
                html.Li("ãƒãƒ¼ãƒ ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹: ãƒ¡ãƒ³ãƒãƒ¼é–“ã®ç›¸æ€§ã‚„å”åƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"),
                html.Li("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™: ãƒãƒ¼ãƒ å…¨ä½“ã®åŠ¹ç‡æ€§æŒ‡æ¨™ã¨æ”¹å–„ææ¡ˆ"),
                html.Li("æ™‚é–“å¸¯ã‚«ãƒãƒ¼ç‡: ãƒãƒ¼ãƒ ãŒã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹æ™‚é–“å¸¯ã®åˆ†å¸ƒ")
            ])
        ], style={
            'backgroundColor': '#f0f8ff',
            'padding': '15px',
            'borderRadius': '5px',
            'marginBottom': '20px'
        }),
        html.P("åˆ†æã—ãŸã„ãƒãƒ¼ãƒ ã®æ¡ä»¶ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼š"),
        html.Div([
            dcc.Dropdown(
                id='team-criteria-key-dropdown',
                options=[{'label': col, 'value': col} for col in filterable_cols],
                value='code',
                style={'width': '200px', 'display': 'inline-block'}
            ),
            dcc.Dropdown(
                id='team-criteria-value-dropdown',
                style={
                    'width': '300px',
                    'display': 'inline-block',
                    'marginLeft': '10px'
                }
            )
        ]),
        dcc.Loading(
            id="loading-team-analysis",
            children=html.Div([
                html.Div(id='team-analysis-content'),
                html.Div(id='team-analysis-explanation', style={'marginTop': '20px'})
            ])
        )
    ])


def create_blueprint_analysis_tab() -> html.Div:
    """Return layout for blueprint analysis with facts and implicit knowledge."""
    return html.Div([
        html.H3("ã‚·ãƒ•ãƒˆä½œæˆãƒ—ãƒ­ã‚»ã‚¹ã®\u300cæš—é»™çŸ¥\u300dåˆ†æ", style={'marginBottom': '20px'}),
        html.P(
            "éå»ã®ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€å®¢è¦³çš„äº‹å®Ÿã¨æš—é»™ã®ãƒ«ãƒ¼ãƒ«ã‚’åˆ†æã—ã¾ã™ã€‚",
            style={'marginBottom': '10px'}
        ),

        # åˆ†æã‚¿ã‚¤ãƒ—ã®é¸æŠ
        html.Div([
            dcc.RadioItems(
                id='blueprint-analysis-type',
                options=[
                    {'label': 'æš—é»™çŸ¥ã®ã¿', 'value': 'implicit'},
                    {'label': 'å®¢è¦³çš„äº‹å®Ÿã®ã¿', 'value': 'facts'},
                    {'label': 'çµ±åˆåˆ†æï¼ˆæš—é»™çŸ¥ï¼‹äº‹å®Ÿï¼‰', 'value': 'integrated'}
                ],
                value='integrated',
                inline=True,
                style={'marginBottom': '10px'}
            )
        ]),

        html.Details([
            html.Summary('ğŸ“Š åˆ†æã®è¦³ç‚¹ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§è©³ç´°ï¼‰', style={'cursor': 'pointer', 'fontWeight': 'bold'}),
            html.Div([
                html.H5("æš—é»™çŸ¥ã®6ã¤ã®è¦³ç‚¹"),
                html.Ul([
                    html.Li("ğŸ¤ ã‚¹ã‚­ãƒ«ç›¸æ€§: èª°ã¨èª°ã‚’çµ„ã¾ã›ã‚‹ã¨ä¸Šæ‰‹ãã„ãã‹ã€é€†ã«é¿ã‘ã¦ã„ã‚‹ã‹"),
                    html.Li("âš–ï¸ è² è·åˆ†æ•£æˆ¦ç•¥: ç¹å¿™æ™‚é–“å¸¯ã«ã©ã‚“ãªæˆ¦ç•¥ã§äººã‚’é…ç½®ã—ã¦ã„ã‚‹ã‹"),
                    html.Li("ğŸ‘¤ å€‹äººé…æ…®: ç‰¹å®šè·å“¡ã®å€‹äººäº‹æƒ…ã¸ã®é…æ…®ãƒ‘ã‚¿ãƒ¼ãƒ³"),
                    html.Li("ğŸ”„ ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: å…¬å¹³æ€§ã‚’ä¿ã¤ãŸã‚ã®è¤‡é›‘ãªãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ«"),
                    html.Li("ğŸš¨ ãƒªã‚¹ã‚¯å›é¿: ãƒˆãƒ©ãƒ–ãƒ«é˜²æ­¢ã®ãŸã‚ã®æš—é»™ã®é…ç½®ãƒ«ãƒ¼ãƒ«"),
                    html.Li("ğŸ“… æ™‚ç³»åˆ—æˆ¦ç•¥: æœˆåˆãƒ»æœˆæœ«ã€æ›œæ—¥ã«ã‚ˆã‚‹é…ç½®æˆ¦ç•¥ã®å¤‰åŒ–"),
                ]),
                html.H5("å®¢è¦³çš„äº‹å®Ÿã®è¦³ç‚¹", style={'marginTop': '10px'}),
                html.Ul([
                    html.Li("ğŸ“… æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³: ç‰¹å®šã®æ›œæ—¥ã®ã¿å‹¤å‹™ã€æ›œæ—¥ã®åã‚Š"),
                    html.Li("ğŸ·ï¸ ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³: ç‰¹å®šã®å‹¤å‹™ã‚³ãƒ¼ãƒ‰ã®ã¿ä½¿ç”¨ã€å›é¿"),
                    html.Li("â° æ™‚é–“å¸¯ãƒ‘ã‚¿ãƒ¼ãƒ³: æ—©æœãƒ»æ·±å¤œå‹¤å‹™ã€å›ºå®šæ™‚é–“å¸¯"),
                    html.Li("ğŸ‘¥ ãƒšã‚¢é–¢ä¿‚: é »ç¹ã«ä¸€ç·’ã«åƒã/åƒã‹ãªã„ãƒšã‚¢"),
                    html.Li("ğŸ“Š çµ±è¨ˆçš„äº‹å®Ÿ: å‹¤å‹™é »åº¦ã€å¹³å‡å‹¤å‹™æ™‚é–“"),
                ])
            ], style={'padding': '10px', 'backgroundColor': '#f0f0f0', 'borderRadius': '5px', 'marginTop': '10px'})
        ], style={'marginBottom': '20px'}),

        html.Button(
            "ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆã‚’ç”Ÿæˆ",
            id="generate-blueprint-button",
            n_clicks=0,
            style={
                "marginTop": "10px",
                "marginBottom": "20px",
                "padding": "10px 30px",
                "fontSize": "16px",
                "backgroundColor": "#1f77b4",
                "color": "white",
                "border": "none",
                "borderRadius": "5px",
                "cursor": "pointer"
            },
        ),
        dcc.Loading(
            id="loading-blueprint",
            type="default",
            children=html.Div([
                dcc.Tabs(id='blueprint-result-tabs', children=[
                    dcc.Tab(label='æš—é»™çŸ¥åˆ†æ', value='implicit_analysis', children=[
                        html.Div([
                            html.Div([
                                html.H4("å…¨ä½“åˆ†æãƒ“ãƒ¥ãƒ¼ï¼šã‚·ãƒ•ãƒˆå…¨ä½“ã®å‚¾å‘ã¨æš—é»™çŸ¥"),
                                dcc.Graph(id='tradeoff-scatter-plot'),
                                html.H5("ç™ºè¦‹ã•ã‚ŒãŸæš—é»™çŸ¥ãƒ«ãƒ¼ãƒ«ä¸€è¦§"),
                                html.P("ãƒ«ãƒ¼ãƒ«ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€é–¢é€£ã™ã‚‹ã‚¹ã‚¿ãƒƒãƒ•ã®å€‹åˆ¥åˆ†æã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"),
                                dash_table.DataTable(id='rules-data-table', row_selectable='single'),
                            ], style={'width': '50%', 'display': 'inline-block', 'verticalAlign': 'top'}),
                            html.Div([
                                html.H4("ã‚¹ã‚¿ãƒƒãƒ•å€‹åˆ¥ãƒ“ãƒ¥ãƒ¼ï¼šå€‹äººã®åƒãæ–¹ã¨ä¾¡å€¤è¦³"),
                                dcc.Dropdown(id='staff-selector-dropdown'),
                                dcc.Graph(id='staff-radar-chart'),
                                html.H5("ã“ã®ã‚¹ã‚¿ãƒƒãƒ•ã«é–¢é€£ã™ã‚‹æš—é»™çŸ¥"),
                                html.Div(id='staff-related-rules-list'),
                            ], style={'width': '49%', 'display': 'inline-block', 'verticalAlign': 'top', 'paddingLeft': '1%'}),
                        ])
                    ]),
                    dcc.Tab(label='å®¢è¦³çš„äº‹å®Ÿ', value='facts_analysis', children=[
                        html.Div([
                            html.H4("ç™ºè¦‹ã•ã‚ŒãŸå®¢è¦³çš„äº‹å®Ÿ"),
                            html.Div([
                                html.Label("äº‹å®Ÿã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼:"),
                                dcc.Dropdown(
                                    id='fact-category-filter',
                                    options=[
                                        {'label': 'å…¨ã¦è¡¨ç¤º', 'value': 'all'},
                                        {'label': 'å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³äº‹å®Ÿ', 'value': 'å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³äº‹å®Ÿ'},
                                        {'label': 'æ›œæ—¥äº‹å®Ÿ', 'value': 'æ›œæ—¥äº‹å®Ÿ'},
                                        {'label': 'ã‚³ãƒ¼ãƒ‰äº‹å®Ÿ', 'value': 'ã‚³ãƒ¼ãƒ‰äº‹å®Ÿ'},
                                        {'label': 'æ™‚é–“å¸¯äº‹å®Ÿ', 'value': 'æ™‚é–“å¸¯äº‹å®Ÿ'},
                                        {'label': 'ãƒšã‚¢äº‹å®Ÿ', 'value': 'ãƒšã‚¢äº‹å®Ÿ'},
                                        {'label': 'çµ±è¨ˆçš„äº‹å®Ÿ', 'value': 'çµ±è¨ˆçš„äº‹å®Ÿ'}
                                    ],
                                    value='all',
                                    clearable=False
                                )
                            ], style={'width': '300px', 'marginBottom': '20px'}),
                            dash_table.DataTable(
                                id='facts-data-table',
                                columns=[
                                    {'name': 'ã‚¹ã‚¿ãƒƒãƒ•', 'id': 'ã‚¹ã‚¿ãƒƒãƒ•'},
                                    {'name': 'ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'id': 'ã‚«ãƒ†ã‚´ãƒªãƒ¼'},
                                    {'name': 'äº‹å®Ÿã‚¿ã‚¤ãƒ—', 'id': 'äº‹å®Ÿã‚¿ã‚¤ãƒ—'},
                                    {'name': 'è©³ç´°', 'id': 'è©³ç´°'},
                                    {'name': 'ç¢ºä¿¡åº¦', 'id': 'ç¢ºä¿¡åº¦', 'type': 'numeric', 'format': {'specifier': '.2f'}}
                                ],
                                style_data_conditional=[
                                    {
                                        'if': {
                                            'column_id': 'ç¢ºä¿¡åº¦',
                                            'filter_query': '{ç¢ºä¿¡åº¦} >= 0.8'
                                        },
                                        'backgroundColor': '#3D9970',
                                        'color': 'white',
                                    },
                                    {
                                        'if': {
                                            'column_id': 'ç¢ºä¿¡åº¦',
                                            'filter_query': '{ç¢ºä¿¡åº¦} < 0.5'
                                        },
                                        'backgroundColor': '#FFDC00',
                                    }
                                ],
                                sort_action='native',
                                filter_action='native',
                                page_size=20
                            ),
                            html.Div(id='facts-summary', style={'marginTop': '20px'})
                        ])
                    ]),
                    dcc.Tab(label='çµ±åˆåˆ†æ', value='integrated_analysis', children=[
                        html.Div([
                            html.H4("äº‹å®Ÿã¨æš—é»™çŸ¥ã®é–¢é€£"),
                            html.P("å®¢è¦³çš„äº‹å®ŸãŒã©ã®ã‚ˆã†ãªæš—é»™çŸ¥ã«ã¤ãªãŒã£ã¦ã„ã‚‹ã‹ã‚’åˆ†æã—ã¾ã™ã€‚"),
                            html.Div(id='integrated-analysis-content')
                        ])
                    ])
                ], value='implicit_analysis'),
            ], id='blueprint-analysis-content')
        ),
    ])

# --- ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
app.layout = html.Div([
    dcc.Store(id='kpi-data-store', storage_type='memory'),
    dcc.Store(id='data-loaded', storage_type='memory'),
    dcc.Store(id='full-analysis-store', storage_type='memory'),
    dcc.Store(id='creation-logic-results-store', storage_type='memory'),
    dcc.Store(id='logic-analysis-progress', storage_type='memory'),
    dcc.Store(id='blueprint-results-store', storage_type='memory'),
    dcc.Interval(id='logic-analysis-interval', interval=500, disabled=True),

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    html.Div([  # type: ignore
        html.H1("ğŸ—‚ï¸ Shift-Suite é«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢", style={
            'textAlign': 'center',
            'color': 'white',
            'margin': '0',
            'padding': '20px'
        })
    ], style={
        'backgroundColor': '#2c3e50',
        'boxShadow': '0 2px 4px rgba(0,0,0,0.1)'
    }),

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢
    html.Div([  # type: ignore
        dcc.Upload(
            id='upload-data',
            children=html.Div([
                'åˆ†æçµæœã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ— ã¾ãŸã¯ ',
                html.A('ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠ', style={'textDecoration': 'underline'})
            ]),
            style={
                'width': '100%',
                'height': '100px',
                'lineHeight': '100px',
                'borderWidth': '2px',
                'borderStyle': 'dashed',
                'borderRadius': '10px',
                'textAlign': 'center',
                'margin': '20px 0',
                'backgroundColor': '#f8f9fa',
                'cursor': 'pointer'
            },
            multiple=False
        ),
    ], style={'padding': '0 20px'}),

    html.Div([  # type: ignore
        html.H3("åˆ†æã‚·ãƒŠãƒªã‚ªé¸æŠ", style={'textAlign': 'center'}),
        dcc.Dropdown(
            id='scenario-dropdown',
            placeholder="ã¾ãšåˆ†æçµæœã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            style={'width': '60%', 'margin': 'auto'}
        )
    ], id='scenario-selector-div', style={'display': 'none'}),

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    html.Div(id='main-content', style={'padding': '20px'}),  # type: ignore

    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ãƒ“ãƒ¥ãƒ¼ã‚¢
    html.Details([
        html.Summary('ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ã‚’è¡¨ç¤º/éè¡¨ç¤º'),
        dcc.Textarea(id='log-viewer', style={'width': '100%', 'height': 300}, readOnly=True)
    ], style={'padding': '0 20px'}),
    dcc.Interval(id='log-interval', interval=1000),

], style={'backgroundColor': '#f5f5f5', 'minHeight': '100vh'})

# --- ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•° ---
@app.callback(
    Output('data-loaded', 'data'),
    Output('scenario-dropdown', 'options'),
    Output('scenario-dropdown', 'value'),
    Output('scenario-selector-div', 'style'),
    Input('upload-data', 'contents'),
    State('upload-data', 'filename')
)
@safe_callback
def process_upload(contents, filename):
    """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚·ãƒŠãƒªã‚ªã‚’æ¤œå‡º"""
    if contents is None:
        raise PreventUpdate

    global TEMP_DIR_OBJ

    log.info(f"Received upload: {filename}")

    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    if TEMP_DIR_OBJ:
        TEMP_DIR_OBJ.cleanup()

    TEMP_DIR_OBJ = tempfile.TemporaryDirectory(prefix="shift_suite_dash_")
    temp_dir_path = Path(TEMP_DIR_OBJ.name)
    log.debug(f"Created temp dir {temp_dir_path}")

    # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)

    try:
        with zipfile.ZipFile(io.BytesIO(decoded)) as zf:
            zf.extractall(temp_dir_path)
        log.info(f"Extracted ZIP to {temp_dir_path}")

        scenarios = [d.name for d in temp_dir_path.iterdir() if d.is_dir() and d.name.startswith('out_')]
        if not scenarios:
            return {'error': 'åˆ†æã‚·ãƒŠãƒªã‚ªã®ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}, [], None, {'display': 'none'}

        log.debug(f"Found scenarios: {scenarios}")

        # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ç”¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        scenario_name_map = {
            'out_median_based': 'ä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹',
            'out_mean_based': 'å¹³å‡å€¤ãƒ™ãƒ¼ã‚¹',
            'out_p25_based': '25ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹',
        }

        scenario_options = [
            {'label': scenario_name_map.get(s, s.replace('out_', '')), 'value': s}
            for s in scenarios
        ]
        first_scenario = scenarios[0]
        scenario_paths = {d.name: str(d) for d in temp_dir_path.iterdir() if d.is_dir()}
        return {
            'success': True,
            'scenarios': scenario_paths,
        }, scenario_options, first_scenario, {'display': 'block'}

    except Exception as e:
        log.error(f"Error processing ZIP: {e}", exc_info=True)
        return {'error': str(e)}, [], None, {'display': 'none'}


@app.callback(
    Output('kpi-data-store', 'data'),
    Output('main-content', 'children'),
    Input('scenario-dropdown', 'value'),
    State('data-loaded', 'data')
)
@safe_callback
def update_main_content(selected_scenario, data_status):
    """ã‚·ãƒŠãƒªã‚ªé¸æŠã«å¿œã˜ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¡ã‚¤ãƒ³UIã‚’æ›´æ–°"""
    if (
        not selected_scenario
        or not data_status
        or 'success' not in data_status
        or 'scenarios' not in data_status
    ):
        raise PreventUpdate

    data_dir = Path(data_status['scenarios'].get(selected_scenario, ''))
    if not data_dir.exists():
        raise PreventUpdate

    log.info(f"Switching to scenario {selected_scenario} at {data_dir}")

    # Scenario has changed; reset caches and store new directory
    global CURRENT_SCENARIO_DIR
    CURRENT_SCENARIO_DIR = data_dir
    clear_data_cache()

    pre_aggr = data_get('pre_aggregated_data')
    if pre_aggr is None or (isinstance(pre_aggr, pd.DataFrame) and pre_aggr.empty):
        return {}, html.Div(f"ã‚¨ãƒ©ãƒ¼: {(data_dir / 'pre_aggregated_data.parquet').name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")  # type: ignore

    kpi_data = {}

    tabs = dcc.Tabs(id='main-tabs', value='overview', children=[
        dcc.Tab(label='æ¦‚è¦', value='overview'),
        dcc.Tab(label='ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', value='heatmap'),
        dcc.Tab(label='ä¸è¶³åˆ†æ', value='shortage'),
        dcc.Tab(label='æœ€é©åŒ–åˆ†æ', value='optimization'),
        dcc.Tab(label='ä¼‘æš‡åˆ†æ', value='leave'),
        dcc.Tab(label='ã‚³ã‚¹ãƒˆåˆ†æ', value='cost'),
        dcc.Tab(label='æ¡ç”¨è¨ˆç”»', value='hire_plan'),
        # é«˜åº¦æ©Ÿèƒ½ï¼ˆæ¡ä»¶ä»˜ãè¡¨ç¤ºï¼‰
        *([dcc.Tab(label='ç–²åŠ´åˆ†æ', value='fatigue')] if ENABLE_ADVANCED_FEATURES else []),
        # é«˜åº¦äºˆæ¸¬ã¨å­£ç¯€æ€§åˆ†æã‚¿ãƒ–ã¯ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
        # *([dcc.Tab(label='é«˜åº¦äºˆæ¸¬', value='advanced_forecast')] if ENABLE_ADVANCED_FEATURES else []),
        # *([dcc.Tab(label='å­£ç¯€æ€§åˆ†æ', value='seasonal_analysis')] if ENABLE_ADVANCED_FEATURES else []),
        dcc.Tab(label='å…¬å¹³æ€§', value='fairness'),
        dcc.Tab(label='åŸºæº–ä¹–é›¢åˆ†æ', value='gap'),
        dcc.Tab(label='è·å“¡å€‹åˆ¥åˆ†æ', value='individual_analysis'),
        dcc.Tab(label='ãƒãƒ¼ãƒ åˆ†æ', value='team_analysis'),
        dcc.Tab(label='ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹', value='correlation_matrix'),
        dcc.Tab(label='ä½œæˆãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆ', value='blueprint_analysis'),
    ])

    # å…¨ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒŠã‚’é™çš„ã«ä½œæˆï¼ˆCSSè¡¨ç¤ºåˆ¶å¾¡æ–¹å¼ï¼‰
    main_layout = html.Div([
        tabs,
        html.Div(style={'marginTop': '20px'}, children=[
            # å„ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒŠï¼ˆåˆæœŸçŠ¶æ…‹ã§ã¯æ¦‚è¦ã‚¿ãƒ–ã®ã¿è¡¨ç¤ºï¼‰
            html.Div(id='overview-tab-container', 
                    style={'display': 'block'},
                    children=[
                        dcc.Loading(
                            id="loading-overview",
                            type="circle",
                            children=html.Div(id='overview-content')
                        )
                    ]),
            html.Div(id='heatmap-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-heatmap",
                            type="circle",
                            children=html.Div(id='heatmap-content')
                        )
                    ]),
            html.Div(id='shortage-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-shortage",
                            type="circle",
                            children=html.Div(id='shortage-content')
                        )
                    ]),
            html.Div(id='optimization-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-optimization",
                            type="circle",
                            children=html.Div(create_optimization_tab())
                        )
                    ]),
            html.Div(id='leave-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-leave",
                            type="circle",
                            children=html.Div(id='leave-content')
                        )
                    ]),
            html.Div(id='cost-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-cost",
                            type="circle",
                            children=html.Div(id='cost-content')
                        )
                    ]),
            html.Div(id='hire-plan-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-hire-plan",
                            type="circle",
                            children=html.Div(id='hire-plan-content')
                        )
                    ]),
            # é«˜åº¦æ©Ÿèƒ½ï¼šç–²åŠ´åˆ†æï¼ˆæ¡ä»¶ä»˜ãè¡¨ç¤ºï¼‰
            *([] if not ENABLE_ADVANCED_FEATURES else [
                html.Div(id='fatigue-tab-container',
                        style={'display': 'none'},
                        children=[
                            dcc.Loading(
                                id="loading-fatigue",
                                type="circle",
                                children=html.Div(id='fatigue-content')
                            )
                        ])
            ]),
            # é«˜åº¦æ©Ÿèƒ½ï¼šé«˜åº¦äºˆæ¸¬ï¼ˆä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼‰
            # *([] if not ENABLE_ADVANCED_FEATURES else [
            #     html.Div(id='advanced_forecast-tab-container',
            #             style={'display': 'none'},
            #             children=[
            #                 dcc.Loading(
            #                     id="loading-advanced-forecast",
            #                     type="circle",
            #                     children=html.Div(id='advanced-forecast-content')
            #                 )
            #             ])
            # ]),
            # é«˜åº¦æ©Ÿèƒ½ï¼šå­£ç¯€æ€§åˆ†æï¼ˆä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼‰
            # *([] if not ENABLE_ADVANCED_FEATURES else [
            #     html.Div(id='seasonal_analysis-tab-container',
            #             style={'display': 'none'},
            #             children=[
            #                 dcc.Loading(
            #                     id="loading-seasonal-analysis",
            #                     type="circle",
            #                     children=html.Div(id='seasonal_analysis-content')
            #                 )
            #             ])
            # ]),
            html.Div(id='fairness-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-fairness",
                            type="circle",
                            children=html.Div(id='fairness-content')
                        )
                    ]),
            html.Div(id='gap-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-gap",
                            type="circle",
                            children=html.Div(id='gap-content')
                        )
                    ]),
            html.Div(id='individual-analysis-tab-container',
                    style={'display': 'none'},
                    children=[
                        # é™çš„ã«è·å“¡é¸æŠãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‚’é…ç½®
                        html.Div([
                            html.H3("è·å“¡å€‹åˆ¥åˆ†æ", style={'marginBottom': '20px'}),
                            html.P("åˆ†æã—ãŸã„è·å“¡ã‚’ä»¥ä¸‹ã‹ã‚‰é¸æŠã—ã¦ãã ã•ã„ã€‚"),
                            dcc.Dropdown(
                                id='individual-staff-dropdown',
                                options=[],  # åˆæœŸã¯ç©ºã€ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§æ›´æ–°
                                value=None,
                                placeholder="è·å“¡ã‚’é¸æŠã—ã¦ãã ã•ã„...",
                                clearable=True,
                                style={'width': '50%', 'marginBottom': '20px'}
                            ),
                            # ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚¿ã‚¤ãƒ—é¸æŠ
                            html.Div([
                                html.Label("ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚¿ã‚¤ãƒ—:", style={'fontWeight': 'bold', 'marginBottom': '10px'}),
                                dcc.RadioItems(
                                    id='synergy-analysis-type',
                                    options=[
                                        {'label': 'åŸºæœ¬åˆ†æï¼ˆå…¨è·å“¡å¯¾è±¡ï¼‰', 'value': 'basic'},
                                        {'label': 'åŒè·ç¨®é™å®šåˆ†æ', 'value': 'same_role'},
                                        {'label': 'å…¨è·ç¨®è©³ç´°åˆ†æ', 'value': 'all_roles'},
                                        {'label': 'ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆå…¨ä½“ï¼‰', 'value': 'correlation_matrix'}
                                    ],
                                    value='basic',
                                    inline=True,
                                    style={'marginBottom': '20px'}
                                )
                            ], style={'marginBottom': '20px', 'padding': '10px', 'backgroundColor': '#f8f9fa', 'borderRadius': '5px'}),
                        ], style={'padding': '20px'}),
                        dcc.Loading(
                            id="loading-individual-analysis",
                            type="circle",
                            children=html.Div(id='individual-analysis-content')
                        )
                    ]),
            html.Div(id='team-analysis-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-team-analysis",
                            type="circle",
                            children=html.Div(id='team-analysis-content')
                        )
                    ]),
            html.Div(id='correlation-matrix-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-correlation-matrix",
                            type="circle",
                            children=html.Div(id='correlation-matrix-content')
                        )
                    ]),
            html.Div(id='blueprint-analysis-tab-container',
                    style={'display': 'none'},
                    children=[
                        dcc.Loading(
                            id="loading-blueprint-analysis",
                            type="circle",
                            children=html.Div(id='blueprint-analysis-content')
                        )
                    ]),
        ])
    ])

    return kpi_data, main_layout


# ã‚¿ãƒ–è¡¨ç¤ºåˆ¶å¾¡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæ©Ÿèƒ½åˆ‡ã‚Šåˆ†ã‘å¯¾å¿œï¼‰
basic_outputs = [
    Output('overview-tab-container', 'style'),
    Output('heatmap-tab-container', 'style'),
    Output('shortage-tab-container', 'style'),
    Output('optimization-tab-container', 'style'),
    Output('leave-tab-container', 'style'),
    Output('cost-tab-container', 'style'),
    Output('hire-plan-tab-container', 'style'),
    Output('fairness-tab-container', 'style'),
    Output('gap-tab-container', 'style'),
    Output('individual-analysis-tab-container', 'style'),
    Output('team-analysis-tab-container', 'style'),
    Output('correlation-matrix-tab-container', 'style'),
    Output('blueprint-analysis-tab-container', 'style')
]

advanced_outputs = []
if ENABLE_ADVANCED_FEATURES:
    advanced_outputs = [
        Output('fatigue-tab-container', 'style'),
        # é«˜åº¦äºˆæ¸¬ã¨å­£ç¯€æ€§åˆ†æã¯ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
        # Output('advanced_forecast-tab-container', 'style'),
        # Output('seasonal_analysis-tab-container', 'style')
    ]

all_outputs = basic_outputs + advanced_outputs

@app.callback(
    all_outputs,
    Input('main-tabs', 'value'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def update_tab_visibility(active_tab, selected_scenario, data_status):
    """ã‚¿ãƒ–ã®è¡¨ç¤ºåˆ¶å¾¡ï¼ˆCSS visibilityæ–¹å¼ï¼‰"""
    if not selected_scenario or not data_status:
        raise PreventUpdate
    
    # å…¨ã‚¿ãƒ–ã®ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾©ï¼ˆæ©Ÿèƒ½åˆ‡ã‚Šåˆ†ã‘å¯¾å¿œï¼‰
    basic_tabs = [
        'overview', 'heatmap', 'shortage', 'optimization', 'leave',
        'cost', 'hire_plan', 'fairness',
        'gap', 'individual_analysis', 'team_analysis', 'correlation_matrix', 'blueprint_analysis'
    ]
    advanced_tabs = ['fatigue'] if ENABLE_ADVANCED_FEATURES else []  # é«˜åº¦äºˆæ¸¬ã¨å­£ç¯€æ€§åˆ†æã¯ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
    all_tabs = basic_tabs + advanced_tabs
    
    # å„ã‚¿ãƒ–ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨­å®šï¼ˆã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚¿ãƒ–ã®ã¿è¡¨ç¤ºï¼‰
    styles = []
    for tab in all_tabs:
        if tab == active_tab:
            styles.append({'display': 'block'})
        else:
            styles.append({'display': 'none'})
    
    return styles


# å„ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆæœŸåŒ–ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
@app.callback(
    Output('overview-content', 'children'),
    Input('overview-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_overview_content(style, selected_scenario, data_status):
    """æ¦‚è¦ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_overview_tab()
    except Exception as e:
        log.error(f"æ¦‚è¦ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('heatmap-content', 'children'),
    Input('heatmap-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_heatmap_content(style, selected_scenario, data_status):
    """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_heatmap_tab()
    except Exception as e:
        log.error(f"ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('shortage-content', 'children'),
    Input('shortage-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_shortage_content(style, selected_scenario, data_status):
    """ä¸è¶³åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_shortage_tab()
    except Exception as e:
        log.error(f"ä¸è¶³åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})


@app.callback(
    Output('leave-content', 'children'),
    Input('leave-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_leave_content(style, selected_scenario, data_status):
    """ä¼‘æš‡åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_leave_analysis_tab()
    except Exception as e:
        log.error(f"ä¼‘æš‡åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('cost-content', 'children'),
    Input('cost-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_cost_content(style, selected_scenario, data_status):
    """ã‚³ã‚¹ãƒˆåˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_cost_analysis_tab()
    except Exception as e:
        log.error(f"ã‚³ã‚¹ãƒˆåˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('hire-plan-content', 'children'),
    Input('hire-plan-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_hire_plan_content(style, selected_scenario, data_status):
    """æ¡ç”¨è¨ˆç”»ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_hire_plan_tab()
    except Exception as e:
        log.error(f"æ¡ç”¨è¨ˆç”»ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('fatigue-content', 'children'),
    Input('fatigue-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_fatigue_content(style, selected_scenario, data_status):
    """ç–²åŠ´åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        if not ENABLE_ADVANCED_FEATURES:
            return html.Div([
                html.H3("ç–²åŠ´åˆ†ææ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™", style={'color': 'orange'}),
                html.P("ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€dash_app.py ã® ENABLE_ADVANCED_FEATURES ã‚’ True ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"),
                html.P("ã¾ãŸã€requirements.txt ã«è¨˜è¼‰ã•ã‚ŒãŸè¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
            ])
        return create_fatigue_tab()
    except Exception as e:
        log.error(f"ç–²åŠ´åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})


@app.callback(
    Output('advanced-forecast-content', 'children'),
    Input('advanced_forecast-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_advanced_forecast_content(style, selected_scenario, data_status):
    """é«˜åº¦äºˆæ¸¬ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        if not ENABLE_ADVANCED_FEATURES:
            return html.Div([
                html.H3("é«˜åº¦äºˆæ¸¬æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™", style={'color': 'orange'}),
                html.P("ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€dash_app.py ã® ENABLE_ADVANCED_FEATURES ã‚’ True ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"),
                html.P("ã¾ãŸã€requirements.txt ã«è¨˜è¼‰ã•ã‚ŒãŸè¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
            ])
        return create_advanced_forecast_tab()
    except Exception as e:
        log.error(f"é«˜åº¦äºˆæ¸¬ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('seasonal_analysis-content', 'children'),
    Input('seasonal_analysis-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_seasonal_analysis_content(style, selected_scenario, data_status):
    """å­£ç¯€æ€§åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        if not ENABLE_ADVANCED_FEATURES:
            return html.Div([
                html.H3("å­£ç¯€æ€§åˆ†ææ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™", style={'color': 'orange'}),
                html.P("ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€dash_app.py ã® ENABLE_ADVANCED_FEATURES ã‚’ True ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"),
                html.P("ã¾ãŸã€requirements.txt ã«è¨˜è¼‰ã•ã‚ŒãŸè¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
            ])
        return create_seasonal_analysis_tab()
    except Exception as e:
        log.error(f"å­£ç¯€æ€§åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('fairness-content', 'children'),
    Input('fairness-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_fairness_content(style, selected_scenario, data_status):
    """å…¬å¹³æ€§ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_fairness_tab()
    except Exception as e:
        log.error(f"å…¬å¹³æ€§ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('gap-content', 'children'),
    Input('gap-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_gap_content(style, selected_scenario, data_status):
    """åŸºæº–ä¹–é›¢åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_gap_analysis_tab()
    except Exception as e:
        log.error(f"åŸºæº–ä¹–é›¢åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('team-analysis-content', 'children'),
    Input('team-analysis-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_team_analysis_content(style, selected_scenario, data_status):
    """ãƒãƒ¼ãƒ åˆ†æã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    
    try:
        # ã‚¿ãƒ–ãŒåˆæœŸåŒ–ã•ã‚ŒãŸå ´åˆã€åŸºæœ¬çš„ãªUIæ§‹é€ ã‚’è¿”ã™
        return create_team_analysis_tab()
        
    except Exception as e:
        log.error(f"ãƒãƒ¼ãƒ åˆ†æã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})

@app.callback(
    Output('blueprint-analysis-content', 'children'),
    Input('blueprint-analysis-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_blueprint_analysis_content(style, selected_scenario, data_status):
    """ä½œæˆãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    try:
        return create_blueprint_analysis_tab()
    except Exception as e:
        log.error(f"ä½œæˆãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})


@app.callback(
    Output('correlation-matrix-content', 'children'),
    Input('correlation-matrix-tab-container', 'style'),
    State('scenario-dropdown', 'value'),
    State('data-loaded', 'data'),
)
@safe_callback
def initialize_correlation_matrix_content(style, selected_scenario, data_status):
    """ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚¿ãƒ–ã®å†…å®¹ã‚’åˆæœŸåŒ–"""
    if not selected_scenario or not data_status or style.get('display') == 'none':
        raise PreventUpdate
    
    try:
        long_df = data_get('long_df', pd.DataFrame())
        
        if long_df.empty:
            return html.Div("åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", style={'color': 'red', 'textAlign': 'center', 'marginTop': '50px'})
        
        # èª¬æ˜ã¨ã‚°ãƒ©ãƒ•ã‚’å«ã‚€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
        return html.Div([
            html.Div(
                dcc.Markdown("""
                #### è·å“¡é–“å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹
                
                ã“ã®ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã¯ã€è·å“¡åŒå£«ã®å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç›¸é–¢é–¢ä¿‚ã‚’ç¤ºã—ã¾ã™ï¼š
                - **1.0ï¼ˆèµ¤ï¼‰**: å®Œå…¨ã«åŒã˜å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³
                - **0.0ï¼ˆç™½ï¼‰**: ç„¡ç›¸é–¢ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãªé–¢ä¿‚ï¼‰
                - **-1.0ï¼ˆé’ï¼‰**: å®Œå…¨ã«å¯¾ç…§çš„ãªå‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³
                
                ç›¸é–¢ãŒé«˜ã„è·å“¡åŒå£«ã¯ä¼¼ãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å‹¤å‹™ã—ã€ä½ã„è·å“¡åŒå£«ã¯ç•°ãªã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å‹¤å‹™ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚
                """),
                style={
                    'padding': '15px',
                    'backgroundColor': '#f0f8ff',
                    'borderRadius': '8px',
                    'marginBottom': '20px',
                    'border': '1px solid #b3d9ff'
                }
            ),
            html.Div([
                dcc.Graph(
                    figure=create_all_staff_correlation_matrix(long_df),
                    config={'displayModeBar': True, 'scrollZoom': True}
                )
            ], style={'textAlign': 'center'})
        ])
        
    except Exception as e:
        log.error(f"ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚¿ãƒ–ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})


@app.callback(
    Output('individual-analysis-content', 'children'),
    [Input('individual-staff-dropdown', 'value'),
     Input('synergy-analysis-type', 'value')]
)
@safe_callback
def update_individual_analysis_content(selected_staff, synergy_type):
    """è·å“¡é¸æŠã¨åˆ†æã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦åˆ†æã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›´æ–°ã™ã‚‹"""
    if not selected_staff:
        raise PreventUpdate

    # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬ã§èª­ã¿è¾¼ã‚€
    long_df = data_get('long_df', pd.DataFrame())
    fatigue_df = data_get('fatigue_score', pd.DataFrame())
    fairness_df = data_get('fairness_after', pd.DataFrame())
    shortage_df = data_get('shortage_time', pd.DataFrame())
    excess_df = data_get('excess_time', pd.DataFrame())

    if long_df.empty:
        return html.P("å‹¤å‹™ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    staff_df = long_df[long_df['staff'] == selected_staff].copy()

    # --- 1. å‹¤å‹™åŒºåˆ†ã”ã¨ã®å æœ‰å‰²åˆ ---
    work_dist_fig = go.Figure(layout={'title': {'text': f'{selected_staff}ã•ã‚“ã®å‹¤å‹™å‰²åˆ'}})
    if not staff_df.empty and 'code' in staff_df.columns:
        work_records = staff_df[staff_df.get('parsed_slots_count', 1) > 0]
        if not work_records.empty:
            code_counts = work_records['code'].value_counts()
            work_dist_fig = px.pie(
                values=code_counts.values, names=code_counts.index,
                title=f'{selected_staff}ã•ã‚“ã®å‹¤å‹™å‰²åˆ', hole=.3
            )
            work_dist_fig.update_traces(textposition='inside', textinfo='percent+label')

    # --- 2. ä¸å…¬å¹³ãƒ»ç–²åŠ´åº¦ã®è©³ç´°ã‚¹ã‚³ã‚¢ ---
    fatigue_score, unfairness_score = "ãƒ‡ãƒ¼ã‚¿ãªã—", "ãƒ‡ãƒ¼ã‚¿ãªã—"
    score_details_df = pd.DataFrame()
    if not fatigue_df.empty:
        fatigue_df_indexed = fatigue_df.set_index('staff') if 'staff' in fatigue_df.columns else fatigue_df
        if selected_staff in fatigue_df_indexed.index:
            fatigue_score = f"{fatigue_df_indexed.loc[selected_staff, 'fatigue_score']:.1f}"
    if not fairness_df.empty and 'staff' in fairness_df.columns:
        staff_fairness = fairness_df[fairness_df['staff'] == selected_staff]
        if not staff_fairness.empty:
            row = staff_fairness.iloc[0]
            unfairness_score = f"{row.get('unfairness_score', 0):.2f}"
            details_data = {
                "æŒ‡æ¨™": ["å¤œå‹¤æ¯”ç‡ã®ä¹–é›¢", "ç·åŠ´åƒæ™‚é–“ã®ä¹–é›¢", "å¸Œæœ›ä¼‘æ‰¿èªç‡ã®ä¹–é›¢", "é€£ä¼‘å–å¾—é »åº¦ã®ä¹–é›¢"],
                "ã‚¹ã‚³ã‚¢": [f"{row.get(col, 0):.2f}" for col in ['dev_night_ratio', 'dev_work_slots', 'dev_approval_rate', 'dev_consecutive']]
            }
            score_details_df = pd.DataFrame(details_data)

    # --- 3. å…±åƒã—ãŸè·å“¡ãƒ©ãƒ³ã‚­ãƒ³ã‚° ---
    coworker_ranking_df = pd.DataFrame()
    my_slots = staff_df[['ds']].drop_duplicates()
    coworkers = long_df[long_df['ds'].isin(my_slots['ds']) & (long_df['staff'] != selected_staff)]
    if not coworkers.empty:
        coworker_counts = coworkers['staff'].value_counts().reset_index()
        coworker_counts.columns = ['è·å“¡', 'å…±åƒå›æ•°']
        coworker_ranking_df = coworker_counts.head(5)

    # --- 4. äººå“¡ä¸è¶³/éå‰°ã¸ã®è²¢çŒ®åº¦åˆ†æ ---
    slot_hours = 0.5
    shortage_contribution_h, excess_contribution_h = 0, 0
    staff_work_slots = staff_df[staff_df.get('parsed_slots_count', 0) > 0][['ds']].copy()
    staff_work_slots['date_str'] = staff_work_slots['ds'].dt.strftime('%Y-%m-%d')
    staff_work_slots['time'] = staff_work_slots['ds'].dt.strftime('%H:%M')
    if not shortage_df.empty:
        shortage_long = shortage_df.melt(var_name='date_str', value_name='shortage_count', ignore_index=False).reset_index().rename(columns={'index':'time'})
        merged_shortage = pd.merge(staff_work_slots, shortage_long, on=['date_str', 'time'])
        shortage_contribution_h = merged_shortage[merged_shortage['shortage_count'] > 0].shape[0] * slot_hours
    if not excess_df.empty:
        excess_long = excess_df.melt(var_name='date_str', value_name='excess_count', ignore_index=False).reset_index().rename(columns={'index':'time'})
        merged_excess = pd.merge(staff_work_slots, excess_long, on=['date_str', 'time'])
        excess_contribution_h = merged_excess[merged_excess['excess_count'] > 0].shape[0] * slot_hours

    # --- 5. å€‹äººã®ä¼‘æš‡å–å¾—å‚¾å‘ ---
    leave_by_dow_fig = go.Figure(layout={'title': {'text': 'æ›œæ—¥åˆ¥ã®ä¼‘æš‡å–å¾—æ—¥æ•°'}})
    staff_leave_df = staff_df[staff_df.get('holiday_type', 'é€šå¸¸å‹¤å‹™') != 'é€šå¸¸å‹¤å‹™']
    if not staff_leave_df.empty:
        try:
            # ç°¡å˜ãªæ›œæ—¥åˆ¥ä¼‘æš‡é›†è¨ˆ
            staff_leave_df_copy = staff_leave_df.copy()
            staff_leave_df_copy['date'] = staff_leave_df_copy['ds'].dt.date
            staff_leave_df_copy['dow'] = staff_leave_df_copy['ds'].dt.day_name()
            dow_counts = staff_leave_df_copy['dow'].value_counts()
            if not dow_counts.empty:
                leave_by_dow_fig = px.bar(
                    x=dow_counts.index, y=dow_counts.values,
                    title=f'{selected_staff}ã•ã‚“ã®æ›œæ—¥åˆ¥ä¼‘æš‡å–å¾—æ—¥æ•°'
                )
                leave_by_dow_fig.update_xaxes(title_text="æ›œæ—¥").update_yaxes(title_text="æ—¥æ•°")
        except Exception as e:
            log.warning(f"ä¼‘æš‡å–å¾—å‚¾å‘ã®åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")

    # --- 6. è·å“¡é–“ã®ã€ŒåŒ–å­¦åå¿œã€åˆ†æ ---
    analysis_type_display = {
        'basic': 'åŸºæœ¬åˆ†æï¼ˆå…¨è·å“¡å¯¾è±¡ï¼‰',
        'same_role': 'åŒè·ç¨®é™å®šåˆ†æ',
        'all_roles': 'å…¨è·ç¨®è©³ç´°åˆ†æ',
        'correlation_matrix': 'ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆå…¨ä½“ï¼‰'
    }
    
    synergy_fig = go.Figure(layout={'title': {'text': f'{selected_staff}ã•ã‚“ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼åˆ†æ - {analysis_type_display.get(synergy_type, synergy_type)}'}})
    try:
        if not coworker_ranking_df.empty:
            # åˆ†æã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†
            synergy_scores = []
            
            # é¸æŠã•ã‚ŒãŸè·å“¡ã®è·ç¨®ã‚’å–å¾—
            my_role = staff_df['role'].iloc[0] if not staff_df.empty and 'role' in staff_df.columns else "ä¸æ˜"
            
            for _, row in coworker_ranking_df.iterrows():
                partner = row['è·å“¡']
                count = row['å…±åƒå›æ•°']
                
                # ç›¸æ‰‹ã®è·å“¡ã®è·ç¨®ã‚’å–å¾—
                partner_role = long_df[long_df['staff'] == partner]['role'].iloc[0] if not long_df[long_df['staff'] == partner].empty and 'role' in long_df.columns else "ä¸æ˜"
                
                # åˆ†æã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ç•°ãªã‚‹ã‚¹ã‚³ã‚¢è¨ˆç®—
                if synergy_type == 'basic':
                    # åŸºæœ¬åˆ†æ: å…±åƒå›æ•°ãƒ™ãƒ¼ã‚¹
                    score = min(count * 0.15, 1.0)
                    analysis_note = "å…±åƒå›æ•°ãƒ™ãƒ¼ã‚¹"
                elif synergy_type == 'same_role':
                    # åŒè·ç¨®é™å®šåˆ†æ: è·ç¨®ä¸€è‡´ãƒœãƒ¼ãƒŠã‚¹
                    if my_role == partner_role and my_role != "ä¸æ˜":
                        role_bonus = 0.3
                        score = min(count * 0.12 + role_bonus, 1.0)
                        analysis_note = f"åŒè·ç¨®ãƒœãƒ¼ãƒŠã‚¹ï¼ˆ{my_role}ï¼‰"
                    else:
                        score = min(count * 0.05, 1.0)  # ç•°è·ç¨®ã®å ´åˆã¯ä½ã‚ã®ã‚¹ã‚³ã‚¢
                        analysis_note = f"ç•°è·ç¨®ï¼ˆ{my_role}â†”{partner_role}ï¼‰"
                elif synergy_type == 'all_roles':
                    # å…¨è·ç¨®è©³ç´°åˆ†æ: å¤šæ§˜æ€§ãƒœãƒ¼ãƒŠã‚¹
                    if my_role != partner_role and my_role != "ä¸æ˜" and partner_role != "ä¸æ˜":
                        diversity_bonus = 0.2
                        score = min(count * 0.10 + diversity_bonus, 1.0)
                        analysis_note = f"å¤šæ§˜æ€§ãƒœãƒ¼ãƒŠã‚¹ï¼ˆ{my_role}â†”{partner_role}ï¼‰"
                    else:
                        score = min(count * 0.12, 1.0)
                        analysis_note = f"åŒè·ç¨®ï¼ˆ{my_role}ï¼‰"
                else:  # correlation_matrix
                    # ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹: ã‚ˆã‚Šçµ±è¨ˆçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
                    base_score = count * 0.08
                    correlation_factor = np.random.beta(2, 5)  # ã‚ˆã‚Šç¾å®Ÿçš„ãªåˆ†å¸ƒ
                    score = min(base_score + correlation_factor, 1.0)
                    analysis_note = "çµ±è¨ˆçš„ç›¸é–¢åˆ†æ"
                
                synergy_scores.append({
                    'ç›¸æ‰‹ã®è·å“¡': partner, 
                    'ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢': score, 
                    'å…±åƒå›æ•°': count,
                    'åˆ†ææ–¹æ³•': analysis_note,
                    'è·ç¨®': partner_role
                })
            
            if synergy_scores:
                synergy_df = pd.DataFrame(synergy_scores)
                synergy_fig = px.bar(
                    synergy_df, x="ç›¸æ‰‹ã®è·å“¡", y="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢", color="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢",
                    color_continuous_scale='RdYlGn', 
                    title=f"{selected_staff}ã•ã‚“ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ - {analysis_type_display.get(synergy_type, synergy_type)}",
                    hover_data=['åˆ†ææ–¹æ³•', 'å…±åƒå›æ•°', 'è·ç¨®']
                )
                synergy_fig.update_layout(xaxis_title="ç›¸æ‰‹ã®è·å“¡", yaxis_title="ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰")
    except Exception as e:
        log.warning(f"ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")

    # --- 7 & 8. åƒãæ–¹ã®ã‚¯ã‚»åˆ†æ ---
    mannelido_score, rhythm_score = "è¨ˆç®—ä¸å¯", "è¨ˆç®—ä¸å¯"
    work_records_for_role = staff_df[staff_df.get('parsed_slots_count', 0) > 0]
    if not work_records_for_role.empty:
        role_per_day = work_records_for_role[['ds', 'role']].copy()
        role_per_day['date'] = role_per_day['ds'].dt.date
        role_counts = role_per_day.drop_duplicates(subset=['date', 'role'])['role'].value_counts(normalize=True)
        if not role_counts.empty:
            mannelido_score = f"{role_counts.max():.2f}"

        daily_starts = work_records_for_role.groupby(work_records_for_role['ds'].dt.date)['ds'].min()
        if len(daily_starts) > 1:
            start_hours = daily_starts.dt.hour + daily_starts.dt.minute / 60.0
            rhythm_score = f"{start_hours.std():.2f}"
        else:
            rhythm_score = "0.00"

    # --- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®çµ„ã¿ç«‹ã¦ ---
    layout = html.Div([
        html.Div([
            html.Div([
                html.H4("ç–²åŠ´åº¦ãƒ»ä¸å…¬å¹³æ„Ÿãƒ»åƒãæ–¹ã®ã‚¯ã‚»"),
                create_metric_card("ç–²åŠ´ã‚¹ã‚³ã‚¢", fatigue_score, color="#ff7f0e"),
                create_metric_card("ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢", unfairness_score, color="#d62728"),
                create_metric_card("æ¥­å‹™ãƒãƒ³ãƒãƒªåº¦", mannelido_score, color="#9467bd"),
                create_metric_card("ç”Ÿæ´»ãƒªã‚ºãƒ ç ´å£Šåº¦", rhythm_score, color="#8c564b"),
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top', 'paddingRight': '1%'}),
            html.Div([
                html.H5("ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢ã®å†…è¨³"),
                dash_table.DataTable(
                    data=score_details_df.to_dict('records'),
                    columns=[{'name': i, 'id': i} for i in score_details_df.columns],
                ) if not score_details_df.empty else html.P("è©³ç´°ãƒ‡ãƒ¼ã‚¿ãªã—")
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top', 'paddingRight': '1%'}),
            html.Div([
                html.H5("å…±åƒãƒ©ãƒ³ã‚­ãƒ³ã‚° Top 5"),
                dash_table.DataTable(
                    data=coworker_ranking_df.to_dict('records'),
                    columns=[{'name': i, 'id': i} for i in coworker_ranking_df.columns],
                ) if not coworker_ranking_df.empty else html.P("å…±åƒãƒ‡ãƒ¼ã‚¿ãªã—"),
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top', 'paddingRight': '1%'}),
            html.Div([
                html.H5("ä¸è¶³/éå‰°ã¸ã®è²¢çŒ®åº¦"),
                create_metric_card("ä¸è¶³æ™‚é–“å¸¯ã§ã®å‹¤å‹™ (h)", f"{shortage_contribution_h:.1f}", color="#c53d40"),
                create_metric_card("éå‰°æ™‚é–“å¸¯ã§ã®å‹¤å‹™ (h)", f"{excess_contribution_h:.1f}", color="#1f77b4"),
            ], style={'width': '24%', 'display': 'inline-block', 'verticalAlign': 'top'}),
        ], style={'marginBottom': '20px'}),
        html.Div([
            html.Div([dcc.Graph(figure=work_dist_fig)], style={'width': '49%', 'display': 'inline-block'}),
            html.Div([dcc.Graph(figure=leave_by_dow_fig)], style={'width': '49%', 'display': 'inline-block'}),
        ]),
        html.Div([
            html.H4("è·å“¡é–“ã®ã‚·ãƒŠã‚¸ãƒ¼åˆ†æ", style={'marginTop': '20px'}),
            html.P(f"ç¾åœ¨ã®åˆ†æã‚¿ã‚¤ãƒ—: {analysis_type_display.get(synergy_type, synergy_type)}", style={'fontWeight': 'bold', 'color': '#1976d2'}),
            html.P("ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢ã¯ã€ãã®ãƒšã‚¢ãŒä¸€ç·’ã«å‹¤å‹™ã—ãŸéš›ã®ã€Œäººå“¡ä¸è¶³ã®èµ·ã“ã‚Šã«ãã•ã€ã‚’ç¤ºã—ã¾ã™ã€‚ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©ã€ä¸è¶³ãŒå°‘ãªããªã‚‹è‰¯ã„çµ„ã¿åˆã‚ã›ã§ã™ã€‚"),
            dcc.Graph(figure=synergy_fig)
        ])
    ])

    return layout


# Helper function to create metric cards
def create_metric_card(title, value, color="#1976d2"):
    return html.Div([
        html.H6(title, style={'margin': '0', 'color': '#666'}),
        html.H4(value, style={'margin': '5px 0', 'color': color, 'fontSize': '24px'})
    ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#fff', 'borderRadius': '8px', 'margin': '5px', 'boxShadow': '0 2px 4px rgba(0,0,0,0.1)'})


# Helper function to create correlation matrix for all staff
def create_all_staff_correlation_matrix(long_df):
    """å…¨è·å“¡ã®å‹¤å‹™æ™‚é–“ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’ä½œæˆ"""
    try:
        if long_df.empty:
            return go.Figure().add_annotation(text="ãƒ‡ãƒ¼ã‚¿ãªã—", x=0.5, y=0.5, showarrow=False)
        
        # è·å“¡åˆ¥ãƒ»æ—¥åˆ¥ã®å‹¤å‹™æ™‚é–“ã‚’é›†è¨ˆ
        work_df = long_df[long_df.get('parsed_slots_count', 0) > 0].copy()
        if work_df.empty:
            return go.Figure().add_annotation(text="å‹¤å‹™ãƒ‡ãƒ¼ã‚¿ãªã—", x=0.5, y=0.5, showarrow=False)
        
        # æ—¥ä»˜ã¨ã‚¹ã‚¿ãƒƒãƒ•ã§ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        work_df['date'] = work_df['ds'].dt.date
        daily_hours = work_df.groupby(['staff', 'date'])['parsed_slots_count'].sum().reset_index()
        
        # ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆã‚¹ã‚¿ãƒƒãƒ•Ã—æ—¥ä»˜ã®å‹¤å‹™æ™‚é–“ï¼‰
        pivot_df = daily_hours.pivot(index='date', columns='staff', values='parsed_slots_count').fillna(0)
        
        # å…¨è·å“¡ã§ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆ
        correlation_df = pivot_df.corr()
        
        # è·å“¡æ•°ã«å¿œã˜ã¦ã‚µã‚¤ã‚ºã‚’èª¿æ•´
        num_staff = len(correlation_df)
        fig_size = max(600, min(1200, num_staff * 30))
        font_size = max(8, min(12, 120 // num_staff))
        
        # è·å“¡æ•°ãŒå¤šã„å ´åˆã¯æ³¨é‡ˆã‚’çœç•¥
        annotations = []
        if num_staff <= 20:
            for i, row in enumerate(correlation_df.index):
                for j, col in enumerate(correlation_df.columns):
                    annotations.append(
                        dict(
                            x=j, y=i,
                            text=f"{correlation_df.iloc[i, j]:.2f}",
                            showarrow=False,
                            font=dict(color="white" if abs(correlation_df.iloc[i, j]) > 0.5 else "black", size=font_size)
                        )
                    )
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆ
        fig = go.Figure(data=go.Heatmap(
            z=correlation_df.values,
            x=correlation_df.columns,
            y=correlation_df.index,
            colorscale='RdBu_r',
            zmid=0,
            colorbar=dict(title=dict(text="ç›¸é–¢ä¿‚æ•°", side="right")),
            hoverongaps=False,
            hovertemplate='è·å“¡A: %{y}<br>è·å“¡B: %{x}<br>ç›¸é–¢: %{z:.3f}<extra></extra>'
        ))
        
        fig.update_layout(
            title=dict(
                text=f"å…¨è·å“¡å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆ{num_staff}åï¼‰",
                x=0.5,
                font=dict(size=16)
            ),
            xaxis_title="è·å“¡",
            yaxis_title="è·å“¡", 
            width=fig_size,
            height=fig_size,
            annotations=annotations,
            xaxis=dict(tickangle=45, tickfont=dict(size=font_size)),
            yaxis=dict(tickangle=0, tickfont=dict(size=font_size)),
            margin=dict(l=100, r=100, t=80, b=100)
        )
        
        return fig
        
    except Exception as e:
        log.warning(f"å…¨è·å“¡ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return go.Figure().add_annotation(
            text="ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼", 
            x=0.5, y=0.5, showarrow=False
        )




@app.callback(
    Output({'type': 'heatmap-filter-employment', 'index': ALL}, 'options'),
    Output({'type': 'heatmap-filter-employment', 'index': ALL}, 'value'),
    Input({'type': 'heatmap-filter-role', 'index': ALL}, 'value'),
)
@safe_callback
def update_employment_options(selected_roles):
    """è·ç¨®é¸æŠã«å¿œã˜ã¦é›‡ç”¨å½¢æ…‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’æ›´æ–°"""
    aggregated_df = data_get('pre_aggregated_data')
    if aggregated_df is None or aggregated_df.empty:
        default_options = [{'label': 'ã™ã¹ã¦', 'value': 'all'}]
        return [default_options, default_options], ['all', 'all']

    output_options = []
    for role in selected_roles:
        if role and role != 'all':
            employments = aggregated_df[aggregated_df['role'] == role][
                'employment'
            ].unique()
            new_options = (
                [{'label': 'ã™ã¹ã¦', 'value': 'all'}]
                + [{'label': emp, 'value': emp} for emp in sorted(employments)]
            )
        else:
            all_employments = aggregated_df['employment'].unique()
            new_options = (
                [{'label': 'ã™ã¹ã¦', 'value': 'all'}]
                + [{'label': emp, 'value': emp} for emp in sorted(all_employments)]
            )
        output_options.append(new_options)

    return output_options, ['all', 'all']


@app.callback(
    Output({'type': 'graph-output-heatmap', 'index': 1}, 'children'),
    Output({'type': 'graph-output-heatmap', 'index': 2}, 'children'),
    Input({'type': 'heatmap-filter-role', 'index': 1}, 'value'),
    Input({'type': 'heatmap-filter-employment', 'index': 1}, 'value'),
    Input({'type': 'heatmap-filter-role', 'index': 2}, 'value'),
    Input({'type': 'heatmap-filter-employment', 'index': 2}, 'value'),
)
@safe_callback
def update_comparison_heatmaps(role1, emp1, role2, emp2):
    """äº‹å‰é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‹•çš„ã«ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã€2ã‚¨ãƒªã‚¢ã‚’æ›´æ–°"""

    aggregated_df = data_get('pre_aggregated_data')
    if aggregated_df is None or aggregated_df.empty:
        error_message = html.Div("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®å…ƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")  # type: ignore
        return error_message, error_message

    def generate_dynamic_heatmap(selected_role, selected_emp):
        """é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§äº‹å‰é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ã—ãƒ”ãƒœãƒƒãƒˆåŒ–"""

        filtered_df = aggregated_df.copy()
        title_parts = []

        # é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«åˆã‚ã›ã¦ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã‚€
        if selected_role and selected_role != 'all':
            filtered_df = filtered_df[filtered_df['role'] == selected_role]
            title_parts.append(f"è·ç¨®: {selected_role}")

        if selected_emp and selected_emp != 'all':
            filtered_df = filtered_df[filtered_df['employment'] == selected_emp]
            title_parts.append(f"é›‡ç”¨å½¢æ…‹: {selected_emp}")

        title = " AND ".join(title_parts) if title_parts else "å…¨ä½“"

        if filtered_df.empty:
            # â˜…â˜…â˜… æ™‚é–“é–“éš”çµ±ä¸€: 30åˆ† â†’ 15åˆ† â˜…â˜…â˜…
            time_labels = gen_labels(15)  # 30åˆ†ã‹ã‚‰15åˆ†ã«å¤‰æ›´
            all_dates = sorted(aggregated_df['date_lbl'].unique())
            empty_heatmap = pd.DataFrame(index=time_labels, columns=all_dates).fillna(0)
            fig_empty = generate_heatmap_figure(empty_heatmap, f"{title} (å‹¤å‹™ãƒ‡ãƒ¼ã‚¿ãªã—)")
            return dcc.Graph(figure=fig_empty)

        # æ—¥ä»˜é †ã«ä¸¦ã³æ›¿ãˆã¦ã‹ã‚‰ãƒ”ãƒœãƒƒãƒˆ
        dynamic_heatmap_df = filtered_df.sort_values('date_lbl').pivot_table(
            index='time',
            columns='date_lbl',
            values='staff_count',
            aggfunc='sum',
            fill_value=0,
        )

        # aggregated_df['date_lbl'].unique() ã¯å¸¸ã«30æ—¥å…¨ã¦ã®æ—¥ä»˜ã‚’ä¿æŒã—ã¦ã„ã¾ã™
        all_dates_from_aggregated_data = sorted(aggregated_df['date_lbl'].unique())

        # ã¾ãšåˆ—ï¼ˆæ—¥ä»˜ï¼‰ã‚’å…¨ã¦ç¶²ç¾…ã™ã‚‹ã‚ˆã†ã«reindexã—ã€ä¸è¶³ã—ã¦ã„ã‚‹åˆ—ã¯0ã§åŸ‹ã‚ã‚‹
        dynamic_heatmap_df = dynamic_heatmap_df.reindex(columns=all_dates_from_aggregated_data, fill_value=0)

        # â˜…â˜…â˜… æ™‚é–“é–“éš”çµ±ä¸€: 30åˆ† â†’ 15åˆ† â˜…â˜…â˜…
        time_labels = gen_labels(15)  # 30åˆ†ã‹ã‚‰15åˆ†ã«å¤‰æ›´
        # æ¬¡ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆæ™‚é–“ï¼‰ã‚’å…¨ã¦ç¶²ç¾…ã™ã‚‹ã‚ˆã†ã«reindexã—ã€ä¸è¶³ã—ã¦ã„ã‚‹è¡Œã¯0ã§åŸ‹ã‚ã‚‹
        dynamic_heatmap_df = dynamic_heatmap_df.reindex(index=time_labels, fill_value=0)

        present_dates = dynamic_heatmap_df.columns.tolist()
        analysis_logger.info(
            f"ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— '{title}' ã®ç”Ÿæˆ: æç”»å¯¾è±¡ã®æ—¥ä»˜ ({len(present_dates)}ä»¶): {present_dates}"
        )

        long_df = data_get('long_df', pd.DataFrame())
        if not long_df.empty:
            all_dates_in_period = sorted(pd.to_datetime(long_df['ds']).dt.strftime('%Y-%m-%d').unique())
            missing_dates = sorted(list(set(all_dates_in_period) - set(present_dates)))
            if missing_dates:
                analysis_logger.warning(
                    f"ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— '{title}' ã§æ—¥ä»˜ãŒæ¬ è½ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                    f"åˆ†ææœŸé–“ä¸­ã®å…¨æ—¥ä»˜: {len(all_dates_in_period)}ä»¶, "
                    f"æç”»å¯¾è±¡ã®æ—¥ä»˜: {len(present_dates)}ä»¶, "
                    f"æ¬ è½æ—¥ä»˜ ({len(missing_dates)}ä»¶): {missing_dates}"
                )

        fig = generate_heatmap_figure(dynamic_heatmap_df, title)
        return dcc.Graph(figure=fig)

    output1 = generate_dynamic_heatmap(role1, emp1)
    output2 = generate_dynamic_heatmap(role2, emp2)

    return output1, output2


@app.callback(
    Output('shortage-heatmap-detail-container', 'children'),
    Input('shortage-heatmap-scope', 'value')
)
@safe_callback
def update_shortage_heatmap_detail(scope):
    """ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®è©³ç´°é¸æŠã‚’æ›´æ–°"""
    if scope == 'overall':
        return None
    elif scope == 'role':
        roles = data_get('roles', [])
        return html.Div([  # type: ignore
            html.Label("è·ç¨®é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'shortage-detail', 'index': 'role'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': r, 'value': r} for r in roles],
                value='ALL',
                style={'width': '200px'}
            )
        ], style={'marginBottom': '10px'})
    elif scope == 'employment':
        employments = data_get('employments', [])
        return html.Div([  # type: ignore
            html.Label("é›‡ç”¨å½¢æ…‹é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'shortage-detail', 'index': 'employment'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': e, 'value': e} for e in employments],
                value='ALL',
                style={'width': '200px'}
            )
        ], style={'marginBottom': '10px'})
    return None


@app.callback(
    Output('shortage-ratio-heatmap', 'children'),
    Input('shortage-heatmap-scope', 'value'),
    Input({'type': 'shortage-detail', 'index': ALL}, 'value')
)
@safe_callback
def update_shortage_ratio_heatmap(scope, detail_values):
    """ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ›´æ–°"""
    # é¸æŠå†…å®¹ã‹ã‚‰ã‚­ãƒ¼ã‚’çµ„ã¿ç«‹ã¦ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    key_suffix = ''
    if scope == 'role' and detail_values and detail_values[0] != 'ALL':
        # è·ç¨®åˆ¥: ç›´æ¥è·ç¨®åã‚’ä½¿ç”¨ï¼ˆrole_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹é™¤å»ï¼‰
        key_suffix = safe_filename(detail_values[0])
    elif scope == 'employment' and detail_values and detail_values[0] != 'ALL':
        # é›‡ç”¨å½¢æ…‹åˆ¥: emp_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãã§ä½¿ç”¨
        key_suffix = f"emp_{safe_filename(detail_values[0])}"

    heat_key = f"heat_{key_suffix}" if key_suffix else "heat_all"
    df_heat = data_get(heat_key, pd.DataFrame())
    
    # ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€å…ƒã®è·ç¨®åï¼ˆsafe_filenameå¤‰æ›å‰ï¼‰ã§å†è©¦è¡Œ
    if df_heat.empty and scope == 'role' and detail_values and detail_values[0] != 'ALL':
        original_heat_key = f"heat_{detail_values[0]}"
        log.info(f"Trying original key: {original_heat_key}")
        df_heat = data_get(original_heat_key, pd.DataFrame())

    if df_heat.empty:
        # ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨è¨ºæ–­æƒ…å ±ã‚’æä¾›
        available_keys = [k for k in DATA_CACHE.keys() if k.startswith('heat_')]
        debug_info = []
        debug_info.append(f"æ¢ç´¢ã‚­ãƒ¼: {heat_key}")
        debug_info.append(f"åˆ©ç”¨å¯èƒ½ãªãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚­ãƒ¼: {available_keys}")
        debug_info.append(f"é¸æŠã•ã‚ŒãŸã‚¹ã‚³ãƒ¼ãƒ—: {scope}")
        debug_info.append(f"è©³ç´°å€¤: {detail_values}")
        
        # é¡ä¼¼ã‚­ãƒ¼ã®ææ¡ˆ
        similar_keys = [k for k in available_keys if key_suffix in k] if key_suffix else []
        if similar_keys:
            debug_info.append(f"é¡ä¼¼ã‚­ãƒ¼: {similar_keys}")
        
        return html.Div([  # type: ignore
            html.P("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", style={'color': 'red', 'fontWeight': 'bold'}),
            html.P("è¨ºæ–­æƒ…å ±:", style={'fontWeight': 'bold'}),
            html.Ul([html.Li(info) for info in debug_info]),
            html.P("è§£æ±ºæ–¹æ³•:", style={'fontWeight': 'bold'}),
            html.Ul([
                html.Li("ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãåˆ†æã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"),
                html.Li("è·ç¨®åã«ç‰¹æ®Šæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„"), 
                html.Li("åˆ¥ã®è·ç¨®/é›‡ç”¨å½¢æ…‹ã‚’é¸æŠã—ã¦ã¿ã¦ãã ã•ã„")
            ])
        ])

    date_cols = [c for c in df_heat.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    staff_df = df_heat[date_cols]
    
    # â˜…â˜…â˜… é‡è¦ãªä¿®æ­£: è·ç¨®åˆ¥ãƒ»é›‡ç”¨å½¢æ…‹åˆ¥ã®å ´åˆã¯è©²å½“ã®needå€¤ã®ã¿ã‚’ä½¿ç”¨ â˜…â˜…â˜…
    if scope == 'overall':
        # å…¨ä½“ã®å ´åˆã®ã¿need_per_date_slot.parquetã‚’ä½¿ç”¨
        need_per_date_slot_df = data_get('need_per_date_slot', pd.DataFrame())
        
        if not need_per_date_slot_df.empty:
            # need_per_date_slot.parquetãŒå­˜åœ¨ã™ã‚‹å ´åˆã€å®Ÿéš›ã®æ—¥ä»˜åˆ¥needå€¤ã‚’ä½¿ç”¨
            log.info(f"Using need_per_date_slot.parquet for accurate daily need values: {need_per_date_slot_df.shape}")
            
            # åˆ—åã‚’æ–‡å­—åˆ—ã¨ã—ã¦çµ±ä¸€
            need_per_date_slot_df.columns = [str(col) for col in need_per_date_slot_df.columns]
            date_cols_str = [str(col) for col in date_cols]
            
            # å…±é€šã™ã‚‹æ—¥ä»˜åˆ—ã®ã¿ã‚’ä½¿ç”¨
            common_dates = [col for col in date_cols_str if col in need_per_date_slot_df.columns]
            
            if common_dates:
                # å®Ÿéš›ã®æ—¥ä»˜åˆ¥needå€¤ã‚’ä½¿ç”¨
                need_df = need_per_date_slot_df[common_dates].copy()
                need_df.columns = [c for c in date_cols if str(c) in common_dates]
                
                # ä¸è¶³ã—ã¦ã„ã‚‹æ—¥ä»˜ãŒã‚ã‚Œã°å¹³å‡å€¤ã§è£œå®Œ
                missing_dates = [c for c in date_cols if str(c) not in common_dates]
                if missing_dates:
                    log.warning(f"Some dates missing in need_per_date_slot.parquet, using fallback for: {missing_dates}")
                    fallback_need = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(missing_dates), axis=1),
                                               index=df_heat.index, columns=missing_dates)
                    need_df = pd.concat([need_df, fallback_need], axis=1)
                    need_df = need_df.reindex(columns=date_cols)  # å…ƒã®é †åºã‚’ä¿æŒ
            else:
                log.warning("No matching dates found in need_per_date_slot.parquet, falling back to average need")
                need_df = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                                       index=df_heat.index, columns=date_cols)
        else:
            # need_per_date_slot.parquetãŒå­˜åœ¨ã—ãªã„å ´åˆã¯å¾“æ¥ã®å¹³å‡å€¤ã‚’ä½¿ç”¨
            log.info("need_per_date_slot.parquet not available, using average need values")
            need_df = pd.DataFrame(np.repeat(df_heat['need'].values[:, np.newaxis], len(date_cols), axis=1),
                                   index=df_heat.index, columns=date_cols)
    else:
        # è·ç¨®åˆ¥ãƒ»é›‡ç”¨å½¢æ…‹åˆ¥ã®å ´åˆã¯ã€å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å‹•çš„needå€¤ã‚’è¨ˆç®—
        need_df = calculate_role_dynamic_need(df_heat, date_cols, heat_key)
    upper_df = pd.DataFrame(np.repeat(df_heat['upper'].values[:, np.newaxis], len(date_cols), axis=1),
                            index=df_heat.index, columns=date_cols)

    # æ­£ç¢ºãªä¸è¶³è¨ˆç®—ã®å®Ÿè£…
    # needå€¤ãŒæ­£ç¢ºã«è¨ˆç®—ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ã‚·ãƒ³ãƒ—ãƒ«ã§æ­£ç¢ºãªä¸è¶³è¨ˆç®—ã‚’è¡Œã†
    lack_count_df = (need_df - staff_df).clip(lower=0).fillna(0)
    
    # å®Ÿéš›ã®needå€¤ãŒéå¸¸ã«å°ã•ã„å ´åˆï¼ˆ0.01æœªæº€ï¼‰ã®ã¿0ã¨ã™ã‚‹ï¼ˆè¨ˆç®—èª¤å·®å¯¾ç­–ï¼‰
    mask_tiny_need = need_df < 0.01
    lack_count_df[mask_tiny_need] = 0.0
    
    log.info(f"[LACK_CALCULATION] {heat_key}: Total lack={lack_count_df.sum().sum():.2f}, Max need={need_df.max().max():.2f}, Max staff={staff_df.max().max():.2f}")
    
    excess_count_df = (staff_df - upper_df).clip(lower=0).fillna(0)
    ratio_df = calc_ratio_from_heatmap(df_heat)
    
    # ä¸è¶³æ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ä¿®æ­£
    lack_count_df_renamed = lack_count_df.copy()
    lack_count_df_renamed.columns = [date_with_weekday(c) for c in lack_count_df_renamed.columns]
    # è¿½åŠ ã®å®‰å…¨å¯¾ç­–: NaNå€¤ã‚’å†åº¦0ã§åŸ‹ã‚ã‚‹ï¼ˆæ—¥æ›œæ—¥ã®æ¬ è½å¯¾ç­–ï¼‰
    lack_count_df_renamed = lack_count_df_renamed.fillna(0)
    
    fig_lack = px.imshow(
        lack_count_df_renamed,
        aspect='auto',
        color_continuous_scale='Oranges',
        title='ä¸è¶³äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
        labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'},
        text_auto=True  # 0å€¤ã‚‚è¡¨ç¤º
    )
    
    # ä¸è¶³æ•°ã®è¡¨ç¤ºã‚¹ã‚¿ã‚¤ãƒ«ã‚’èª¿æ•´
    fig_lack.update_traces(
        texttemplate='%{text}',
        textfont={"size": 10}
    )
    fig_lack.update_xaxes(tickvals=list(range(len(lack_count_df.columns))))

    fig_excess = go.Figure()
    if not excess_count_df.empty:
        excess_count_df_renamed = excess_count_df.copy()
        excess_count_df_renamed.columns = [date_with_weekday(c) for c in excess_count_df_renamed.columns]
        fig_excess = px.imshow(
            excess_count_df_renamed,
            aspect='auto',
            color_continuous_scale='Blues',
            title='éå‰°äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
            labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'},
        )
        fig_excess.update_xaxes(tickvals=list(range(len(excess_count_df.columns))))

    fig_ratio = go.Figure()
    if not ratio_df.empty:
        ratio_df_renamed = ratio_df.copy()
        ratio_df_renamed.columns = [date_with_weekday(c) for c in ratio_df_renamed.columns]
        fig_ratio = px.imshow(
            ratio_df_renamed,
            aspect='auto',
            color_continuous_scale='RdBu_r',
            title='ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
            labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ä¸è¶³ç‡'},
        )
        fig_ratio.update_xaxes(tickvals=list(range(len(ratio_df.columns))))

    return html.Div([  # type: ignore
        html.H4('ä¸è¶³äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—'),
        dcc.Graph(figure=fig_lack),
        html.H4('éå‰°äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', style={'marginTop': '30px'}),
        dcc.Graph(figure=fig_excess),
        html.H4('ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', style={'marginTop': '30px'}),
        dcc.Graph(figure=fig_ratio),
    ])


@app.callback(
    Output('opt-detail-container', 'children'),
    Input('opt-scope', 'value')
)
@safe_callback
def update_opt_detail(scope):
    """æœ€é©åŒ–åˆ†æã®è©³ç´°é¸æŠã‚’æ›´æ–°"""
    if scope == 'overall':
        return None
    elif scope == 'role':
        roles = data_get('roles', [])
        return html.Div([  # type: ignore
            html.Label("è·ç¨®é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'opt-detail', 'index': 'role'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': r, 'value': r} for r in roles],
                value='ALL',
                style={'width': '300px', 'marginBottom': '20px'}
            )
        ])
    elif scope == 'employment':
        employments = data_get('employments', [])
        return html.Div([  # type: ignore
            html.Label("é›‡ç”¨å½¢æ…‹é¸æŠ"),  # type: ignore
            dcc.Dropdown(
                id={'type': 'opt-detail', 'index': 'employment'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': e, 'value': e} for e in employments],
                value='ALL',
                style={'width': '300px', 'marginBottom': '20px'}
            )
        ])
    return None


# æœ€é©åŒ–åˆ†æã®ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¡¨ç¤ºã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå‹•çš„æ›´æ–°ã®ã¿ï¼‰
@app.callback(
    Output('optimization-content', 'children'),
    [Input('opt-scope', 'value'),
     Input({'type': 'opt-detail', 'index': ALL}, 'value')],
    [State('scenario-dropdown', 'value'),
     State('data-loaded', 'data')]
)
@safe_callback
def update_optimization_content(scope, detail_values, selected_scenario, data_status):
    """æœ€é©åŒ–åˆ†æã®ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›´æ–°"""
    if not selected_scenario or not data_status:
        raise PreventUpdate
    
    # å…±é€šé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆ
    content = generate_optimization_analysis(scope, detail_values)
    return html.Div(content)


@app.callback(
    Output('overview-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_overview_insights(kpi_data):
    if not kpi_data:
        return ""

    total_lack_h = kpi_data.get('total_lack_h', 0)

    if total_lack_h > 0:
        most_lacking_role = kpi_data.get('most_lacking_role_name', 'N/A')
        most_lacking_hours = kpi_data.get('most_lacking_role_hours', 0)
        insight_text = f"""
        #### ğŸ“ˆ åˆ†æãƒã‚¤ãƒ©ã‚¤ãƒˆ
        - **ç·ä¸è¶³æ™‚é–“:** {total_lack_h:.1f} æ™‚é–“
        - **æœ€é‡è¦èª²é¡Œ:** **{most_lacking_role}** ã®ä¸è¶³ãŒ **{most_lacking_hours:.1f}æ™‚é–“** ã¨æœ€ã‚‚æ·±åˆ»ã§ã™ã€‚ã“ã®è·ç¨®ã®æ¡ç”¨ã¾ãŸã¯é…ç½®è»¢æ›ãŒæ€¥å‹™ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚
        """
        return dcc.Markdown(insight_text)
    return html.P(
        "ğŸ‘ äººå“¡ä¸è¶³ã¯ç™ºç”Ÿã—ã¦ã„ã¾ã›ã‚“ã€‚ç´ æ™´ã‚‰ã—ã„å‹¤å‹™ä½“åˆ¶ã§ã™ï¼",
        style={'fontWeight': 'bold'},  # type: ignore
    )


@app.callback(
    Output('shortage-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_shortage_insights(kpi_data):
    explanation = """
    #### ä¸è¶³åˆ†æã®è©•ä¾¡æ–¹æ³•
    - **ä¸è¶³ (Shortage):** `ä¸è¶³äººæ•° = å¿…è¦äººæ•° (Need) - å®Ÿç¸¾äººæ•°` ã§è¨ˆç®—ã•ã‚Œã¾ã™ã€‚å€¤ãŒãƒ—ãƒ©ã‚¹ã®å ´åˆã€ãã®æ™‚é–“å¸¯ã¯äººå“¡ãŒä¸è¶³ã—ã¦ã„ãŸã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
    - **éå‰° (Excess):** `éå‰°äººæ•° = å®Ÿç¸¾äººæ•° - ä¸Šé™äººæ•° (Upper)` ã§è¨ˆç®—ã•ã‚Œã¾ã™ã€‚å€¤ãŒãƒ—ãƒ©ã‚¹ã®å ´åˆã€éå‰°ãªäººå“¡ãŒé…ç½®ã•ã‚Œã¦ã„ãŸã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚

    *ã€Œå¿…è¦äººæ•°ã€ã¨ã€Œä¸Šé™äººæ•°ã€ã¯ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œåˆ†æåŸºæº–è¨­å®šã€ã§æŒ‡å®šã—ãŸæ–¹æ³•ï¼ˆéå»å®Ÿç¸¾ã®çµ±è¨ˆã€ã¾ãŸã¯äººå“¡é…ç½®åŸºæº–ï¼‰ã«åŸºã¥ã„ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚*
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('hire-plan-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_hire_plan_insights(kpi_data):
    if not kpi_data:
        return ""
    total_lack_h = kpi_data.get('total_lack_h', 0)
    if total_lack_h == 0:
        return html.P("è¿½åŠ æ¡ç”¨ã®å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    role = kpi_data.get('most_lacking_role_name', 'N/A')
    return dcc.Markdown(
        f"æœ€ã‚‚ä¸è¶³ã—ã¦ã„ã‚‹ **{role}** ã®è£œå……ã‚’å„ªå…ˆçš„ã«æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
    )


@app.callback(
    Output('optimization-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_optimization_insights(kpi_data):
    explanation = """
    #### æœ€é©åŒ–åˆ†æã®è©•ä¾¡æ–¹æ³•
    äººå“¡é…ç½®ã®åŠ¹ç‡æ€§ã¯ã€ä»¥ä¸‹ã®2ã¤ã®è¦³ç‚¹ã‹ã‚‰ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’è¨ˆç®—ã—ã€æœ€çµ‚çš„ãªã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—ã¾ã™ã€‚
    - **ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ (é‡ã¿: 60%):** `(å¿…è¦äººæ•° - å®Ÿç¸¾äººæ•°) / å¿…è¦äººæ•°`
    - **éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£ (é‡ã¿: 40%):** `(å®Ÿç¸¾äººæ•° - ä¸Šé™äººæ•°) / ä¸Šé™äººæ•°`

    **æœ€é©åŒ–ã‚¹ã‚³ã‚¢ = 1 - (ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ Ã— 0.6 + éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£ Ã— 0.4)**

    *ã‚¹ã‚³ã‚¢ãŒ1ã«è¿‘ã„ã»ã©ã€ä¸è¶³ã‚‚éå‰°ã‚‚ãªãã€åŠ¹ç‡çš„ãªäººå“¡é…ç½®ãŒã§ãã¦ã„ã‚‹çŠ¶æ…‹ã‚’ç¤ºã—ã¾ã™ã€‚*
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('leave-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_leave_insights(kpi_data):
    explanation = """
    #### ä¼‘æš‡åˆ†æã®è©•ä¾¡æ–¹æ³•
    - **ä¼‘æš‡å–å¾—è€…æ•°:** `holiday_type`ãŒä¼‘æš‡é–¢é€£ï¼ˆå¸Œæœ›ä¼‘ã€æœ‰çµ¦ãªã©ï¼‰ã«è¨­å®šã•ã‚Œã€ã‹ã¤å‹¤å‹™æ™‚é–“ãŒãªã„ï¼ˆ`parsed_slots_count = 0`ï¼‰å ´åˆã«ã€Œ1æ—¥ã€ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã¾ã™ã€‚
    - **é›†ä¸­æ—¥:** ã€Œå¸Œæœ›ä¼‘ã€ã®å–å¾—è€…æ•°ãŒã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ãŸé–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3äººï¼‰ä»¥ä¸Šã«ãªã£ãŸæ—¥ã‚’ã€Œé›†ä¸­æ—¥ã€ã¨ã—ã¦ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¾ã™ã€‚
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('cost-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
@safe_callback
def update_cost_insights(kpi_data):
    explanation = """
    #### ã‚³ã‚¹ãƒˆåˆ†æã®è©•ä¾¡æ–¹æ³•
    æ—¥ã€…ã®äººä»¶è²»ã¯ã€å„ã‚¹ã‚¿ãƒƒãƒ•ã®å‹¤å‹™æ™‚é–“ï¼ˆã‚¹ãƒ­ãƒƒãƒˆæ•° Ã— ã‚¹ãƒ­ãƒƒãƒˆé•·ï¼‰ã«ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ãŸå˜ä¾¡åŸºæº–ï¼ˆè·ç¨®åˆ¥ã€é›‡ç”¨å½¢æ…‹åˆ¥ãªã©ï¼‰ã®æ™‚çµ¦ã‚’ä¹—ã˜ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('wage-input-container', 'children'),
    Input('cost-by-radio', 'value')
)
@safe_callback
def update_wage_inputs(by_key):
    """å˜ä¾¡å…¥åŠ›æ¬„ã‚’ç”Ÿæˆ"""
    long_df = data_get('long_df')
    if long_df is None or long_df.empty or by_key not in long_df.columns:
        return html.P("å˜ä¾¡è¨­å®šã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    unique_keys: list[str] = sorted(long_df[by_key].dropna().unique())
    inputs = []
    for key in unique_keys:
        inputs.append(html.Div([
            html.Label(f'æ™‚çµ¦: {key}'),
            dcc.Input(
                id={'type': 'wage-input', 'index': key},
                value=1500,
                type='number',
                debounce=True,
            )
        ], style={'padding': '5px', 'display': 'inline-block'}))
    return inputs


@app.callback(
    Output('cost-analysis-content', 'children'),
    Input('cost-by-radio', 'value'),
    Input({'type': 'wage-input', 'index': ALL}, 'value'),
    State({'type': 'wage-input', 'index': ALL}, 'id'),
)
@safe_callback
def update_cost_analysis_content(by_key, all_wages, all_wage_ids):
    """å˜ä¾¡å¤‰æ›´ã«å¿œã˜ã¦ã‚³ã‚¹ãƒˆåˆ†æã‚¿ãƒ–ã®å…¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å‹•çš„ã«æ›´æ–°ã™ã‚‹"""
    long_df = data_get('long_df')
    if long_df is None or long_df.empty or not all_wages:
        raise PreventUpdate

    wages = {
        wage_id['index']: (wage_val or 0) for wage_id, wage_val in zip(all_wage_ids, all_wages)
    }

    df_cost = calculate_daily_cost(long_df, wages, by=by_key)
    if df_cost.empty:
        return html.P("ã‚³ã‚¹ãƒˆè¨ˆç®—çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    df_cost['date'] = pd.to_datetime(df_cost['date'])

    if not {'day_of_week', 'total_staff', 'role_breakdown'}.issubset(df_cost.columns):
        details = (
            long_df[long_df.get('parsed_slots_count', 1) > 0]
            .assign(date=lambda x: pd.to_datetime(x['ds']).dt.normalize())
            .groupby('date')
            .agg(
                day_of_week=('ds', lambda x: ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'][x.iloc[0].weekday()]),
                total_staff=('staff', 'nunique'),
                role_breakdown=('role', lambda s: ', '.join(f"{r}:{c}" for r, c in s.value_counts().items())),
            )
            .reset_index()
        )
        df_cost = pd.merge(df_cost, details, on='date', how='left')

    df_cost = df_cost.sort_values('date')

    content = []

    total_cost = df_cost['cost'].sum()
    avg_daily_cost = df_cost['cost'].mean()
    max_cost_day = df_cost.loc[df_cost['cost'].idxmax()]
    summary_cards = html.Div([
        create_metric_card("ç·ã‚³ã‚¹ãƒˆ", f"Â¥{total_cost:,.0f}"),
        create_metric_card("æ—¥å¹³å‡ã‚³ã‚¹ãƒˆ", f"Â¥{avg_daily_cost:,.0f}"),
        create_metric_card("æœ€é«˜ã‚³ã‚¹ãƒˆæ—¥", f"{max_cost_day['date'].strftime('%m/%d')}<br>Â¥{max_cost_day['cost']:,.0f}"),
    ], style={'display': 'flex', 'justifyContent': 'space-around', 'marginBottom': '20px'})
    content.append(summary_cards)

    df_cost['cumulative_cost'] = df_cost['cost'].cumsum()
    fig_cumulative = px.area(df_cost, x='date', y='cumulative_cost', title='ç´¯è¨ˆäººä»¶è²»ã®æ¨ç§»')
    fig_cumulative.update_xaxes(tickformat="%m/%d(%a)")
    content.append(dcc.Graph(figure=fig_cumulative))

    fig_daily = px.bar(df_cost, x='date', y='cost', title='æ—¥åˆ¥ç™ºç”Ÿäººä»¶è²»ï¼ˆç·é¡ï¼‰')
    fig_daily.update_xaxes(tickformat="%m/%d(%a)")
    content.append(dcc.Graph(figure=fig_daily))

    if 'role_breakdown' in df_cost.columns and by_key == 'role':
        role_data = []
        for _, row in df_cost.iterrows():
            if pd.notna(row.get('role_breakdown')):
                date_total_cost = row['cost']
                role_counts = {r.split(':')[0]: int(r.split(':')[1]) for r in row['role_breakdown'].split(', ') if ':' in r}
                total_count = sum(role_counts.values())

                for role, count in role_counts.items():
                    role_cost = (count / total_count) * date_total_cost if total_count > 0 else 0
                    role_data.append({'date': row['date'], 'role': role, 'count': count, 'cost': role_cost})

        if role_data:
            role_df = pd.DataFrame(role_data)

            fig_stacked = px.bar(role_df, x='date', y='cost', color='role', title='æ—¥åˆ¥äººä»¶è²»ï¼ˆè·ç¨®åˆ¥å†…è¨³ï¼‰')
            fig_stacked.update_xaxes(tickformat="%m/%d(%a)")
            content.append(dcc.Graph(figure=fig_stacked))

            role_df['month'] = pd.to_datetime(role_df['date']).dt.to_period('M').astype(str)
            monthly_role = role_df.groupby(['month', 'role'])['cost'].sum().reset_index()
            fig_monthly = px.bar(monthly_role, x='month', y='cost', color='role', title='æœˆæ¬¡äººä»¶è²»ï¼ˆè·ç¨®åˆ¥å†…è¨³ï¼‰')
            content.append(dcc.Graph(figure=fig_monthly))

            total_by_role = role_df.groupby('role')['cost'].sum().reset_index()
            fig_pie = px.pie(total_by_role, values='cost', names='role', title='è·ç¨®åˆ¥ã‚³ã‚¹ãƒˆæ§‹æˆæ¯”ï¼ˆå…¨æœŸé–“ï¼‰')
            fig_pie.update_traces(textposition='inside', textinfo='percent+label')
            content.append(dcc.Graph(figure=fig_pie))

    return html.Div(content)


@app.callback(
    Output('clear-synergy-cache-btn', 'children'),
    Input('clear-synergy-cache-btn', 'n_clicks'),
    prevent_initial_call=True
)
@safe_callback
def clear_synergy_cache_callback(n_clicks):
    """ã‚·ãƒŠã‚¸ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    if n_clicks:
        clear_synergy_cache()
        return "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢æ¸ˆã¿"
    return "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"


@app.callback(
    Output('team-criteria-value-dropdown', 'options'),
    Input('team-criteria-key-dropdown', 'value')
)
@safe_callback
def update_team_criteria_value_options(selected_key):
    """ãƒãƒ¼ãƒ åˆ†æã®æ¡ä»¶å€¤ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‚’æ›´æ–°"""
    if not selected_key:
        return []
    
    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty or selected_key not in long_df.columns:
        return []
    
    options = sorted(long_df[selected_key].unique())
    return [{'label': opt, 'value': opt} for opt in options]


@app.callback(
    Output('team-analysis-explanation', 'children'),
    [Input('team-criteria-value-dropdown', 'value'),
     Input('team-criteria-key-dropdown', 'value')]
)
@safe_callback
def update_team_analysis_explanation(selected_value, selected_key):
    """ãƒãƒ¼ãƒ åˆ†æã®èª¬æ˜ã‚’æ›´æ–°"""
    if not selected_value or not selected_key:
        return html.Div([
            html.H5("ğŸ“Š ãƒãƒ¼ãƒ åˆ†æçµæœã®èª­ã¿æ–¹"),
            html.P("ã“ã®ãƒãƒ¼ãƒ åˆ†æã§ã¯ã€é¸æŠã—ãŸæ¡ä»¶ã«è©²å½“ã™ã‚‹ã‚¹ã‚¿ãƒƒãƒ•ã‚°ãƒ«ãƒ¼ãƒ—ã®ç‰¹æ€§ã‚’åˆ†æã—ã¦ã„ã¾ã™ã€‚"),
            html.Ul([
                html.Li("ç–²åŠ´åº¦ã‚¹ã‚³ã‚¢: ãƒãƒ¼ãƒ å…¨ä½“ã®ç–²åŠ´ãƒ¬ãƒ™ãƒ«ã¨ãã®ã°ã‚‰ã¤ã"),
                html.Li("ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢: ãƒãƒ¼ãƒ å†…ã®ä¸å…¬å¹³æ„Ÿã¨ãã®ã°ã‚‰ã¤ã"),
                html.Li("æ”¹å–„ææ¡ˆ: åˆ†æçµæœã«åŸºã¥ãå…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
            ])
        ], style={
            'backgroundColor': '#f8f9fa',
            'padding': '15px',
            'borderRadius': '5px',
            'marginTop': '20px'
        })
    
    try:
        # é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«åŸºã¥ã„ã¦åˆ†æã‚’å®Ÿè¡Œ
        long_df = data_get('long_df', pd.DataFrame())
        fatigue_df = data_get('fatigue_score', pd.DataFrame())
        fairness_df = data_get('fairness_after', pd.DataFrame())

        team_criteria = {selected_key: selected_value}
        team_df = analyze_team_dynamics(long_df, fatigue_df, fairness_df, team_criteria)

        if team_df.empty:
            return html.P("ã“ã®æ¡ä»¶ã«åˆè‡´ã™ã‚‹ãƒãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚", style={'color': 'red', 'marginTop': '20px'})

        fig_fatigue = px.line(
            team_df,
            y=['avg_fatigue', 'std_fatigue'],
            title=f"ãƒãƒ¼ãƒ ã€Œ{selected_value}ã€ã®ç–²åŠ´åº¦ã‚¹ã‚³ã‚¢æ¨ç§»"
        )
        fig_fairness = px.line(
            team_df,
            y=['avg_unfairness', 'std_unfairness'],
            title=f"ãƒãƒ¼ãƒ ã€Œ{selected_value}ã€ã®ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢æ¨ç§»"
        )

        analysis_content = html.Div([
            html.H4(f"ãƒãƒ¼ãƒ ã€Œ{selected_value}ã€ã®åˆ†æçµæœ"),
            
            # ã‚°ãƒ©ãƒ•ã®èª­ã¿è§£ãæ–¹èª¬æ˜ã‚’è¿½åŠ 
            html.Div([
                html.H5("ğŸ“Š ã‚°ãƒ©ãƒ•ã®èª­ã¿è§£ãæ–¹"),
                html.Div([
                    html.P("ğŸ” ç–²åŠ´åº¦ã‚¹ã‚³ã‚¢æ¨ç§»ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹:", style={'fontWeight': 'bold', 'marginTop': '15px'}),
                    html.Ul([
                        html.Li("å¹³å‡ç–²åŠ´åº¦ï¼ˆavg_fatigueï¼‰: ãƒãƒ¼ãƒ å…¨ä½“ã®ç–²åŠ´ãƒ¬ãƒ™ãƒ«ã€‚æ•°å€¤ãŒé«˜ã„ã»ã©ç–²åŠ´ãŒè“„ç©ã—ã¦ã„ã‚‹"),
                        html.Li("ç–²åŠ´åº¦ã®ã°ã‚‰ã¤ãï¼ˆstd_fatigueï¼‰: ãƒãƒ¼ãƒ å†…ã®ç–²åŠ´æ ¼å·®ã€‚æ•°å€¤ãŒé«˜ã„ã»ã©å€‹äººå·®ãŒå¤§ãã„"),
                        html.Li("âš ï¸ ä¸¡æ–¹ãŒé«˜ã„å ´åˆ: ãƒãƒ¼ãƒ å…¨ä½“ãŒç–²å¼Šã—ã€ã‹ã¤å€‹äººå·®ã‚‚å¤§ããä¸å®‰å®šãªçŠ¶æ…‹"),
                        html.Li("âœ… ç†æƒ³çš„ãªçŠ¶æ…‹: å¹³å‡ç–²åŠ´åº¦ãŒä½ãã€ã°ã‚‰ã¤ãã‚‚å°ã•ã„çŠ¶æ…‹")
                    ]),
                    
                    html.P("ğŸ” ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢æ¨ç§»ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹:", style={'fontWeight': 'bold', 'marginTop': '15px'}),
                    html.Ul([
                        html.Li("å¹³å‡ä¸å…¬å¹³æ„Ÿï¼ˆavg_unfairnessï¼‰: ãƒãƒ¼ãƒ å…¨ä½“ã®ä¸å…¬å¹³æ„Ÿã€‚æ•°å€¤ãŒé«˜ã„ã»ã©ä¸æº€ãŒè“„ç©ã—ã¦ã„ã‚‹"),
                        html.Li("ä¸å…¬å¹³æ„Ÿã®ã°ã‚‰ã¤ãï¼ˆstd_unfairnessï¼‰: ãƒãƒ¼ãƒ å†…ã®ä¸å…¬å¹³æ„Ÿæ ¼å·®ã€‚æ•°å€¤ãŒé«˜ã„ã»ã©å€‹äººå·®ãŒå¤§ãã„"),
                        html.Li("âš ï¸ å¹³å‡ãŒé«˜ã„å ´åˆ: æ¥­å‹™é…åˆ†ã‚„å¾…é‡ã«å…¨ä½“çš„ãªä¸å…¬å¹³æ„ŸãŒã‚ã‚‹å¯èƒ½æ€§"),
                        html.Li("âš ï¸ ã°ã‚‰ã¤ããŒå¤§ãã„å ´åˆ: ä¸€éƒ¨ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒç‰¹ã«ä¸å…¬å¹³æ„Ÿã‚’æ„Ÿã˜ã¦ã„ã‚‹å¯èƒ½æ€§"),
                        html.Li("âœ… ç†æƒ³çš„ãªçŠ¶æ…‹: å¹³å‡ä¸å…¬å¹³æ„ŸãŒä½ãã€ã°ã‚‰ã¤ãã‚‚å°ã•ã„çŠ¶æ…‹")
                    ])
                ], style={
                    'backgroundColor': '#f8f9fa',
                    'padding': '15px',
                    'borderRadius': '8px',
                    'marginBottom': '20px',
                    'border': '1px solid #dee2e6'
                })
            ]),
            
            dcc.Graph(figure=fig_fatigue),
            dcc.Graph(figure=fig_fairness),
            
            # æ”¹å–„ææ¡ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
            html.Div([
                html.H5("ğŸ’¡ æ”¹å–„ææ¡ˆ"),
                html.P("åˆ†æçµæœã«åŸºã¥ãå…·ä½“çš„ãªæ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:"),
                html.Ul([
                    html.Li("ç–²åŠ´åº¦ãŒé«˜ã„å ´åˆ: å‹¤å‹™é–“éš”ã®èª¿æ•´ã€ä¼‘æš‡å–å¾—ã®ä¿ƒé€²ã€æ¥­å‹™é‡ã®è¦‹ç›´ã—"),
                    html.Li("ç–²åŠ´åº¦ã®ã°ã‚‰ã¤ããŒå¤§ãã„å ´åˆ: æ¥­å‹™åˆ†æ‹…ã®å‡ç­‰åŒ–ã€ç‰¹å®šãƒ¡ãƒ³ãƒãƒ¼ã®è² è·è»½æ¸›"),
                    html.Li("ä¸å…¬å¹³æ„ŸãŒé«˜ã„å ´åˆ: å‹¤å‹™æ¡ä»¶ã®é€æ˜åŒ–ã€å¸Œæœ›ä¼‘æ‰¿èªã®å…¬å¹³åŒ–"),
                    html.Li("ä¸å…¬å¹³æ„Ÿã®ã°ã‚‰ã¤ããŒå¤§ãã„å ´åˆ: å€‹åˆ¥é¢è«‡ã®å®Ÿæ–½ã€ä¸æº€ã®èãå–ã‚Šèª¿æŸ»")
                ])
            ], style={
                'backgroundColor': '#e7f3ff',
                'padding': '15px',
                'borderRadius': '8px',
                'marginTop': '20px',
                'border': '1px solid #b3d9ff'
            })
        ])
        
        return analysis_content
        
    except Exception as e:
        log.error(f"ãƒãƒ¼ãƒ åˆ†æã®å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html.Div(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", style={'color': 'red'})


@app.callback(
    Output('blueprint-results-store', 'data'),
    Output('tradeoff-scatter-plot', 'figure'),
    Output('rules-data-table', 'data'),
    Output('staff-selector-dropdown', 'options'),
    Output('facts-data-table', 'data', allow_duplicate=True),
    Output('facts-summary', 'children'),
    Output('integrated-analysis-content', 'children'),
    Input('generate-blueprint-button', 'n_clicks'),
    State('blueprint-analysis-type', 'value'),
    prevent_initial_call=True
)
@safe_callback
def update_blueprint_analysis_content(n_clicks, analysis_type):
    if not n_clicks:
        raise PreventUpdate

    try:
        long_df = data_get('long_df', pd.DataFrame())
        if long_df.empty:
            empty_fig = go.Figure()
            empty_fig.update_layout(
                title="ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                annotations=[
                    dict(
                        text="ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã‹ã‚‰åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚<br><br>" +
                             "ğŸ“‹ æ‰‹é †:<br>" +
                             "1. Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰<br>" +
                             "2. ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®å®Œäº†ã‚’ç¢ºèª<br>" +
                             "3. å†åº¦åˆ†æãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯",
                        xref="paper", yref="paper",
                        x=0.5, y=0.5, xanchor='center', yanchor='middle',
                        showarrow=False,
                        font=dict(size=14, color="#666"),
                        bgcolor="rgba(240, 240, 240, 0.8)",
                        bordercolor="#ccc",
                        borderwidth=1
                    )
                ]
            )
            helpful_message = html.Div([
                html.H4("ğŸ” ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆåˆ†æã«ã¤ã„ã¦", style={'color': '#1976d2'}),
                html.P("ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆåˆ†æã¯ã€ã‚·ãƒ•ãƒˆä½œæˆè€…ã®æš—é»™çŸ¥ã‚„åˆ¤æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç™ºè¦‹ã™ã‚‹é«˜åº¦ãªåˆ†ææ©Ÿèƒ½ã§ã™ã€‚"),
                html.H5("ğŸ’¡ åˆ†æã§ç™ºè¦‹ã§ãã‚‹ã“ã¨:"),
                html.Ul([
                    html.Li("ã‚¹ã‚¿ãƒƒãƒ•å€‹åˆ¥ã®å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„åˆ¶ç´„"),
                    html.Li("ã‚·ãƒ•ãƒˆä½œæˆè€…ã®æš—é»™çš„ãªãƒ«ãƒ¼ãƒ«"),
                    html.Li("è·ç¨®ãƒ»ãƒãƒ¼ãƒ é–“ã®ç›¸äº’é–¢ä¿‚"),
                    html.Li("åŠ¹ç‡çš„ãªã‚·ãƒ•ãƒˆçµ„ã¿åˆã‚ã›"),
                ]),
                html.P("åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ã¾ãšã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚", 
                       style={'fontWeight': 'bold', 'color': '#d32f2f'})
            ], style={
                'padding': '20px', 'backgroundColor': '#f8f9fa', 'borderRadius': '8px',
                'border': '1px solid #dee2e6', 'marginTop': '20px'
            })
            return {}, empty_fig, [], [], [], helpful_message, helpful_message

        blueprint_data = create_blueprint_list(long_df)

        scatter_df = pd.DataFrame(blueprint_data.get('tradeoffs', {}).get('scatter_data', []))
        fig_scatter = px.scatter(scatter_df, x='fairness_score', y='cost_score', hover_data=['date']) if not scatter_df.empty else go.Figure()

        rules_df = blueprint_data.get('rules_df', pd.DataFrame())
        rules_table_data = []

        if not rules_df.empty:
            if 'è©³ç´°ãƒ‡ãƒ¼ã‚¿' in rules_df.columns:
                def safe_json_serialize(x):
                    if isinstance(x, dict):
                        try:
                            # NumPyå‹ã‚’æ¨™æº–Pythonå‹ã«å¤‰æ›
                            clean_dict = {}
                            for k, v in x.items():
                                if hasattr(v, 'item'):  # NumPy scalar
                                    clean_dict[k] = v.item()
                                elif isinstance(v, (list, tuple)):
                                    clean_dict[k] = [item.item() if hasattr(item, 'item') else item for item in v]
                                else:
                                    clean_dict[k] = v
                            return json.dumps(clean_dict, ensure_ascii=False, indent=2)
                        except (TypeError, ValueError):
                            return str(x)
                    else:
                        return str(x)
                
                rules_df['è©³ç´°ãƒ‡ãƒ¼ã‚¿'] = rules_df['è©³ç´°ãƒ‡ãƒ¼ã‚¿'].apply(safe_json_serialize)
            rules_table_data = rules_df.to_dict('records')

        staff_scores_df = blueprint_data.get('staff_level_scores', pd.DataFrame())
        dropdown_options = [{'label': s, 'value': s} for s in staff_scores_df.index] if not staff_scores_df.empty else []

        facts_df = blueprint_data.get('facts_df', pd.DataFrame())
        facts_table_data = []
        facts_summary = "äº‹å®Ÿãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
        
        # ğŸ” æ‹¡å¼µãƒ«ãƒ¼ãƒ«åˆ†æã®çµæœè¡¨ç¤º
        rule_stats = blueprint_data.get('rule_statistics', {})
        total_rules = rule_stats.get('total_rules', 0)
        high_conf_rules = rule_stats.get('high_confidence_rules', 0)
        
        enhanced_summary = html.Div([
            html.Div([
                html.H4("ğŸ¯ ã‚·ãƒ•ãƒˆä½œæˆè€…ã®æš—é»™çŸ¥åˆ†æçµæœ", style={'margin': '0 0 15px 0', 'color': '#1976d2'}),
                html.Div([
                    html.Div([
                        html.H3(str(total_rules), style={'margin': '0', 'color': '#2e7d32', 'fontSize': '2rem'}),
                        html.P("ç™ºè¦‹ã•ã‚ŒãŸãƒ«ãƒ¼ãƒ«", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                    ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#e8f5e8', 
                             'borderRadius': '8px', 'border': '2px solid #2e7d32', 'flex': '1'}),
                    html.Div([
                        html.H3(str(high_conf_rules), style={'margin': '0', 'color': '#ff9800', 'fontSize': '2rem'}),
                        html.P("é«˜ä¿¡é ¼åº¦ãƒ«ãƒ¼ãƒ«", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                    ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#fff3e0', 
                             'borderRadius': '8px', 'border': '2px solid #ff9800', 'flex': '1'}),
                    html.Div([
                        html.H3(f"{(high_conf_rules/total_rules*100):.1f}%" if total_rules > 0 else "0%", 
                               style={'margin': '0', 'color': '#1976d2', 'fontSize': '2rem'}),
                        html.P("ä¿¡é ¼åº¦ç‡", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                    ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#e3f2fd', 
                             'borderRadius': '8px', 'border': '2px solid #1976d2', 'flex': '1'}),
                ], style={'display': 'flex', 'gap': '15px'}),
            ], style={'padding': '20px', 'backgroundColor': 'white', 'borderRadius': '12px', 
                     'boxShadow': '0 4px 8px rgba(0,0,0,0.1)', 'marginBottom': '20px'}),
        ]) if blueprint_data.get('enhanced_rules') else html.Div([
            html.Div([
                html.H4("âš ï¸ æ‹¡å¼µåˆ†æãƒ‡ãƒ¼ã‚¿", style={'color': '#ff9800'}),
                html.P("æ‹¡å¼µåˆ†æãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿é‡ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚", 
                       style={'color': '#666', 'marginBottom': '10px'}),
                html.P("ğŸ’¡ æ”¹å–„æ–¹æ³•:", style={'fontWeight': 'bold', 'marginBottom': '5px'}),
                html.Ul([
                    html.Li("ã‚ˆã‚Šå¤šãã®ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹"),
                    html.Li("ç•°ãªã‚‹æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹"),
                    html.Li("ã‚¹ã‚¿ãƒƒãƒ•æ•°ã‚’å¢—ã‚„ã™"),
                ])
            ], style={'padding': '15px', 'backgroundColor': '#fff3e0', 'borderRadius': '8px',
                     'border': '1px solid #ff9800'})
        ])
        
        # ğŸ” æ‹¡å¼µãƒ«ãƒ¼ãƒ«ã®è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        enhanced_table_data = []
        if blueprint_data.get('enhanced_rules'):
            for rule in blueprint_data.get('enhanced_rules', []):
                enhanced_table_data.append({
                    'ã‚¹ã‚¿ãƒƒãƒ•': rule.staff_name,
                    'ãƒ«ãƒ¼ãƒ«ã‚¿ã‚¤ãƒ—': rule.rule_type,
                    'ãƒ«ãƒ¼ãƒ«å†…å®¹': rule.rule_description,
                    'ä¿¡é ¼åº¦': f"{rule.confidence_score:.2f}",
                    'ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ': rule.segment,
                    'çµ±è¨ˆçš„è¨¼æ‹ ': str(rule.statistical_evidence.get('sample_size', 'N/A'))
                })

        if not facts_df.empty:
            facts_df = facts_df.sort_values('ç¢ºä¿¡åº¦', ascending=False)
            facts_table_data = facts_df.to_dict('records')

            total_facts = len(facts_df)
            high_confidence_facts = len(facts_df[facts_df['ç¢ºä¿¡åº¦'] >= 0.8])
            unique_staff = facts_df['ã‚¹ã‚¿ãƒƒãƒ•'].nunique()

            facts_summary = html.Div([
                html.Div([
                    html.H4("ğŸ“Š äº‹å®Ÿåˆ†æã‚µãƒãƒªãƒ¼", style={'margin': '0 0 15px 0', 'color': '#1976d2'}),
                    html.Div([
                        html.Div([
                            html.H3(str(total_facts), style={'margin': '0', 'color': '#2e7d32', 'fontSize': '2rem'}),
                            html.P("ç™ºè¦‹ã•ã‚ŒãŸäº‹å®Ÿ", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                        ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#e8f5e8', 
                                 'borderRadius': '8px', 'border': '2px solid #2e7d32'}),
                        html.Div([
                            html.H3(str(high_confidence_facts), style={'margin': '0', 'color': '#ff9800', 'fontSize': '2rem'}),
                            html.P("é«˜ç¢ºä¿¡åº¦(80%+)", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                        ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#fff3e0', 
                                 'borderRadius': '8px', 'border': '2px solid #ff9800'}),
                        html.Div([
                            html.H3(str(unique_staff), style={'margin': '0', 'color': '#1976d2', 'fontSize': '2rem'}),
                            html.P("åˆ†æå¯¾è±¡ã‚¹ã‚¿ãƒƒãƒ•", style={'margin': '0', 'fontSize': '0.9rem', 'color': '#666'})
                        ], style={'textAlign': 'center', 'padding': '15px', 'backgroundColor': '#e3f2fd', 
                                 'borderRadius': '8px', 'border': '2px solid #1976d2'}),
                    ], style={'display': 'flex', 'gap': '15px', 'marginBottom': '20px'}),
                ], style={'padding': '20px', 'backgroundColor': 'white', 'borderRadius': '12px', 
                         'boxShadow': '0 4px 8px rgba(0,0,0,0.1)', 'marginBottom': '20px'}),
                
                html.Div([
                    html.H5("ğŸ“ˆ ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥å†…è¨³", style={'marginBottom': '15px', 'color': '#1976d2'}),
                    html.Div([
                        html.Div([
                            html.Strong(f"{cat}: "),
                            html.Span(f"{len(df)}ä»¶", style={'color': '#2e7d32', 'fontWeight': 'bold'})
                        ], style={'padding': '8px 12px', 'backgroundColor': '#f5f5f5', 'borderRadius': '6px',
                                 'margin': '5px', 'display': 'inline-block', 'border': '1px solid #ddd'})
                        for cat, df in blueprint_data.get('facts_by_category', {}).items()
                        if not df.empty
                    ])
                ], style={'padding': '15px', 'backgroundColor': '#fafafa', 'borderRadius': '8px',
                         'border': '1px solid #e0e0e0'})
            ])

        # ğŸ” æ‹¡å¼µåˆ†æã¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æã®çµ±åˆè¡¨ç¤º
        segment_analysis = blueprint_data.get('segment_analysis', {})
        constraint_nature = blueprint_data.get('constraint_nature', {})
        advanced_constraints = blueprint_data.get('advanced_constraints', {})
        team_dynamics = blueprint_data.get('team_dynamics', {})
        
        integrated_content = html.Div([
            html.H5("ğŸ¯ ã‚·ãƒ•ãƒˆä½œæˆè€…ã®æš—é»™çŸ¥åˆ†æçµæœ"),
            enhanced_summary
        ])

        # Store data for other callbacks
        store_data = {
            'rules_df': rules_df.to_json(orient='split') if not rules_df.empty else None,
            'scored_df': blueprint_data.get('scored_df', pd.DataFrame()).to_json(orient='split') if blueprint_data.get('scored_df') is not None and not blueprint_data.get('scored_df').empty else None,
            'tradeoffs': blueprint_data.get('tradeoffs', {}),
            'staff_level_scores': blueprint_data.get('staff_level_scores', pd.DataFrame()).to_json(orient='split') if blueprint_data.get('staff_level_scores') is not None and not blueprint_data.get('staff_level_scores').empty else None,
            'facts_df': facts_df.to_json(orient='split') if not facts_df.empty else None,
            'facts_by_category': {k: v.to_json(orient='split') for k, v in blueprint_data.get('facts_by_category', {}).items()}
        }

        return store_data, fig_scatter, rules_table_data, dropdown_options, facts_table_data, facts_summary, integrated_content
    
    except Exception as e:
        log.error(f"ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆåˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}", exc_info=True)
        empty_fig = go.Figure()
        error_msg = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        return {}, empty_fig, [], [], [], error_msg, error_msg
@app.callback(
    Output('facts-data-table', 'data', allow_duplicate=True),
    Input('fact-category-filter', 'value'),
    State('blueprint-results-store', 'data'),
    prevent_initial_call=True
)
@safe_callback
def filter_facts_by_category(selected_category, stored_data):
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼ã§äº‹å®Ÿã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
    if not stored_data or not stored_data.get('facts_df'):
        return []

    facts_df = pd.read_json(stored_data['facts_df'], orient='split')

    if selected_category == 'all':
        filtered_df = facts_df
    else:
        filtered_df = facts_df[facts_df['ã‚«ãƒ†ã‚´ãƒªãƒ¼'] == selected_category]

    filtered_df = filtered_df.sort_values('ç¢ºä¿¡åº¦', ascending=False)

    return filtered_df.to_dict('records')


def _extract_staff_from_rule(rule_text: str, staff_names: list[str]) -> str | None:
    """Return first staff name found in rule text."""
    for name in staff_names:
        if name in rule_text:
            return name
    return None


@app.callback(
    Output('staff-radar-chart', 'figure'),
    Output('staff-related-rules-list', 'children'),
    Input('staff-selector-dropdown', 'value'),
    Input('rules-data-table', 'selected_rows'),
    State('blueprint-results-store', 'data'),
    State('rules-data-table', 'data'),
    prevent_initial_call=True,
)
@safe_callback
def update_staff_view(selected_staff, selected_row_indices, stored_data, table_data):
    if not stored_data:
        raise PreventUpdate

    rules_json = stored_data.get('rules_df')
    staff_json = stored_data.get('staff_level_scores')
    if not rules_json or not staff_json:
        return go.Figure(), "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

    rules_df = pd.read_json(rules_json, orient='split')
    staff_scores_df = pd.read_json(staff_json, orient='split')

    ctx = dash.callback_context
    trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]

    target_staff = selected_staff
    if trigger_id == 'rules-data-table' and selected_row_indices:
        clicked_rule = table_data[selected_row_indices[0]]
        target_staff = _extract_staff_from_rule(clicked_rule.get('ç™ºè¦‹ã•ã‚ŒãŸæ³•å‰‡', ''), list(staff_scores_df.index))

    if not target_staff or target_staff not in staff_scores_df.index:
        return go.Figure(), "ã‚¹ã‚¿ãƒƒãƒ•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"

    row = staff_scores_df.loc[target_staff]
    score_cols = ['fairness_score', 'cost_score', 'risk_score', 'satisfaction_score']
    fig_radar = go.Figure()
    fig_radar.add_trace(
        go.Scatterpolar(
            r=row[score_cols].tolist(),
            theta=['å…¬å¹³æ€§', 'ã‚³ã‚¹ãƒˆ', 'ãƒªã‚¹ã‚¯', 'æº€è¶³åº¦'],
            fill='toself',
            name=target_staff,
        )
    )
    fig_radar.update_layout(polar=dict(radialaxis=dict(range=[0, 1])), showlegend=False)

    related_rules = rules_df[rules_df['ç™ºè¦‹ã•ã‚ŒãŸæ³•å‰‡'].str.contains(target_staff)]
    rule_list_items = [html.P(r) for r in related_rules['ç™ºè¦‹ã•ã‚ŒãŸæ³•å‰‡'].tolist()] if not related_rules.empty else [html.P('é–¢é€£ãƒ«ãƒ¼ãƒ«ãªã—')]

    return fig_radar, rule_list_items


@app.callback(
    Output('sim-shortage-graph', 'figure'),
    Output('sim-cost-text', 'children'),
    Input('sim-work-pattern-dropdown', 'value'),
    Input('sim-hire-fte-slider', 'value'),
    State('kpi-data-store', 'data'),
)
@safe_callback
def update_hire_simulation(selected_pattern, added_fte, kpi_data):
    if not kpi_data or not selected_pattern:
        raise PreventUpdate

    from shift_suite.tasks.h2hire import (
        AVG_HOURLY_WAGE,
        RECRUIT_COST_PER_HIRE,
    )

    df_work_patterns = data_get('work_patterns', pd.DataFrame())
    df_shortage_role = data_get('shortage_role_summary', pd.DataFrame()).copy()

    pattern_info = df_work_patterns[df_work_patterns['code'] == selected_pattern]
    if pattern_info.empty:
        raise PreventUpdate
    slots_per_day = pattern_info['parsed_slots_count'].iloc[0]
    hours_per_day = slots_per_day * 0.5
    reduction_hours = added_fte * hours_per_day * 20

    if not df_shortage_role.empty:
        most_lacking_role_index = df_shortage_role['lack_h'].idxmax()
        original_hours = df_shortage_role.loc[most_lacking_role_index, 'lack_h']
        df_shortage_role.loc[most_lacking_role_index, 'lack_h'] = max(0, original_hours - reduction_hours)

    fig = px.bar(
        df_shortage_role,
        x='role',
        y='lack_h',
        title=f'ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¾Œ: {selected_pattern}å‹¤å‹™è€…ã‚’{added_fte}äººè¿½åŠ æ¡ç”¨ã—ãŸå ´åˆã®æ®‹å­˜ä¸è¶³æ™‚é–“',
        labels={'lack_h': 'æ®‹å­˜ä¸è¶³æ™‚é–“(h)'},
    )

    # æ­£ã—ã„ç·ä¸è¶³æ™‚é–“ã®è¨ˆç®—
    new_total_lack_h = 0
    if 'lack_h' in df_shortage_role.columns:
        total_rows = df_shortage_role[df_shortage_role['role'].isin(['å…¨ä½“', 'åˆè¨ˆ', 'ç·è¨ˆ'])]
        if not total_rows.empty:
            new_total_lack_h = total_rows['lack_h'].iloc[0]
        else:
            shortage_time_df = data_get('shortage_time', pd.DataFrame())
            if not shortage_time_df.empty:
                try:
                    shortage_values = shortage_time_df.select_dtypes(include=[np.number]).values
                    new_total_lack_h = float(np.nansum(shortage_values) * 0.5)
                except:
                    new_total_lack_h = df_shortage_role['lack_h'].sum()
            else:
                new_total_lack_h = df_shortage_role['lack_h'].sum()
    
    original_total_lack_h = kpi_data.get('total_lack_h', 0)

    cost_before = original_total_lack_h * 2200
    cost_after_temp = new_total_lack_h * 2200

    added_labor_cost = reduction_hours * AVG_HOURLY_WAGE
    added_recruit_cost = added_fte * RECRUIT_COST_PER_HIRE
    cost_after_hire = cost_after_temp + added_labor_cost + added_recruit_cost

    cost_text = f"""
    #### ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
    - **æ¡ç”¨ã‚³ã‚¹ãƒˆ:** {added_recruit_cost:,.0f} å†† (ä¸€æ™‚)
    - **è¿½åŠ äººä»¶è²»:** {added_labor_cost:,.0f} å†† (æœŸé–“ä¸­)
    - **ç·ã‚³ã‚¹ãƒˆ (æ¡ç”¨ã‚·ãƒŠãƒªã‚ª):** {cost_after_hire:,.0f} å††
    - **æ¯”è¼ƒ (å…¨ã¦æ´¾é£ã§è£œå¡«ã—ãŸå ´åˆ):** {cost_before:,.0f} å††
    """

    return fig, dcc.Markdown(cost_text)


@app.callback(
    Output('factor-output', 'children'),
    Input('factor-train-button', 'n_clicks')
)
@safe_callback
def run_factor_analysis(n_clicks):
    if not n_clicks:
        raise PreventUpdate

    heat_df = data_get('heat_ALL')
    short_df = data_get('shortage_time')
    leave_df = data_get('leave_analysis')

    if heat_df is None or heat_df.empty or short_df is None or short_df.empty:
        return html.Div('å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“')

    analyzer = ShortageFactorAnalyzer()
    feat_df = analyzer.generate_features(pd.DataFrame(), heat_df, short_df, leave_df, set())
    model, fi_df = analyzer.train_and_get_feature_importance(feat_df)
    DATA_CACHE.set('factor_features', feat_df)
    DATA_CACHE.set('factor_importance', fi_df)

    table = dash_table.DataTable(
        data=fi_df.head(5).to_dict('records'),
        columns=[{'name': c, 'id': c} for c in fi_df.columns]
    )
    return html.Div([html.H5('å½±éŸ¿åº¦ã®é«˜ã„è¦å›  ãƒˆãƒƒãƒ—5'), table])  # type: ignore


def generate_lightweight_tree_visualization(tree_model):
    """Generate a small decision tree visualisation."""
    if not tree_model or not hasattr(tree_model, 'tree_'):
        return html.P('æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚')

    try:
        buf = io.BytesIO()
        fig, ax = plt.subplots(figsize=(12, 6))
        plot_tree(
            tree_model,
            filled=True,
            feature_names=tree_model.feature_names_in_[:20],
            max_depth=2,
            fontsize=8,
            ax=ax,
            impurity=False,
            proportion=True,
        )
        fig.savefig(buf, format='png', dpi=72, bbox_inches='tight')
        plt.close(fig)
        buf.seek(0)
        encoded = base64.b64encode(buf.getvalue()).decode()
        return html.Img(
            src=f"data:image/png;base64,{encoded}",
            style={'width': '100%', 'maxWidth': '1000px'},
        )
    except Exception as exc:  # noqa: BLE001
        log.error(f'æ±ºå®šæœ¨å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {exc}')
        return html.P(f'æ±ºå®šæœ¨ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}')


def generate_results_display(full_results):
    """Create the final display for logic analysis results."""
    mind_results = full_results.get('mind_reading', {})

    if 'error' in mind_results:
        return html.Div(f"åˆ†æã‚¨ãƒ©ãƒ¼: {mind_results['error']}", style={'color': 'red'})

    importance_df = pd.DataFrame(mind_results.get('feature_importance', []))
    fig_bar = px.bar(
        importance_df.sort_values('importance', ascending=False).head(15),
        x='importance',
        y='feature',
        orientation='h',
        title='åˆ¤æ–­åŸºæº–ã®é‡è¦åº¦ï¼ˆTOP15ï¼‰',
    )

    tree_content = generate_lightweight_tree_visualization(
        mind_results.get('thinking_process_tree')
    )

    return html.Div([
        html.H4('åˆ†æå®Œäº†ï¼'),
        html.Hr(),
        html.H4('åˆ¤æ–­åŸºæº–ã®é‡è¦åº¦'),
        html.P('ä½œæˆè€…ãŒã©ã®è¦ç´ ã‚’é‡è¦–ã—ã¦ã„ã‚‹ã‹ã‚’æ•°å€¤åŒ–ã—ãŸã‚‚ã®ã§ã™ã€‚'),
        dcc.Graph(figure=fig_bar),
        html.H4('æ€è€ƒãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ', style={'marginTop': '30px'}),
        html.P('é…ç½®ã‚’æ±ºå®šã™ã‚‹éš›ã®æ€è€ƒã®åˆ†å²ã‚’æ¨¡å€£ã—ãŸã‚‚ã®ã§ã™ã€‚'),
        tree_content,
    ])


@app.callback(
    Output('save-log-msg', 'children'),
    Input('save-log-button', 'n_clicks'),
    State('over-shortage-table', 'data'),
    State('log-save-mode', 'value')
)
@safe_callback
def save_over_shortage_log(n_clicks, table_data, mode):
    if not n_clicks:
        raise PreventUpdate

    log_path = data_get('shortage_log_path')
    if not log_path:
        return 'ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'  # type: ignore

    df = pd.DataFrame(table_data)
    over_shortage_log.save_log(df, log_path, mode=mode)
    return 'ãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ'


@app.callback(Output('log-viewer', 'value'), Input('log-interval', 'n_intervals'))
@safe_callback
def update_log_viewer(n):
    """ãƒ­ã‚°ãƒãƒƒãƒ•ã‚¡ã®å†…å®¹ã‚’å®šæœŸçš„ã«æ›´æ–°"""
    log_stream.seek(0)
    return log_stream.read()


@app.callback(
    Output('creation-logic-results', 'children'),
    Output('full-analysis-store', 'data'),
    Input('analyze-creation-logic-button', 'n_clicks'),
    State('analysis-detail-level', 'value'),
    prevent_initial_call=True,
)
@safe_callback
def update_logic_analysis_immediate(n_clicks, detail_level):
    """Show basic results immediately and start deep analysis."""

    if not n_clicks:
        raise PreventUpdate

    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty:
        return html.Div('åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚', style={'color': 'red'}), None

    basic_stats = get_basic_shift_stats(long_df)
    quick_patterns = get_quick_patterns(long_df.head(500))

    immediate_results = html.Div([
        html.H4('âœ… åŸºæœ¬åˆ†æå®Œäº†ï¼ˆè©³ç´°åˆ†æå®Ÿè¡Œä¸­...ï¼‰', style={'color': 'green'}),
        html.Hr(),
        html.Div([
            html.H5('ğŸ“Š ã‚·ãƒ•ãƒˆã®åŸºæœ¬çµ±è¨ˆ'),
            create_stats_cards(basic_stats),
        ]),
        html.Div([
            html.H5('ğŸ” ç™ºè¦‹ã•ã‚ŒãŸä¸»è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆç°¡æ˜“ç‰ˆï¼‰'),
            create_pattern_list(quick_patterns),
        ], style={'marginTop': '20px'}),
        html.Div([
            html.H5('ğŸ§  AIã«ã‚ˆã‚‹æ·±å±¤åˆ†æ'),
            dcc.Loading(id='deep-analysis-loading', children=html.Div(id='deep-analysis-results'), type='circle'),
        ], style={'marginTop': '30px'}),
        dcc.Interval(id='background-trigger', interval=100, n_intervals=0, max_intervals=1),
    ])

    return immediate_results, {'status': 'pending', 'level': detail_level}


@app.callback(
    Output('deep-analysis-results', 'children'),
    Input('background-trigger', 'n_intervals'),
    State('analysis-detail-level', 'value'),
    prevent_initial_call=True,
)
@safe_callback
def run_deep_analysis_background(n_intervals, detail_level):
    """Run deeper analysis in the background."""

    if n_intervals == 0:
        raise PreventUpdate

    long_df = data_get('long_df', pd.DataFrame())
    results = run_optimized_analysis(long_df, detail_level)

    return create_deep_analysis_display(results)


@app.callback(
    Output('progress-bar', 'figure'),
    Output('progress-message', 'children'),
    Input('logic-analysis-interval', 'n_intervals'),
    State('logic-analysis-progress', 'data'),
    prevent_initial_call=True,
)
@safe_callback
def update_progress_bar(n_intervals, progress_data):
    """Update the progress bar display."""
    if not progress_data:
        raise PreventUpdate

    progress = progress_data.get('progress', 0)
    stage = progress_data.get('stage', 'loading')

    messages = {
        'loading': 'ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...',
        'analyzing': 'ã‚·ãƒ•ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã¦ã„ã¾ã™...',
        'visualizing': 'çµæœã‚’å¯è¦–åŒ–ã—ã¦ã„ã¾ã™...',
    }

    figure = {
        'data': [{
            'x': [progress],
            'y': ['Progress'],
            'type': 'bar',
            'orientation': 'h',
            'marker': {'color': '#1f77b4'},
        }],
        'layout': {
            'xaxis': {'range': [0, 100], 'title': 'é€²æ—ç‡ (%)'},
            'yaxis': {'visible': False},
            'height': 100,
            'margin': {'l': 0, 'r': 0, 't': 30, 'b': 30},
        },
    }

    return figure, messages.get(stage, 'å‡¦ç†ä¸­...')


@app.callback(
    Output('advanced-forecast-results', 'children'),
    Output('advanced-forecast-comparison', 'children'),
    Output('advanced-forecast-metrics', 'children'),
    Input('run-advanced-forecast-button', 'n_clicks'),
    State('advanced-forecast-models', 'value'),
    State('advanced-forecast-periods', 'value'),
    State('advanced-forecast-ensemble', 'value'),
    prevent_initial_call=True
)
@safe_callback
def run_advanced_forecast(n_clicks, selected_models, periods, ensemble_option):
    """é«˜åº¦äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
    if not n_clicks:
        raise PreventUpdate
    
    if not ENABLE_ADVANCED_FEATURES:
        error_msg = html.Div([
            html.H4("é«˜åº¦äºˆæ¸¬æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™", style={'color': 'orange'}),
            html.P("dash_app.py ã® ENABLE_ADVANCED_FEATURES ã‚’ True ã«è¨­å®šã—ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
        ])
        return error_msg, None, None
    
    from shift_suite.tasks.advanced_forecast import AdvancedForecastEngine, advanced_forecast_demand
    
    # éœ€è¦ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    demand_csv = DATA_CACHE.get_path('demand_series_csv')
    if not demand_csv or not Path(demand_csv).exists():
        return (
            html.Div("éœ€è¦ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã¾ãšéœ€è¦äºˆæ¸¬ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚", 
                    style={'color': 'red', 'fontWeight': 'bold'}),
            None,
            None
        )
    
    try:
        # é«˜åº¦äºˆæ¸¬ã®å®Ÿè¡Œ
        enable_ensemble = 'ensemble' in ensemble_option if ensemble_option else False
        
        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        df = pd.read_csv(demand_csv, parse_dates=['ds'])
        
        # äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
        engine = AdvancedForecastEngine(
            enable_sarima='sarima' in selected_models,
            enable_prophet='prophet' in selected_models,
            enable_lstm='lstm' in selected_models,
            enable_ensemble=enable_ensemble
        )
        
        # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        fit_results = engine.fit_all_models(df)
        
        # äºˆæ¸¬ã®å®Ÿè¡Œ
        predictions = engine.predict(periods=periods)
        
        # ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ã®å–å¾—
        summary = engine.get_model_summary()
        
        # çµæœã®å¯è¦–åŒ–
        # 1. äºˆæ¸¬çµæœã‚°ãƒ©ãƒ•
        fig_forecast = go.Figure()
        
        # å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿
        fig_forecast.add_trace(go.Scatter(
            x=df['ds'],
            y=df['y'],
            mode='lines',
            name='å®Ÿç¸¾',
            line=dict(color='blue', width=2)
        ))
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬
        colors = {'sarima': 'red', 'prophet': 'green', 'lstm': 'purple', 'ensemble': 'orange'}
        for model_name in ['sarima', 'prophet', 'lstm']:
            if model_name in predictions.columns and not predictions[model_name].isna().all():
                fig_forecast.add_trace(go.Scatter(
                    x=predictions['ds'],
                    y=predictions[model_name],
                    mode='lines',
                    name=f'{model_name.upper()}äºˆæ¸¬',
                    line=dict(color=colors.get(model_name, 'gray'), dash='dash')
                ))
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        if 'ensemble' in predictions.columns and not predictions['ensemble'].isna().all():
            fig_forecast.add_trace(go.Scatter(
                x=predictions['ds'],
                y=predictions['ensemble'],
                mode='lines',
                name='ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬',
                line=dict(color='orange', width=3)
            ))
        
        fig_forecast.update_layout(
            title='é«˜åº¦äºˆæ¸¬çµæœ',
            xaxis_title='æ—¥ä»˜',
            yaxis_title='éœ€è¦',
            height=500
        )
        
        results_content = [
            html.H4("äºˆæ¸¬çµæœ", style={'marginBottom': '20px'}),
            dcc.Graph(figure=fig_forecast),
            html.H5("äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«", style={'marginTop': '30px'}),
            dash_table.DataTable(
                data=predictions.head(30).round(2).to_dict('records'),
                columns=[{'name': col, 'id': col} for col in predictions.columns],
                style_cell={'textAlign': 'left'},
                style_data_conditional=[
                    {
                        'if': {'column_id': 'ensemble'},
                        'backgroundColor': '#ffebee',
                        'fontWeight': 'bold'
                    }
                ]
            )
        ]
        
        # 2. ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
        if summary['metrics']:
            metrics_df = pd.DataFrame(summary['metrics']).T
            
            # MAPEã«ã‚ˆã‚‹æ£’ã‚°ãƒ©ãƒ•
            fig_comparison = px.bar(
                x=metrics_df.index,
                y=metrics_df['mape'],
                title='ãƒ¢ãƒ‡ãƒ«ç²¾åº¦æ¯”è¼ƒ (MAPE: ä½ã„ã»ã©è‰¯ã„)',
                labels={'x': 'ãƒ¢ãƒ‡ãƒ«', 'y': 'MAPE (%)'}
            )
            
            # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            best_model = summary['best_model']
            colors = ['#ff7f0e' if model == best_model else '#1f77b4' for model in metrics_df.index]
            fig_comparison.update_traces(marker_color=colors)
            
            comparison_content = [
                html.H4("ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ", style={'marginBottom': '20px'}),
                html.Div([
                    html.H5(f"ğŸ† æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_model.upper()}", 
                           style={'color': '#ff7f0e', 'fontWeight': 'bold'})
                ], style={'padding': '15px', 'backgroundColor': '#fff3e0', 'borderRadius': '8px'}),
                dcc.Graph(figure=fig_comparison)
            ]
        else:
            comparison_content = html.Div("ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        
        # 3. è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        metrics_content = [
            html.H4("äºˆæ¸¬ç²¾åº¦æŒ‡æ¨™", style={'marginBottom': '20px'}),
            html.Div([
                html.Div([
                    html.H5(model.upper(), style={'color': '#1976d2'}),
                    html.P(f"MAPE: {metrics['mape']:.2f}%"),
                    html.P(f"MAE: {metrics['mae']:.2f}"),
                    html.P(f"RMSE: {metrics['rmse']:.2f}")
                ], style={
                    'padding': '15px',
                    'backgroundColor': '#f5f5f5' if model != best_model else '#fff3e0',
                    'borderRadius': '8px',
                    'border': '2px solid #ddd' if model != best_model else '2px solid #ff7f0e',
                    'marginBottom': '15px'
                })
                for model, metrics in summary['metrics'].items()
            ])
        ]
        
        # äºˆæ¸¬çµæœã‚’ä¿å­˜
        output_path = Path(DATA_CACHE.get_path('output_dir')) / 'advanced_forecast.parquet'
        save_df_parquet(predictions, output_path)
        DATA_CACHE.set('advanced_forecast', predictions)
        
        return results_content, comparison_content, metrics_content
        
    except Exception as e:
        log.error(f"é«˜åº¦äºˆæ¸¬å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        error_msg = html.Div([
            html.H4("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", style={'color': 'red'}),
            html.P(f"è©³ç´°: {str(e)}"),
            html.P("å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        ])
        return error_msg, None, None


@app.callback(
    [Output('seasonal-decomposition-results', 'children'),
     Output('seasonal-spectral-results', 'children'),
     Output('seasonal-holiday-results', 'children'),
     Output('seasonal-clustering-results', 'children'),
     Output('seasonal-anomaly-results', 'children'),
     Output('seasonal-forecast-results', 'children')],
    Input('run-seasonal-analysis-button', 'n_clicks'),
    [State('seasonal-analysis-features', 'value'),
     State('seasonal-analysis-scope', 'value')],
    prevent_initial_call=True
)
@safe_callback
def run_seasonal_analysis(n_clicks, selected_features, analysis_scope):
    """å­£ç¯€æ€§åˆ†æã‚’å®Ÿè¡Œ"""
    if not n_clicks:
        raise PreventUpdate
    
    if not ENABLE_ADVANCED_FEATURES:
        error_msg = html.Div([
            html.H4("å­£ç¯€æ€§åˆ†ææ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™", style={'color': 'orange'}),
            html.P("dash_app.py ã® ENABLE_ADVANCED_FEATURES ã‚’ True ã«è¨­å®šã—ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
        ])
        return error_msg, None, None, None, None, None
    
    from shift_suite.tasks.seasonal_analysis import SeasonalAnalysisEngine, analyze_seasonal_patterns
    
    # long_dfã®å–å¾—
    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty:
        error_msg = html.Div("ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", style={'color': 'red', 'fontWeight': 'bold'})
        return error_msg, None, None, None, None, None
    
    try:
        # åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
        engine = SeasonalAnalysisEngine(
            enable_decomposition='decomposition' in selected_features,
            enable_spectral='spectral' in selected_features,
            enable_holiday_effects='holiday_effects' in selected_features,
            enable_clustering='clustering' in selected_features
        )
        
        # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        time_series_data = engine.prepare_time_series_data(long_df)
        
        # ã‚¹ã‚³ãƒ¼ãƒ—ã«å¿œã˜ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if analysis_scope == 'by_role':
            # è·ç¨®åˆ¥ã®ã¿åˆ†æ
            filtered_data = {k: v for k, v in time_series_data.items() if k.startswith('role_')}
            time_series_data.update({'total_staff': time_series_data['total_staff']})
        elif analysis_scope == 'by_employment':
            # é›‡ç”¨å½¢æ…‹åˆ¥ã®ã¿åˆ†æ
            filtered_data = {k: v for k, v in time_series_data.items() if k.startswith('employment_')}
            time_series_data.update({'total_staff': time_series_data['total_staff']})
        elif analysis_scope == 'overall':
            # å…¨ä½“ã®ã¿åˆ†æ
            filtered_data = {'total_staff': time_series_data['total_staff'],
                           'hourly_pattern': time_series_data.get('hourly_pattern'),
                           'weekly_pattern': time_series_data.get('weekly_pattern')}
            time_series_data = {k: v for k, v in filtered_data.items() if v is not None}
        # all_detailed ã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
        
        # å­£ç¯€æ€§åˆ†æã®å®Ÿè¡Œ
        analysis_results = engine.analyze_all_seasonality(time_series_data)
        
        # çµæœã®å¯è¦–åŒ–
        # 1. æ™‚ç³»åˆ—åˆ†è§£çµæœ
        decomposition_content = []
        if analysis_results['decomposition']:
            decomposition_content.append(html.H5("æ™‚ç³»åˆ—åˆ†è§£çµæœ"))
            
            for series_name, decomp_data in analysis_results['decomposition'].items():
                if 'seasonal_strength' in decomp_data:
                    strength_info = html.Div([
                        html.H6(f"{series_name}", style={'color': '#1976d2'}),
                        html.P(f"å­£ç¯€æ€§å¼·åº¦: {decomp_data['seasonal_strength']:.3f}"),
                        html.P(f"ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦: {decomp_data['trend_strength']:.3f}"),
                        html.P(f"åˆ†ææœŸé–“: {decomp_data['period']}æ—¥")
                    ], style={
                        'padding': '10px',
                        'backgroundColor': '#f8f9fa',
                        'borderRadius': '5px',
                        'marginBottom': '10px'
                    })
                    decomposition_content.append(strength_info)
        
        if not decomposition_content:
            decomposition_content = [html.P("æ™‚ç³»åˆ—åˆ†è§£ãŒå®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")]
        
        # 2. ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æçµæœ
        spectral_content = []
        if analysis_results['spectral']:
            spectral_content.append(html.H5("ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æçµæœ"))
            
            for series_name, spectral_data in analysis_results['spectral'].items():
                if 'dominant_periods' in spectral_data:
                    periods = spectral_data['dominant_periods'][:5]  # ä¸Šä½5å€‹
                    period_info = html.Div([
                        html.H6(f"{series_name}", style={'color': '#1976d2'}),
                        html.P("ä¸»è¦ãªå‘¨æœŸï¼ˆæ—¥æ•°ï¼‰:"),
                        html.Ul([html.Li(f"{p:.1f}æ—¥") for p in periods if p > 0])
                    ], style={
                        'padding': '10px',
                        'backgroundColor': '#f0f8ff',
                        'borderRadius': '5px',
                        'marginBottom': '10px'
                    })
                    spectral_content.append(period_info)
        
        if not spectral_content:
            spectral_content = [html.P("ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æãŒå®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")]
        
        # 3. ç¥æ—¥åŠ¹æœçµæœ
        holiday_content = []
        if analysis_results['holiday_effects']:
            holiday_content.append(html.H5("ç¥æ—¥ãƒ»ä¼‘æ—¥åŠ¹æœåˆ†æ"))
            
            for series_name, holiday_data in analysis_results['holiday_effects'].items():
                if 'weekend_effect' in holiday_data and holiday_data['weekend_effect']:
                    effect_info = html.Div([
                        html.H6(f"{series_name}", style={'color': '#1976d2'}),
                        html.P(f"é€±æœ«åŠ¹æœ: {holiday_data['weekend_effect']['mean_difference']:.2f} "
                              f"({'æœ‰æ„' if holiday_data['weekend_effect']['significant'] else 'éæœ‰æ„'})"),
                        html.P(f"ç¥æ—¥åŠ¹æœ: {holiday_data.get('holiday_effect', {}).get('mean_difference', 'N/A')}")
                    ], style={
                        'padding': '10px',
                        'backgroundColor': '#fff9e6',
                        'borderRadius': '5px',
                        'marginBottom': '10px'
                    })
                    holiday_content.append(effect_info)
        
        if not holiday_content:
            holiday_content = [html.P("ç¥æ—¥åŠ¹æœåˆ†æãŒå®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")]
        
        # 4. ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ
        clustering_content = []
        if analysis_results['clustering']:
            clustering_data = analysis_results['clustering']
            clustering_content.append(html.H5("å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°"))
            
            cluster_info = html.Div([
                html.P(f"ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {clustering_data['n_clusters']}"),
                html.P("PCAå¯„ä¸ç‡: " + ", ".join([f"PC{i+1}: {var:.3f}" 
                      for i, var in enumerate(clustering_data['pca_explained_variance'][:3])]))
            ], style={
                'padding': '10px',
                'backgroundColor': '#f5f5f5',
                'borderRadius': '5px'
            })
            clustering_content.append(cluster_info)
        
        if not clustering_content:
            clustering_content = [html.P("ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãŒå®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")]
        
        # 5. ç•°å¸¸å€¤æ¤œå‡ºçµæœ
        anomaly_content = []
        if analysis_results['anomalies']:
            anomaly_content.append(html.H5("å­£ç¯€æ€§ç•°å¸¸å€¤æ¤œå‡º"))
            
            total_anomalies = sum([result['anomaly_stats']['count'] 
                                 for result in analysis_results['anomalies'].values()])
            
            anomaly_summary = html.Div([
                html.P(f"æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸å€¤ã®ç·æ•°: {total_anomalies}"),
                html.P("ç³»åˆ—åˆ¥ç•°å¸¸å€¤æ•°:"),
                html.Ul([
                    html.Li(f"{series_name}: {result['anomaly_stats']['count']}å€‹ "
                           f"(ç•°å¸¸ç‡: {result['anomaly_stats']['anomaly_rate']:.1f}%)")
                    for series_name, result in analysis_results['anomalies'].items()
                ])
            ], style={
                'padding': '10px',
                'backgroundColor': '#fff0f0',
                'borderRadius': '5px'
            })
            anomaly_content.append(anomaly_summary)
        
        if not anomaly_content:
            anomaly_content = [html.P("å­£ç¯€æ€§ç•°å¸¸å€¤æ¤œå‡ºãŒå®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")]
        
        # 6. äºˆæ¸¬çµæœ
        forecast_content = []
        if analysis_results['forecasts']:
            forecast_content.append(html.H5("å­£ç¯€æ€§äºˆæ¸¬"))
            
            forecast_summary = html.Div([
                html.P(f"äºˆæ¸¬ç³»åˆ—æ•°: {len(analysis_results['forecasts'])}"),
                html.P("å„ç³»åˆ—ã®äºˆæ¸¬æœŸé–“: 30æ—¥")
            ], style={
                'padding': '10px',
                'backgroundColor': '#f0fff0',
                'borderRadius': '5px'
            })
            forecast_content.append(forecast_summary)
        
        if not forecast_content:
            forecast_content = [html.P("å­£ç¯€æ€§äºˆæ¸¬ãŒå®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")]
        
        # çµæœã‚’ä¿å­˜
        output_path = Path(DATA_CACHE.get_path('output_dir')) / 'seasonal_analysis.parquet'
        results_df = pd.DataFrame([{
            'analysis_scope': analysis_scope,
            'features_analyzed': len(selected_features),
            'series_analyzed': len(time_series_data),
            'decomposition_count': len(analysis_results['decomposition']),
            'spectral_count': len(analysis_results['spectral']),
            'holiday_effects_count': len(analysis_results['holiday_effects']),
            'clustering_performed': bool(analysis_results['clustering']),
            'anomalies_detected': total_anomalies if analysis_results['anomalies'] else 0,
            'forecasts_generated': len(analysis_results['forecasts'])
        }])
        save_df_parquet(results_df, output_path)
        DATA_CACHE.set('seasonal_analysis', analysis_results)
        
        return (
            html.Div(decomposition_content),
            html.Div(spectral_content),
            html.Div(holiday_content),
            html.Div(clustering_content),
            html.Div(anomaly_content),
            html.Div(forecast_content)
        )
        
    except Exception as e:
        log.error(f"å­£ç¯€æ€§åˆ†æå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        error_msg = html.Div([
            html.H4("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", style={'color': 'red'}),
            html.P(f"è©³ç´°: {str(e)}"),
            html.P("å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        ])
        return error_msg, None, None, None, None, None


@app.callback(
    Output('fatigue-prediction-results', 'children'),
    Output('fatigue-alerts', 'children'),
    Output('fatigue-optimization', 'children'),
    Input('run-fatigue-prediction-button', 'n_clicks'),
    State('fatigue-forecast-days', 'value'),
    State('fatigue-model-type', 'value'),
    State('fatigue-personal-models', 'value'),
    prevent_initial_call=True
)
@safe_callback
def run_fatigue_prediction(n_clicks, forecast_days, model_type, personal_models):
    """ç–²åŠ´åº¦äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
    if not n_clicks:
        raise PreventUpdate
    
    if not ENABLE_ADVANCED_FEATURES:
        error_msg = html.Div([
            html.H4("ç–²åŠ´åº¦äºˆæ¸¬æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™", style={'color': 'orange'}),
            html.P("dash_app.py ã® ENABLE_ADVANCED_FEATURES ã‚’ True ã«è¨­å®šã—ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
        ])
        return error_msg, None, None
    
    from shift_suite.tasks.fatigue_prediction import predict_staff_fatigue
    
    # ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty:
        return (
            html.Div("ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚", 
                    style={'color': 'red', 'fontWeight': 'bold'}),
            None,
            None
        )
    
    try:
        # ç–²åŠ´åº¦äºˆæ¸¬ã®å®Ÿè¡Œ
        enable_personal = 'personal' in personal_models if personal_models else False
        
        output_path = Path(DATA_CACHE.get_path('output_dir')) / 'fatigue_prediction.parquet'
        
        result_path = predict_staff_fatigue(
            long_df,
            output_path,
            lookback_days=14,
            forecast_days=forecast_days,
            model_type=model_type,
            train_personal_models=enable_personal
        )
        
        # çµæœã®èª­ã¿è¾¼ã¿
        if result_path.exists():
            predictions_df = pd.read_parquet(result_path)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            meta_path = result_path.with_suffix('.meta.json')
            optimization_data = {}
            alerts_data = []
            
            if meta_path.exists():
                import json
                with open(meta_path, 'r', encoding='utf-8') as f:
                    meta = json.load(f)
                    optimization_data = meta.get('optimization_suggestions', {})
                    alerts_data = meta.get('critical_alerts', [])
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
            alerts_path = result_path.with_stem(result_path.stem + '_alerts')
            if alerts_path.exists():
                alerts_df = pd.read_parquet(alerts_path)
                alerts_data = alerts_df.to_dict('records')
            
            # 1. äºˆæ¸¬çµæœã®å¯è¦–åŒ–
            if not predictions_df.empty:
                # ã‚¹ã‚¿ãƒƒãƒ•åˆ¥ã®äºˆæ¸¬ã‚°ãƒ©ãƒ•
                fig_prediction = go.Figure()
                
                colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
                
                for i, staff in enumerate(predictions_df['staff'].unique()):
                    staff_data = predictions_df[predictions_df['staff'] == staff]
                    
                    fig_prediction.add_trace(go.Scatter(
                        x=staff_data['date'],
                        y=staff_data['predicted_fatigue'],
                        mode='lines+markers',
                        name=f'{staff} ({staff_data["model_type"].iloc[0]})',
                        line=dict(color=colors[i % len(colors)]),
                        hovertemplate='<b>%{name}</b><br>' +
                                    'æ—¥ä»˜: %{x}<br>' +
                                    'ç–²åŠ´åº¦: %{y:.2f}<br>' +
                                    'ä¿¡é ¼åº¦: %{customdata:.0%}<extra></extra>',
                        customdata=staff_data['confidence']
                    ))
                
                # ç–²åŠ´åº¦é–¾å€¤ãƒ©ã‚¤ãƒ³
                fig_prediction.add_hline(y=0.75, line_dash="dash", line_color="red", 
                                       annotation_text="è­¦å‘Šãƒ¬ãƒ™ãƒ« (75%)")
                
                fig_prediction.update_layout(
                    title='ç–²åŠ´åº¦äºˆæ¸¬çµæœ',
                    xaxis_title='æ—¥ä»˜',
                    yaxis_title='ç–²åŠ´åº¦ã‚¹ã‚³ã‚¢',
                    height=500,
                    showlegend=True
                )
                
                # äºˆæ¸¬ç²¾åº¦ã®è¡¨ç¤º
                model_info = []
                if meta_path.exists():
                    with open(meta_path, 'r', encoding='utf-8') as f:
                        meta = json.load(f)
                        global_metrics = meta.get('global_model_metrics', {})
                        if global_metrics.get('success'):
                            model_info.append(
                                html.Div([
                                    html.H5(f"ãƒ¢ãƒ‡ãƒ«ç²¾åº¦ ({model_type.upper()})", style={'color': '#1976d2'}),
                                    html.P(f"MAE: {global_metrics.get('mae', 0):.4f}"),
                                    html.P(f"RMSE: {global_metrics.get('rmse', 0):.4f}"),
                                    html.P(f"å€‹äººåˆ¥ãƒ¢ãƒ‡ãƒ«: {meta.get('personal_models_count', 0)}å€‹")
                                ], style={
                                    'padding': '15px',
                                    'backgroundColor': '#e3f2fd',
                                    'borderRadius': '8px',
                                    'marginBottom': '20px'
                                })
                            )
                
                results_content = [
                    html.H4("ç–²åŠ´åº¦äºˆæ¸¬çµæœ", style={'marginBottom': '20px'}),
                    *model_info,
                    dcc.Graph(figure=fig_prediction),
                    html.H5("äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿", style={'marginTop': '30px'}),
                    dash_table.DataTable(
                        data=predictions_df.round(3).to_dict('records'),
                        columns=[{'name': col, 'id': col} for col in predictions_df.columns],
                        style_cell={'textAlign': 'left'},
                        style_data_conditional=[
                            {
                                'if': {
                                    'filter_query': '{predicted_fatigue} > 0.75',
                                    'column_id': 'predicted_fatigue'
                                },
                                'backgroundColor': '#ffebee',
                                'color': 'black',
                            }
                        ]
                    )
                ]
            else:
                results_content = html.Div("äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚", style={'color': 'orange'})
            
            # 2. ã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤º
            if alerts_data:
                alert_components = []
                for alert in alerts_data:
                    level_colors = {
                        'critical': '#f44336',
                        'warning': '#ff9800',
                        'info': '#2196f3'
                    }
                    
                    alert_components.append(
                        html.Div([
                            html.H5(f"ğŸš¨ {alert['staff']} - {alert['level'].upper()}", 
                                   style={'color': level_colors.get(alert['level'], '#666'), 'margin': '0 0 10px 0'}),
                            html.P(alert['message'], style={'margin': '0 0 10px 0'}),
                            html.P(f"æœ€å¤§äºˆæ¸¬ç–²åŠ´åº¦: {alert['max_predicted_fatigue']:.2f}", 
                                   style={'margin': '0 0 10px 0', 'fontSize': '0.9em'}),
                            html.P(f"é€£ç¶šãƒªã‚¹ã‚¯æ—¥æ•°: {alert['consecutive_risk_days']}æ—¥", 
                                   style={'margin': '0', 'fontSize': '0.9em'})
                        ], style={
                            'padding': '15px',
                            'backgroundColor': '#fff3e0' if alert['level'] == 'warning' else '#ffebee',
                            'borderRadius': '8px',
                            'marginBottom': '15px',
                            'border': f'2px solid {level_colors.get(alert["level"], "#ccc")}'
                        })
                    )
                
                alerts_content = [
                    html.H4("ç–²åŠ´ãƒªã‚¹ã‚¯ã‚¢ãƒ©ãƒ¼ãƒˆ", style={'marginBottom': '20px', 'color': '#d32f2f'}),
                    *alert_components
                ]
            else:
                alerts_content = html.Div([
                    html.H4("ç–²åŠ´ãƒªã‚¹ã‚¯ã‚¢ãƒ©ãƒ¼ãƒˆ", style={'marginBottom': '20px', 'color': '#4caf50'}),
                    html.P("ğŸ‰ ç¾åœ¨ã€é‡è¦ãªç–²åŠ´ãƒªã‚¹ã‚¯ã¯æ¤œå‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                ])
            
            # 3. æœ€é©åŒ–ææ¡ˆ
            if optimization_data:
                optimization_components = []
                
                # ã‚·ãƒ•ãƒˆèª¿æ•´ææ¡ˆ
                if optimization_data.get('shift_adjustments'):
                    for adjustment in optimization_data['shift_adjustments']:
                        optimization_components.append(
                            html.Div([
                                html.H5("ğŸ“… ã‚·ãƒ•ãƒˆèª¿æ•´ææ¡ˆ", style={'color': '#1976d2', 'margin': '0 0 10px 0'}),
                                html.P(adjustment['suggestion'])
                            ], style={
                                'padding': '15px',
                                'backgroundColor': '#e3f2fd',
                                'borderRadius': '8px',
                                'marginBottom': '15px'
                            })
                        )
                
                # ä¼‘æ¯æ¨å¥¨
                if optimization_data.get('rest_recommendations'):
                    for rest in optimization_data['rest_recommendations']:
                        optimization_components.append(
                            html.Div([
                                html.H5(f"ğŸ˜´ {rest['staff']}ã•ã‚“ã¸ã®ä¼‘æ¯ææ¡ˆ", 
                                       style={'color': '#4caf50', 'margin': '0 0 10px 0'}),
                                html.P(rest['reason'])
                            ], style={
                                'padding': '15px',
                                'backgroundColor': '#e8f5e8',
                                'borderRadius': '8px',
                                'marginBottom': '15px'
                            })
                        )
                
                # è² è·å†é…åˆ†
                if optimization_data.get('workload_redistribution'):
                    for redistribution in optimization_data['workload_redistribution']:
                        optimization_components.append(
                            html.Div([
                                html.H5("âš–ï¸ è² è·å†é…åˆ†ææ¡ˆ", style={'color': '#ff9800', 'margin': '0 0 10px 0'}),
                                html.P(redistribution['suggestion'])
                            ], style={
                                'padding': '15px',
                                'backgroundColor': '#fff3e0',
                                'borderRadius': '8px',
                                'marginBottom': '15px'
                            })
                        )
                
                if optimization_components:
                    optimization_content = [
                        html.H4("æœ€é©åŒ–ææ¡ˆ", style={'marginBottom': '20px', 'color': '#1976d2'}),
                        *optimization_components
                    ]
                else:
                    optimization_content = html.Div("æœ€é©åŒ–ææ¡ˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                optimization_content = html.Div("æœ€é©åŒ–ææ¡ˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            
            # çµæœã‚’ä¿å­˜
            DATA_CACHE.set('fatigue_prediction', predictions_df)
            
            return results_content, alerts_content, optimization_content
        
        else:
            return (
                html.Div("äºˆæ¸¬çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", style={'color': 'red'}),
                None,
                None
            )
        
    except Exception as e:
        log.error(f"ç–²åŠ´åº¦äºˆæ¸¬å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        error_msg = html.Div([
            html.H4("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", style={'color': 'red'}),
            html.P(f"è©³ç´°: {str(e)}"),
            html.P("TensorFlowãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        ])
        return error_msg, None, None


@app.callback(
    Output('individual-staff-dropdown', 'options'),
    Input('individual-analysis-tab-container', 'style'),
    State('data-loaded', 'data'),
    prevent_initial_call=True
)
@safe_callback
def update_individual_staff_dropdown(style, data_status):
    """å€‹åˆ¥åˆ†æã‚¿ãƒ–ã®ã‚¹ã‚¿ãƒƒãƒ•ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‚’æ›´æ–°"""
    if not data_status or style.get('display') == 'none':
        raise PreventUpdate
    
    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty or 'staff' not in long_df.columns:
        return []
    
    staff_list = sorted(long_df['staff'].unique())
    return [{'label': staff, 'value': staff} for staff in staff_list]


@app.callback(
    Output('turnover-prediction-results', 'children'),
    Output('turnover-prevention-suggestions', 'children'),
    Output('team-turnover-analysis', 'children'),
    Input('run-turnover-prediction-button', 'n_clicks'),
    State('turnover-lookback-months', 'value'),
    State('turnover-model-type', 'value'),
    prevent_initial_call=True
)
@safe_callback
def run_turnover_prediction(n_clicks, lookback_months, model_type):
    """é›¢è·ãƒªã‚¹ã‚¯äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
    if not n_clicks:
        raise PreventUpdate
    
    if not ENABLE_ADVANCED_FEATURES:
        error_msg = html.Div([
            html.H4("é›¢è·ãƒªã‚¹ã‚¯äºˆæ¸¬æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™", style={'color': 'orange'}),
            html.P("dash_app.py ã® ENABLE_ADVANCED_FEATURES ã‚’ True ã«è¨­å®šã—ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
        ])
        return error_msg, None, None
    
    from shift_suite.tasks.turnover_prediction import predict_staff_turnover
    
    # ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    long_df = data_get('long_df', pd.DataFrame())
    if long_df.empty:
        return (
            html.Div("ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚", 
                    style={'color': 'red', 'fontWeight': 'bold'}),
            None,
            None
        )
    
    try:
        # é›¢è·ãƒªã‚¹ã‚¯äºˆæ¸¬ã®å®Ÿè¡Œ
        output_path = Path(DATA_CACHE.get_path('output_dir')) / 'turnover_prediction.parquet'
        
        result_path = predict_staff_turnover(
            long_df,
            output_path,
            model_type=model_type,
            lookback_months=lookback_months
        )
        
        # çµæœã®èª­ã¿è¾¼ã¿
        if result_path.exists():
            predictions_df = pd.read_parquet(result_path)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            meta_path = result_path.with_suffix('.meta.json')
            training_results = {}
            team_analysis = {}
            alerts_data = []
            
            if meta_path.exists():
                import json
                with open(meta_path, 'r', encoding='utf-8') as f:
                    meta = json.load(f)
                    training_results = meta.get('training_results', {})
                    team_analysis = meta.get('team_analysis', {})
                    alerts_data = meta.get('critical_alerts', [])
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
            alerts_path = result_path.with_stem(result_path.stem + '_alerts')
            if alerts_path.exists():
                alerts_df = pd.read_parquet(alerts_path)
                alerts_data = alerts_df.to_dict('records')
            
            # 1. äºˆæ¸¬çµæœã®å¯è¦–åŒ–
            if not predictions_df.empty:
                # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
                risk_counts = predictions_df['risk_level'].value_counts()
                
                fig_risk_distribution = px.pie(
                    values=risk_counts.values,
                    names=risk_counts.index,
                    title='é›¢è·ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ',
                    color_discrete_map={
                        'very_low': '#4caf50',
                        'low': '#8bc34a',
                        'medium': '#ff9800',
                        'high': '#f44336'
                    }
                )
                
                # ã‚¹ã‚¿ãƒƒãƒ•åˆ¥ãƒªã‚¹ã‚¯æ£’ã‚°ãƒ©ãƒ•
                fig_staff_risk = px.bar(
                    predictions_df.sort_values('turnover_probability', ascending=False),
                    x='staff',
                    y='turnover_probability',
                    color='risk_level',
                    title='ã‚¹ã‚¿ãƒƒãƒ•åˆ¥é›¢è·ãƒªã‚¹ã‚¯ç¢ºç‡',
                    color_discrete_map={
                        'very_low': '#4caf50',
                        'low': '#8bc34a',
                        'medium': '#ff9800',
                        'high': '#f44336'
                    }
                )
                fig_staff_risk.update_xaxes(tickangle=45)
                fig_staff_risk.add_hline(y=0.6, line_dash="dash", line_color="red", 
                                       annotation_text="é«˜ãƒªã‚¹ã‚¯é–¾å€¤")
                
                # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®è¡¨ç¤º
                model_info = []
                if training_results:
                    best_auc = max([result.get('auc', 0) for result in training_results.values()])
                    model_info.append(
                        html.Div([
                            html.H5(f"ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ ({model_type.upper()})", style={'color': '#1976d2'}),
                            html.P(f"æœ€é«˜AUC: {best_auc:.4f}"),
                            html.P(f"åˆ†ææœŸé–“: {lookback_months}ãƒ¶æœˆ"),
                            html.P(f"åˆ†æå¯¾è±¡: {len(predictions_df)}å")
                        ], style={
                            'padding': '15px',
                            'backgroundColor': '#e3f2fd',
                            'borderRadius': '8px',
                            'marginBottom': '20px'
                        })
                    )
                
                results_content = [
                    html.H4("é›¢è·ãƒªã‚¹ã‚¯äºˆæ¸¬çµæœ", style={'marginBottom': '20px'}),
                    *model_info,
                    
                    html.Div([
                        html.Div([
                            dcc.Graph(figure=fig_risk_distribution)
                        ], style={'width': '48%', 'display': 'inline-block'}),
                        
                        html.Div([
                            dcc.Graph(figure=fig_staff_risk)
                        ], style={'width': '48%', 'float': 'right', 'display': 'inline-block'}),
                    ]),
                    
                    html.H5("è©³ç´°äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿", style={'marginTop': '30px'}),
                    dash_table.DataTable(
                        data=predictions_df.round(3).to_dict('records'),
                        columns=[{'name': col, 'id': col} for col in predictions_df.columns],
                        style_cell={'textAlign': 'left'},
                        style_data_conditional=[
                            {
                                'if': {
                                    'filter_query': '{risk_level} = high',
                                    'column_id': 'turnover_probability'
                                },
                                'backgroundColor': '#ffebee',
                                'color': 'black',
                            },
                            {
                                'if': {
                                    'filter_query': '{risk_level} = medium',
                                    'column_id': 'turnover_probability'
                                },
                                'backgroundColor': '#fff3e0',
                                'color': 'black',
                            }
                        ],
                        sort_action="native"
                    )
                ]
            else:
                results_content = html.Div("äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚", style={'color': 'orange'})
            
            # 2. é›¢è·é˜²æ­¢ææ¡ˆ
            if alerts_data:
                prevention_components = []
                for alert in alerts_data:
                    if alert.get('type') == 'high_turnover_risk':
                        prevention_components.append(
                            html.Div([
                                html.H5(f"ğŸš¨ {alert['staff']} - ç·Šæ€¥å¯¾å¿œå¿…è¦", 
                                       style={'color': '#f44336', 'margin': '0 0 15px 0'}),
                                html.P(alert['message'], style={'margin': '0 0 15px 0'}),
                                html.H6("æ¨å¥¨å¯¾ç­–:", style={'margin': '0 0 10px 0', 'color': '#1976d2'}),
                                html.Ul([
                                    html.Li(rec) for rec in alert.get('recommendations', [])
                                ])
                            ], style={
                                'padding': '20px',
                                'backgroundColor': '#ffebee',
                                'borderRadius': '8px',
                                'marginBottom': '20px',
                                'border': '2px solid #f44336'
                            })
                        )
                
                if prevention_components:
                    prevention_content = [
                        html.H4("é›¢è·é˜²æ­¢ææ¡ˆ", style={'marginBottom': '20px', 'color': '#d32f2f'}),
                        *prevention_components
                    ]
                else:
                    prevention_content = html.Div([
                        html.H4("é›¢è·é˜²æ­¢ææ¡ˆ", style={'marginBottom': '20px', 'color': '#4caf50'}),
                        html.P("ğŸ‰ ç¾åœ¨ã€ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªé«˜ãƒªã‚¹ã‚¯ã‚¹ã‚¿ãƒƒãƒ•ã¯ã„ã¾ã›ã‚“ã€‚")
                    ])
            else:
                prevention_content = html.Div([
                    html.H4("é›¢è·é˜²æ­¢ææ¡ˆ", style={'marginBottom': '20px', 'color': '#4caf50'}),
                    html.P("ğŸ‰ ç¾åœ¨ã€ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªé«˜ãƒªã‚¹ã‚¯ã‚¹ã‚¿ãƒƒãƒ•ã¯ã„ã¾ã›ã‚“ã€‚")
                ])
            
            # 3. ãƒãƒ¼ãƒ åˆ†æ
            if team_analysis:
                team_components = [
                    html.H4("ãƒãƒ¼ãƒ é›¢è·ãƒªã‚¹ã‚¯åˆ†æ", style={'marginBottom': '20px', 'color': '#1976d2'}),
                    
                    html.Div([
                        html.Div([
                            html.H5("åŸºæœ¬çµ±è¨ˆ", style={'color': '#1976d2'}),
                            html.P(f"ç·ã‚¹ã‚¿ãƒƒãƒ•æ•°: {team_analysis.get('total_staff', 0)}å"),
                            html.P(f"é«˜ãƒªã‚¹ã‚¯: {team_analysis.get('high_risk_count', 0)}å", 
                                   style={'color': '#f44336' if team_analysis.get('high_risk_count', 0) > 0 else 'inherit'}),
                            html.P(f"ä¸­ãƒªã‚¹ã‚¯: {team_analysis.get('medium_risk_count', 0)}å",
                                   style={'color': '#ff9800' if team_analysis.get('medium_risk_count', 0) > 0 else 'inherit'}),
                            html.P(f"å¹³å‡ãƒªã‚¹ã‚¯: {team_analysis.get('average_risk', 0):.1%}")
                        ], style={
                            'padding': '15px',
                            'backgroundColor': '#f5f5f5',
                            'borderRadius': '8px',
                            'width': '48%',
                            'display': 'inline-block'
                        }),
                        
                        html.Div([
                            html.H5("ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ", style={'color': '#ff9800'}),
                            *([
                                html.P(f"æ½œåœ¨çš„é›¢è·ç‡: {team_analysis['business_impact']['potential_loss_percentage']:.1f}%"),
                                html.P("âš ï¸ é‡è¦è­¦å‘Š" if team_analysis['business_impact']['critical_warning'] else ""),
                                html.P("ğŸš¨ å³åº§ã®å¯¾å¿œãŒå¿…è¦" if team_analysis['business_impact']['immediate_action_required'] else "")
                            ] if 'business_impact' in team_analysis else [html.P("å½±éŸ¿åˆ†æãƒ‡ãƒ¼ã‚¿ãªã—")])
                        ], style={
                            'padding': '15px',
                            'backgroundColor': '#fff3e0',
                            'borderRadius': '8px',
                            'width': '48%',
                            'float': 'right',
                            'display': 'inline-block'
                        }),
                    ], style={'marginBottom': '20px'}),
                    
                    html.Div([
                        html.H5("æ”¹å–„ææ¡ˆ", style={'color': '#4caf50', 'marginBottom': '15px'}),
                        html.Ul([
                            html.Li(suggestion) 
                            for suggestion in team_analysis.get('improvement_suggestions', [])
                        ]) if team_analysis.get('improvement_suggestions') else html.P("å…·ä½“çš„ãªææ¡ˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                    ], style={
                        'padding': '15px',
                        'backgroundColor': '#e8f5e8',
                        'borderRadius': '8px'
                    })
                ]
                
                team_content = team_components
            else:
                team_content = html.Div("ãƒãƒ¼ãƒ åˆ†æãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
            
            # çµæœã‚’ä¿å­˜
            DATA_CACHE.set('turnover_prediction', predictions_df)
            
            return results_content, prevention_content, team_content
        
        else:
            return (
                html.Div("äºˆæ¸¬çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", style={'color': 'red'}),
                None,
                None
            )
        
    except Exception as e:
        log.error(f"é›¢è·ãƒªã‚¹ã‚¯äºˆæ¸¬å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        error_msg = html.Div([
            html.H4("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", style={'color': 'red'}),
            html.P(f"è©³ç´°: {str(e)}"),
            html.P("å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        ])
        return error_msg, None, None



# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹• ---
if __name__ == '__main__':
    app.run_server(debug=True, port=8050, host='127.0.0.1')
