# dash_app.py - Shift-Suiteé«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢ (app.pyæ©Ÿèƒ½å®Œå…¨å†ç¾ç‰ˆ)
import base64
import io
import json
import logging
import tempfile
import zipfile
from pathlib import Path
from typing import List, Tuple
import unicodedata

import dash
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from dash import dash_table, dcc, html
from dash.dependencies import Input, Output, State, ALL
from dash.exceptions import PreventUpdate
from shift_suite.tasks.utils import safe_read_excel, gen_labels
from shift_suite.tasks.shortage_factor_analyzer import ShortageFactorAnalyzer
from shift_suite.tasks import over_shortage_log

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s'
)
log = logging.getLogger(__name__)

# Dashã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
app = dash.Dash(__name__, suppress_callback_exceptions=True)
server = app.server
app.title = "Shift-Suite é«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢"

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
DATA_STORE = {}
TEMP_DIR = None

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
def safe_filename(name: str) -> str:
    """Normalize and sanitize strings for file keys"""
    name = unicodedata.normalize("NFKC", name)
    for ch in ["/", "\\", ":", "*", "?", "\"", "<", ">", "|", "ãƒ»", "ï¼", "ï¼¼"]:
        name = name.replace(ch, "_")
    return name

def date_with_weekday(date_str: str) -> str:
    """æ—¥ä»˜æ–‡å­—åˆ—ã«æ›œæ—¥ã‚’è¿½åŠ """
    try:
        date = pd.to_datetime(date_str)
        weekdays = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
        return f"{date.strftime('%m/%d')}({weekdays[date.weekday()]})"
    except Exception:
        return str(date_str)


def safe_read_parquet(filepath: Path) -> pd.DataFrame:
    """Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã‚€"""
    try:
        return pd.read_parquet(filepath)
    except Exception as e:
        log.warning(f"Failed to read {filepath}: {e}")
        return pd.DataFrame()


def safe_read_csv(filepath: Path) -> pd.DataFrame:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã‚€"""
    try:
        return pd.read_csv(filepath)
    except Exception as e:
        log.warning(f"Failed to read {filepath}: {e}")
        return pd.DataFrame()


def calc_ratio_from_heatmap(df: pd.DataFrame) -> pd.DataFrame:
    """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸è¶³ç‡ã‚’è¨ˆç®—"""
    if df.empty or "need" not in df.columns:
        return pd.DataFrame()

    date_cols = [c for c in df.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    if not date_cols:
        return pd.DataFrame()

    need_series = df["need"].fillna(0)
    need_df = pd.DataFrame(
        np.repeat(need_series.values[:, np.newaxis], len(date_cols), axis=1),
        index=need_series.index,
        columns=date_cols
    )
    staff_df = df[date_cols].fillna(0)
    ratio_df = ((need_df - staff_df) / need_df.replace(0, np.nan)).clip(lower=0).fillna(0)
    return ratio_df


def load_shortage_meta(data_dir: Path) -> Tuple[List[str], List[str]]:
    """è·ç¨®ã¨é›‡ç”¨å½¢æ…‹ã®ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    roles = []
    employments = []
    meta_fp = data_dir / "shortage.meta.json"
    if meta_fp.exists():
        try:
            with open(meta_fp, 'r', encoding='utf-8') as f:
                meta = json.load(f)
            roles = meta.get("roles", [])
            employments = meta.get("employments", [])
        except Exception as e:
            log.debug(f"Failed to load shortage meta: {e}")
    return roles, employments


def load_and_sum_heatmaps(data_dir: Path, keys: List[str]) -> pd.DataFrame:
    """Load multiple heatmap files and aggregate them."""
    dfs = []
    for key in keys:
        df = DATA_STORE.get(key)
        if df is None and data_dir:
            fp = Path(data_dir) / f"{key}.parquet"
            if fp.exists():
                df = safe_read_parquet(fp)
                if not df.empty:
                    DATA_STORE[key] = df
        if isinstance(df, pd.DataFrame) and not df.empty:
            dfs.append(df)

    if not dfs:
        return pd.DataFrame()

    total = dfs[0].copy()
    for df in dfs[1:]:
        total = total.add(df, fill_value=0)

    if {"need", "staff"}.issubset(total.columns):
        total["lack"] = (total["need"] - total["staff"]).clip(lower=0)
    if {"staff", "upper"}.issubset(total.columns):
        total["excess"] = (total["staff"] - total["upper"]).clip(lower=0)

    return total


def generate_heatmap_figure(df_heat: pd.DataFrame, title: str) -> go.Figure:
    """æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã™ã‚‹"""
    if df_heat is None or df_heat.empty:
        return go.Figure().update_layout(title_text=f"{title}: ãƒ‡ãƒ¼ã‚¿ãªã—", height=300)

    date_cols = [c for c in df_heat.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    if not date_cols:
        return go.Figure().update_layout(title_text=f"{title}: è¡¨ç¤ºå¯èƒ½ãªæ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãªã—", height=300)

    display_df = df_heat[date_cols]
    time_labels = gen_labels(30)
    display_df = display_df.reindex(time_labels, fill_value=0)

    fig = px.imshow(
        display_df,
        aspect='auto',
        color_continuous_scale=px.colors.sequential.Viridis,
        title=title,
        labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'}
    )
    fig.update_xaxes(
        ticktext=[date_with_weekday(c) for c in display_df.columns],
        tickvals=list(range(len(display_df.columns)))
    )
    return fig

# --- UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç”Ÿæˆé–¢æ•° ---
def create_metric_card(label: str, value: str, color: str = "#1f77b4") -> html.Div:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆ"""
    return html.Div([
        html.Div(label, style={
            'fontSize': '14px',
            'color': '#666',
            'marginBottom': '5px'
        }),
        html.Div(value, style={
            'fontSize': '24px',
            'fontWeight': 'bold',
            'color': color
        })
    ], style={
        'padding': '15px',
        'backgroundColor': 'white',
        'borderRadius': '8px',
        'boxShadow': '0 2px 4px rgba(0,0,0,0.1)',
        'textAlign': 'center',
        'minHeight': '80px'
    })


def create_overview_tab() -> html.Div:
    """æ¦‚è¦ã‚¿ãƒ–ã‚’ä½œæˆ"""
    df_shortage_role = DATA_STORE.get('shortage_role_summary', pd.DataFrame())
    df_fairness = DATA_STORE.get('fairness_before', pd.DataFrame())
    df_staff = DATA_STORE.get('staff_stats', pd.DataFrame())
    df_alerts = DATA_STORE.get('stats_alerts', pd.DataFrame())

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    lack_h = df_shortage_role['lack_h'].sum() if 'lack_h' in df_shortage_role.columns else 0
    excess_cost = df_shortage_role['estimated_excess_cost'].sum() if 'estimated_excess_cost' in df_shortage_role.columns else 0
    lack_temp_cost = df_shortage_role['estimated_lack_cost_if_temporary_staff'].sum() if 'estimated_lack_cost_if_temporary_staff' in df_shortage_role.columns else 0
    lack_penalty_cost = df_shortage_role['estimated_lack_penalty_cost'].sum() if 'estimated_lack_penalty_cost' in df_shortage_role.columns else 0

    jain_index = "N/A"
    if not df_fairness.empty and 'metric' in df_fairness.columns:
        jain_row = df_fairness[df_fairness['metric'] == 'jain_index']
        if not jain_row.empty:
            jain_index = f"{float(jain_row['value'].iloc[0]):.3f}"

    staff_count = len(df_staff) if not df_staff.empty else 0
    avg_night_ratio = df_staff['night_ratio'].mean() if 'night_ratio' in df_staff.columns else 0
    alerts_count = len(df_alerts) if not df_alerts.empty else 0

    return html.Div([
        html.Div(id='overview-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("åˆ†ææ¦‚è¦", style={'marginBottom': '20px'}),
        html.Div([
            html.Div([
                create_metric_card("ç·ä¸è¶³æ™‚é–“(h)", f"{lack_h:.1f}"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("å¤œå‹¤ JainæŒ‡æ•°", jain_index),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("ç·ã‚¹ã‚¿ãƒƒãƒ•æ•°", str(staff_count)),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("å¹³å‡å¤œå‹¤æ¯”ç‡", f"{avg_night_ratio:.3f}"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("ã‚¢ãƒ©ãƒ¼ãƒˆæ•°", str(alerts_count), "#ff7f0e" if alerts_count > 0 else "#1f77b4"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("ç·éå‰°ã‚³ã‚¹ãƒˆ(Â¥)", f"{excess_cost:,.0f}"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("ä¸è¶³ã‚³ã‚¹ãƒˆ(æ´¾é£)(Â¥)", f"{lack_temp_cost:,.0f}"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
            html.Div([
                create_metric_card("ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£(Â¥)", f"{lack_penalty_cost:,.0f}"),
            ], style={'width': '12.5%', 'display': 'inline-block', 'padding': '5px'}),
        ], style={'marginBottom': '20px'}),
    ])


def create_heatmap_tab() -> html.Div:
    """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚¿ãƒ–ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚ä¸Šä¸‹2ã¤ã®æ¯”è¼ƒã‚¨ãƒªã‚¢ã‚’æŒã¡ã¾ã™ã€‚"""
    roles = DATA_STORE.get('roles', [])
    employments = DATA_STORE.get('employments', [])

    # æ¯”è¼ƒã‚¨ãƒªã‚¢ã‚’1ã¤ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    def create_comparison_area(area_id: int):
        return html.Div([
            html.H4(f"æ¯”è¼ƒã‚¨ãƒªã‚¢ {area_id}", style={'marginTop': '20px', 'borderTop': '2px solid #ddd', 'paddingTop': '20px'}),

            # --- å„ã‚¨ãƒªã‚¢ã«è·ç¨®ã¨é›‡ç”¨å½¢æ…‹ã®ä¸¡æ–¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’è¨­ç½® ---
            html.Div([
                html.Div([
                    html.Label("è·ç¨®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"),
                    dcc.Dropdown(
                        id={'type': 'heatmap-filter-role', 'index': area_id},
                        options=[{'label': 'ã™ã¹ã¦', 'value': 'all'}] + [{'label': r, 'value': r} for r in roles],
                        value='all',
                        clearable=False
                    )
                ], style={'width': '48%', 'display': 'inline-block', 'marginRight': '4%'}),

                html.Div([
                    html.Label("é›‡ç”¨å½¢æ…‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"),
                    dcc.Dropdown(
                        id={'type': 'heatmap-filter-employment', 'index': area_id},
                        options=[{'label': 'ã™ã¹ã¦', 'value': 'all'}] + [{'label': e, 'value': e} for e in employments],
                        value='all',
                        clearable=False
                    )
                ], style={'width': '48%', 'display': 'inline-block'}),
            ], style={'marginBottom': '10px'}),

            # --- ã‚°ãƒ©ãƒ•æç”»é ˜åŸŸ ---
            dcc.Loading(
                id={'type': 'loading-heatmap', 'index': area_id},
                children=html.Div(id={'type': 'graph-output-heatmap', 'index': area_id})
            )
        ], style={'padding': '10px', 'backgroundColor': '#f9f9f9', 'borderRadius': '5px', 'marginBottom': '10px'})

    return html.Div([
        html.H3("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æ¯”è¼ƒåˆ†æ", style={'marginBottom': '20px'}),
        html.P("ä¸Šä¸‹ã®ã‚¨ãƒªã‚¢ã§ãã‚Œãã‚Œã€Œè·ç¨®ã€ã¨ã€Œé›‡ç”¨å½¢æ…‹ã€ã®çµ„ã¿åˆã‚ã›ã‚’é¸æŠã—ã€ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚"),
        create_comparison_area(1),
        create_comparison_area(2)
    ])


def create_shortage_tab() -> html.Div:
    """ä¸è¶³åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    df_shortage_role = DATA_STORE.get('shortage_role_summary', pd.DataFrame())
    df_shortage_emp = DATA_STORE.get('shortage_employment_summary', pd.DataFrame())

    content = [html.Div(id='shortage-insights', style={
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("ä¸è¶³åˆ†æ", style={'marginBottom': '20px'}),
        html.Div(
            dcc.Markdown(
                "\n".join(
                    [
                        "### è¨ˆç®—ã«ä½¿ç”¨ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
                        f"- Needç®—å‡ºæ–¹æ³•: {DATA_STORE.get('need_method', 'N/A')}",
                        f"- Upperç®—å‡ºæ–¹æ³•: {DATA_STORE.get('upper_method', 'N/A')}",
                        f"- ç›´æ¥é›‡ç”¨å˜ä¾¡: Â¥{DATA_STORE.get('wage_direct', 0):,.0f}/h",
                        f"- æ´¾é£å˜ä¾¡: Â¥{DATA_STORE.get('wage_temp', 0):,.0f}/h",
                        f"- æ¡ç”¨ã‚³ã‚¹ãƒˆ: Â¥{DATA_STORE.get('hiring_cost', 0):,}/äºº",
                        f"- ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£: Â¥{DATA_STORE.get('penalty_cost', 0):,.0f}/h",
                    ]
                )
            ),
            style={
                'backgroundColor': '#e9f2fa',
                'padding': '10px',
                'borderRadius': '8px',
                'border': '1px solid #cce5ff',
                'marginBottom': '20px'
            },
        )]

    # è·ç¨®åˆ¥ä¸è¶³åˆ†æ
    if not df_shortage_role.empty:
        content.append(html.H4("è·ç¨®åˆ¥ä¸è¶³æ™‚é–“"))

        # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        total_lack = df_shortage_role['lack_h'].sum() if 'lack_h' in df_shortage_role.columns else 0
        if total_lack > 0:
            top_roles = df_shortage_role.nlargest(3, 'lack_h')[['role', 'lack_h']]
            metrics = [
                html.Div([
                    create_metric_card("ç·ä¸è¶³æ™‚é–“", f"{total_lack:.1f}h")
                ], style={'width': '25%', 'display': 'inline-block', 'padding': '5px'})
            ]
            for i, row in enumerate(top_roles.itertuples(index=False)):
                metrics.append(
                    html.Div([
                        create_metric_card(f"ä¸è¶³Top{i+1}", f"{row.role}: {row.lack_h:.1f}h")
                    ], style={'width': '25%', 'display': 'inline-block', 'padding': '5px'})
                )
            content.append(html.Div(metrics, style={'marginBottom': '20px'}))

        # è·ç¨®åˆ¥ä¸è¶³æ™‚é–“ã‚°ãƒ©ãƒ•
        fig_role_lack = px.bar(
            df_shortage_role,
            x='role',
            y='lack_h',
            title='è·ç¨®åˆ¥ä¸è¶³æ™‚é–“',
            labels={'role': 'è·ç¨®', 'lack_h': 'ä¸è¶³æ™‚é–“(h)'},
            color_discrete_sequence=['#FFA500']
        )
        content.append(dcc.Graph(figure=fig_role_lack))

        # è·ç¨®åˆ¥éå‰°æ™‚é–“ã‚°ãƒ©ãƒ•
        if 'excess_h' in df_shortage_role.columns:
            fig_role_excess = px.bar(
                df_shortage_role,
                x='role',
                y='excess_h',
                title='è·ç¨®åˆ¥éå‰°æ™‚é–“',
                labels={'role': 'è·ç¨®', 'excess_h': 'éå‰°æ™‚é–“(h)'},
                color_discrete_sequence=['#00BFFF']
            )
            content.append(dcc.Graph(figure=fig_role_excess))

    # é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³åˆ†æ
    if not df_shortage_emp.empty:
        content.append(html.H4("é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³æ™‚é–“", style={'marginTop': '30px'}))

        fig_emp_lack = px.bar(
            df_shortage_emp,
            x='employment',
            y='lack_h',
            title='é›‡ç”¨å½¢æ…‹åˆ¥ä¸è¶³æ™‚é–“',
            labels={'employment': 'é›‡ç”¨å½¢æ…‹', 'lack_h': 'ä¸è¶³æ™‚é–“(h)'},
            color_discrete_sequence=['#2ca02c']
        )
        content.append(dcc.Graph(figure=fig_emp_lack))

    # ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    content.append(html.Div([
        html.H4("ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", style={'marginTop': '30px'}),
        html.P("å„æ™‚é–“å¸¯ã§å¿…è¦äººæ•°ã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„ã®å‰²åˆã§äººå“¡ãŒä¸è¶³ã—ã¦ã„ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚"),
        html.Div([
            html.Label("è¡¨ç¤ºç¯„å›²"),
            dcc.Dropdown(
                id='shortage-heatmap-scope',
                options=[
                    {'label': 'å…¨ä½“', 'value': 'overall'},
                    {'label': 'è·ç¨®åˆ¥', 'value': 'role'},
                    {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'employment'}
                ],
                value='overall',
                style={'width': '200px'}
            ),
        ], style={'marginBottom': '10px'}),
        html.Div(id='shortage-heatmap-detail-container'),
        html.Div(id='shortage-ratio-heatmap')
    ]))

    # Factor Analysis section
    content.append(html.Hr())
    content.append(html.H4('Factor Analysis (AI)', style={'marginTop': '30px'}))
    content.append(html.Button('Train factor model', id='factor-train-button', n_clicks=0))
    content.append(html.Div(id='factor-output'))

    # Over/Short Log section
    events_df = DATA_STORE.get('shortage_events', pd.DataFrame())
    if not events_df.empty:
        content.append(html.Hr())
        content.append(html.H4('Over/Short Log', style={'marginTop': '30px'}))
        content.append(dash_table.DataTable(
            id='over-shortage-table',
            data=events_df.to_dict('records'),
            columns=[{'name': c, 'id': c, 'presentation': 'input'} for c in events_df.columns],
            editable=True,
        ))
        content.append(dcc.RadioItems(
            id='log-save-mode',
            options=[{'label': 'Append', 'value': 'append'}, {'label': 'Overwrite', 'value': 'overwrite'}],
            value='append',
            inline=True,
            style={'marginTop': '10px'}
        ))
        content.append(html.Button('Save log', id='save-log-button', n_clicks=0, style={'marginTop': '10px'}))
        content.append(html.Div(id='save-log-msg'))

    return html.Div(content)


def create_optimization_tab() -> html.Div:
    """æœ€é©åŒ–åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    return html.Div([
        html.Div(id='optimization-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("æœ€é©åŒ–åˆ†æ", style={'marginBottom': '20px'}),
        html.Div([
            html.Label("è¡¨ç¤ºç¯„å›²"),
            dcc.Dropdown(
                id='opt-scope',
                options=[
                    {'label': 'å…¨ä½“', 'value': 'overall'},
                    {'label': 'è·ç¨®åˆ¥', 'value': 'role'},
                    {'label': 'é›‡ç”¨å½¢æ…‹åˆ¥', 'value': 'employment'}
                ],
                value='overall',
                clearable=False
            ),
        ], style={'width': '30%', 'marginBottom': '20px'}),
        html.Div(id='opt-detail-container'),
        html.Div(id='optimization-content')
    ])


def create_leave_analysis_tab() -> html.Div:
    """ä¼‘æš‡åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='leave-insights', style={
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("ä¼‘æš‡åˆ†æ", style={'marginBottom': '20px'})]

    df_staff_balance = DATA_STORE.get('staff_balance_daily', pd.DataFrame())
    df_daily_summary = DATA_STORE.get('daily_summary', pd.DataFrame())
    df_concentration = DATA_STORE.get('concentration_requested', pd.DataFrame())
    df_ratio_breakdown = DATA_STORE.get('leave_ratio_breakdown', pd.DataFrame())

    if not df_staff_balance.empty:
        fig_balance = px.line(
            df_staff_balance,
            x='date',
            y=['total_staff', 'leave_applicants_count', 'non_leave_staff'],
            title='å‹¤å‹™äºˆå®šäººæ•°ã¨å…¨ä¼‘æš‡å–å¾—è€…æ•°ã®æ¨ç§»',
            labels={'value': 'äººæ•°', 'variable': 'é …ç›®', 'date': 'æ—¥ä»˜'},
            markers=True
        )
        fig_balance.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_balance))
        content.append(dash_table.DataTable(
            data=df_staff_balance.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_staff_balance.columns]
        ))

    if not df_daily_summary.empty:
        fig_breakdown = px.bar(
            df_daily_summary,
            x='date',
            y='total_leave_days',
            color='leave_type',
            barmode='stack',
            title='æ—¥åˆ¥ ä¼‘æš‡å–å¾—è€…æ•°ï¼ˆå†…è¨³ï¼‰',
            labels={'date': 'æ—¥ä»˜', 'total_leave_days': 'ä¼‘æš‡å–å¾—è€…æ•°', 'leave_type': 'ä¼‘æš‡ã‚¿ã‚¤ãƒ—'}
        )
        fig_breakdown.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_breakdown))

    if not df_ratio_breakdown.empty:
        fig_ratio_break = px.bar(
            df_ratio_breakdown,
            x='dayofweek',
            y='leave_ratio',
            color='leave_type',
            facet_col='month_period',
            category_orders={
                'dayofweek': ['æœˆæ›œæ—¥', 'ç«æ›œæ—¥', 'æ°´æ›œæ—¥', 'æœ¨æ›œæ—¥', 'é‡‘æ›œæ—¥', 'åœŸæ›œæ—¥', 'æ—¥æ›œæ—¥'],
                'month_period': ['æœˆåˆ(1-10æ—¥)', 'æœˆä¸­(11-20æ—¥)', 'æœˆæœ«(21-æœ«æ—¥)'],
            },
            labels={'dayofweek': 'æ›œæ—¥', 'leave_ratio': 'å‰²åˆ', 'leave_type': 'ä¼‘æš‡ã‚¿ã‚¤ãƒ—', 'month_period': 'æœˆæœŸé–“'},
            title='æ›œæ—¥ãƒ»æœˆæœŸé–“åˆ¥ä¼‘æš‡å–å¾—ç‡'
        )
        content.append(dcc.Graph(figure=fig_ratio_break))

    if not df_concentration.empty:
        fig_conc = go.Figure()
        fig_conc.add_trace(go.Scatter(
            x=df_concentration['date'],
            y=df_concentration['leave_applicants_count'],
            mode='lines+markers',
            name='ä¼‘æš‡ç”³è«‹è€…æ•°',
            line=dict(shape='spline', smoothing=0.5),
            marker=dict(size=6)
        ))
        if 'is_concentrated' in df_concentration.columns:
            concentrated = df_concentration[df_concentration['is_concentrated']]
            if not concentrated.empty:
                fig_conc.add_trace(go.Scatter(
                    x=concentrated['date'],
                    y=concentrated['leave_applicants_count'],
                    mode='markers',
                    marker=dict(color='red', size=12, symbol='diamond'),
                    name='é–¾å€¤è¶…éæ—¥',
                    hovertemplate='<b>%{x|%Y-%m-%d}</b><br>ç”³è«‹è€…æ•°: %{y}äºº<extra></extra>'
                ))

        fig_conc.update_layout(
            title='å¸Œæœ›ä¼‘ ç”³è«‹è€…æ•°ã®æ¨ç§»ã¨é›†ä¸­æ—¥',
            xaxis_title='æ—¥ä»˜',
            yaxis_title='ç”³è«‹è€…æ•°'
        )
        fig_conc.update_xaxes(tickformat="%m/%d(%a)")
        content.append(dcc.Graph(figure=fig_conc))

    return html.Div(content)


def create_cost_analysis_tab() -> html.Div:
    """ã‚³ã‚¹ãƒˆåˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='cost-insights', style={
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("äººä»¶è²»åˆ†æ", style={'marginBottom': '20px'})]

    df_cost = DATA_STORE.get('daily_cost', pd.DataFrame())
    if not df_cost.empty:
        df_cost['date'] = pd.to_datetime(df_cost['date'])
        if not {'day_of_week', 'total_staff', 'role_breakdown', 'staff_list_summary'} <= set(df_cost.columns):
            long_df = DATA_STORE.get('long_df', pd.DataFrame())
            if not long_df.empty and 'ds' in long_df.columns:
                details = (
                    long_df[long_df.get('parsed_slots_count', 1) > 0]
                    .assign(date=lambda x: pd.to_datetime(x['ds']).dt.normalize())
                    .groupby('date')
                    .agg(
                        day_of_week=(
                            'ds',
                            lambda x: ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'][x.iloc[0].weekday()],
                        ),
                        total_staff=('staff', 'nunique'),
                        role_breakdown=(
                            'role',
                            lambda s: ', '.join(f"{r}:{c}" for r, c in s.value_counts().items()),
                        ),
                        staff_list=('staff', lambda s: ', '.join(sorted(s.unique()))),
                    )
                    .reset_index()
                )

                def summarize(names: str, limit: int = 5) -> str:
                    lst = names.split(', ')
                    if len(lst) > limit:
                        return ', '.join(lst[:limit]) + f", ...ä»–{len(lst) - limit}å"
                    return names

                details['staff_list_summary'] = details['staff_list'].apply(summarize)
                df_cost = pd.merge(df_cost, details, on='date', how='left')
        # æ—¥åˆ¥ã‚³ã‚¹ãƒˆã‚°ãƒ©ãƒ•
        fig_daily = px.bar(
            df_cost,
            x='date',
            y='cost',
            title='æ—¥åˆ¥ç™ºç”Ÿäººä»¶è²»',
            labels={'date': 'æ—¥ä»˜', 'cost': 'ã‚³ã‚¹ãƒˆ(å††)'}
        )
        fig_daily.update_xaxes(tickformat="%m/%d(%a)")

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ›ãƒãƒ¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿½åŠ 
        custom_cols = [c for c in ['day_of_week', 'total_staff', 'role_breakdown', 'staff_list_summary'] if c in df_cost.columns]
        if set(['day_of_week', 'total_staff', 'role_breakdown']).issubset(custom_cols):
            fig_daily.update_traces(
                customdata=df_cost[custom_cols],
                hovertemplate='<b>%{x|%Y-%m-%d} (%{customdata[0]})</b><br><br>' +
                             'ã‚³ã‚¹ãƒˆ: %{y:,.0f}å††<br>' +
                             'æ§‹æˆäººæ•°: %{customdata[1]}äºº<br>' +
                             'è·ç¨®ä¸€è¦§: %{customdata[2]}<br>' +
                             ('ã‚¹ã‚¿ãƒƒãƒ•: %{customdata[3]}' if 'staff_list_summary' in custom_cols else '') +
                             '<extra></extra>'
            )

        content.append(dcc.Graph(figure=fig_daily))

        # ç´¯è¨ˆã‚³ã‚¹ãƒˆã‚°ãƒ©ãƒ•
        if 'cost' in df_cost.columns:
            df_cost_sorted = df_cost.sort_values('date').copy()
            df_cost_sorted['cumulative_cost'] = df_cost_sorted['cost'].cumsum()

            fig_cumulative = px.line(
                df_cost_sorted,
                x='date',
                y='cumulative_cost',
                title='æ—¥åˆ¥ç´¯è¨ˆäººä»¶è²»',
                labels={'date': 'æ—¥ä»˜', 'cumulative_cost': 'ç´¯è¨ˆäººä»¶è²»(å††)'},
                markers=True
            )
            fig_cumulative.update_xaxes(tickformat="%m/%d(%a)")
            content.append(dcc.Graph(figure=fig_cumulative))

    return html.Div(content)


def create_hire_plan_tab() -> html.Div:
    """æ¡ç”¨è¨ˆç”»ã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='hire-plan-insights', style={
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("æ¡ç”¨è¨ˆç”»", style={'marginBottom': '20px'})]

    df_hire = DATA_STORE.get('hire_plan', pd.DataFrame())
    df_shortage_role = DATA_STORE.get('shortage_role_summary', pd.DataFrame())
    df_work_patterns = DATA_STORE.get('work_patterns', pd.DataFrame())
    if not df_hire.empty:
        content.append(html.H4("å¿…è¦FTEï¼ˆè·ç¨®åˆ¥ï¼‰"))

        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        content.append(dash_table.DataTable(
            data=df_hire.to_dict('records'),
            columns=[{'name': col, 'id': col} for col in df_hire.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'}
        ))

        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
        if 'role' in df_hire.columns and 'hire_fte' in df_hire.columns:
            fig_hire = px.bar(
                df_hire,
                x='role',
                y='hire_fte',
                title='è·ç¨®åˆ¥å¿…è¦FTE',
                labels={'role': 'è·ç¨®', 'hire_fte': 'å¿…è¦FTE'},
                color_discrete_sequence=['#1f77b4']
            )
            content.append(dcc.Graph(figure=fig_hire))

    if not df_hire.empty and not df_shortage_role.empty:
        content.append(html.Div([
            html.H4("What-if æ¡ç”¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", style={'marginTop': '30px'}),
            html.P("ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’å‹•ã‹ã—ã¦ã€è¿½åŠ æ¡ç”¨ã«ã‚ˆã‚‹ä¸è¶³æ™‚é–“ã®å‰Šæ¸›åŠ¹æœã¨ã‚³ã‚¹ãƒˆã®å¤‰åŒ–ã‚’ç¢ºèªã§ãã¾ã™ã€‚"),
            dcc.Dropdown(
                id='sim-work-pattern-dropdown',
                options=[{'label': i, 'value': i} for i in df_work_patterns['code'].unique()] if not df_work_patterns.empty else [],
                value=df_work_patterns['code'].iloc[0] if not df_work_patterns.empty else None,
                clearable=False,
            ),
            dcc.Slider(
                id='sim-hire-fte-slider',
                min=0,
                max=10,
                step=1,
                value=0,
                marks={i: str(i) for i in range(11)},
            ),
        ], style={'padding': '20px', 'backgroundColor': '#f0f0f0', 'borderRadius': '8px'}))
        content.append(dcc.Graph(id='sim-shortage-graph'))
        content.append(html.Div(id='sim-cost-text'))

    # æœ€é©æ¡ç”¨è¨ˆç”»
    df_optimal = DATA_STORE.get('optimal_hire_plan', pd.DataFrame())
    if not df_optimal.empty:
        content.append(html.H4("æœ€é©æ¡ç”¨è¨ˆç”»", style={'marginTop': '30px'}))
        content.append(html.P("åˆ†æã®çµæœã€ä»¥ä¸‹ã®å…·ä½“çš„ãªæ¡ç”¨è¨ˆç”»ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"))
        content.append(dash_table.DataTable(
            data=df_optimal.to_dict('records'),
            columns=[{'name': col, 'id': col} for col in df_optimal.columns],
            style_cell={'textAlign': 'left'},
            style_header={'backgroundColor': 'rgb(230, 230, 230)', 'fontWeight': 'bold'}
        ))

    return html.Div(content)


def create_fatigue_tab() -> html.Div:
    """ç–²åŠ´åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    explanation = """
    #### ç–²åŠ´åˆ†æã®è©•ä¾¡æ–¹æ³•
    ã‚¹ã‚¿ãƒƒãƒ•ã®ç–²åŠ´ã‚¹ã‚³ã‚¢ã¯ã€ä»¥ä¸‹ã®è¦ç´ ã‚’ç·åˆçš„ã«è©•ä¾¡ã—ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚å„è¦ç´ ã¯ã€å…¨ã‚¹ã‚¿ãƒƒãƒ•å†…ã§ã®ç›¸å¯¾çš„ãªä½ç½®ï¼ˆåå·®ï¼‰ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢åŒ–ã•ã‚Œã€é‡ã¿ä»˜ã‘ã•ã‚Œã¦åˆè¨ˆã•ã‚Œã¾ã™ã€‚
    - **å‹¤å‹™é–‹å§‹æ™‚åˆ»ã®ã°ã‚‰ã¤ã:** å‡ºå‹¤æ™‚åˆ»ãŒä¸è¦å‰‡ã§ã‚ã‚‹ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **æ¥­å‹™ã®å¤šæ§˜æ€§:** æ‹…å½“ã™ã‚‹æ¥­å‹™ï¼ˆå‹¤å‹™ã‚³ãƒ¼ãƒ‰ï¼‰ã®ç¨®é¡ãŒå¤šã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **åŠ´åƒæ™‚é–“ã®ã°ã‚‰ã¤ã:** æ—¥ã€…ã®åŠ´åƒæ™‚é–“ãŒä¸è¦å‰‡ã§ã‚ã‚‹ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **çŸ­ã„ä¼‘æ¯æœŸé–“:** å‹¤å‹™é–“ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«ãŒçŸ­ã„é »åº¦ãŒé«˜ã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **é€£å‹¤:** 3é€£å‹¤ä»¥ä¸Šã®é€£ç¶šå‹¤å‹™ãŒå¤šã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚
    - **å¤œå‹¤æ¯”ç‡:** å…¨å‹¤å‹™ã«å ã‚ã‚‹å¤œå‹¤ã®å‰²åˆãŒé«˜ã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚Šã¾ã™ã€‚

    *ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€ã“ã‚Œã‚‰ã®è¦ç´ ã¯å‡ç­‰ãªé‡ã¿ï¼ˆå„1.0ï¼‰ã§è©•ä¾¡ã•ã‚Œã¾ã™ã€‚*
    """
    content = [
        html.Div(
            dcc.Markdown(explanation),
            style={
                'padding': '15px',
                'backgroundColor': '#e9f2fa',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #cce5ff',
            },
        ),
        html.H3("ç–²åŠ´åˆ†æ", style={'marginBottom': '20px'}),
    ]
    df_fatigue = DATA_STORE.get('fatigue_score', pd.DataFrame())

    if not df_fatigue.empty:
        df_fatigue_for_plot = df_fatigue.reset_index().rename(columns={'index': 'staff'})
        fig = px.bar(
            df_fatigue_for_plot,
            x='staff',
            y='fatigue_score',
            title='ã‚¹ã‚¿ãƒƒãƒ•åˆ¥ç–²åŠ´ã‚¹ã‚³ã‚¢',
            labels={'staff': 'ã‚¹ã‚¿ãƒƒãƒ•', 'fatigue_score': 'ç–²åŠ´ã‚¹ã‚³ã‚¢'}
        )
        content.append(dcc.Graph(figure=fig))
        content.append(dash_table.DataTable(
            data=df_fatigue_for_plot.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_fatigue_for_plot.columns]
        ))
    else:
        content.append(html.P("ç–²åŠ´åˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

    return html.Div(content)


def create_forecast_tab() -> html.Div:
    """éœ€è¦äºˆæ¸¬ã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='forecast-insights', style={
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("éœ€è¦äºˆæ¸¬", style={'marginBottom': '20px'})]
    df_fc = DATA_STORE.get('forecast', pd.DataFrame())
    df_actual = DATA_STORE.get('demand_series', pd.DataFrame())

    if not df_fc.empty:
        fig = go.Figure()
        if {'ds', 'yhat'}.issubset(df_fc.columns):
            fig.add_trace(go.Scatter(x=df_fc['ds'], y=df_fc['yhat'], mode='lines+markers', name='äºˆæ¸¬'))
        if not df_actual.empty and {'ds', 'y'}.issubset(df_actual.columns):
            fig.add_trace(go.Scatter(x=df_actual['ds'], y=df_actual['y'], mode='lines', name='å®Ÿç¸¾', line=dict(dash='dash')))
        fig.update_layout(title='éœ€è¦äºˆæ¸¬ã¨å®Ÿç¸¾', xaxis_title='æ—¥ä»˜', yaxis_title='éœ€è¦')
        content.append(dcc.Graph(figure=fig))
        content.append(dash_table.DataTable(
            data=df_fc.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_fc.columns]
        ))
    else:
        content.append(html.P("éœ€è¦äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

    return html.Div(content)


def create_fairness_tab() -> html.Div:
    """å…¬å¹³æ€§ã‚¿ãƒ–ã‚’ä½œæˆ"""
    explanation = """
    #### å…¬å¹³æ€§åˆ†æã®è©•ä¾¡æ–¹æ³•
    ã‚¹ã‚¿ãƒƒãƒ•é–“ã®ã€Œä¸å…¬å¹³æ„Ÿã€ã¯ã€å„å€‹äººã®åƒãæ–¹ãŒå…¨ä½“ã®å¹³å‡ã‹ã‚‰ã©ã‚Œã ã‘ä¹–é›¢ã—ã¦ã„ã‚‹ã‹ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢åŒ–ã•ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®è¦ç´ ã®ä¹–é›¢åº¦ã‚’å‡ç­‰ã«è©•ä¾¡ã—ã€ãã®å¹³å‡å€¤ã‚’ã€Œä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢ã€ã¨ã—ã¦ã„ã¾ã™ã€‚
    - **å¤œå‹¤æ¯”ç‡ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€å¤œå‹¤ã®å‰²åˆãŒæ¥µç«¯ã«å¤šã„ã€ã¾ãŸã¯å°‘ãªã„ã€‚
    - **ç·åŠ´åƒæ™‚é–“ï¼ˆã‚¹ãƒ­ãƒƒãƒˆæ•°ï¼‰ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€ç·åŠ´åƒæ™‚é–“ãŒæ¥µç«¯ã«å¤šã„ã€ã¾ãŸã¯å°‘ãªã„ã€‚
    - **å¸Œæœ›ä¼‘ã®æ‰¿èªç‡ã®ä¹–é›¢:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€å¸Œæœ›ä¼‘ã®é€šã‚Šã‚„ã™ã•ã«å·®ãŒã‚ã‚‹ã€‚
    - **é€£ä¼‘å–å¾—é »åº¦ã®ä¹–ãƒª:** ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã¨æ¯”è¼ƒã—ã¦ã€é€£ä¼‘ã®å–å¾—ã—ã‚„ã™ã•ã«å·®ãŒã‚ã‚‹ã€‚

    *ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©ã€ã“ã‚Œã‚‰ã®è¦ç´ ã«ãŠã„ã¦å¹³å‡ã‹ã‚‰ã®ä¹–é›¢ãŒå¤§ãã„ï¼ˆï¼ä¸å…¬å¹³æ„Ÿã‚’æ„Ÿã˜ã‚„ã™ã„å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚*
    """
    content = [
        html.Div(
            dcc.Markdown(explanation),
            style={
                'padding': '15px',
                'backgroundColor': '#f0f0f0',
                'borderRadius': '8px',
                'marginBottom': '20px',
                'border': '1px solid #ddd',
            },
        ),
        html.H3("å…¬å¹³æ€§ (ä¸å…¬å¹³æ„Ÿã‚¹ã‚³ã‚¢)", style={'marginBottom': '20px'}),
    ]
    df_fair = DATA_STORE.get('fairness_after', pd.DataFrame())

    if not df_fair.empty:
        metric_col = (
            'unfairness_score'
            if 'unfairness_score' in df_fair.columns
            else ('fairness_score' if 'fairness_score' in df_fair.columns else 'night_ratio')
        )
        fig_bar = px.bar(
            df_fair,
            x='staff',
            y=metric_col,
            labels={'staff': 'ã‚¹ã‚¿ãƒƒãƒ•', metric_col: 'ã‚¹ã‚³ã‚¢'},
            color_discrete_sequence=['#FF8C00']
        )
        avg_val = df_fair[metric_col].mean()
        fig_bar.add_hline(y=avg_val, line_dash='dash', line_color='red')
        content.append(dcc.Graph(figure=fig_bar))

        fig_hist = px.histogram(
            df_fair,
            x=metric_col,
            nbins=20,
            title="å…¬å¹³æ€§ã‚¹ã‚³ã‚¢åˆ†å¸ƒ",
            labels={metric_col: 'ã‚¹ã‚³ã‚¢'}
        )
        fig_hist.update_layout(yaxis_title="äººæ•°")
        fig_hist.add_vline(x=avg_val, line_dash='dash', line_color='red')
        content.append(dcc.Graph(figure=fig_hist))

        if 'unfairness_score' in df_fair.columns:
            ranking = df_fair.sort_values('unfairness_score', ascending=False)[['staff', 'unfairness_score']]
            ranking.index += 1
            content.append(html.H4('ä¸å…¬å¹³æ„Ÿãƒ©ãƒ³ã‚­ãƒ³ã‚°'))
            content.append(dash_table.DataTable(
                data=ranking.to_dict('records'),
                columns=[{'name': i, 'id': i} for i in ranking.columns]
            ))
        content.append(dash_table.DataTable(
            data=df_fair.to_dict('records'),
            columns=[{'name': i, 'id': i} for i in df_fair.columns]
        ))
    else:
        content.append(html.P("å…¬å¹³æ€§ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

    return html.Div(content)


def create_gap_analysis_tab() -> html.Div:
    """åŸºæº–ä¹–é›¢åˆ†æã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='gap-insights', style={
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("åŸºæº–ä¹–é›¢åˆ†æ", style={'marginBottom': '20px'})]
    df_summary = DATA_STORE.get('gap_summary', pd.DataFrame())
    df_heat = DATA_STORE.get('gap_heatmap', pd.DataFrame())

    if not df_summary.empty:
        content.append(dash_table.DataTable(
            data=df_summary.to_dict('records'),
            columns=[{'name': c, 'id': c} for c in df_summary.columns]
        ))
    if not df_heat.empty:
        fig = px.imshow(
            df_heat,
            aspect='auto',
            color_continuous_scale='RdBu_r',
            labels={'x': 'æ™‚é–“å¸¯', 'y': 'è·ç¨®', 'color': 'ä¹–é›¢'}
        )
        content.append(dcc.Graph(figure=fig))
    if df_summary.empty and df_heat.empty:
        content.append(html.P("åŸºæº–ä¹–é›¢ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

    return html.Div(content)


def create_summary_report_tab() -> html.Div:
    """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚¿ãƒ–ã‚’ä½œæˆ"""
    content = [html.Div(id='summary-report-insights', style={
        'padding': '15px',
        'backgroundColor': '#e9f2fa',
        'borderRadius': '8px',
        'marginBottom': '20px',
        'border': '1px solid #cce5ff'
    }),
        html.H3("Summary Report", style={'marginBottom': '20px'})]
    report_text = DATA_STORE.get('summary_report')
    if report_text:
        content.append(dcc.Markdown(report_text))
    else:
        content.append(html.P("ãƒ¬ãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))
    return html.Div(content)


def create_ppt_report_tab() -> html.Div:
    """PowerPointãƒ¬ãƒãƒ¼ãƒˆã‚¿ãƒ–ã‚’ä½œæˆ"""
    return html.Div([
        html.Div(id='ppt-report-insights', style={
            'padding': '15px',
            'backgroundColor': '#e9f2fa',
            'borderRadius': '8px',
            'marginBottom': '20px',
            'border': '1px solid #cce5ff'
        }),
        html.H3("PPT Report", style={'marginBottom': '20px'}),
        html.P("ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦PowerPointãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"),
        html.Button('Generate PPT', id='ppt-generate', n_clicks=0)
    ])

# --- ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
app.layout = html.Div([
    dcc.Store(id='kpi-data-store', storage_type='memory'),
    dcc.Store(id='data-loaded', storage_type='memory'),

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    html.Div([
        html.H1("ğŸ—‚ï¸ Shift-Suite é«˜é€Ÿåˆ†æãƒ“ãƒ¥ãƒ¼ã‚¢", style={
            'textAlign': 'center',
            'color': 'white',
            'margin': '0',
            'padding': '20px'
        })
    ], style={
        'backgroundColor': '#2c3e50',
        'boxShadow': '0 2px 4px rgba(0,0,0,0.1)'
    }),

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢
    html.Div([
        dcc.Upload(
            id='upload-data',
            children=html.Div([
                'åˆ†æçµæœã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ— ã¾ãŸã¯ ',
                html.A('ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠ', style={'textDecoration': 'underline'})
            ]),
            style={
                'width': '100%',
                'height': '100px',
                'lineHeight': '100px',
                'borderWidth': '2px',
                'borderStyle': 'dashed',
                'borderRadius': '10px',
                'textAlign': 'center',
                'margin': '20px 0',
                'backgroundColor': '#f8f9fa',
                'cursor': 'pointer'
            },
            multiple=False
        ),
    ], style={'padding': '0 20px'}),

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    html.Div(id='main-content', style={'padding': '20px'}),

], style={'backgroundColor': '#f5f5f5', 'minHeight': '100vh'})

# --- ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•° ---
@app.callback(
    Output('kpi-data-store', 'data'),
    Output('data-loaded', 'data'),
    Input('upload-data', 'contents'),
    State('upload-data', 'filename')
)
def process_upload(contents, filename):
    """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»å‡¦ç†"""
    if contents is None:
        raise PreventUpdate

    global DATA_STORE, TEMP_DIR

    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    if TEMP_DIR:
        import shutil
        shutil.rmtree(TEMP_DIR, ignore_errors=True)

    TEMP_DIR = Path(tempfile.mkdtemp(prefix="shift_suite_dash_"))

    # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)

    try:
        with zipfile.ZipFile(io.BytesIO(decoded)) as zf:
            zf.extractall(TEMP_DIR)

        # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ã™
        data_dir = None
        if (TEMP_DIR / 'out').exists():
            data_dir = TEMP_DIR / 'out'
        elif (TEMP_DIR / 'heat_ALL.parquet').exists():
            data_dir = TEMP_DIR
        else:
            # å†å¸°çš„ã«æ¢ã™
            for p in TEMP_DIR.rglob('heat_ALL.parquet'):
                data_dir = p.parent
                break

        if not data_dir:
            return {}, {'error': 'ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}

        # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        DATA_STORE = {}

        # Parquetãƒ•ã‚¡ã‚¤ãƒ«
        parquet_files = [
            'heat_ALL.parquet',
            'shortage_role_summary.parquet',
            'shortage_employment_summary.parquet',
            'shortage_time.parquet',
            'shortage_ratio.parquet',
            'shortage_freq.parquet',
            'excess_time.parquet',
            'excess_ratio.parquet',
            'excess_freq.parquet',
            'fatigue_score.parquet',
            'fairness_before.parquet',
            'fairness_after.parquet',
            'staff_stats.parquet',
            'stats_alerts.parquet',
            'hire_plan.parquet',
            'optimal_hire_plan.parquet',
            'daily_cost.parquet',
            'forecast.parquet',
            'cost_benefit.parquet',
            'work_patterns.parquet'
        ]

        for file in parquet_files:
            if (data_dir / file).exists():
                df = safe_read_parquet(data_dir / file)
                if not df.empty:
                    DATA_STORE[file.replace('.parquet', '')] = df
            elif file == 'daily_cost.parquet' and (data_dir / 'daily_cost.xlsx').exists():
                df = safe_read_excel(data_dir / 'daily_cost.xlsx')
                if not df.empty:
                    DATA_STORE['daily_cost'] = df

        # CSVãƒ•ã‚¡ã‚¤ãƒ«
        csv_files = [
            'leave_analysis.csv',
            'staff_balance_daily.csv',
            'concentration_requested.csv',
            'leave_ratio_breakdown.csv',
            'demand_series.csv'
        ]

        for file in csv_files:
            if (data_dir / file).exists():
                df = safe_read_csv(data_dir / file)
                if not df.empty:
                    DATA_STORE[file.replace('.csv', '')] = df

        # å‹•çš„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«
        for p in data_dir.glob('heat_*.parquet'):
            if p.name == 'heat_ALL.parquet' or p.name.startswith('heat_emp_'):
                continue
            df = safe_read_parquet(p)
            if not df.empty:
                DATA_STORE[safe_filename(p.stem)] = df

        for p in data_dir.glob('heat_emp_*.parquet'):
            df = safe_read_parquet(p)
            if not df.empty:
                DATA_STORE[safe_filename(p.stem)] = df

        # long_df ã¯ intermediate_data.parquet ã‹ã‚‰èª­ã¿è¾¼ã‚€
        intermediate_fp = data_dir / 'intermediate_data.parquet'
        if intermediate_fp.exists():
            log.info("intermediate_data.parquet ã‚’ long_df ã¨ã—ã¦èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
            df = safe_read_parquet(intermediate_fp)
            if not df.empty:
                DATA_STORE['long_df'] = df
        else:
            DATA_STORE['long_df'] = None
            log.warning(
                'å‹•çš„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®å…ƒã¨ãªã‚‹ intermediate_data.parquet ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚'
            )

        # Gap analysis files (excel or parquet)
        for name in ['gap_summary', 'gap_heatmap']:
            excel_fp = data_dir / f'{name}.xlsx'
            parquet_fp = data_dir / f'{name}.parquet'
            df = pd.DataFrame()
            if excel_fp.exists():
                try:
                    df = safe_read_excel(excel_fp)
                except Exception as e:  # noqa: BLE001
                    log.warning(f'Failed to read {excel_fp}: {e}')
            elif parquet_fp.exists():
                df = safe_read_parquet(parquet_fp)
            if not df.empty:
                DATA_STORE[name] = df

        # Summary report markdown
        report_files = sorted(data_dir.glob('OverShortage_SummaryReport_*.md'))
        if report_files:
            latest = report_files[-1]
            try:
                DATA_STORE['summary_report'] = latest.read_text(encoding='utf-8')
            except Exception as e:  # noqa: BLE001
                log.warning(f'Failed to read {latest}: {e}')

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        roles, employments = load_shortage_meta(data_dir)
        DATA_STORE['roles'] = roles
        DATA_STORE['employments'] = employments

        # Over/Shortage events and log
        events_df = over_shortage_log.list_events(data_dir)
        if not events_df.empty:
            log_fp = data_dir / 'over_shortage_log.csv'
            existing = over_shortage_log.load_log(log_fp)
            merged = events_df.merge(
                existing,
                on=['date', 'time', 'type'],
                how='left',
                suffixes=('', '_log'),
            )
            for col in ['reason', 'staff', 'memo']:
                if col not in merged.columns:
                    merged[col] = ''
            DATA_STORE['shortage_events'] = merged
            DATA_STORE['shortage_log_path'] = str(log_fp)

        kpi_data = {}
        df_shortage_role = DATA_STORE.get('shortage_role_summary', pd.DataFrame())
        if not df_shortage_role.empty and 'lack_h' in df_shortage_role.columns:
            total_lack_h = df_shortage_role['lack_h'].sum()
            most_lacking_role = df_shortage_role.loc[df_shortage_role['lack_h'].idxmax()]
            kpi_data['total_lack_h'] = total_lack_h
            kpi_data['most_lacking_role_name'] = most_lacking_role['role']
            kpi_data['most_lacking_role_hours'] = most_lacking_role['lack_h']

        log.info(
            f"Loaded {len(DATA_STORE)} data files and calculated {len(kpi_data)} KPIs."
        )
        return kpi_data, {'success': True, 'files': len(DATA_STORE)}

    except Exception as e:
        log.error(f"Error processing ZIP: {e}", exc_info=True)
        return {}, {'error': str(e)}


@app.callback(
    Output('main-content', 'children'),
    Input('data-loaded', 'data')
)
def update_main_content(data_status):
    """ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›´æ–°"""
    if not data_status:
        return html.Div([
            html.P("åˆ†æçµæœã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
                  style={'textAlign': 'center', 'fontSize': '18px', 'color': '#666'})
        ])

    if 'error' in data_status:
        return html.Div([
            html.P(f"ã‚¨ãƒ©ãƒ¼: {data_status['error']}",
                  style={'color': 'red', 'textAlign': 'center'})
        ])

    # ã‚¿ãƒ–ã‚’ä½œæˆ
    tabs = dcc.Tabs(id='main-tabs', value='overview', children=[
        dcc.Tab(label='æ¦‚è¦', value='overview'),
        dcc.Tab(label='ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', value='heatmap'),
        dcc.Tab(label='ä¸è¶³åˆ†æ', value='shortage'),
        dcc.Tab(label='æœ€é©åŒ–åˆ†æ', value='optimization'),
        dcc.Tab(label='ä¼‘æš‡åˆ†æ', value='leave'),
        dcc.Tab(label='ã‚³ã‚¹ãƒˆåˆ†æ', value='cost'),
        dcc.Tab(label='æ¡ç”¨è¨ˆç”»', value='hire_plan'),
        dcc.Tab(label='ç–²åŠ´åˆ†æ', value='fatigue'),
        dcc.Tab(label='éœ€è¦äºˆæ¸¬', value='forecast'),
        dcc.Tab(label='å…¬å¹³æ€§', value='fairness'),
        dcc.Tab(label='åŸºæº–ä¹–é›¢åˆ†æ', value='gap'),
        dcc.Tab(label='Summary Report', value='summary_report'),
        dcc.Tab(label='PPT Report', value='ppt_report'),
    ])

    return html.Div([
        tabs,
        html.Div(id='tab-content', style={'marginTop': '20px'})
    ])


@app.callback(
    Output('tab-content', 'children'),
    Input('main-tabs', 'value')
)
def update_tab_content(active_tab):
    """ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›´æ–°"""
    if active_tab == 'overview':
        return create_overview_tab()
    elif active_tab == 'heatmap':
        return create_heatmap_tab()
    elif active_tab == 'shortage':
        return create_shortage_tab()
    elif active_tab == 'optimization':
        return create_optimization_tab()
    elif active_tab == 'leave':
        return create_leave_analysis_tab()
    elif active_tab == 'cost':
        return create_cost_analysis_tab()
    elif active_tab == 'hire_plan':
        return create_hire_plan_tab()
    elif active_tab == 'fatigue':
        return create_fatigue_tab()
    elif active_tab == 'forecast':
        return create_forecast_tab()
    elif active_tab == 'fairness':
        return create_fairness_tab()
    elif active_tab == 'gap':
        return create_gap_analysis_tab()
    elif active_tab == 'summary_report':
        return create_summary_report_tab()
    elif active_tab == 'ppt_report':
        return create_ppt_report_tab()
    else:
        return html.Div("ã‚¿ãƒ–ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“")


@app.callback(
    Output({'type': 'graph-output-heatmap', 'index': 1}, 'children'),
    Output({'type': 'graph-output-heatmap', 'index': 2}, 'children'),
    Input({'type': 'heatmap-filter-role', 'index': 1}, 'value'),
    Input({'type': 'heatmap-filter-employment', 'index': 1}, 'value'),
    Input({'type': 'heatmap-filter-role', 'index': 2}, 'value'),
    Input({'type': 'heatmap-filter-employment', 'index': 2}, 'value'),
)
def update_comparison_heatmaps(role1, emp1, role2, emp2):
    """ã€æ–°ãƒ­ã‚¸ãƒƒã‚¯ã€‘ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‹•çš„ã«ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã€2ã‚¨ãƒªã‚¢ã‚’æ›´æ–°"""

    # åˆ†æã®å…ƒã¨ãªã‚‹ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’DATA_STOREã‹ã‚‰å–å¾—
    long_df = DATA_STORE.get('long_df')
    if long_df is None or long_df.empty:
        error_message = html.Div("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®å…ƒã¨ãªã‚‹ç”Ÿãƒ‡ãƒ¼ã‚¿(long_df)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return error_message, error_message

    # 'ds' åˆ—ã‚’datetimeå‹ã«å¤‰æ›ã—ã€'time' ã¨ 'date_lbl' åˆ—ã‚’æº–å‚™
    if 'date_lbl' not in long_df.columns:
        long_df['ds'] = pd.to_datetime(long_df['ds'])
        long_df['time'] = long_df['ds'].dt.strftime('%H:%M')
        long_df['date_lbl'] = long_df['ds'].dt.strftime('%Y-%m-%d')

    def generate_dynamic_heatmap(selected_role, selected_emp):
        """é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§long_dfã‚’ãƒ•ã‚£ãƒ«ã‚¿ã—ã€ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã™ã‚‹å†…éƒ¨é–¢æ•°"""

        filtered_df = long_df.copy()
        title_parts = []

        # è·ç¨®ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if selected_role and selected_role != 'all':
            filtered_df = filtered_df[filtered_df['role'] == selected_role]
            title_parts.append(f"è·ç¨®: {selected_role}")

        # é›‡ç”¨å½¢æ…‹ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if selected_emp and selected_emp != 'all':
            filtered_df = filtered_df[filtered_df['employment'] == selected_emp]
            title_parts.append(f"é›‡ç”¨å½¢æ…‹: {selected_emp}")

        title = " AND ".join(title_parts) if title_parts else "å…¨ä½“"

        if filtered_df.empty:
            return generate_heatmap_figure(pd.DataFrame(), f"{title} (ãƒ‡ãƒ¼ã‚¿ãªã—)")

        dynamic_heatmap_df = filtered_df.pivot_table(
            index='time',
            columns='date_lbl',
            values='staff',
            aggfunc='nunique',
            fill_value=0
        )
        time_labels = gen_labels(30)
        dynamic_heatmap_df = dynamic_heatmap_df.reindex(time_labels, fill_value=0)

        fig = generate_heatmap_figure(dynamic_heatmap_df, title)
        return dcc.Graph(figure=fig)

    output1 = generate_dynamic_heatmap(role1, emp1)
    output2 = generate_dynamic_heatmap(role2, emp2)

    return output1, output2


@app.callback(
    Output('shortage-heatmap-detail-container', 'children'),
    Input('shortage-heatmap-scope', 'value')
)
def update_shortage_heatmap_detail(scope):
    """ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®è©³ç´°é¸æŠã‚’æ›´æ–°"""
    if scope == 'overall':
        return None
    elif scope == 'role':
        roles = DATA_STORE.get('roles', [])
        return html.Div([
            html.Label("è·ç¨®é¸æŠ"),
            dcc.Dropdown(
                id={'type': 'shortage-detail', 'index': 'role'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': r, 'value': r} for r in roles],
                value='ALL',
                style={'width': '200px'}
            )
        ], style={'marginBottom': '10px'})
    elif scope == 'employment':
        employments = DATA_STORE.get('employments', [])
        return html.Div([
            html.Label("é›‡ç”¨å½¢æ…‹é¸æŠ"),
            dcc.Dropdown(
                id={'type': 'shortage-detail', 'index': 'employment'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': e, 'value': e} for e in employments],
                value='ALL',
                style={'width': '200px'}
            )
        ], style={'marginBottom': '10px'})
    return None


@app.callback(
    Output('shortage-ratio-heatmap', 'children'),
    Input('shortage-heatmap-scope', 'value'),
    Input({'type': 'shortage-detail', 'index': ALL}, 'value')
)
def update_shortage_ratio_heatmap(scope, detail_values):
    """ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’æ›´æ–°"""
    # ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼ã‚’æ±ºå®š
    if scope == 'overall':
        heat_key = 'heat_ALL'
    else:
        detail = detail_values[0] if detail_values else None
        if not detail or detail == 'ALL':
            heat_key = 'heat_ALL'
        elif scope == 'role':
            heat_key = f'heat_{safe_filename(detail)}'
        else:
            heat_key = f'heat_emp_{safe_filename(detail)}'

    df_heat = DATA_STORE.get(heat_key)
    if df_heat is None:
        for key in DATA_STORE.keys():
            if (
                key.startswith('heat_')
                and not key.startswith('heat_emp_')
                and key != 'heat_ALL'
                and detail in key
            ):
                df_heat = DATA_STORE[key]
                break
            if key.startswith('heat_emp_') and detail in key:
                df_heat = DATA_STORE[key]
                break
    if df_heat is None or df_heat.empty:
        return html.Div("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # ä¸è¶³ç‡ã‚’è¨ˆç®—
    date_cols = [c for c in df_heat.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    if not date_cols:
        return html.Div("æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    time_labels = gen_labels(30)
    staff_df = df_heat[date_cols].fillna(0).reindex(time_labels, fill_value=0)
    need_series = df_heat.get('need', pd.Series()).fillna(0)
    need_df = pd.DataFrame(
        np.repeat(need_series.values[:, np.newaxis], len(date_cols), axis=1),
        index=time_labels,
        columns=date_cols,
    )
    upper_series = df_heat.get('upper', pd.Series()).fillna(0)
    upper_df = pd.DataFrame(
        np.repeat(upper_series.values[:, np.newaxis], len(date_cols), axis=1),
        index=time_labels,
        columns=date_cols,
    )

    lack_count_df = (need_df - staff_df).clip(lower=0)
    excess_count_df = (staff_df - upper_df).clip(lower=0)
    ratio_df = calc_ratio_from_heatmap(df_heat)
    ratio_df = ratio_df.reindex(time_labels, fill_value=0)

    fig_lack = px.imshow(
        lack_count_df,
        aspect='auto',
        color_continuous_scale='Oranges',
        title='ä¸è¶³äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
        labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'},
    )
    fig_lack.update_xaxes(
        ticktext=[date_with_weekday(c) for c in lack_count_df.columns],
        tickvals=list(range(len(lack_count_df.columns)))
    )

    fig_excess = px.imshow(
        excess_count_df,
        aspect='auto',
        color_continuous_scale='Blues',
        title='éå‰°äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
        labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'äººæ•°'},
    )
    fig_excess.update_xaxes(
        ticktext=[date_with_weekday(c) for c in excess_count_df.columns],
        tickvals=list(range(len(excess_count_df.columns)))
    )

    fig_ratio = px.imshow(
        ratio_df,
        aspect='auto',
        color_continuous_scale='RdBu_r',
        title='ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
        labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ä¸è¶³ç‡'},
    )
    fig_ratio.update_xaxes(
        ticktext=[date_with_weekday(c) for c in ratio_df.columns],
        tickvals=list(range(len(ratio_df.columns)))
    )

    return html.Div([
        html.H4('ä¸è¶³äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—'),
        dcc.Graph(figure=fig_lack),
        html.H4('éå‰°äººæ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', style={'marginTop': '30px'}),
        dcc.Graph(figure=fig_excess),
        html.H4('ä¸è¶³ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', style={'marginTop': '30px'}),
        dcc.Graph(figure=fig_ratio),
    ])


@app.callback(
    Output('opt-detail-container', 'children'),
    Input('opt-scope', 'value')
)
def update_opt_detail(scope):
    """æœ€é©åŒ–åˆ†æã®è©³ç´°é¸æŠã‚’æ›´æ–°"""
    if scope == 'overall':
        return None
    elif scope == 'role':
        roles = DATA_STORE.get('roles', [])
        return html.Div([
            html.Label("è·ç¨®é¸æŠ"),
            dcc.Dropdown(
                id={'type': 'opt-detail', 'index': 'role'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': r, 'value': r} for r in roles],
                value='ALL',
                style={'width': '300px', 'marginBottom': '20px'}
            )
        ])
    elif scope == 'employment':
        employments = DATA_STORE.get('employments', [])
        return html.Div([
            html.Label("é›‡ç”¨å½¢æ…‹é¸æŠ"),
            dcc.Dropdown(
                id={'type': 'opt-detail', 'index': 'employment'},
                options=[{'label': 'å…¨ä½“', 'value': 'ALL'}] + [{'label': e, 'value': e} for e in employments],
                value='ALL',
                style={'width': '300px', 'marginBottom': '20px'}
            )
        ])
    return None


@app.callback(
    Output('optimization-content', 'children'),
    Input('opt-scope', 'value'),
    Input({'type': 'opt-detail', 'index': ALL}, 'value')
)
def update_optimization_content(scope, detail_values):
    """æœ€é©åŒ–åˆ†æã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›´æ–°"""
    # ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼ã‚’æ±ºå®š
    if scope == 'overall':
        heat_key = 'heat_ALL'
    else:
        detail = detail_values[0] if detail_values else None
        if not detail or detail == 'ALL':
            heat_key = 'heat_ALL'
        elif scope == 'role':
            heat_key = f'heat_{safe_filename(detail)}'
        else:
            heat_key = f'heat_emp_{safe_filename(detail)}'

    df_heat = DATA_STORE.get(heat_key)
    if df_heat is None:
        for key in DATA_STORE.keys():
            if (
                key.startswith('heat_')
                and not key.startswith('heat_emp_')
                and key != 'heat_ALL'
                and detail in key
            ):
                df_heat = DATA_STORE[key]
                break
            if key.startswith('heat_emp_') and detail in key:
                df_heat = DATA_STORE[key]
                break
    if df_heat is None or df_heat.empty:
        return html.Div("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # æ—¥ä»˜åˆ—ã‚’æŠ½å‡º
    date_cols = [c for c in df_heat.columns if pd.to_datetime(c, errors='coerce') is not pd.NaT]
    if not date_cols:
        return html.Div("æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    time_labels = gen_labels(30)
    # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—
    staff_df = df_heat[date_cols].fillna(0).reindex(time_labels, fill_value=0)
    need_series = df_heat.get('need', pd.Series()).fillna(0)
    upper_series = df_heat.get('upper', pd.Series()).fillna(0)

    # DataFrameã«å¤‰æ›
    need_df = pd.DataFrame(
        np.repeat(need_series.values[:, np.newaxis], len(date_cols), axis=1),
        index=time_labels,
        columns=date_cols
    )
    upper_df = pd.DataFrame(
        np.repeat(upper_series.values[:, np.newaxis], len(date_cols), axis=1),
        index=time_labels,
        columns=date_cols
    )

    # å„æŒ‡æ¨™ã‚’è¨ˆç®—
    surplus_df = (staff_df - need_df).clip(lower=0)
    margin_df = (upper_df - staff_df).clip(lower=0)
    surplus_df = surplus_df.reindex(time_labels, fill_value=0)
    margin_df = margin_df.reindex(time_labels, fill_value=0)

    # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆä¸è¶³ã¨éå‰°ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
    lack_ratio = ((need_df - staff_df) / need_df.replace(0, np.nan)).clip(lower=0).fillna(0)
    excess_ratio = ((staff_df - upper_df) / upper_df.replace(0, np.nan)).clip(lower=0).fillna(0)
    score_df = 1 - (0.6 * lack_ratio + 0.4 * excess_ratio)
    score_df = score_df.clip(lower=0, upper=1)
    score_df = score_df.reindex(time_labels, fill_value=0)

    content = []

    # 1. å¿…è¦äººæ•°ã«å¯¾ã™ã‚‹ä½™å‰°
    content.append(html.Div([
        html.H4("1. å¿…è¦äººæ•°ã«å¯¾ã™ã‚‹ä½™å‰° (Surplus vs Need)"),
        html.P("å„æ™‚é–“å¸¯ã§å¿…è¦äººæ•°ï¼ˆneedï¼‰ã«å¯¾ã—ã¦ä½•äººå¤šãã‚¹ã‚¿ãƒƒãƒ•ãŒã„ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚"),
        dcc.Graph(figure=px.imshow(
            surplus_df,
            aspect='auto',
            color_continuous_scale='Blues',
            title='å¿…è¦äººæ•°ã«å¯¾ã™ã‚‹ä½™å‰°äººå“¡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
            labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ä½™å‰°äººæ•°'}
        ).update_xaxes(
            ticktext=[date_with_weekday(c) for c in surplus_df.columns],
            tickvals=list(range(len(surplus_df.columns)))
        ))
    ]))

    # 2. ä¸Šé™ã«å¯¾ã™ã‚‹ä½™ç™½
    content.append(html.Div([
        html.H4("2. ä¸Šé™ã«å¯¾ã™ã‚‹ä½™ç™½ (Margin to Upper)", style={'marginTop': '30px'}),
        html.P("å„æ™‚é–“å¸¯ã§é…ç½®äººæ•°ã®ä¸Šé™ï¼ˆupperï¼‰ã¾ã§ã‚ã¨ä½•äººã®ä½™è£•ãŒã‚ã£ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚"),
        dcc.Graph(figure=px.imshow(
            margin_df,
            aspect='auto',
            color_continuous_scale='Greens',
            title='ä¸Šé™äººæ•°ã¾ã§ã®ä½™ç™½ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
            labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ä½™ç™½äººæ•°'}
        ).update_xaxes(
            ticktext=[date_with_weekday(c) for c in margin_df.columns],
            tickvals=list(range(len(margin_df.columns)))
        )),
        dcc.Markdown(
            "æ³¨: ã“ã®ä½™ç™½ã¯ã€éå»ã®å®Ÿç¸¾ã‹ã‚‰ç®—å‡ºã•ã‚ŒãŸä¸Šé™äººæ•°ã¨å®Ÿéš›ã®é…ç½®äººæ•°ã®å·®ã‚’ç¤ºã—ã¾ã™ã€‚"\
            "éœ€è¦ãŒä½ã„æ—¥ã‚„ä¼‘æ¥­æ—¥ï¼ˆä¾‹: æ—¥æ›œæ—¥ï¼‰ã¯ã€éå»ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãä¸Šé™å€¤ãŒé«˜ã‚ã«ç®—å‡º"\
            "ã•ã‚Œã‚‹ã“ã¨ã§ã€è¦‹ã‹ã‘ä¸Šã®ä½™ç™½ãŒå¤§ãããªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ã€æ½œåœ¨çš„ãªé"\
            "å‰°äººå“¡ã‚„ã‚³ã‚¹ãƒˆç™ºç”Ÿã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚",
            style={'marginTop': '10px'}
        )
    ]))

    # 3. æœ€é©åŒ–ã‚¹ã‚³ã‚¢
    content.append(html.Div([
        html.H4("3. äººå“¡é…ç½® æœ€é©åŒ–ã‚¹ã‚³ã‚¢", style={'marginTop': '30px'}),
        html.P("äººå“¡é…ç½®ã®åŠ¹ç‡æ€§ã‚’0ã‹ã‚‰1ã®ã‚¹ã‚³ã‚¢ã§ç¤ºã—ã¾ã™ï¼ˆ1ãŒæœ€ã‚‚è‰¯ã„ï¼‰ã€‚"),
        dcc.Graph(figure=px.imshow(
            score_df,
            aspect='auto',
            color_continuous_scale='RdYlGn',
            zmin=0,
            zmax=1,
            title='æœ€é©åŒ–ã‚¹ã‚³ã‚¢ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
            labels={'x': 'æ—¥ä»˜', 'y': 'æ™‚é–“', 'color': 'ã‚¹ã‚³ã‚¢'}
        ).update_xaxes(
            ticktext=[date_with_weekday(c) for c in score_df.columns],
            tickvals=list(range(len(score_df.columns)))
        ))
    ]))

    return html.Div(content)


@app.callback(
    Output('overview-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_overview_insights(kpi_data):
    if not kpi_data:
        return ""

    total_lack_h = kpi_data.get('total_lack_h', 0)

    if total_lack_h > 0:
        most_lacking_role = kpi_data.get('most_lacking_role_name', 'N/A')
        most_lacking_hours = kpi_data.get('most_lacking_role_hours', 0)
        insight_text = f"""
        #### ğŸ“ˆ åˆ†æãƒã‚¤ãƒ©ã‚¤ãƒˆ
        - **ç·ä¸è¶³æ™‚é–“:** {total_lack_h:.1f} æ™‚é–“
        - **æœ€é‡è¦èª²é¡Œ:** **{most_lacking_role}** ã®ä¸è¶³ãŒ **{most_lacking_hours:.1f}æ™‚é–“** ã¨æœ€ã‚‚æ·±åˆ»ã§ã™ã€‚ã“ã®è·ç¨®ã®æ¡ç”¨ã¾ãŸã¯é…ç½®è»¢æ›ãŒæ€¥å‹™ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚
        """
        return dcc.Markdown(insight_text)
    return html.P(
        "ğŸ‘ äººå“¡ä¸è¶³ã¯ç™ºç”Ÿã—ã¦ã„ã¾ã›ã‚“ã€‚ç´ æ™´ã‚‰ã—ã„å‹¤å‹™ä½“åˆ¶ã§ã™ï¼",
        style={'fontWeight': 'bold'},
    )


@app.callback(
    Output('shortage-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_shortage_insights(kpi_data):
    explanation = """
    #### ä¸è¶³åˆ†æã®è©•ä¾¡æ–¹æ³•
    - **ä¸è¶³ (Shortage):** `ä¸è¶³äººæ•° = å¿…è¦äººæ•° (Need) - å®Ÿç¸¾äººæ•°` ã§è¨ˆç®—ã•ã‚Œã¾ã™ã€‚å€¤ãŒãƒ—ãƒ©ã‚¹ã®å ´åˆã€ãã®æ™‚é–“å¸¯ã¯äººå“¡ãŒä¸è¶³ã—ã¦ã„ãŸã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
    - **éå‰° (Excess):** `éå‰°äººæ•° = å®Ÿç¸¾äººæ•° - ä¸Šé™äººæ•° (Upper)` ã§è¨ˆç®—ã•ã‚Œã¾ã™ã€‚å€¤ãŒãƒ—ãƒ©ã‚¹ã®å ´åˆã€éå‰°ãªäººå“¡ãŒé…ç½®ã•ã‚Œã¦ã„ãŸã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚

    *ã€Œå¿…è¦äººæ•°ã€ã¨ã€Œä¸Šé™äººæ•°ã€ã¯ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œåˆ†æåŸºæº–è¨­å®šã€ã§æŒ‡å®šã—ãŸæ–¹æ³•ï¼ˆéå»å®Ÿç¸¾ã®çµ±è¨ˆã€ã¾ãŸã¯äººå“¡é…ç½®åŸºæº–ï¼‰ã«åŸºã¥ã„ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚*
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('hire-plan-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_hire_plan_insights(kpi_data):
    if not kpi_data:
        return ""
    total_lack_h = kpi_data.get('total_lack_h', 0)
    if total_lack_h == 0:
        return html.P("è¿½åŠ æ¡ç”¨ã®å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    role = kpi_data.get('most_lacking_role_name', 'N/A')
    return dcc.Markdown(
        f"æœ€ã‚‚ä¸è¶³ã—ã¦ã„ã‚‹ **{role}** ã®è£œå……ã‚’å„ªå…ˆçš„ã«æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
    )


@app.callback(
    Output('optimization-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_optimization_insights(kpi_data):
    explanation = """
    #### æœ€é©åŒ–åˆ†æã®è©•ä¾¡æ–¹æ³•
    äººå“¡é…ç½®ã®åŠ¹ç‡æ€§ã¯ã€ä»¥ä¸‹ã®2ã¤ã®è¦³ç‚¹ã‹ã‚‰ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’è¨ˆç®—ã—ã€æœ€çµ‚çš„ãªã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—ã¾ã™ã€‚
    - **ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ (é‡ã¿: 60%):** `(å¿…è¦äººæ•° - å®Ÿç¸¾äººæ•°) / å¿…è¦äººæ•°`
    - **éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£ (é‡ã¿: 40%):** `(å®Ÿç¸¾äººæ•° - ä¸Šé™äººæ•°) / ä¸Šé™äººæ•°`

    **æœ€é©åŒ–ã‚¹ã‚³ã‚¢ = 1 - (ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£ Ã— 0.6 + éå‰°ãƒšãƒŠãƒ«ãƒ†ã‚£ Ã— 0.4)**

    *ã‚¹ã‚³ã‚¢ãŒ1ã«è¿‘ã„ã»ã©ã€ä¸è¶³ã‚‚éå‰°ã‚‚ãªãã€åŠ¹ç‡çš„ãªäººå“¡é…ç½®ãŒã§ãã¦ã„ã‚‹çŠ¶æ…‹ã‚’ç¤ºã—ã¾ã™ã€‚*
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('leave-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_leave_insights(kpi_data):
    explanation = """
    #### ä¼‘æš‡åˆ†æã®è©•ä¾¡æ–¹æ³•
    - **ä¼‘æš‡å–å¾—è€…æ•°:** `holiday_type`ãŒä¼‘æš‡é–¢é€£ï¼ˆå¸Œæœ›ä¼‘ã€æœ‰çµ¦ãªã©ï¼‰ã«è¨­å®šã•ã‚Œã€ã‹ã¤å‹¤å‹™æ™‚é–“ãŒãªã„ï¼ˆ`parsed_slots_count = 0`ï¼‰å ´åˆã«ã€Œ1æ—¥ã€ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã¾ã™ã€‚
    - **é›†ä¸­æ—¥:** ã€Œå¸Œæœ›ä¼‘ã€ã®å–å¾—è€…æ•°ãŒã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ãŸé–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3äººï¼‰ä»¥ä¸Šã«ãªã£ãŸæ—¥ã‚’ã€Œé›†ä¸­æ—¥ã€ã¨ã—ã¦ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¾ã™ã€‚
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('cost-insights', 'children'),
    Input('kpi-data-store', 'data'),
)
def update_cost_insights(kpi_data):
    explanation = """
    #### ã‚³ã‚¹ãƒˆåˆ†æã®è©•ä¾¡æ–¹æ³•
    æ—¥ã€…ã®äººä»¶è²»ã¯ã€å„ã‚¹ã‚¿ãƒƒãƒ•ã®å‹¤å‹™æ™‚é–“ï¼ˆã‚¹ãƒ­ãƒƒãƒˆæ•° Ã— ã‚¹ãƒ­ãƒƒãƒˆé•·ï¼‰ã«ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã—ãŸå˜ä¾¡åŸºæº–ï¼ˆè·ç¨®åˆ¥ã€é›‡ç”¨å½¢æ…‹åˆ¥ãªã©ï¼‰ã®æ™‚çµ¦ã‚’ä¹—ã˜ã¦ç®—å‡ºã•ã‚Œã¾ã™ã€‚
    """
    return dcc.Markdown(explanation)


@app.callback(
    Output('sim-shortage-graph', 'figure'),
    Output('sim-cost-text', 'children'),
    Input('sim-work-pattern-dropdown', 'value'),
    Input('sim-hire-fte-slider', 'value'),
    State('kpi-data-store', 'data'),
)
def update_hire_simulation(selected_pattern, added_fte, kpi_data):
    if not kpi_data or not selected_pattern:
        raise PreventUpdate

    from shift_suite.tasks.h2hire import (
        AVG_HOURLY_WAGE,
        RECRUIT_COST_PER_HIRE,
    )

    df_work_patterns = DATA_STORE.get('work_patterns', pd.DataFrame())
    df_shortage_role = DATA_STORE.get('shortage_role_summary', pd.DataFrame()).copy()

    pattern_info = df_work_patterns[df_work_patterns['code'] == selected_pattern]
    if pattern_info.empty:
        raise PreventUpdate
    slots_per_day = pattern_info['parsed_slots_count'].iloc[0]
    hours_per_day = slots_per_day * 0.5
    reduction_hours = added_fte * hours_per_day * 20

    if not df_shortage_role.empty:
        most_lacking_role_index = df_shortage_role['lack_h'].idxmax()
        original_hours = df_shortage_role.loc[most_lacking_role_index, 'lack_h']
        df_shortage_role.loc[most_lacking_role_index, 'lack_h'] = max(0, original_hours - reduction_hours)

    fig = px.bar(
        df_shortage_role,
        x='role',
        y='lack_h',
        title=f'ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¾Œ: {selected_pattern}å‹¤å‹™è€…ã‚’{added_fte}äººè¿½åŠ æ¡ç”¨ã—ãŸå ´åˆã®æ®‹å­˜ä¸è¶³æ™‚é–“',
        labels={'lack_h': 'æ®‹å­˜ä¸è¶³æ™‚é–“(h)'},
    )

    new_total_lack_h = df_shortage_role['lack_h'].sum()
    original_total_lack_h = kpi_data.get('total_lack_h', 0)

    cost_before = original_total_lack_h * 2200
    cost_after_temp = new_total_lack_h * 2200

    added_labor_cost = reduction_hours * AVG_HOURLY_WAGE
    added_recruit_cost = added_fte * RECRUIT_COST_PER_HIRE
    cost_after_hire = cost_after_temp + added_labor_cost + added_recruit_cost

    cost_text = f"""
    #### ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
    - **æ¡ç”¨ã‚³ã‚¹ãƒˆ:** {added_recruit_cost:,.0f} å†† (ä¸€æ™‚)
    - **è¿½åŠ äººä»¶è²»:** {added_labor_cost:,.0f} å†† (æœŸé–“ä¸­)
    - **ç·ã‚³ã‚¹ãƒˆ (æ¡ç”¨ã‚·ãƒŠãƒªã‚ª):** {cost_after_hire:,.0f} å††
    - **æ¯”è¼ƒ (å…¨ã¦æ´¾é£ã§è£œå¡«ã—ãŸå ´åˆ):** {cost_before:,.0f} å††
    """

    return fig, dcc.Markdown(cost_text)


@app.callback(
    Output('factor-output', 'children'),
    Input('factor-train-button', 'n_clicks')
)
def run_factor_analysis(n_clicks):
    if not n_clicks:
        raise PreventUpdate

    heat_df = DATA_STORE.get('heat_ALL', pd.DataFrame())
    short_df = DATA_STORE.get('shortage_time', pd.DataFrame())
    leave_df = DATA_STORE.get('leave_analysis', pd.DataFrame())

    if heat_df.empty or short_df.empty:
        return html.Div('å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“')

    analyzer = ShortageFactorAnalyzer()
    feat_df = analyzer.generate_features(pd.DataFrame(), heat_df, short_df, leave_df, set())
    model, fi_df = analyzer.train_and_get_feature_importance(feat_df)
    DATA_STORE['factor_features'] = feat_df
    DATA_STORE['factor_importance'] = fi_df

    table = dash_table.DataTable(
        data=fi_df.head(5).to_dict('records'),
        columns=[{'name': c, 'id': c} for c in fi_df.columns]
    )
    return html.Div([html.H5('Top factors'), table])


@app.callback(
    Output('save-log-msg', 'children'),
    Input('save-log-button', 'n_clicks'),
    State('over-shortage-table', 'data'),
    State('log-save-mode', 'value')
)
def save_over_shortage_log(n_clicks, table_data, mode):
    if not n_clicks:
        raise PreventUpdate

    log_path = DATA_STORE.get('shortage_log_path')
    if not log_path:
        return 'ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'

    df = pd.DataFrame(table_data)
    over_shortage_log.save_log(df, log_path, mode=mode)
    return 'ãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ'

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹• ---
if __name__ == '__main__':
    app.run_server(debug=True, port=8050, host='127.0.0.1')
