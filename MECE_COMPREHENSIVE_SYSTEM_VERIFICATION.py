"""
MECEåŒ…æ‹¬çš„ã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½æ¤œè¨¼
ãƒ‡ãƒ¼ã‚¿å…¥ç¨¿â†’åˆ†è§£â†’åˆ†æžâ†’åŠ å·¥â†’å¯è¦–åŒ–ã®å…¨ãƒ•ãƒ­ãƒ¼ã‚’å¾¹åº•æ¤œè¨¼
"""

import os
import sys
import json
import datetime
import importlib.util
import traceback
from typing import Dict, List, Any, Optional, Union, Tuple
from enum import Enum
from pathlib import Path

class VerificationCategory(Enum):
    DATA_INGESTION = "ãƒ‡ãƒ¼ã‚¿å…¥ç¨¿"
    DATA_DECOMPOSITION = "ãƒ‡ãƒ¼ã‚¿åˆ†è§£" 
    DATA_ANALYSIS = "ãƒ‡ãƒ¼ã‚¿åˆ†æž"
    RESULT_PROCESSING = "åˆ†æžçµæžœåŠ å·¥"
    VISUALIZATION = "å¯è¦–åŒ–"
    END_TO_END_FLOW = "ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ•ãƒ­ãƒ¼"

class VerificationSeverity(Enum):
    CRITICAL = "è‡´å‘½çš„"
    HIGH = "é«˜"
    MEDIUM = "ä¸­"
    LOW = "ä½Ž"
    INFO = "æƒ…å ±"

class SystemComponent(Enum):
    CORE_ENGINE = "ã‚³ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³"
    AI_ML_INTEGRATION = "AI/MLçµ±åˆ"
    USABILITY_LAYER = "ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£å±¤"
    DATA_LAYER = "ãƒ‡ãƒ¼ã‚¿å±¤"
    VISUALIZATION_LAYER = "å¯è¦–åŒ–å±¤"

class MECEComprehensiveVerifier:
    """MECEåŒ…æ‹¬çš„ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.base_path = "/mnt/c/Users/fuji1/OneDrive/ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/ã‚·ãƒ•ãƒˆåˆ†æž"
        self.verification_start_time = datetime.datetime.now()
        
        # æ¤œè¨¼å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«
        self.system_files = {
            'core_system': [
                'app.py',
                'dash_app.py', 
                'shift_suite/__init__.py'
            ],
            'data_processing': [
                'shift_suite/tasks/utils.py',
                'shift_suite/tasks/shortage.py',
                'shift_suite/tasks/build_stats.py'
            ],
            'ai_ml_integration': [
                'dash_app_ai_ml_enhanced.py',
                'p2a2_realtime_prediction_display.py',
                'p2a3_anomaly_alert_system.py',
                'p2a4_optimization_visualization.py'
            ],
            'usability_enhancement': [
                'p3a1_customizable_reports.py',
                'p3a2_mobile_responsive_ui.py', 
                'p3a4_user_preferences.py'
            ],
            'maintenance_optimization': [
                'm1_system_maintenance_optimization.py'
            ],
            'system_expansion': [
                's1_system_expansion.py'
            ]
        }
        
        # æ¤œè¨¼çµæžœæ ¼ç´
        self.verification_results = {
            'session_id': f'mece_verification_{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}',
            'start_time': self.verification_start_time.isoformat(),
            'categories': {},
            'components': {},
            'critical_issues': [],
            'recommendations': [],
            'overall_assessment': {}
        }
    
    def execute_comprehensive_verification(self):
        """åŒ…æ‹¬çš„æ¤œè¨¼å®Ÿè¡Œ"""
        
        print("ðŸ” MECEåŒ…æ‹¬çš„ã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½æ¤œè¨¼é–‹å§‹...")
        print(f"ðŸ“Š æ¤œè¨¼ã‚«ãƒ†ã‚´ãƒª: {len(VerificationCategory)}ã‚«ãƒ†ã‚´ãƒª")
        print(f"ðŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: {len(SystemComponent)}ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ")
        print("=" * 80)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ¤œè¨¼å®Ÿè¡Œ
        for category in VerificationCategory:
            print(f"\nðŸŽ¯ {category.value} æ¤œè¨¼é–‹å§‹...")
            category_result = self._verify_category(category)
            self.verification_results['categories'][category.value] = category_result
            
            # è‡´å‘½çš„å•é¡Œã®æŠ½å‡º
            if category_result.get('critical_issues'):
                self.verification_results['critical_issues'].extend(category_result['critical_issues'])
        
        # ç·åˆåˆ†æžãƒ»è©•ä¾¡
        self._perform_comprehensive_analysis()
        self._generate_recommendations()
        self._calculate_overall_assessment()
        
        # æ¤œè¨¼å®Œäº†
        self.verification_results['end_time'] = datetime.datetime.now().isoformat()
        self.verification_results['total_duration_minutes'] = (
            datetime.datetime.now() - self.verification_start_time
        ).total_seconds() / 60
        
        return self.verification_results
    
    def _verify_category(self, category: VerificationCategory) -> Dict[str, Any]:
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥æ¤œè¨¼å®Ÿè¡Œ"""
        
        category_result = {
            'category': category.value,
            'tests_executed': [],
            'passed_tests': 0,
            'failed_tests': 0,
            'critical_issues': [],
            'findings': [],
            'score': 0.0
        }
        
        if category == VerificationCategory.DATA_INGESTION:
            category_result = self._verify_data_ingestion()
        elif category == VerificationCategory.DATA_DECOMPOSITION:
            category_result = self._verify_data_decomposition()
        elif category == VerificationCategory.DATA_ANALYSIS:
            category_result = self._verify_data_analysis()
        elif category == VerificationCategory.RESULT_PROCESSING:
            category_result = self._verify_result_processing()
        elif category == VerificationCategory.VISUALIZATION:
            category_result = self._verify_visualization()
        elif category == VerificationCategory.END_TO_END_FLOW:
            category_result = self._verify_end_to_end_flow()
        
        return category_result
    
    def _verify_data_ingestion(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿å…¥ç¨¿ãƒ•ãƒ­ãƒ¼æ¤œè¨¼"""
        
        print("  ðŸ“¥ ãƒ‡ãƒ¼ã‚¿å…¥ç¨¿ãƒ•ãƒ­ãƒ¼æ¤œè¨¼ä¸­...")
        
        result = {
            'category': 'ãƒ‡ãƒ¼ã‚¿å…¥ç¨¿',
            'tests_executed': [],
            'passed_tests': 0,
            'failed_tests': 0,
            'critical_issues': [],
            'findings': []
        }
        
        # ãƒ†ã‚¹ãƒˆ1: Excel/CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ©Ÿèƒ½
        test_name = "Excel/CSVèª­ã¿è¾¼ã¿æ©Ÿèƒ½"
        try:
            # utils.pyã®safe_read_excelé–¢æ•°ç¢ºèª
            utils_path = os.path.join(self.base_path, 'shift_suite/tasks/utils.py')
            if os.path.exists(utils_path):
                with open(utils_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'safe_read_excel' in content and 'pd.read_excel' in content:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'Excel/CSVèª­ã¿è¾¼ã¿é–¢æ•°ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'FAIL',
                            'details': 'Excel/CSVèª­ã¿è¾¼ã¿é–¢æ•°ãŒè¦‹ã¤ã‹ã‚‰ãªã„',
                            'severity': VerificationSeverity.HIGH.value
                        })
                        result['failed_tests'] += 1
            else:
                result['critical_issues'].append({
                    'issue': f'{test_name}: utils.pyãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„',
                    'severity': VerificationSeverity.CRITICAL.value
                })
                result['failed_tests'] += 1
        except Exception as e:
            result['critical_issues'].append({
                'issue': f'{test_name}: {str(e)}',
                'severity': VerificationSeverity.CRITICAL.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ2: ZIPãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ
        test_name = "ZIPãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ"
        try:
            # dash_app.pyã§ã®ZIPå‡¦ç†ç¢ºèª
            dash_app_path = os.path.join(self.base_path, 'dash_app.py')
            if os.path.exists(dash_app_path):
                with open(dash_app_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'zipfile' in content and 'ZipFile' in content:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'ZIPãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'ZIPãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãŒé™å®šçš„',
                            'severity': VerificationSeverity.MEDIUM.value
                        })
                        result['failed_tests'] += 1
            else:
                result['critical_issues'].append({
                    'issue': f'{test_name}: dash_app.pyãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„',
                    'severity': VerificationSeverity.CRITICAL.value
                })
                result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.HIGH.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ3: ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        test_name = "ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"
        try:
            # utils.pyã®_valid_dfé–¢æ•°ç¢ºèª
            if os.path.exists(utils_path):
                with open(utils_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if '_valid_df' in content and 'validation' in content.lower():
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'FAIL',
                            'details': 'ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ãŒä¸ååˆ†',
                            'severity': VerificationSeverity.HIGH.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.MEDIUM.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ4: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        test_name = "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"
        try:
            error_handling_count = 0
            for file_category, files in self.system_files.items():
                for file_name in files:
                    file_path = os.path.join(self.base_path, file_name)
                    if os.path.exists(file_path):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            if 'try:' in content and 'except' in content:
                                error_handling_count += 1
            
            if error_handling_count >= len(self.system_files) * 0.8:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PASS',
                    'details': f'ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒ{error_handling_count}ãƒ•ã‚¡ã‚¤ãƒ«ã§å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                })
                result['passed_tests'] += 1
            else:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PARTIAL',
                    'details': f'ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒ{error_handling_count}ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã§å®Ÿè£…',
                    'severity': VerificationSeverity.MEDIUM.value
                })
                result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.MEDIUM.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        total_tests = len(result['tests_executed'])
        if total_tests > 0:
            result['score'] = (result['passed_tests'] / total_tests) * 100
        
        print(f"    ðŸ“Š ãƒ‡ãƒ¼ã‚¿å…¥ç¨¿ãƒ•ãƒ­ãƒ¼: {result['passed_tests']}/{total_tests} ãƒ†ã‚¹ãƒˆåˆæ ¼ ({result['score']:.1f}%)")
        
        return result
    
    def _verify_data_decomposition(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿åˆ†è§£ãƒ—ãƒ­ã‚»ã‚¹æ¤œè¨¼"""
        
        print("  ðŸ”§ ãƒ‡ãƒ¼ã‚¿åˆ†è§£ãƒ—ãƒ­ã‚»ã‚¹æ¤œè¨¼ä¸­...")
        
        result = {
            'category': 'ãƒ‡ãƒ¼ã‚¿åˆ†è§£',
            'tests_executed': [],
            'passed_tests': 0,
            'failed_tests': 0,
            'critical_issues': [],
            'findings': []
        }
        
        # ãƒ†ã‚¹ãƒˆ1: ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿æ§‹é€ è§£æž
        test_name = "ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿æ§‹é€ è§£æž"
        try:
            utils_path = os.path.join(self.base_path, 'shift_suite/tasks/utils.py')
            if os.path.exists(utils_path):
                with open(utils_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'gen_labels' in content and 'shift' in content.lower():
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿æ§‹é€ è§£æžæ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'FAIL',
                            'details': 'ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿æ§‹é€ è§£æžæ©Ÿèƒ½ãŒä¸ååˆ†',
                            'severity': VerificationSeverity.HIGH.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.HIGH.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ2: å½¹è·ãƒ»æ™‚é–“è»¸åˆ†è§£
        test_name = "å½¹è·ãƒ»æ™‚é–“è»¸åˆ†è§£"
        try:
            shortage_path = os.path.join(self.base_path, 'shift_suite/tasks/shortage.py')
            if os.path.exists(shortage_path):
                with open(shortage_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'role' in content.lower() and 'time' in content.lower():
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'å½¹è·ãƒ»æ™‚é–“è»¸åˆ†è§£æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'å½¹è·ãƒ»æ™‚é–“è»¸åˆ†è§£æ©Ÿèƒ½ãŒé™å®šçš„',
                            'severity': VerificationSeverity.MEDIUM.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.MEDIUM.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ3: ä¼‘æ—¥ãƒ»å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜
        test_name = "ä¼‘æ—¥ãƒ»å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜"
        try:
            # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®ä¼‘æ—¥å‡¦ç†ç¢ºèª
            holiday_implementation_found = False
            for file_category, files in self.system_files.items():
                for file_name in files:
                    file_path = os.path.join(self.base_path, file_name)
                    if os.path.exists(file_path):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            if 'holiday' in content.lower() or 'ä¼‘æ—¥' in content:
                                holiday_implementation_found = True
                                break
                if holiday_implementation_found:
                    break
            
            if holiday_implementation_found:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PASS',
                    'details': 'ä¼‘æ—¥ãƒ»å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                })
                result['passed_tests'] += 1
            else:
                result['findings'].append({
                    'test': test_name,
                    'status': 'FAIL',
                    'details': 'ä¼‘æ—¥ãƒ»å‹¤å‹™ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜æ©Ÿèƒ½ãŒè¦‹ã¤ã‹ã‚‰ãªã„',
                    'severity': VerificationSeverity.HIGH.value
                })
                result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.MEDIUM.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ4: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        test_name = "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"
        try:
            build_stats_path = os.path.join(self.base_path, 'shift_suite/tasks/build_stats.py')
            if os.path.exists(build_stats_path):
                with open(build_stats_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'metadata' in content.lower() or 'çµ±è¨ˆ' in content:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæ©Ÿèƒ½ãŒé™å®šçš„',
                            'severity': VerificationSeverity.LOW.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.LOW.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        total_tests = len(result['tests_executed'])
        if total_tests > 0:
            result['score'] = (result['passed_tests'] / total_tests) * 100
        
        print(f"    ðŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†è§£ãƒ—ãƒ­ã‚»ã‚¹: {result['passed_tests']}/{total_tests} ãƒ†ã‚¹ãƒˆåˆæ ¼ ({result['score']:.1f}%)")
        
        return result
    
    def _verify_data_analysis(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿åˆ†æžã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¤œè¨¼"""
        
        print("  ðŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ†æžã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¤œè¨¼ä¸­...")
        
        result = {
            'category': 'ãƒ‡ãƒ¼ã‚¿åˆ†æž',
            'tests_executed': [],
            'passed_tests': 0,
            'failed_tests': 0,
            'critical_issues': [],
            'findings': []
        }
        
        # ãƒ†ã‚¹ãƒˆ1: AI/MLéœ€è¦äºˆæ¸¬ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
        test_name = "AI/MLéœ€è¦äºˆæ¸¬ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ "
        try:
            prediction_path = os.path.join(self.base_path, 'p2a2_realtime_prediction_display.py')
            if os.path.exists(prediction_path):
                with open(prediction_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'prediction' in content.lower() and 'forecast' in content.lower():
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'AI/MLéœ€è¦äºˆæ¸¬ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'AI/MLéœ€è¦äºˆæ¸¬ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒé™å®šçš„',
                            'severity': VerificationSeverity.MEDIUM.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.HIGH.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ2: ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
        test_name = "ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ "
        try:
            anomaly_path = os.path.join(self.base_path, 'p2a3_anomaly_alert_system.py')
            if os.path.exists(anomaly_path):
                with open(anomaly_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'anomaly' in content.lower() and 'detection' in content.lower():
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ãŒé™å®šçš„',
                            'severity': VerificationSeverity.MEDIUM.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.HIGH.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ3: æœ€é©åŒ–è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
        test_name = "æœ€é©åŒ–è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³"
        try:
            optimization_path = os.path.join(self.base_path, 'p2a4_optimization_visualization.py')
            if os.path.exists(optimization_path):
                with open(optimization_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'optimization' in content.lower() and 'algorithm' in content.lower():
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'æœ€é©åŒ–è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'æœ€é©åŒ–è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³ãŒé™å®šçš„',
                            'severity': VerificationSeverity.MEDIUM.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.HIGH.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ4: çµ±è¨ˆåˆ†æžæ©Ÿèƒ½
        test_name = "çµ±è¨ˆåˆ†æžæ©Ÿèƒ½"
        try:
            # shortage.pyã§ã®çµ±è¨ˆè¨ˆç®—ç¢ºèª
            shortage_path = os.path.join(self.base_path, 'shift_suite/tasks/shortage.py')
            if os.path.exists(shortage_path):
                with open(shortage_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'statistics' in content.lower() or 'çµ±è¨ˆ' in content:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'çµ±è¨ˆåˆ†æžæ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'çµ±è¨ˆåˆ†æžæ©Ÿèƒ½ãŒé™å®šçš„',
                            'severity': VerificationSeverity.LOW.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.MEDIUM.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        total_tests = len(result['tests_executed'])
        if total_tests > 0:
            result['score'] = (result['passed_tests'] / total_tests) * 100
        
        print(f"    ðŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æžã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : {result['passed_tests']}/{total_tests} ãƒ†ã‚¹ãƒˆåˆæ ¼ ({result['score']:.1f}%)")
        
        return result
    
    def _verify_result_processing(self) -> Dict[str, Any]:
        """åˆ†æžçµæžœåŠ å·¥ãƒ—ãƒ­ã‚»ã‚¹æ¤œè¨¼"""
        
        print("  âš™ï¸ åˆ†æžçµæžœåŠ å·¥ãƒ—ãƒ­ã‚»ã‚¹æ¤œè¨¼ä¸­...")
        
        result = {
            'category': 'åˆ†æžçµæžœåŠ å·¥',
            'tests_executed': [],
            'passed_tests': 0,
            'failed_tests': 0,
            'critical_issues': [],
            'findings': []
        }
        
        # ãƒ†ã‚¹ãƒˆ1: KPIè¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ 
        test_name = "KPIè¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ "
        try:
            # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®KPIè¨ˆç®—ç¢ºèª
            kpi_implementation_found = False
            for file_category, files in self.system_files.items():
                for file_name in files:
                    file_path = os.path.join(self.base_path, file_name)
                    if os.path.exists(file_path):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            if 'kpi' in content.lower() or 'metrics' in content.lower():
                                kpi_implementation_found = True
                                break
                if kpi_implementation_found:
                    break
            
            if kpi_implementation_found:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PASS',
                    'details': 'KPIè¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                })
                result['passed_tests'] += 1
            else:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PARTIAL',
                    'details': 'KPIè¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ ãŒé™å®šçš„',
                    'severity': VerificationSeverity.MEDIUM.value
                })
                result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.MEDIUM.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ2: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
        test_name = "ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ "
        try:
            reports_path = os.path.join(self.base_path, 'p3a1_customizable_reports.py')
            if os.path.exists(reports_path):
                with open(reports_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'report' in content.lower() and 'generate' in content.lower():
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ãŒé™å®šçš„',
                            'severity': VerificationSeverity.MEDIUM.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.MEDIUM.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ3: ãƒ‡ãƒ¼ã‚¿é›†ç´„ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        test_name = "ãƒ‡ãƒ¼ã‚¿é›†ç´„ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"
        try:
            # utils.pyã§ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ©Ÿèƒ½ç¢ºèª
            utils_path = os.path.join(self.base_path, 'shift_suite/tasks/utils.py')
            if os.path.exists(utils_path):
                with open(utils_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'filter' in content.lower() and 'aggregate' in content.lower():
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'ãƒ‡ãƒ¼ã‚¿é›†ç´„ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'ãƒ‡ãƒ¼ã‚¿é›†ç´„ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ãŒé™å®šçš„',
                            'severity': VerificationSeverity.MEDIUM.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.MEDIUM.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ4: ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
        test_name = "ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½"  
        try:
            # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½ç¢ºèª
            export_implementation_found = False
            for file_category, files in self.system_files.items():
                for file_name in files:
                    file_path = os.path.join(self.base_path, file_name)
                    if os.path.exists(file_path):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            if 'export' in content.lower() or 'download' in content.lower():
                                export_implementation_found = True
                                break
                if export_implementation_found:
                    break
            
            if export_implementation_found:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PASS',
                    'details': 'ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                })
                result['passed_tests'] += 1
            else:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PARTIAL',
                    'details': 'ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½ãŒé™å®šçš„',
                    'severity': VerificationSeverity.LOW.value
                })
                result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.LOW.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        total_tests = len(result['tests_executed'])
        if total_tests > 0:
            result['score'] = (result['passed_tests'] / total_tests) * 100
        
        print(f"    ðŸ“Š åˆ†æžçµæžœåŠ å·¥ãƒ—ãƒ­ã‚»ã‚¹: {result['passed_tests']}/{total_tests} ãƒ†ã‚¹ãƒˆåˆæ ¼ ({result['score']:.1f}%)")
        
        return result
    
    def _verify_visualization(self) -> Dict[str, Any]:
        """å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼"""
        
        print("  ðŸ“Š å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼ä¸­...")
        
        result = {
            'category': 'å¯è¦–åŒ–',
            'tests_executed': [],
            'passed_tests': 0,
            'failed_tests': 0,
            'critical_issues': [],
            'findings': []
        }
        
        # ãƒ†ã‚¹ãƒˆ1: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ©Ÿèƒ½
        test_name = "ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ©Ÿèƒ½"
        try:
            dash_app_path = os.path.join(self.base_path, 'dash_app.py')
            if os.path.exists(dash_app_path):
                with open(dash_app_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'dashboard' in content.lower() and 'layout' in content.lower():
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ©Ÿèƒ½ãŒé™å®šçš„',
                            'severity': VerificationSeverity.MEDIUM.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.HIGH.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ2: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒ¼ãƒˆ
        test_name = "ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒ¼ãƒˆ"
        try:
            # Plotlyãƒãƒ£ãƒ¼ãƒˆå®Ÿè£…ç¢ºèª
            plotly_implementation_found = False
            for file_category, files in self.system_files.items():
                for file_name in files:
                    file_path = os.path.join(self.base_path, file_name)
                    if os.path.exists(file_path):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            if 'plotly' in content.lower() and 'graph' in content.lower():
                                plotly_implementation_found = True
                                break
                if plotly_implementation_found:
                    break
            
            if plotly_implementation_found:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PASS',
                    'details': 'ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒ¼ãƒˆãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                })
                result['passed_tests'] += 1
            else:
                result['findings'].append({
                    'test': test_name,
                    'status': 'FAIL',
                    'details': 'ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„',
                    'severity': VerificationSeverity.HIGH.value
                })
                result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.HIGH.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ3: ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³
        test_name = "ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³"
        try:
            responsive_path = os.path.join(self.base_path, 'p3a2_mobile_responsive_ui.py')
            if os.path.exists(responsive_path):
                with open(responsive_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'responsive' in content.lower() and 'mobile' in content.lower():
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ãŒé™å®šçš„',
                            'severity': VerificationSeverity.MEDIUM.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.MEDIUM.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ4: ã‚«ã‚¹ã‚¿ãƒžã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½
        test_name = "ã‚«ã‚¹ã‚¿ãƒžã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½"
        try:
            preferences_path = os.path.join(self.base_path, 'p3a4_user_preferences.py')
            if os.path.exists(preferences_path):
                with open(preferences_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'preferences' in content.lower() and 'custom' in content.lower():
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PASS',
                            'details': 'ã‚«ã‚¹ã‚¿ãƒžã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                        })
                        result['passed_tests'] += 1
                    else:
                        result['findings'].append({
                            'test': test_name,
                            'status': 'PARTIAL',
                            'details': 'ã‚«ã‚¹ã‚¿ãƒžã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ãŒé™å®šçš„',
                            'severity': VerificationSeverity.LOW.value
                        })
                        result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.LOW.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        total_tests = len(result['tests_executed'])
        if total_tests > 0:
            result['score'] = (result['passed_tests'] / total_tests) * 100
        
        print(f"    ðŸ“Š å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ : {result['passed_tests']}/{total_tests} ãƒ†ã‚¹ãƒˆåˆæ ¼ ({result['score']:.1f}%)")
        
        return result
    
    def _verify_end_to_end_flow(self) -> Dict[str, Any]:
        """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ•ãƒ­ãƒ¼æ¤œè¨¼"""
        
        print("  ðŸ”„ ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ•ãƒ­ãƒ¼æ¤œè¨¼ä¸­...")
        
        result = {
            'category': 'ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ•ãƒ­ãƒ¼',
            'tests_executed': [],
            'passed_tests': 0,
            'failed_tests': 0,
            'critical_issues': [],
            'findings': []
        }
        
        # ãƒ†ã‚¹ãƒˆ1: ãƒ‡ãƒ¼ã‚¿å…¥ç¨¿â†’å¯è¦–åŒ–ãƒ•ãƒ­ãƒ¼
        test_name = "ãƒ‡ãƒ¼ã‚¿å…¥ç¨¿â†’å¯è¦–åŒ–ãƒ•ãƒ­ãƒ¼"
        try:
            # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®çµ±åˆãƒ•ãƒ­ãƒ¼ç¢ºèª
            main_flow_files = ['app.py', 'dash_app.py']
            flow_implementation_found = False
            
            for file_name in main_flow_files:
                file_path = os.path.join(self.base_path, file_name)
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if ('upload' in content.lower() and 
                            'process' in content.lower() and 
                            'display' in content.lower()):
                            flow_implementation_found = True
                            break
            
            if flow_implementation_found:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PASS',
                    'details': 'ãƒ‡ãƒ¼ã‚¿å…¥ç¨¿â†’å¯è¦–åŒ–ãƒ•ãƒ­ãƒ¼ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                })
                result['passed_tests'] += 1
            else:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PARTIAL',
                    'details': 'ãƒ‡ãƒ¼ã‚¿å…¥ç¨¿â†’å¯è¦–åŒ–ãƒ•ãƒ­ãƒ¼ãŒé™å®šçš„',
                    'severity': VerificationSeverity.HIGH.value
                })
                result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.HIGH.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ2: çµ±åˆãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ 
        test_name = "çµ±åˆãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ "
        try:
            integration_test_files = [
                'p2a5_phase2_integration_test.py',
                'p3a5_phase3_integration_test.py'
            ]
            
            integration_tests_found = 0
            for file_name in integration_test_files:
                file_path = os.path.join(self.base_path, file_name)
                if os.path.exists(file_path):
                    integration_tests_found += 1
            
            if integration_tests_found >= len(integration_test_files):
                result['findings'].append({
                    'test': test_name,
                    'status': 'PASS',
                    'details': f'çµ±åˆãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ãŒ{integration_tests_found}å€‹å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                })
                result['passed_tests'] += 1
            else:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PARTIAL',
                    'details': f'çµ±åˆãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ãŒ{integration_tests_found}å€‹ã®ã¿å®Ÿè£…',
                    'severity': VerificationSeverity.MEDIUM.value
                })
                result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.MEDIUM.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ãƒ†ã‚¹ãƒˆ3: ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ãƒ»ç®¡ç†
        test_name = "ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ãƒ»ç®¡ç†"
        try:
            management_files = [
                'start_production_system.py',
                'system_health_check.py'
            ]
            
            management_found = 0
            for file_name in management_files:
                file_path = os.path.join(self.base_path, file_name)
                if os.path.exists(file_path):
                    management_found += 1
            
            if management_found >= len(management_files) * 0.8:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PASS',
                    'details': f'ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ãƒ»ç®¡ç†æ©Ÿèƒ½ãŒ{management_found}å€‹å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹'
                })
                result['passed_tests'] += 1
            else:
                result['findings'].append({
                    'test': test_name,
                    'status': 'PARTIAL',
                    'details': f'ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ãƒ»ç®¡ç†æ©Ÿèƒ½ãŒ{management_found}å€‹ã®ã¿å®Ÿè£…',
                    'severity': VerificationSeverity.MEDIUM.value
                })
                result['failed_tests'] += 1
        except Exception as e:
            result['findings'].append({
                'test': test_name,
                'status': 'ERROR',
                'details': str(e),
                'severity': VerificationSeverity.MEDIUM.value
            })
            result['failed_tests'] += 1
        
        result['tests_executed'].append(test_name)
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        total_tests = len(result['tests_executed'])
        if total_tests > 0:
            result['score'] = (result['passed_tests'] / total_tests) * 100
        
        print(f"    ðŸ“Š ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ•ãƒ­ãƒ¼: {result['passed_tests']}/{total_tests} ãƒ†ã‚¹ãƒˆåˆæ ¼ ({result['score']:.1f}%)")
        
        return result
    
    def _perform_comprehensive_analysis(self):
        """åŒ…æ‹¬çš„åˆ†æžå®Ÿè¡Œ"""
        
        print("\nðŸ§  åŒ…æ‹¬çš„åˆ†æžå®Ÿè¡Œä¸­...")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¹ã‚³ã‚¢åˆ†æž
        category_scores = {}
        for category, result in self.verification_results['categories'].items():
            category_scores[category] = result.get('score', 0)
        
        # å¹³å‡ã‚¹ã‚³ã‚¢ç®—å‡º
        average_score = sum(category_scores.values()) / len(category_scores) if category_scores else 0
        
        # å¼·ã¿ãƒ»å¼±ã¿åˆ†æž
        strengths = []
        weaknesses = []
        
        for category, score in category_scores.items():
            if score >= 80:
                strengths.append(category)
            elif score < 60:
                weaknesses.append(category)
        
        # ã‚·ã‚¹ãƒ†ãƒ æˆç†Ÿåº¦è©•ä¾¡
        maturity_level = self._calculate_system_maturity(average_score)
        
        # åˆ†æžçµæžœæ ¼ç´
        self.verification_results['comprehensive_analysis'] = {
            'category_scores': category_scores,
            'average_score': round(average_score, 1),
            'strengths': strengths,
            'weaknesses': weaknesses,
            'system_maturity': maturity_level,
            'total_critical_issues': len(self.verification_results['critical_issues'])
        }
        
        print(f"    ðŸ“Š å¹³å‡ã‚¹ã‚³ã‚¢: {average_score:.1f}%")
        print(f"    ðŸŒŸ å¼·ã¿: {len(strengths)}ã‚«ãƒ†ã‚´ãƒª")
        print(f"    âš ï¸ å¼±ã¿: {len(weaknesses)}ã‚«ãƒ†ã‚´ãƒª")
        print(f"    ðŸ† ã‚·ã‚¹ãƒ†ãƒ æˆç†Ÿåº¦: {maturity_level}")
    
    def _calculate_system_maturity(self, average_score: float) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ æˆç†Ÿåº¦è¨ˆç®—"""
        
        if average_score >= 90:
            return "æœ€é«˜æ°´æº– (Optimized)"
        elif average_score >= 80:
            return "æˆç†Ÿ (Managed)"
        elif average_score >= 70:
            return "å®šç¾©æ¸ˆã¿ (Defined)"
        elif average_score >= 60:
            return "åŸºæœ¬ (Basic)"
        else:
            return "åˆæœŸ (Initial)"
    
    def _generate_recommendations(self):
        """æŽ¨å¥¨äº‹é …ç”Ÿæˆ"""
        
        print("  ðŸ’¡ æŽ¨å¥¨äº‹é …ç”Ÿæˆä¸­...")
        
        recommendations = []
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥æŽ¨å¥¨äº‹é …
        for category, result in self.verification_results['categories'].items():
            score = result.get('score', 0)
            
            if score < 60:
                recommendations.append({
                    'category': category,
                    'priority': 'HIGH',
                    'recommendation': f'{category}ã®æ©Ÿèƒ½å¼·åŒ–ãŒå¿…è¦ã§ã™ã€‚ã‚¹ã‚³ã‚¢{score:.1f}%ã‚’80%ä»¥ä¸Šã«å‘ä¸Šã•ã›ã¦ãã ã•ã„ã€‚',
                    'actions': [
                        f'{category}ã®å®Ÿè£…çŠ¶æ³è©³ç´°èª¿æŸ»',
                        f'{category}ã®è¨­è¨ˆãƒ»å®Ÿè£…æ”¹å–„',
                        f'{category}ã®ãƒ†ã‚¹ãƒˆå¼·åŒ–'
                    ]
                })
            elif score < 80:
                recommendations.append({
                    'category': category,
                    'priority': 'MEDIUM',
                    'recommendation': f'{category}ã®å“è³ªå‘ä¸Šã‚’æŽ¨å¥¨ã—ã¾ã™ã€‚ã‚¹ã‚³ã‚¢{score:.1f}%ã‚’ã•ã‚‰ã«å‘ä¸Šã•ã›ã¦ãã ã•ã„ã€‚',
                    'actions': [
                        f'{category}ã®æœ€é©åŒ–',
                        f'{category}ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æ”¹å–„'
                    ]
                })
        
        # è‡´å‘½çš„å•é¡Œã¸ã®å¯¾å¿œ
        if self.verification_results['critical_issues']:
            recommendations.append({
                'category': 'è‡´å‘½çš„å•é¡Œ',
                'priority': 'CRITICAL',
                'recommendation': f'{len(self.verification_results["critical_issues"])}ä»¶ã®è‡´å‘½çš„å•é¡Œã‚’å³åº§ã«ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚',
                'actions': [
                    'è‡´å‘½çš„å•é¡Œã®è©³ç´°èª¿æŸ»',
                    'ç·Šæ€¥ä¿®æ­£å¯¾å¿œ',
                    'æ ¹æœ¬åŽŸå› åˆ†æžãƒ»å†ç™ºé˜²æ­¢'
                ]
            })
        
        # ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“æŽ¨å¥¨äº‹é …
        overall_score = self.verification_results['comprehensive_analysis']['average_score']
        if overall_score >= 85:
            recommendations.append({
                'category': 'ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“',
                'priority': 'LOW',
                'recommendation': 'ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ãŒé«˜å“è³ªã§ã™ã€‚ç¶™ç¶šçš„æ”¹å–„ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚',
                'actions': [
                    'å®šæœŸçš„å“è³ªç›£è¦–',
                    'æ–°æ©Ÿèƒ½è¿½åŠ æ¤œè¨Ž',
                    'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æœ€é©åŒ–'
                ]
            })
        
        self.verification_results['recommendations'] = recommendations
        
        print(f"    ðŸ’¡ {len(recommendations)}ä»¶ã®æŽ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ")
    
    def _calculate_overall_assessment(self):
        """ç·åˆè©•ä¾¡è¨ˆç®—"""
        
        print("  ðŸ† ç·åˆè©•ä¾¡è¨ˆç®—ä¸­...")
        
        analysis = self.verification_results['comprehensive_analysis']
        
        # å“è³ªã‚°ãƒ¬ãƒ¼ãƒ‰æ±ºå®š
        average_score = analysis['average_score']
        critical_issues = analysis['total_critical_issues']
        
        if average_score >= 90 and critical_issues == 0:
            quality_grade = 'OUTSTANDING'
            grade_description = 'å„ªç§€ - æ¥­ç•Œæœ€é«˜æ°´æº–'
        elif average_score >= 80 and critical_issues <= 1:
            quality_grade = 'EXCELLENT'
            grade_description = 'å„ªè‰¯ - é«˜å“è³ªã‚·ã‚¹ãƒ†ãƒ '
        elif average_score >= 70 and critical_issues <= 3:
            quality_grade = 'GOOD'
            grade_description = 'è‰¯å¥½ - æ¨™æº–ä»¥ä¸Š'
        elif average_score >= 60 and critical_issues <= 5:
            quality_grade = 'ACCEPTABLE'
            grade_description = 'è¨±å®¹ - æ”¹å–„æŽ¨å¥¨'
        else:
            quality_grade = 'NEEDS_IMPROVEMENT'
            grade_description = 'è¦æ”¹å–„ - é‡è¦èª²é¡Œã‚ã‚Š'
        
        # é‹ç”¨æº–å‚™åº¦è©•ä¾¡
        readiness_factors = {
            'data_processing': analysis['category_scores'].get('ãƒ‡ãƒ¼ã‚¿å…¥ç¨¿', 0) >= 70,
            'analysis_capability': analysis['category_scores'].get('ãƒ‡ãƒ¼ã‚¿åˆ†æž', 0) >= 70,
            'visualization': analysis['category_scores'].get('å¯è¦–åŒ–', 0) >= 70,
            'end_to_end': analysis['category_scores'].get('ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ•ãƒ­ãƒ¼', 0) >= 70,
            'no_critical_issues': critical_issues == 0
        }
        
        readiness_score = sum(readiness_factors.values()) / len(readiness_factors) * 100
        
        if readiness_score >= 80:
            readiness_status = 'æœ¬æ ¼é‹ç”¨æº–å‚™å®Œäº†'
        elif readiness_score >= 60:
            readiness_status = 'è©¦ç”¨é‹ç”¨å¯èƒ½'
        else:
            readiness_status = 'é‹ç”¨æº–å‚™ä¸­'
        
        # ç·åˆè©•ä¾¡æ ¼ç´
        self.verification_results['overall_assessment'] = {
            'quality_grade': quality_grade,
            'grade_description': grade_description,
            'overall_score': round(average_score, 1),
            'critical_issues_count': critical_issues,
            'readiness_score': round(readiness_score, 1),
            'readiness_status': readiness_status,
            'readiness_factors': readiness_factors,
            'system_maturity': analysis['system_maturity']
        }
        
        print(f"    ðŸ† å“è³ªã‚°ãƒ¬ãƒ¼ãƒ‰: {quality_grade}")
        print(f"    ðŸ“Š ç·åˆã‚¹ã‚³ã‚¢: {average_score:.1f}%")
        print(f"    ðŸš€ é‹ç”¨æº–å‚™åº¦: {readiness_score:.1f}% ({readiness_status})")

def execute_mece_comprehensive_verification():
    """MECEåŒ…æ‹¬çš„æ¤œè¨¼å®Ÿè¡Œãƒ¡ã‚¤ãƒ³"""
    
    print("ðŸ” MECEåŒ…æ‹¬çš„ã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½æ¤œè¨¼å®Ÿè¡Œé–‹å§‹...")
    print("=" * 80)
    
    # æ¤œè¨¼å®Ÿè¡Œ
    verifier = MECEComprehensiveVerifier()
    verification_results = verifier.execute_comprehensive_verification()
    
    # çµæžœä¿å­˜
    result_filename = f"mece_comprehensive_verification_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    result_filepath = os.path.join("/mnt/c/Users/fuji1/OneDrive/ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/ã‚·ãƒ•ãƒˆåˆ†æž", result_filename)
    
    with open(result_filepath, 'w', encoding='utf-8') as f:
        json.dump(verification_results, f, ensure_ascii=False, indent=2)
    
    # çµæžœè¡¨ç¤º
    print("\n" + "=" * 80)
    print("ðŸŽ¯ MECEåŒ…æ‹¬çš„æ¤œè¨¼å®Œäº†!")
    print(f"ðŸ“ æ¤œè¨¼çµæžœ: {result_filename}")
    
    # ã‚µãƒžãƒªãƒ¼è¡¨ç¤º
    overall = verification_results['overall_assessment']
    analysis = verification_results['comprehensive_analysis']
    
    print(f"\nðŸ“Š æ¤œè¨¼çµæžœã‚µãƒžãƒªãƒ¼:")
    print(f"  ðŸ† å“è³ªã‚°ãƒ¬ãƒ¼ãƒ‰: {overall['quality_grade']} ({overall['grade_description']})")
    print(f"  ðŸ“ˆ ç·åˆã‚¹ã‚³ã‚¢: {overall['overall_score']}%")
    print(f"  ðŸš€ é‹ç”¨æº–å‚™åº¦: {overall['readiness_score']}% ({overall['readiness_status']})")
    print(f"  ðŸŽ¯ ã‚·ã‚¹ãƒ†ãƒ æˆç†Ÿåº¦: {overall['system_maturity']}")
    print(f"  âš ï¸ è‡´å‘½çš„å•é¡Œ: {overall['critical_issues_count']}ä»¶")
    
    print(f"\nðŸ“‹ ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¹ã‚³ã‚¢:")
    for category, score in analysis['category_scores'].items():
        status_icon = "âœ…" if score >= 80 else "âš ï¸" if score >= 60 else "âŒ"
        print(f"  {status_icon} {category}: {score:.1f}%")
    
    print(f"\nðŸ’¡ æŽ¨å¥¨äº‹é …: {len(verification_results['recommendations'])}ä»¶")
    for rec in verification_results['recommendations'][:3]:  # ä¸Šä½3ä»¶è¡¨ç¤º
        priority_icon = "ðŸ”´" if rec['priority'] == 'CRITICAL' else "ðŸŸ¡" if rec['priority'] == 'HIGH' else "ðŸŸ¢"
        print(f"  {priority_icon} [{rec['priority']}] {rec['recommendation']}")
    
    # é‹ç”¨å¯èƒ½æ€§åˆ¤å®š
    if overall['readiness_score'] >= 80:
        print(f"\nðŸŒŸ ã‚·ã‚¹ãƒ†ãƒ ã¯æœ¬æ ¼é‹ç”¨æº–å‚™ãŒå®Œäº†ã—ã¦ã„ã¾ã™!")
    elif overall['readiness_score'] >= 60:
        print(f"\nâœ… ã‚·ã‚¹ãƒ†ãƒ ã¯è©¦ç”¨é‹ç”¨ãŒå¯èƒ½ãªçŠ¶æ…‹ã§ã™")
    else:
        print(f"\nðŸ”§ ã‚·ã‚¹ãƒ†ãƒ ã¯é‹ç”¨æº–å‚™ä¸­ã§ã™ã€‚æ”¹å–„ãŒå¿…è¦ã§ã™")
    
    return verification_results

if __name__ == "__main__":
    execute_mece_comprehensive_verification()