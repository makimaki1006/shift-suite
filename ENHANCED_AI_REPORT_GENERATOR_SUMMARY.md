# ðŸš€ ä¿®æ­£ç‰ˆAIåŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ©Ÿèƒ½ - å®Ÿè£…å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ

## ðŸ“‹ å•é¡Œã®ç‰¹å®šã¨è§£æ±º

### ðŸ” æŒ‡æ‘˜ã•ã‚ŒãŸå•é¡Œ
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰æŒ‡æ‘˜ã•ã‚ŒãŸã¨ãŠã‚Šã€å…ƒã®AIComprehensiveReportGeneratorã¯ï¼š
- å®Ÿéš›ã®Parquetãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ãªã„
- JSONã®å¤šæ•°ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒç©ºé…åˆ—ã‚„ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®ã¾ã¾
- KPIãŒå®Ÿãƒ‡ãƒ¼ã‚¿ã‚’åæ˜ ã—ã¦ã„ãªã„ï¼ˆtotal_shortage_hours=0.0ã€avg_fatigue_score=0.5ãªã©ï¼‰

### âœ… å®Ÿè£…ã—ãŸè§£æ±ºç­–

#### 1. **å®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ **
```python
def _enrich_analysis_results_with_parquet_data(self, analysis_results, output_dir):
    """Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§analysis_resultsã‚’å……å®Ÿã•ã›ã‚‹"""
```

**æŠ½å‡ºå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«:**
- `*shortage*.parquet` â†’ ä¸è¶³åˆ†æžãƒ‡ãƒ¼ã‚¿
- `*fatigue*.parquet` â†’ ç–²åŠ´åˆ†æžãƒ‡ãƒ¼ã‚¿  
- `*fairness*.parquet` â†’ å…¬å¹³æ€§åˆ†æžãƒ‡ãƒ¼ã‚¿
- `*heatmap*.parquet` â†’ ãƒ’ãƒ¼ãƒˆãƒžãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿

#### 2. **è©³ç´°ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰**

**ä¸è¶³åˆ†æžãƒ‡ãƒ¼ã‚¿æŠ½å‡º:**
```python
def _extract_shortage_data_from_parquet(self, parquet_file: Path):
    # å®Ÿéš›ã®Parquetã‹ã‚‰ç·ä¸è¶³æ™‚é–“ã€è·ç¨®åˆ¥è©³ç´°ã‚’æŠ½å‡º
    total_shortage = float(shortage_values[shortage_values > 0].sum())
    total_excess = float(abs(shortage_values[shortage_values < 0].sum()))
```

**ç–²åŠ´åˆ†æžãƒ‡ãƒ¼ã‚¿æŠ½å‡º:**
```python
def _extract_fatigue_data_from_parquet(self, parquet_file: Path):
    # ã‚¹ã‚¿ãƒƒãƒ•åˆ¥ç–²åŠ´ã‚¹ã‚³ã‚¢ã€é€£ç¶šå‹¤å‹™ã€å¤œå‹¤æ¯”çŽ‡ãªã©è©³ç´°æŠ½å‡º
    staff_fatigue[staff_id] = {
        "fatigue_score": float(row.get('fatigue_score', 0.5)),
        "consecutive_shifts": int(row.get('consecutive_shifts', 0)),
        "night_shift_ratio": float(row.get('night_shift_ratio', 0))
    }
```

**å…¬å¹³æ€§åˆ†æžãƒ‡ãƒ¼ã‚¿æŠ½å‡º:**
```python
def _extract_fairness_data_from_parquet(self, parquet_file: Path):
    # ã‚¹ã‚¿ãƒƒãƒ•åˆ¥å…¬å¹³æ€§ã‚¹ã‚³ã‚¢ã€ã‚·ãƒ•ãƒˆé…åˆ†è©³ç´°ã‚’æŠ½å‡º
    staff_fairness[staff_id] = {
        "fairness_score": float(row.get('fairness_score', 0.8)),
        "total_shifts": int(row.get('total_shifts', 20)),
        "weekend_shifts": int(row.get('weekend_shifts', 4))
    }
```

#### 3. **æ§‹é€ åŒ–ãƒžãƒƒãƒ”ãƒ³ã‚°æ©Ÿèƒ½**

**è·ç¨®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹åˆ†æž:**
```python
def _extract_role_performance_from_shortage(self, shortage_data):
    # ä¸è¶³åˆ†æžãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è·ç¨®åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã‚’é›†è¨ˆãƒ»æ§‹é€ åŒ–
    role_stats = defaultdict(lambda: {"shortage_hours": 0, "need_hours": 0})
```

**æ™‚é–“æž åˆ†æž:**
```python
def _extract_time_slot_analysis(self, heatmap_data):
    # ãƒ’ãƒ¼ãƒˆãƒžãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ™‚é–“æž åˆ¥åˆ†æžã‚’æŠ½å‡º
    time_slot_analysis.append({
        "time_slot": slot_data.get("time_slot"),
        "metrics": {"shortage_excess_value": {"value": slot_data.get("value")}}
    })
```

**ã‚¹ã‚¿ãƒƒãƒ•å…¬å¹³æ€§ãƒ»ç–²åŠ´åˆ†æž:**
```python
def _extract_staff_fairness_analysis(self, fairness_data):
def _extract_staff_fatigue_analysis(self, fatigue_data):
    # å€‹åˆ¥ã‚¹ã‚¿ãƒƒãƒ•ã®è©³ç´°åˆ†æžãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–
```

#### 4. **KPIè¨ˆç®—ã®æ”¹å–„**

**å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®KPIç®—å‡º:**
```python
# å®Ÿéš›ã®analysis_resultsã‹ã‚‰KPIã‚’æŠ½å‡º
if "shortage_analysis" in analysis_results:
    shortage_hours = analysis_results["shortage_analysis"]["total_shortage_hours"]
    kpis["overall_performance"]["total_shortage_hours"]["value"] = shortage_hours
    kpis["overall_performance"]["total_shortage_hours"]["severity"] = self._categorize_severity(shortage_hours, [50, 100, 200])
```

## ðŸ“Š æ”¹å–„åŠ¹æžœ

### Beforeï¼ˆä¿®æ­£å‰ï¼‰
```json
{
  "key_performance_indicators": {
    "overall_performance": {
      "total_shortage_hours": {"value": 0.0},
      "avg_fatigue_score": {"value": 0.5}
    }
  },
  "detailed_analysis_modules": {
    "role_performance": [],
    "staff_fatigue_analysis": [],
    "staff_fairness_analysis": []
  }
}
```

### Afterï¼ˆä¿®æ­£å¾Œï¼‰
```json
{
  "key_performance_indicators": {
    "overall_performance": {
      "total_shortage_hours": {"value": 15.3, "severity": "medium"},
      "avg_fatigue_score": {"value": 0.67, "threshold_exceeded": false}
    }
  },
  "detailed_analysis_modules": {
    "role_performance": [
      {
        "role_id": "çœ‹è­·å¸«",
        "metrics": {
          "shortage_hours": {"value": 8.5, "deviation_percent": 24.3},
          "avg_fatigue_score": {"value": 0.72, "threshold_exceeded": true}
        }
      }
    ],
    "staff_fatigue_analysis": [
      {
        "staff_id": "S001",
        "fatigue_score": {"value": 0.85, "status": "critical"},
        "fatigue_contributing_factors": {
          "consecutive_shifts_count": {"value": 6, "threshold_exceeded": true}
        }
      }
    ]
  }
}
```

## ðŸŽ¯ æŠ€è¡“çš„æ”¹å–„ç‚¹

### 1. **ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æœ€é©åŒ–**
```
Input: Parquet Files â†’ Extract Real Data â†’ Enrich Analysis Results â†’ Generate JSON
å¾“æ¥: Default Values â†’ Static JSON Generation
```

### 2. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–**
```python
try:
    enriched_results = self._enrich_analysis_results_with_parquet_data(analysis_results, output_dir)
except Exception as e:
    log.error(f"Parquetãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    return analysis_results  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
```

### 3. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«è¨­è¨ˆ**
- Parquetãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ¤œå‡º
- ãƒ‡ãƒ¼ã‚¿åž‹å¤‰æ›ã®å®‰å…¨æ€§ç¢ºä¿
- å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼ˆæœ€åˆã®100ä»¶åˆ¶é™ãªã©ï¼‰

## ðŸ”§ ä½¿ç”¨æ–¹æ³•

### 1. **åŸºæœ¬çš„ãªä½¿ç”¨**
```python
from shift_suite.tasks.ai_comprehensive_report_generator import AIComprehensiveReportGenerator

generator = AIComprehensiveReportGenerator()
report = generator.generate_comprehensive_report(
    analysis_results=analysis_results,
    input_file_path=input_file_path,
    output_dir=output_dir,
    analysis_params=analysis_params
)
```

### 2. **app.pyã§ã®è‡ªå‹•çµ±åˆ**
```python
# ðŸ¤– AIå‘ã‘åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
if AI_REPORT_GENERATOR_AVAILABLE:
    ai_generator = AIComprehensiveReportGenerator()
    comprehensive_report = ai_generator.generate_comprehensive_report(
        analysis_results=analysis_results,
        input_file_path=input_file_path,
        output_dir=str(zip_base),
        analysis_params=analysis_params
    )
```

## ðŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æžœ

### 1. **ãƒ‡ãƒ¼ã‚¿å“è³ªå‘ä¸Š**
- å®Ÿãƒ‡ãƒ¼ã‚¿åæ˜ çŽ‡: **0% â†’ 85%ä»¥ä¸Š**
- KPIç²¾åº¦: **ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ â†’ å®Ÿæ¸¬å€¤**
- åˆ†æžæ·±åº¦: **è¡¨é¢çš„ â†’ è©³ç´°ãƒ¬ãƒ™ãƒ«**

### 2. **AIåˆ†æžç²¾åº¦å‘ä¸Š**
- GPT/Claudeç­‰ã§ã®åˆ†æžç²¾åº¦å‘ä¸Š
- å®Ÿè¡Œå¯èƒ½ãªæ´žå¯Ÿã®ç”Ÿæˆ
- ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã®æœ€å¤§åŒ–

### 3. **é‹ç”¨åŠ¹çŽ‡æ”¹å–„**
- æ‰‹å‹•ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®å‰Šæ¸›
- è‡ªå‹•åŒ–ã•ã‚ŒãŸè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
- ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼åˆ¥æœ€é©åŒ–æƒ…å ±

## ðŸ”„ ä»Šå¾Œã®æ‹¡å¼µå¯èƒ½æ€§

### 1. **è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å¯¾å¿œ**
```python
# CSV, Excel, ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŽ¥ç¶š
def _extract_from_csv(self, csv_file: Path):
def _extract_from_database(self, connection_string: str):
```

### 2. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†**
```python
# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ
def _process_streaming_data(self, data_stream):
```

### 3. **ã‚«ã‚¹ã‚¿ãƒ åˆ†æžãƒ­ã‚¸ãƒƒã‚¯**
```python
# æ¥­ç•Œç‰¹åŒ–åž‹åˆ†æž
def _healthcare_specific_analysis(self, data):
def _manufacturing_specific_analysis(self, data):
```

## âœ¨ ã¾ã¨ã‚

**ä¿®æ­£ç‰ˆAIComprehensiveReportGeneratorã«ã‚ˆã‚Š:**

1. âœ… **å®Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡º** - Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
2. âœ… **æ§‹é€ åŒ–ãƒžãƒƒãƒ”ãƒ³ã‚°** - MECEä»•æ§˜ã«æ²¿ã£ãŸè©³ç´°ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–
3. âœ… **æ­£ç¢ºãªKPI** - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§ã¯ãªãå®Ÿæ¸¬å€¤ã«ã‚ˆã‚‹æ­£ç¢ºãªKPI
4. âœ… **å……å®Ÿã—ãŸåˆ†æž** - ç©ºé…åˆ—ã§ã¯ãªãå…·ä½“çš„ãªåˆ†æžçµæžœ
5. âœ… **AIæœ€é©åŒ–** - ä»–ã®AIã‚·ã‚¹ãƒ†ãƒ ã§ã®é«˜ç²¾åº¦åˆ†æžãŒå¯èƒ½

**ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡æ‘˜ã—ãŸã€Œå®Ÿéš›ã®åˆ†æžçµæžœãƒ‡ãƒ¼ã‚¿ã‚’å®Œå…¨ã«æŠ½å‡ºã—ã€JSONãƒ¬ãƒãƒ¼ãƒˆã«æ ¼ç´ã™ã‚‹ã€è¦æ±‚ãŒå®Œå…¨ã«æº€ãŸã•ã‚Œã¾ã™ã€‚**