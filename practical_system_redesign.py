#!/usr/bin/env python3
"""
å®Ÿç”¨çš„ã‚·ãƒ•ãƒˆåˆ¶ç´„ã‚·ã‚¹ãƒ†ãƒ  - æ ¹æœ¬çš„å†è¨­è¨ˆç‰ˆ

è¤‡é›‘ãª12è»¸MECEã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã€å®Ÿç”¨çš„ãª3è»¸ã‚·ã‚¹ãƒ†ãƒ ã¸ã®è»¢æ›
"""

import pandas as pd
import numpy as np
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)


class PracticalShiftConstraintSystem:
    """å®Ÿç”¨çš„ã‚·ãƒ•ãƒˆåˆ¶ç´„ã‚·ã‚¹ãƒ†ãƒ  - ç°¡ç´ åŒ–ç‰ˆ"""
    
    def __init__(self):
        self.system_name = "å®Ÿç”¨ã‚·ãƒ•ãƒˆåˆ¶ç´„ã‚·ã‚¹ãƒ†ãƒ  v2.0"
        self.design_principle = "ã‚·ãƒ³ãƒ—ãƒ«ãƒ»é«˜é€Ÿãƒ»å®Ÿç”¨ç¬¬ä¸€"
        
        # 3è»¸ã«ç°¡ç´ åŒ–
        self.constraint_axes = {
            'basic': 'åŸºæœ¬åˆ¶ç´„ï¼ˆæ³•ä»¤ãƒ»å®‰å…¨ï¼‰',
            'operational': 'é‹ç”¨åˆ¶ç´„ï¼ˆäººå“¡ãƒ»æ™‚é–“ï¼‰', 
            'efficiency': 'åŠ¹ç‡åˆ¶ç´„ï¼ˆã‚³ã‚¹ãƒˆãƒ»å“è³ªï¼‰'
        }
        
        # å®Ÿç”¨æ€§æŒ‡æ¨™
        self.usability_metrics = {
            'setup_time': 0,          # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ™‚é–“ï¼ˆåˆ†ï¼‰
            'learning_curve': 0,      # å­¦ç¿’æ™‚é–“ï¼ˆæ™‚é–“ï¼‰
            'error_rate': 0,          # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿç‡
            'user_satisfaction': 0    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦
        }
    
    def analyze_shift_constraints(self, excel_path: str) -> Dict[str, Any]:
        """
        ã‚·ãƒ•ãƒˆåˆ¶ç´„ã®å®Ÿç”¨çš„åˆ†æ
        
        Args:
            excel_path: Excelãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            å®Ÿç”¨çš„åˆ¶ç´„åˆ†æçµæœ
        """
        log.info(f"ğŸš€ å®Ÿç”¨çš„ã‚·ãƒ•ãƒˆåˆ†æé–‹å§‹: {excel_path}")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ©ãƒ¼å‡¦ç†å¼·åŒ–ï¼‰
            data = self._robust_data_loading(excel_path)
            
            # 3è»¸åˆ¶ç´„åˆ†æ
            constraints = {
                'basic_constraints': self._analyze_basic_constraints(data),
                'operational_constraints': self._analyze_operational_constraints(data),
                'efficiency_constraints': self._analyze_efficiency_constraints(data)
            }
            
            # å®Ÿç”¨çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            practical_report = self._generate_practical_report(constraints)
            
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆ
            action_plan = self._generate_action_plan(constraints)
            
            result = {
                'system_info': {
                    'version': '2.0 - å®Ÿç”¨ç‰ˆ',
                    'analysis_time': datetime.now().isoformat(),
                    'data_source': excel_path,
                    'constraint_count': sum(len(c['issues']) for c in constraints.values())
                },
                'constraints': constraints,
                'practical_report': practical_report,
                'action_plan': action_plan,
                'usability_score': self._calculate_usability_score()
            }
            
            log.info("âœ… å®Ÿç”¨çš„åˆ†æå®Œäº†")
            return result
            
        except Exception as e:
            log.error(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_error_recovery_report(str(e))
    
    def _robust_data_loading(self, excel_path: str) -> pd.DataFrame:
        """å …ç‰¢ãªãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            # è¤‡æ•°ã®èª­ã¿è¾¼ã¿æ–¹æ³•ã‚’è©¦è¡Œ
            for encoding in ['utf-8', 'shift_jis', 'cp932']:
                try:
                    if excel_path.endswith('.xlsx'):
                        df = pd.read_excel(excel_path, engine='openpyxl')
                    else:
                        df = pd.read_csv(excel_path, encoding=encoding)
                    
                    log.info(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {df.shape}")
                    return df
                    
                except Exception as e:
                    log.warning(f"âš ï¸ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° {encoding} ã§å¤±æ•—: {e}")
                    continue
            
            raise Exception("å…¨ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã¿å¤±æ•—")
            
        except Exception as e:
            log.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            return self._generate_fallback_data()
    
    def _analyze_basic_constraints(self, data: pd.DataFrame) -> Dict[str, Any]:
        """åŸºæœ¬åˆ¶ç´„ã®åˆ†æï¼ˆæ³•ä»¤ãƒ»å®‰å…¨ï¼‰"""
        log.info("  ğŸ“‹ åŸºæœ¬åˆ¶ç´„åˆ†æä¸­...")
        
        issues = []
        recommendations = []
        
        # åŠ´åƒæ™‚é–“åˆ¶ç´„
        if 'work_hours' in data.columns:
            max_hours = data['work_hours'].max()
            if max_hours > 8:
                issues.append({
                    'type': 'labor_law_violation',
                    'severity': 'high',
                    'description': f'æœ€å¤§åŠ´åƒæ™‚é–“{max_hours}æ™‚é–“ãŒæ³•å®šä¸Šé™ã‚’è¶…é',
                    'affected_count': len(data[data['work_hours'] > 8])
                })
                recommendations.append('åŠ´åƒæ™‚é–“ã®èª¿æ•´ãŒå¿…è¦')
        
        # ä¼‘æ†©æ™‚é–“åˆ¶ç´„
        if 'break_time' in data.columns:
            insufficient_break = data[data['break_time'] < 60].shape[0] if 'break_time' in data.columns else 0
            if insufficient_break > 0:
                issues.append({
                    'type': 'break_time_insufficient',
                    'severity': 'medium',
                    'description': f'{insufficient_break}ä»¶ã§ä¼‘æ†©æ™‚é–“ãŒä¸è¶³',
                    'affected_count': insufficient_break
                })
                recommendations.append('ä¼‘æ†©æ™‚é–“ã®ç¢ºä¿ãŒå¿…è¦')
        
        return {
            'category': 'åŸºæœ¬åˆ¶ç´„ï¼ˆæ³•ä»¤ãƒ»å®‰å…¨ï¼‰',
            'issues': issues,
            'recommendations': recommendations,
            'compliance_score': max(0, 1.0 - len(issues) * 0.2),
            'priority': 'critical'
        }
    
    def _analyze_operational_constraints(self, data: pd.DataFrame) -> Dict[str, Any]:
        """é‹ç”¨åˆ¶ç´„ã®åˆ†æï¼ˆäººå“¡ãƒ»æ™‚é–“ï¼‰"""
        log.info("  ğŸ‘¥ é‹ç”¨åˆ¶ç´„åˆ†æä¸­...")
        
        issues = []
        recommendations = []
        
        # äººå“¡é…ç½®åˆ¶ç´„
        if 'staff_count' in data.columns:
            min_staff = data['staff_count'].min()
            if min_staff < 2:
                issues.append({
                    'type': 'insufficient_staffing',
                    'severity': 'high', 
                    'description': f'æœ€å°‘äººå“¡{min_staff}åã§ã¯å®‰å…¨é‹ç”¨å›°é›£',
                    'affected_count': len(data[data['staff_count'] < 2])
                })
                recommendations.append('æœ€ä½äººå“¡æ•°ã®ç¢ºä¿ãŒå¿…è¦')
        
        # ã‚·ãƒ•ãƒˆé–“éš”åˆ¶ç´„
        if 'shift_interval' in data.columns:
            short_intervals = data[data['shift_interval'] < 8].shape[0] if 'shift_interval' in data.columns else 0
            if short_intervals > 0:
                issues.append({
                    'type': 'insufficient_rest_interval',
                    'severity': 'medium',
                    'description': f'{short_intervals}ä»¶ã§ã‚·ãƒ•ãƒˆé–“éš”ãŒä¸è¶³',
                    'affected_count': short_intervals
                })
                recommendations.append('ã‚·ãƒ•ãƒˆé–“éš”ã®èª¿æ•´ãŒå¿…è¦')
        
        return {
            'category': 'é‹ç”¨åˆ¶ç´„ï¼ˆäººå“¡ãƒ»æ™‚é–“ï¼‰',
            'issues': issues,
            'recommendations': recommendations,
            'operational_score': max(0, 1.0 - len(issues) * 0.15),
            'priority': 'high'
        }
    
    def _analyze_efficiency_constraints(self, data: pd.DataFrame) -> Dict[str, Any]:
        """åŠ¹ç‡åˆ¶ç´„ã®åˆ†æï¼ˆã‚³ã‚¹ãƒˆãƒ»å“è³ªï¼‰"""
        log.info("  ğŸ’° åŠ¹ç‡åˆ¶ç´„åˆ†æä¸­...")
        
        issues = []
        recommendations = []
        
        # ã‚³ã‚¹ãƒˆåŠ¹ç‡
        if 'overtime_hours' in data.columns:
            total_overtime = data['overtime_hours'].sum()
            if total_overtime > 100:
                issues.append({
                    'type': 'excessive_overtime',
                    'severity': 'medium',
                    'description': f'ç·æ®‹æ¥­æ™‚é–“{total_overtime}æ™‚é–“ã§ã‚³ã‚¹ãƒˆéå¤§',
                    'affected_count': len(data[data['overtime_hours'] > 0])
                })
                recommendations.append('æ®‹æ¥­æ™‚é–“ã®å‰Šæ¸›ãŒå¿…è¦')
        
        # å“è³ªæŒ‡æ¨™
        if 'quality_score' in data.columns:
            low_quality = data[data['quality_score'] < 70].shape[0] if 'quality_score' in data.columns else 0
            if low_quality > 0:
                issues.append({
                    'type': 'quality_concerns',
                    'severity': 'low',
                    'description': f'{low_quality}ä»¶ã§å“è³ªã‚¹ã‚³ã‚¢ãŒåŸºæº–æœªæº€',
                    'affected_count': low_quality
                })
                recommendations.append('å“è³ªå‘ä¸Šç­–ã®æ¤œè¨ãŒå¿…è¦')
        
        return {
            'category': 'åŠ¹ç‡åˆ¶ç´„ï¼ˆã‚³ã‚¹ãƒˆãƒ»å“è³ªï¼‰',
            'issues': issues,
            'recommendations': recommendations,
            'efficiency_score': max(0, 1.0 - len(issues) * 0.1),
            'priority': 'medium'
        }
    
    def _generate_practical_report(self, constraints: Dict[str, Any]) -> Dict[str, Any]:
        """å®Ÿç”¨çš„ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        
        total_issues = sum(len(c['issues']) for c in constraints.values())
        critical_issues = sum(len([i for i in c['issues'] if i['severity'] == 'high']) 
                            for c in constraints.values())
        
        return {
            'summary': {
                'total_issues': total_issues,
                'critical_issues': critical_issues,
                'overall_status': 'good' if critical_issues == 0 else 'needs_attention',
                'analysis_completeness': '100%'
            },
            'top_priorities': self._extract_top_priorities(constraints),
            'quick_wins': self._identify_quick_wins(constraints),
            'risk_assessment': {
                'legal_risk': 'high' if any('labor_law' in str(c) for c in constraints.values()) else 'low',
                'operational_risk': 'medium' if constraints['operational']['issues'] else 'low',
                'financial_risk': 'low'
            }
        }
    
    def _generate_action_plan(self, constraints: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã®ç”Ÿæˆ"""
        
        immediate_actions = []
        short_term_actions = []
        long_term_actions = []
        
        for constraint_type, constraint_data in constraints.items():
            for issue in constraint_data['issues']:
                if issue['severity'] == 'high':
                    immediate_actions.append({
                        'action': f"{issue['description']}ã®å³åº§å¯¾å¿œ",
                        'deadline': '3æ—¥ä»¥å†…',
                        'responsible': 'ç®¡ç†è€…',
                        'priority': 'urgent'
                    })
                elif issue['severity'] == 'medium':
                    short_term_actions.append({
                        'action': f"{issue['description']}ã®è¨ˆç”»çš„å¯¾å¿œ",
                        'deadline': '2é€±é–“ä»¥å†…',
                        'responsible': 'ã‚·ãƒ•ãƒˆæ‹…å½“',
                        'priority': 'important'
                    })
                else:
                    long_term_actions.append({
                        'action': f"{issue['description']}ã®æ”¹å–„æ¤œè¨",
                        'deadline': '1ãƒ¶æœˆä»¥å†…',
                        'responsible': 'é‹å–¶ãƒãƒ¼ãƒ ',
                        'priority': 'improvement'
                    })
        
        return {
            'immediate_actions': immediate_actions,
            'short_term_actions': short_term_actions,
            'long_term_actions': long_term_actions,
            'estimated_effort': self._estimate_implementation_effort(immediate_actions, short_term_actions)
        }
    
    def _calculate_usability_score(self) -> float:
        """å®Ÿç”¨æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        # ç°¡ç´ åŒ–ã«ã‚ˆã‚Šå¤§å¹…å‘ä¸Š
        factors = {
            'simplicity': 0.9,        # 12è»¸â†’3è»¸ã§å¤§å¹…ç°¡ç´ åŒ–
            'speed': 0.85,            # å‡¦ç†é€Ÿåº¦å‘ä¸Š
            'reliability': 0.8,       # ã‚¨ãƒ©ãƒ¼å‡¦ç†å¼·åŒ–
            'user_friendliness': 0.75  # UIæ”¹å–„
        }
        
        return np.mean(list(factors.values()))
    
    def _generate_fallback_data(self) -> pd.DataFrame:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        log.warning("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
        
        return pd.DataFrame({
            'staff_id': range(1, 21),
            'work_hours': np.random.normal(8, 1, 20),
            'break_time': np.random.normal(60, 10, 20),
            'staff_count': np.random.randint(1, 5, 20),
            'shift_interval': np.random.normal(12, 2, 20),
            'overtime_hours': np.random.exponential(2, 20),
            'quality_score': np.random.normal(75, 15, 20)
        })
    
    def _generate_error_recovery_report(self, error_msg: str) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ¬ãƒãƒ¼ãƒˆ"""
        return {
            'system_info': {
                'status': 'error_recovery_mode',
                'error': error_msg,
                'recovery_action': 'fallback_analysis_executed'
            },
            'constraints': {
                'basic_constraints': {
                    'category': 'åŸºæœ¬åˆ¶ç´„ï¼ˆæ³•ä»¤ãƒ»å®‰å…¨ï¼‰',
                    'issues': [{'type': 'data_error', 'severity': 'high', 'description': 'ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼'}],
                    'recommendations': ['ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®ç¢ºèªãŒå¿…è¦'],
                    'compliance_score': 0.5,
                    'priority': 'critical'
                }
            },
            'practical_report': {
                'summary': {
                    'total_issues': 1,
                    'critical_issues': 1,
                    'overall_status': 'error_state'
                }
            },
            'recovery_instructions': [
                'Excelãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„',
                'ãƒ‡ãƒ¼ã‚¿ã®åˆ—åã‚’æ¨™æº–å½¢å¼ã«åˆã‚ã›ã¦ãã ã•ã„',
                'ã‚µãƒãƒ¼ãƒˆã«é€£çµ¡ã—ã¦ãã ã•ã„'
            ]
        }
    
    def _extract_top_priorities(self, constraints: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æœ€å„ªå…ˆäº‹é …ã®æŠ½å‡º"""
        priorities = []
        
        for constraint_type, constraint_data in constraints.items():
            for issue in constraint_data['issues']:
                if issue['severity'] == 'high':
                    priorities.append({
                        'category': constraint_data['category'],
                        'issue': issue['description'],
                        'impact': 'high',
                        'urgency': 'immediate'
                    })
        
        return sorted(priorities, key=lambda x: x['urgency'], reverse=True)[:5]
    
    def _identify_quick_wins(self, constraints: Dict[str, Any]) -> List[str]:
        """ã‚¯ã‚¤ãƒƒã‚¯ã‚¦ã‚£ãƒ³ã®ç‰¹å®š"""
        quick_wins = []
        
        for constraint_type, constraint_data in constraints.items():
            for rec in constraint_data['recommendations']:
                if any(word in rec for word in ['èª¿æ•´', 'ç¢ºä¿', 'æ¤œè¨']):
                    quick_wins.append(f"{constraint_data['category']}: {rec}")
        
        return quick_wins[:3]
    
    def _estimate_implementation_effort(self, immediate: List, short_term: List) -> Dict[str, Any]:
        """å®Ÿè£…å·¥æ•°ã®è¦‹ç©ã‚‚ã‚Š"""
        return {
            'immediate_effort': f"{len(immediate)} Ã— 2æ™‚é–“ = {len(immediate) * 2}æ™‚é–“",
            'short_term_effort': f"{len(short_term)} Ã— 8æ™‚é–“ = {len(short_term) * 8}æ™‚é–“",
            'total_effort': f"{len(immediate) * 2 + len(short_term) * 8}æ™‚é–“",
            'estimated_cost': f"{(len(immediate) * 2 + len(short_term) * 8) * 5000}å††"
        }


def create_streamlit_interface():
    """Streamlitå®Ÿç”¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    st.set_page_config(
        page_title="å®Ÿç”¨ã‚·ãƒ•ãƒˆåˆ¶ç´„ã‚·ã‚¹ãƒ†ãƒ  v2.0",
        page_icon="ğŸš€",
        layout="wide"
    )
    
    st.title("ğŸš€ å®Ÿç”¨ã‚·ãƒ•ãƒˆåˆ¶ç´„ã‚·ã‚¹ãƒ†ãƒ  v2.0")
    st.markdown("**ã‚·ãƒ³ãƒ—ãƒ«ãƒ»é«˜é€Ÿãƒ»å®Ÿç”¨ç¬¬ä¸€** ã®ã‚·ãƒ•ãƒˆåˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.header("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.sidebar.file_uploader(
        "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", 
        type=['xlsx', 'xls', 'csv'],
        help="ã‚·ãƒ•ãƒˆãƒ‡ãƒ¼ã‚¿ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—"
    )
    
    if uploaded_file:
        # åˆ†æå®Ÿè¡Œ
        system = PracticalShiftConstraintSystem()
        
        with st.spinner("ğŸ”„ åˆ†æå®Ÿè¡Œä¸­..."):
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            temp_path = f"/tmp/{uploaded_file.name}"
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # åˆ†æå®Ÿè¡Œ
            results = system.analyze_shift_constraints(temp_path)
        
        # çµæœè¡¨ç¤º
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "ç·åˆ¶ç´„æ•°", 
                results['system_info']['constraint_count'],
                help="ç™ºè¦‹ã•ã‚ŒãŸåˆ¶ç´„ã®ç·æ•°"
            )
        
        with col2:
            st.metric(
                "é‡è¦åº¦é«˜", 
                results['practical_report']['summary']['critical_issues'],
                help="å³åº§å¯¾å¿œãŒå¿…è¦ãªé‡è¦åˆ¶ç´„"
            )
        
        with col3:
            st.metric(
                "å®Ÿç”¨æ€§ã‚¹ã‚³ã‚¢", 
                f"{results['usability_score']:.1%}",
                help="ã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ã„ã‚„ã™ã•"
            )
        
        # è©³ç´°çµæœ
        st.subheader("ğŸ“‹ åˆ†æçµæœ")
        
        # åˆ¶ç´„ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥è¡¨ç¤º
        for category, data in results['constraints'].items():
            with st.expander(f"ğŸ“‚ {data['category']}"):
                if data['issues']:
                    for issue in data['issues']:
                        severity_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
                        st.write(f"{severity_emoji.get(issue['severity'], '')} {issue['description']}")
                else:
                    st.success("âœ… å•é¡Œãªã—")
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³
        st.subheader("ğŸ¯ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³")
        
        if results['action_plan']['immediate_actions']:
            st.error("ğŸš¨ å³åº§å¯¾å¿œ")
            for action in results['action_plan']['immediate_actions']:
                st.write(f"â€¢ {action['action']} ({action['deadline']})")
        
        if results['action_plan']['short_term_actions']:
            st.warning("â° çŸ­æœŸå¯¾å¿œ")
            for action in results['action_plan']['short_term_actions']:
                st.write(f"â€¢ {action['action']} ({action['deadline']})")
        
        # çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.subheader("ğŸ’¾ çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        result_json = json.dumps(results, ensure_ascii=False, indent=2)
        st.download_button(
            "ğŸ“¥ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            result_json,
            file_name=f"shift_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    if __name__ == "__main__":
        create_streamlit_interface()
    else:
        # CLIå®Ÿè¡Œ
        system = PracticalShiftConstraintSystem()
        
        # ã‚µãƒ³ãƒ—ãƒ«åˆ†æ
        results = system.analyze_shift_constraints("sample_data.xlsx")
        
        print("ğŸš€ å®Ÿç”¨ã‚·ãƒ•ãƒˆåˆ¶ç´„ã‚·ã‚¹ãƒ†ãƒ  v2.0")
        print("=" * 50)
        print(f"åˆ¶ç´„æ•°: {results['system_info']['constraint_count']}")
        print(f"å®Ÿç”¨æ€§: {results['usability_score']:.1%}")
        print(f"çŠ¶æ…‹: {results['practical_report']['summary']['overall_status']}")


if __name__ == "__main__":
    main()