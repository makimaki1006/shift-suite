"""
å¼·åŒ–ç‰ˆã‚·ãƒ•ãƒˆåˆ†ææ©Ÿèƒ½ç·åˆãƒ†ã‚¹ãƒˆ
å‰å›ã®ã‚¨ãƒ©ãƒ¼ä¿®æ­£ç‰ˆ - å¤–éƒ¨ä¾å­˜é–¢ä¿‚ãªã—ã®å®Œå…¨ãƒ†ã‚¹ãƒˆ
"""

import os
import json
import datetime
import traceback
from typing import Dict, List, Any, Optional

class EnhancedShiftAnalysisFunctionalityTest:
    """å¼·åŒ–ç‰ˆã‚·ãƒ•ãƒˆåˆ†ææ©Ÿèƒ½ç·åˆãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.base_path = "/mnt/c/Users/fuji1/OneDrive/ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/ã‚·ãƒ•ãƒˆåˆ†æ"
        self.test_execution_time = datetime.datetime.now()
        
        # ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
        self.critical_files = {
            'main_applications': ['app.py', 'dash_app.py'],
            'core_modules': [
                'shift_suite/__init__.py',
                'shift_suite/tasks/utils.py',
                'shift_suite/tasks/heatmap.py',
                'shift_suite/tasks/shortage.py',
                'shift_suite/tasks/fatigue.py',
                'shift_suite/tasks/anomaly.py',
                'shift_suite/tasks/build_stats.py',  
                'shift_suite/tasks/cluster.py',
                'shift_suite/tasks/fairness.py',
                'shift_suite/tasks/forecast.py',
                'shift_suite/tasks/skill_nmf.py'
            ],
            'strategy_execution_files': [
                'phase1_emergency_protocol_verification.py',
                'phase2_incremental_enhancement_execution.py', 
                'phase3_roi_optimization_execution.py',
                'phase4_strategic_evolution_execution.py',
                'd1_technical_innovation_execution.py',
                'd2_business_expansion_execution.py',
                'comprehensive_strategy_completion_report.py'
            ]
        }
        
        # ãƒ†ã‚¹ãƒˆè©•ä¾¡åŸºæº–
        self.test_criteria = {
            'file_existence_threshold': 0.95,  # 95%ä»¥ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨
            'syntax_validity_threshold': 1.0,   # 100%æ§‹æ–‡æ­£å¸¸
            'module_import_threshold': 0.90,    # 90%ä»¥ä¸Šã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ
            'algorithm_functionality_threshold': 0.85,  # 85%ä»¥ä¸Šæ©Ÿèƒ½å‹•ä½œ
            'integration_success_threshold': 0.80      # 80%ä»¥ä¸Šçµ±åˆæˆåŠŸ
        }
    
    def execute_comprehensive_functionality_test(self):
        """åŒ…æ‹¬çš„æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ¡ã‚¤ãƒ³"""
        try:
            print("ğŸš€ å¼·åŒ–ç‰ˆã‚·ãƒ•ãƒˆåˆ†ææ©Ÿèƒ½ç·åˆãƒ†ã‚¹ãƒˆé–‹å§‹...")
            print(f"ğŸ“… ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–‹å§‹æ™‚åˆ»: {self.test_execution_time.strftime('%Y-%m-%d %H:%M:%S')}")
            
            test_results = {}
            
            # 1. ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªãƒ†ã‚¹ãƒˆ
            file_existence_test = self._test_file_existence()
            test_results['file_existence'] = file_existence_test
            print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª: {'âœ…' if file_existence_test['success'] else 'âŒ'}")
            
            # 2. Pythonæ§‹æ–‡æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
            syntax_validation_test = self._test_python_syntax_validation()
            test_results['syntax_validation'] = syntax_validation_test
            print(f"ğŸ” æ§‹æ–‡æ¤œè¨¼: {'âœ…' if syntax_validation_test['success'] else 'âŒ'}")
            
            # 3. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
            module_import_test = self._test_module_imports()
            test_results['module_imports'] = module_import_test
            print(f"ğŸ“¦ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {'âœ…' if module_import_test['success'] else 'âŒ'}")
            
            # 4. ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            algorithm_functionality_test = self._test_algorithm_functionality()
            test_results['algorithm_functionality'] = algorithm_functionality_test
            print(f"âš™ï¸ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ©Ÿèƒ½: {'âœ…' if algorithm_functionality_test['success'] else 'âŒ'}")
            
            # 5. ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ
            system_integration_test = self._test_system_integration()
            test_results['system_integration'] = system_integration_test
            print(f"ğŸ”„ ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ: {'âœ…' if system_integration_test['success'] else 'âŒ'}")
            
            # 6. æˆ¦ç•¥å®Ÿè¡Œçµæœæ¤œè¨¼ãƒ†ã‚¹ãƒˆ
            strategy_execution_test = self._test_strategy_execution_results()
            test_results['strategy_execution'] = strategy_execution_test
            print(f"ğŸ“Š æˆ¦ç•¥å®Ÿè¡Œçµæœ: {'âœ…' if strategy_execution_test['success'] else 'âŒ'}")
            
            # ç·åˆè©•ä¾¡è¨ˆç®—
            comprehensive_evaluation = self._calculate_comprehensive_evaluation(test_results)
            test_results['comprehensive_evaluation'] = comprehensive_evaluation
            
            return {
                'success': comprehensive_evaluation['overall_test_status'] == 'success',
                'test_execution_timestamp': self.test_execution_time.isoformat(),
                'test_completion_timestamp': datetime.datetime.now().isoformat(),
                'test_results': test_results,
                'comprehensive_evaluation': comprehensive_evaluation,
                'system_readiness_level': comprehensive_evaluation['system_readiness_level']
            }
            
        except Exception as e:
            error_details = {
                'error': str(e),
                'traceback': traceback.format_exc(),
                'test_execution_timestamp': self.test_execution_time.isoformat()
            }
            return {
                'success': False,
                'error_details': error_details
            }
    
    def _test_file_existence(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªãƒ†ã‚¹ãƒˆ"""
        try:
            existence_results = {}
            total_files = 0
            existing_files = 0
            
            for category, file_list in self.critical_files.items():
                category_results = {}
                for file_path in file_list:
                    full_path = os.path.join(self.base_path, file_path)
                    exists = os.path.exists(full_path)
                    category_results[file_path] = {
                        'exists': exists,
                        'full_path': full_path,
                        'file_size': os.path.getsize(full_path) if exists else 0
                    }
                    total_files += 1
                    if exists:
                        existing_files += 1
                
                existence_results[category] = category_results
            
            existence_rate = existing_files / total_files if total_files > 0 else 0
            success = existence_rate >= self.test_criteria['file_existence_threshold']
            
            return {
                'success': success,
                'existence_rate': existence_rate,
                'total_files': total_files,
                'existing_files': existing_files,
                'missing_files': total_files - existing_files,
                'detailed_results': existence_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _test_python_syntax_validation(self):
        """Pythonæ§‹æ–‡æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        try:
            syntax_results = {}
            total_python_files = 0
            valid_syntax_files = 0
            
            for category, file_list in self.critical_files.items():
                category_results = {}
                for file_path in file_list:
                    if file_path.endswith('.py'):
                        full_path = os.path.join(self.base_path, file_path)
                        if os.path.exists(full_path):
                            try:
                                with open(full_path, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                compile(content, full_path, 'exec')
                                category_results[file_path] = {
                                    'syntax_valid': True,
                                    'error': None
                                }
                                valid_syntax_files += 1
                            except SyntaxError as e:
                                category_results[file_path] = {
                                    'syntax_valid': False,
                                    'error': str(e),
                                    'line_number': e.lineno
                                }
                        else:
                            category_results[file_path] = {
                                'syntax_valid': False,
                                'error': 'File not found'
                            }
                        total_python_files += 1
                
                syntax_results[category] = category_results
            
            syntax_validity_rate = valid_syntax_files / total_python_files if total_python_files > 0 else 0
            success = syntax_validity_rate >= self.test_criteria['syntax_validity_threshold']
            
            return {
                'success': success,
                'syntax_validity_rate': syntax_validity_rate,
                'total_python_files': total_python_files,
                'valid_syntax_files': valid_syntax_files,
                'syntax_error_files': total_python_files - valid_syntax_files,
                'detailed_results': syntax_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _test_module_imports(self):
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
        try:
            import_results = {}
            total_modules = 0
            successful_imports = 0
            
            # shift_suiteãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ
            shift_suite_modules = [
                'shift_suite.tasks.utils',
                'shift_suite.tasks.heatmap', 
                'shift_suite.tasks.shortage',
                'shift_suite.tasks.fatigue',
                'shift_suite.tasks.anomaly'
            ]
            
            for module_name in shift_suite_modules:
                try:
                    # __import__ã‚’ä½¿ç”¨ã—ã¦å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                    module = __import__(module_name, fromlist=[''])
                    import_results[module_name] = {
                        'import_successful': True,
                        'module_attributes': len(dir(module)),
                        'error': None
                    }
                    successful_imports += 1
                except Exception as e:
                    import_results[module_name] = {
                        'import_successful': False,
                        'error': str(e)
                    }
                total_modules += 1
            
            import_success_rate = successful_imports / total_modules if total_modules > 0 else 0
            success = import_success_rate >= self.test_criteria['module_import_threshold']
            
            return {
                'success': success,
                'import_success_rate': import_success_rate,
                'total_modules': total_modules,
                'successful_imports': successful_imports,
                'failed_imports': total_modules - successful_imports,
                'detailed_results': import_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _test_algorithm_functionality(self):
        """ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        try:
            algorithm_results = {}
            total_algorithms = 0
            functional_algorithms = 0
            
            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ†ã‚¹ãƒˆ
            basic_algorithms = {
                'data_processing': self._test_data_processing_algorithm,
                'shortage_calculation': self._test_shortage_calculation_algorithm,
                'fatigue_analysis': self._test_fatigue_analysis_algorithm,
                'anomaly_detection': self._test_anomaly_detection_algorithm
            }
            
            for algorithm_name, test_function in basic_algorithms.items():
                try:
                    result = test_function()
                    algorithm_results[algorithm_name] = result
                    if result.get('functional', False):
                        functional_algorithms += 1
                except Exception as e:
                    algorithm_results[algorithm_name] = {
                        'functional': False,
                        'error': str(e)
                    }
                total_algorithms += 1
            
            functionality_rate = functional_algorithms / total_algorithms if total_algorithms > 0 else 0
            success = functionality_rate >= self.test_criteria['algorithm_functionality_threshold']
            
            return {
                'success': success,
                'functionality_rate': functionality_rate,
                'total_algorithms': total_algorithms,
                'functional_algorithms': functional_algorithms,
                'non_functional_algorithms': total_algorithms - functional_algorithms,
                'detailed_results': algorithm_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _test_data_processing_algorithm(self):
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ†ã‚¹ãƒˆ"""
        try:
            # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
            test_data = [
                {'day': '2025-01-01', 'shift': 'A', 'hours': 8},
                {'day': '2025-01-02', 'shift': 'B', 'hours': 6},
                {'day': '2025-01-03', 'shift': 'C', 'hours': 10}
            ]
            
            # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ†ã‚¹ãƒˆ
            processed_data = []
            for item in test_data:
                processed_item = {
                    'date': item['day'],
                    'shift_type': item['shift'],
                    'working_hours': float(item['hours']),
                    'processed_timestamp': datetime.datetime.now().isoformat()
                }
                processed_data.append(processed_item)
            
            # é›†è¨ˆãƒ†ã‚¹ãƒˆ
            total_hours = sum(item['working_hours'] for item in processed_data)
            average_hours = total_hours / len(processed_data)
            
            return {
                'functional': True,
                'processed_records': len(processed_data),
                'total_hours': total_hours,
                'average_hours': average_hours,
                'test_data_sample': processed_data[0] if processed_data else None
            }
            
        except Exception as e:
            return {
                'functional': False,
                'error': str(e)
            }
    
    def _test_shortage_calculation_algorithm(self):
        """ä¸è¶³æ™‚é–“ç®—å‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ†ã‚¹ãƒˆ"""
        try:
            # ä¸è¶³æ™‚é–“è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
            required_hours = 100
            assigned_hours = 75
            shortage = max(0, required_hours - assigned_hours)
            shortage_percentage = (shortage / required_hours) * 100 if required_hours > 0 else 0
            
            # è¤‡æ•°ã‚·ãƒ•ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ
            shift_patterns = [
                {'required': 100, 'assigned': 85},
                {'required': 120, 'assigned': 120},
                {'required': 80, 'assigned': 90}
            ]
            
            pattern_results = []
            for pattern in shift_patterns:
                pattern_shortage = max(0, pattern['required'] - pattern['assigned'])
                pattern_results.append({
                    'required': pattern['required'],
                    'assigned': pattern['assigned'],
                    'shortage': pattern_shortage,
                    'shortage_rate': (pattern_shortage / pattern['required']) * 100 if pattern['required'] > 0 else 0
                })
            
            return {
                'functional': True,
                'basic_shortage': shortage,
                'shortage_percentage': shortage_percentage,
                'pattern_test_results': pattern_results,
                'total_patterns_tested': len(shift_patterns)
            }
            
        except Exception as e:
            return {
                'functional': False,
                'error': str(e)
            }
    
    def _test_fatigue_analysis_algorithm(self):
        """ç–²åŠ´åº¦åˆ†æã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ†ã‚¹ãƒˆ"""
        try:
            # ç–²åŠ´åº¦è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
            work_schedules = [
                {'consecutive_days': 5, 'daily_hours': 8},
                {'consecutive_days': 3, 'daily_hours': 12},
                {'consecutive_days': 7, 'daily_hours': 6}
            ]
            
            fatigue_results = []
            for schedule in work_schedules:
                # ç°¡æ˜“ç–²åŠ´åº¦è¨ˆç®—ï¼ˆé€£ç¶šå‹¤å‹™æ—¥æ•° Ã— æ—¥å¹³å‡æ™‚é–“ã®é‡ã¿ä»˜ã‘ï¼‰
                base_fatigue = schedule['consecutive_days'] * 0.1
                hours_fatigue = max(0, schedule['daily_hours'] - 8) * 0.05
                total_fatigue = base_fatigue + hours_fatigue
                
                fatigue_level = 'low'
                if total_fatigue > 0.8:
                    fatigue_level = 'high'
                elif total_fatigue > 0.4:
                    fatigue_level = 'medium'
                
                fatigue_results.append({
                    'consecutive_days': schedule['consecutive_days'],
                    'daily_hours': schedule['daily_hours'],
                    'fatigue_score': round(total_fatigue, 2),
                    'fatigue_level': fatigue_level
                })
            
            return {
                'functional': True,
                'fatigue_analysis_results': fatigue_results,
                'schedules_analyzed': len(work_schedules),
                'high_fatigue_count': len([r for r in fatigue_results if r['fatigue_level'] == 'high'])
            }
            
        except Exception as e:
            return {
                'functional': False,
                'error': str(e)
            }
    
    def _test_anomaly_detection_algorithm(self):
        """ç•°å¸¸æ¤œçŸ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ†ã‚¹ãƒˆ"""
        try:
            # ç•°å¸¸æ¤œçŸ¥ãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
            normal_data = [8, 8.5, 7.5, 8, 9, 7, 8.5, 8, 7.5, 8]
            test_values = [8, 15, 7.5, 2, 8.5]  # 15ã¨2ãŒç•°å¸¸å€¤
            
            # ç°¡æ˜“ç•°å¸¸æ¤œçŸ¥ï¼ˆå¹³å‡Â±2æ¨™æº–åå·®ï¼‰
            mean_value = sum(normal_data) / len(normal_data)
            variance = sum((x - mean_value) ** 2 for x in normal_data) / len(normal_data)
            std_dev = variance ** 0.5
            
            upper_threshold = mean_value + (2 * std_dev)
            lower_threshold = mean_value - (2 * std_dev)
            
            anomaly_results = []
            for value in test_values:
                is_anomaly = value > upper_threshold or value < lower_threshold
                anomaly_results.append({
                    'value': value,
                    'is_anomaly': is_anomaly,
                    'deviation_from_mean': abs(value - mean_value)
                })
            
            detected_anomalies = len([r for r in anomaly_results if r['is_anomaly']])
            
            return {
                'functional': True,
                'mean_value': round(mean_value, 2),
                'std_deviation': round(std_dev, 2),
                'upper_threshold': round(upper_threshold, 2),
                'lower_threshold': round(lower_threshold, 2),
                'anomaly_detection_results': anomaly_results,
                'total_test_values': len(test_values),
                'detected_anomalies': detected_anomalies
            }
            
        except Exception as e:
            return {
                'functional': False,
                'error': str(e)
            }
    
    def _test_system_integration(self):
        """ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ"""
        try:
            integration_results = {}
            total_integrations = 0
            successful_integrations = 0
            
            # JSONå‡¦ç†çµ±åˆãƒ†ã‚¹ãƒˆ
            json_test = self._test_json_processing_integration()
            integration_results['json_processing'] = json_test
            total_integrations += 1
            if json_test.get('integration_successful', False):
                successful_integrations += 1
            
            # æ—¥æ™‚å‡¦ç†çµ±åˆãƒ†ã‚¹ãƒˆ
            datetime_test = self._test_datetime_processing_integration()
            integration_results['datetime_processing'] = datetime_test
            total_integrations += 1
            if datetime_test.get('integration_successful', False):
                successful_integrations += 1
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼çµ±åˆãƒ†ã‚¹ãƒˆ
            dataflow_test = self._test_dataflow_integration()
            integration_results['dataflow'] = dataflow_test
            total_integrations += 1
            if dataflow_test.get('integration_successful', False):
                successful_integrations += 1
            
            integration_success_rate = successful_integrations / total_integrations if total_integrations > 0 else 0
            success = integration_success_rate >= self.test_criteria['integration_success_threshold']
            
            return {
                'success': success,
                'integration_success_rate': integration_success_rate,
                'total_integrations': total_integrations,
                'successful_integrations': successful_integrations,
                'failed_integrations': total_integrations - successful_integrations,
                'detailed_results': integration_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _test_json_processing_integration(self):
        """JSONå‡¦ç†çµ±åˆãƒ†ã‚¹ãƒˆ"""
        try:
            test_data = {
                'shift_analysis': {
                    'date': '2025-01-01',
                    'shifts': [
                        {'type': 'morning', 'hours': 8},
                        {'type': 'evening', 'hours': 6}
                    ],
                    'total_hours': 14
                },
                'metadata': {
                    'processed_at': datetime.datetime.now().isoformat(),
                    'version': '1.0'
                }
            }
            
            # JSON serialization test
            json_string = json.dumps(test_data, ensure_ascii=False, indent=2)
            
            # JSON deserialization test
            parsed_data = json.loads(json_string)
            
            # Data integrity check
            integrity_check = (
                parsed_data['shift_analysis']['total_hours'] == 14 and
                len(parsed_data['shift_analysis']['shifts']) == 2
            )
            
            return {
                'integration_successful': True,
                'json_size': len(json_string),
                'data_integrity_check': integrity_check,
                'parsed_shifts_count': len(parsed_data['shift_analysis']['shifts'])
            }
            
        except Exception as e:
            return {
                'integration_successful': False,
                'error': str(e)
            }
    
    def _test_datetime_processing_integration(self):
        """æ—¥æ™‚å‡¦ç†çµ±åˆãƒ†ã‚¹ãƒˆ"""
        try:
            current_time = datetime.datetime.now()
            
            # æ—¥æ™‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ†ã‚¹ãƒˆ
            formatted_time = current_time.strftime('%Y-%m-%d %H:%M:%S')
            iso_format_time = current_time.isoformat()
            
            # æ—¥æ™‚è¨ˆç®—ãƒ†ã‚¹ãƒˆ
            future_time = current_time + datetime.timedelta(days=7)
            time_difference = future_time - current_time
            
            # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆåŸºæœ¬ï¼‰
            utc_time = datetime.datetime.utcnow()
            
            return {
                'integration_successful': True,
                'current_time': formatted_time,
                'iso_format': iso_format_time,
                'future_time': future_time.strftime('%Y-%m-%d %H:%M:%S'),
                'time_difference_days': time_difference.days,
                'utc_time': utc_time.isoformat()
            }
            
        except Exception as e:
            return {
                'integration_successful': False,
                'error': str(e)
            }
    
    def _test_dataflow_integration(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼çµ±åˆãƒ†ã‚¹ãƒˆ"""
        try:
            # ãƒ‡ãƒ¼ã‚¿å…¥åŠ›â†’å‡¦ç†â†’å‡ºåŠ›ã®çµ±åˆãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ
            input_data = {
                'employees': [
                    {'id': 1, 'name': 'Employee A', 'shift_hours': [8, 6, 8, 0, 8]},
                    {'id': 2, 'name': 'Employee B', 'shift_hours': [6, 8, 0, 8, 6]},
                    {'id': 3, 'name': 'Employee C', 'shift_hours': [8, 8, 8, 8, 0]}
                ]
            }
            
            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ•ãƒ­ãƒ¼
            processed_employees = []
            for employee in input_data['employees']:
                total_hours = sum(employee['shift_hours'])
                working_days = len([h for h in employee['shift_hours'] if h > 0])
                average_daily_hours = total_hours / working_days if working_days > 0 else 0
                
                processed_employee = {
                    'id': employee['id'],
                    'name': employee['name'],
                    'total_hours': total_hours,
                    'working_days': working_days,
                    'average_daily_hours': round(average_daily_hours, 1)
                }
                processed_employees.append(processed_employee)
            
            # é›†è¨ˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            summary_data = {
                'total_employees': len(processed_employees),
                'total_work_hours': sum(emp['total_hours'] for emp in processed_employees),
                'average_work_hours_per_employee': round(
                    sum(emp['total_hours'] for emp in processed_employees) / len(processed_employees), 1
                ) if processed_employees else 0
            }
            
            return {
                'integration_successful': True,
                'input_records': len(input_data['employees']),
                'processed_records': len(processed_employees),
                'summary_data': summary_data,
                'sample_processed_employee': processed_employees[0] if processed_employees else None
            }
            
        except Exception as e:
            return {
                'integration_successful': False,
                'error': str(e)
            }
    
    def _test_strategy_execution_results(self):
        """æˆ¦ç•¥å®Ÿè¡Œçµæœæ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        try:
            strategy_files = [
                'Phase1_Emergency_Protocol_Verification_*.json',
                'Phase2_Incremental_Enhancement_Execution_*.json',
                'Phase3_ROI_Optimization_Execution_*.json',
                'Phase4_Strategic_Evolution_Execution_*.json',
                'D1_Technical_Innovation_Execution_*.json',
                'D2_Business_Expansion_Execution_*.json',
                'Comprehensive_Strategy_Completion_Report_*.json'
            ]
            
            found_files = {}
            strategy_results = {}
            
            for pattern in strategy_files:
                # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
                import glob
                matching_files = glob.glob(os.path.join(self.base_path, pattern))
                found_files[pattern] = len(matching_files)
                
                if matching_files:
                    latest_file = max(matching_files, key=os.path.getmtime)
                    try:
                        with open(latest_file, 'r', encoding='utf-8') as f:
                            result_data = json.load(f)
                        strategy_results[pattern] = {
                            'file_found': True,
                            'success': result_data.get('success', False),
                            'file_size': os.path.getsize(latest_file),
                            'latest_file': latest_file
                        }
                    except Exception as e:
                        strategy_results[pattern] = {
                            'file_found': True,
                            'success': False,
                            'error': str(e)
                        }
                else:
                    strategy_results[pattern] = {
                        'file_found': False,
                        'success': False
                    }
            
            total_strategy_files = len(strategy_files)
            found_strategy_files = len([r for r in strategy_results.values() if r['file_found']])
            successful_strategies = len([r for r in strategy_results.values() if r.get('success', False)])
            
            success = (found_strategy_files / total_strategy_files) >= 0.7  # 70%ä»¥ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹
            
            return {
                'success': success,
                'total_strategy_files': total_strategy_files,
                'found_strategy_files': found_strategy_files,
                'successful_strategies': successful_strategies,
                'strategy_completion_rate': found_strategy_files / total_strategy_files,
                'strategy_success_rate': successful_strategies / total_strategy_files,
                'detailed_results': strategy_results,
                'test_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _calculate_comprehensive_evaluation(self, test_results):
        """ç·åˆè©•ä¾¡è¨ˆç®—"""
        try:
            # å„ãƒ†ã‚¹ãƒˆçµæœã®ã‚¹ã‚³ã‚¢è¨ˆç®—
            scores = {
                'file_existence': test_results['file_existence']['existence_rate'] * 100 if test_results['file_existence']['success'] else 0,
                'syntax_validation': test_results['syntax_validation']['syntax_validity_rate'] * 100 if test_results['syntax_validation']['success'] else 0,
                'module_imports': test_results['module_imports']['import_success_rate'] * 100 if test_results['module_imports']['success'] else 0,
                'algorithm_functionality': test_results['algorithm_functionality']['functionality_rate'] * 100 if test_results['algorithm_functionality']['success'] else 0,
                'system_integration': test_results['system_integration']['integration_success_rate'] * 100 if test_results['system_integration']['success'] else 0,
                'strategy_execution': test_results['strategy_execution']['strategy_completion_rate'] * 100 if test_results['strategy_execution']['success'] else 0
            }
            
            # é‡ã¿ä»˜ãã‚¹ã‚³ã‚¢è¨ˆç®—
            weighted_scores = {
                'file_existence': scores['file_existence'] * 0.15,
                'syntax_validation': scores['syntax_validation'] * 0.20,
                'module_imports': scores['module_imports'] * 0.15,
                'algorithm_functionality': scores['algorithm_functionality'] * 0.25,
                'system_integration': scores['system_integration'] * 0.15,
                'strategy_execution': scores['strategy_execution'] * 0.10
            }
            
            total_score = sum(weighted_scores.values())
            
            # ç·åˆè©•ä¾¡ãƒ¬ãƒ™ãƒ«åˆ¤å®š
            if total_score >= 95:
                overall_status = 'excellent'
                readiness_level = 'å®Ÿæˆ¦é‹ç”¨æº–å‚™å®Œå…¨å®Œäº†'
            elif total_score >= 90:
                overall_status = 'very_good'
                readiness_level = 'å®Ÿæˆ¦é‹ç”¨æº–å‚™ã»ã¼å®Œäº†'
            elif total_score >= 85:
                overall_status = 'good'
                readiness_level = 'å®Ÿç”¨ãƒ¬ãƒ™ãƒ«é‹ç”¨æº–å‚™å®Œäº†'
            elif total_score >= 80:
                overall_status = 'acceptable'
                readiness_level = 'åŸºæœ¬ãƒ¬ãƒ™ãƒ«é‹ç”¨æº–å‚™å®Œäº†'
            elif total_score >= 70:
                overall_status = 'needs_improvement'
                readiness_level = 'é‹ç”¨æº–å‚™è¦æ”¹å–„'
            else:
                overall_status = 'critical_issues'
                readiness_level = 'é‡å¤§å•é¡Œè¦å¯¾å¿œ'
            
            # æˆåŠŸåˆ¤å®š
            overall_test_status = 'success' if total_score >= 80 else 'failure'
            
            return {
                'overall_test_status': overall_test_status,
                'total_score': round(total_score, 1),
                'individual_scores': scores,
                'weighted_scores': weighted_scores,
                'evaluation_level': overall_status,
                'system_readiness_level': readiness_level,
                'passed_tests': len([result for result in test_results.values() if result.get('success', False)]),
                'total_tests': len(test_results),
                'test_pass_rate': len([result for result in test_results.values() if result.get('success', False)]) / len(test_results) * 100,
                'recommendations': self._generate_recommendations(scores, overall_status),
                'evaluation_timestamp': datetime.datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'overall_test_status': 'evaluation_error',
                'error': str(e)
            }
    
    def _generate_recommendations(self, scores, overall_status):
        """æ”¹å–„æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        if scores['file_existence'] < 95:
            recommendations.append('é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸è¶³ç¢ºèªãƒ»è£œå®ŒãŒå¿…è¦')
        
        if scores['syntax_validation'] < 100:
            recommendations.append('Pythonæ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã®ä¿®æ­£ãŒå¿…è¦')
        
        if scores['module_imports'] < 90:
            recommendations.append('ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¾å­˜é–¢ä¿‚ã®ç¢ºèªãƒ»ä¿®æ­£ãŒå¿…è¦')
        
        if scores['algorithm_functionality'] < 85:
            recommendations.append('ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ©Ÿèƒ½ã®æ”¹å–„ãƒ»æœ€é©åŒ–ãŒå¿…è¦')
        
        if scores['system_integration'] < 80:
            recommendations.append('ã‚·ã‚¹ãƒ†ãƒ çµ±åˆéƒ¨åˆ†ã®å¼·åŒ–ãŒå¿…è¦')
        
        if scores['strategy_execution'] < 70:
            recommendations.append('æˆ¦ç•¥å®Ÿè¡Œçµæœã®ç¢ºèªãƒ»æ”¹å–„ãŒå¿…è¦')
        
        if not recommendations:
            recommendations.append('ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒé«˜æ°´æº–ã§æˆåŠŸ - ç¶™ç¶šç›£è¦–ä½“åˆ¶ã¸ç§»è¡Œæ¨å¥¨')
        
        return recommendations

if __name__ == "__main__":
    # å¼·åŒ–ç‰ˆã‚·ãƒ•ãƒˆåˆ†ææ©Ÿèƒ½ç·åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_system = EnhancedShiftAnalysisFunctionalityTest()
    
    print("ğŸš€ å¼·åŒ–ç‰ˆã‚·ãƒ•ãƒˆåˆ†ææ©Ÿèƒ½ç·åˆãƒ†ã‚¹ãƒˆé–‹å§‹...")
    result = test_system.execute_comprehensive_functionality_test()
    
    # çµæœãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    result_filename = f"Enhanced_Shift_Analysis_Functionality_Test_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    result_filepath = os.path.join(test_system.base_path, result_filename)
    
    with open(result_filepath, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ¯ å¼·åŒ–ç‰ˆã‚·ãƒ•ãƒˆåˆ†ææ©Ÿèƒ½ç·åˆãƒ†ã‚¹ãƒˆå®Œäº†!")
    print(f"ğŸ“ ãƒ†ã‚¹ãƒˆçµæœãƒ•ã‚¡ã‚¤ãƒ«: {result_filename}")
    
    if result['success']:
        evaluation = result['comprehensive_evaluation']
        
        print(f"\nğŸ† ãƒ†ã‚¹ãƒˆçµæœ: {evaluation['overall_test_status']}")
        print(f"â­ ã‚·ã‚¹ãƒ†ãƒ æº–å‚™ãƒ¬ãƒ™ãƒ«: {evaluation['system_readiness_level']}")
        print(f"ğŸ“Š ç·åˆã‚¹ã‚³ã‚¢: {evaluation['total_score']}/100")
        print(f"âœ… æˆåŠŸãƒ†ã‚¹ãƒˆ: {evaluation['passed_tests']}/{evaluation['total_tests']}")
        print(f"ğŸ“ˆ ãƒ†ã‚¹ãƒˆæˆåŠŸç‡: {evaluation['test_pass_rate']:.1f}%")
        
        print(f"\nğŸ“‹ å€‹åˆ¥ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢:")
        for test_name, score in evaluation['individual_scores'].items():
            print(f"  â€¢ {test_name}: {score:.1f}/100")
        
        if evaluation['recommendations']:
            print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
            for recommendation in evaluation['recommendations']:
                print(f"  â€¢ {recommendation}")
        
        print(f"\nğŸŒŸ {evaluation['system_readiness_level']}!")
        
    else:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼")
        if 'error_details' in result:
            print(f"ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°: {result['error_details']['error']}")