#!/usr/bin/env python3
"""
app.pyçµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
æŒ‰åˆ†å»ƒæ­¢ãƒ»è·ç¨®åˆ¥åˆ†æã‚·ã‚¹ãƒ†ãƒ  - Streamlitã‚¢ãƒ—ãƒªçµ±åˆç‰ˆ
Created: 2025-08-08T09:17:05.482151
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import time, datetime, timedelta
import json
import sys
import re

# åŸºæœ¬ã‚¯ãƒ©ã‚¹å®šç¾©

class AppParameterExtractor:
    """app.pyã‹ã‚‰ã®å‹•çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡ºã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, app_file_path='app.py'):
        self.app_file_path = Path(app_file_path)
        
    def extract_period_parameters(self):
        """æœŸé–“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡º"""
        
        try:
            with open(self.app_file_path, 'r', encoding='utf-8') as f:
                app_content = f.read()
            
            # need_ref_start_date_widget ã¨ need_ref_end_date_widget ã®æ¤œç´¢
            period_params = {}
            
            # é–‹å§‹æ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢
            start_date_patterns = [
                r'need_ref_start_date_widget.*?=.*?(['"].*?['"])',
                r'need_ref_start_date.*?=.*?(['"].*?['"])',
                r'start.*?date.*?=.*?(['"].*?['"])',
            ]
            
            # çµ‚äº†æ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢
            end_date_patterns = [
                r'need_ref_end_date_widget.*?=.*?(['"].*?['"])',
                r'need_ref_end_date.*?=.*?(['"].*?['"])',
                r'end.*?date.*?=.*?(['"].*?['"])',
            ]
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
            period_params = {
                'start_date': None,
                'end_date': None,
                'period_days': 30,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                'extraction_method': 'DEFAULT'
            }
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œ
            for pattern in start_date_patterns:
                match = re.search(pattern, app_content, re.IGNORECASE | re.DOTALL)
                if match:
                    period_params['start_date'] = match.group(1).strip(''"')
                    period_params['extraction_method'] = 'REGEX_EXTRACTED'
                    break
            
            for pattern in end_date_patterns:
                match = re.search(pattern, app_content, re.IGNORECASE | re.DOTALL)
                if match:
                    period_params['end_date'] = match.group(1).strip(''"')
                    period_params['extraction_method'] = 'REGEX_EXTRACTED'
                    break
            
            # æœŸé–“æ—¥æ•°è¨ˆç®—
            if period_params['start_date'] and period_params['end_date']:
                try:
                    start_dt = pd.to_datetime(period_params['start_date'])
                    end_dt = pd.to_datetime(period_params['end_date'])
                    period_params['period_days'] = (end_dt - start_dt).days + 1
                except Exception as e:
                    print(f'[WARNING] æ—¥ä»˜è§£æå¤±æ•—: {e}')
                    period_params['period_days'] = 30
            
            return period_params
            
        except Exception as e:
            print(f'[WARNING] app.pyãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•—: {e}')
            return {
                'start_date': None,
                'end_date': None,
                'period_days': 30,
                'extraction_method': 'ERROR_FALLBACK'
            }
    
    def extract_scenario_directory(self):
        """ã‚·ãƒŠãƒªã‚ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæŠ½å‡º"""
        
        try:
            with open(self.app_file_path, 'r', encoding='utf-8') as f:
                app_content = f.read()
            
            # ã‚·ãƒŠãƒªã‚ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢
            directory_patterns = [
                r'extracted_results[/\\]([^/\\'"\s]+)',
                r'scenario.*?dir.*?=.*?['"]([^'"]+)['"]',
                r'out_[a-zA-Z0-9_]+',
            ]
            
            scenario_info = {
                'directory': 'extracted_results/out_p25_based',  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                'extraction_method': 'DEFAULT'
            }
            
            for pattern in directory_patterns:
                matches = re.findall(pattern, app_content, re.IGNORECASE)
                if matches:
                    scenario_info['directory'] = f'extracted_results/{matches[-1]}'
                    scenario_info['extraction_method'] = 'REGEX_EXTRACTED'
                    break
            
            return scenario_info
            
        except Exception as e:
            print(f'[WARNING] ã‚·ãƒŠãƒªã‚ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæŠ½å‡ºå¤±æ•—: {e}')
            return {
                'directory': 'extracted_results/out_p25_based',
                'extraction_method': 'ERROR_FALLBACK'
            }
    
    def extract_all_parameters(self):
        """å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ±åˆæŠ½å‡º"""
        
        period_params = self.extract_period_parameters()
        scenario_info = self.extract_scenario_directory()
        
        return {
            'period': period_params,
            'scenario': scenario_info,
            'extraction_timestamp': datetime.now().isoformat(),
            'app_file_path': str(self.app_file_path)
        }



class DynamicNeedCalculationIntegration:
    """å‹•çš„Needç®—å‡ºçµ±åˆã‚¯ãƒ©ã‚¹ - app.pyçµ±åˆå°‚ç”¨"""
    
    def __init__(self, app_file_path='app.py'):
        self.param_extractor = AppParameterExtractor(app_file_path)
        self.calculation_results = {}
        
    def execute_integrated_calculation(self):
        """çµ±åˆè¨ˆç®—å®Ÿè¡Œ"""
        
        print('app.pyçµ±åˆNeedç®—å‡ºå®Ÿè¡Œä¸­...')
        
        # 1. app.pyã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡º
        app_params = self.param_extractor.extract_all_parameters()
        print(f'æŠ½å‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: æœŸé–“{app_params["period"]["period_days"]}æ—¥')
        
        # 2. ã‚·ãƒŠãƒªã‚ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        scenario_dir = Path(app_params['scenario']['directory'])
        if not scenario_dir.exists():
            raise FileNotFoundError(f'ã‚·ãƒŠãƒªã‚ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {scenario_dir}')
        
        # 3. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        data_package = self.load_dynamic_data(scenario_dir, app_params['period']['period_days'])
        
        # 4. Needç®—å‡ºå®Ÿè¡Œ
        calculation_results = self.execute_proportional_abolition_calculation(
            data_package, app_params['period']['period_days']
        )
        
        # 5. çµæœçµ±åˆ
        integrated_results = {
            'app_parameters': app_params,
            'data_metadata': data_package['metadata'],
            'calculation_results': calculation_results,
            'integration_timestamp': datetime.now().isoformat()
        }
        
        self.calculation_results = integrated_results
        return integrated_results
    
    def load_dynamic_data(self, scenario_dir, period_days):
        """å‹•çš„ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        
        # intermediate_dataèª­ã¿è¾¼ã¿
        intermediate_data = pd.read_parquet(scenario_dir / 'intermediate_data.parquet')
        operating_data = intermediate_data[intermediate_data['role'] != 'NIGHT_SLOT']
        
        # Needå€¤å‹•çš„èª­ã¿è¾¼ã¿ï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œï¼‰
        need_files_patterns = [
            'need_per_date_slot_role_*.parquet',
            'need_*_role_*.parquet',
            'need_*.parquet'
        ]
        
        need_files = []
        for pattern in need_files_patterns:
            found_files = list(scenario_dir.glob(pattern))
            if found_files:
                need_files = found_files
                break
        
        if not need_files:
            raise FileNotFoundError(f'Needãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {scenario_dir}')
        
        # Needå€¤å‡¦ç†
        need_data = {}
        for need_file in need_files:
            role_name = self.extract_role_name_from_filename(need_file.name)
            df = pd.read_parquet(need_file)
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            total_need = df[numeric_cols].sum().sum()
            
            need_data[role_name] = {
                'file_path': need_file,
                'total_need_value': total_need,
                'need_hours_total': total_need * 0.5,  # UNIFIED_SLOT_HOURS
                'need_hours_daily': (total_need * 0.5) / period_days  # å‹•çš„æœŸé–“å¯¾å¿œ
            }
        
        return {
            'intermediate_data': intermediate_data,
            'operating_data': operating_data,
            'need_data': need_data,
            'metadata': {
                'total_records': len(operating_data),
                'period_days': period_days,  # å‹•çš„æœŸé–“
                'unique_roles': operating_data['role'].nunique(),
                'unique_staff': operating_data['staff'].nunique(),
                'need_files_count': len(need_files),
                'total_need_hours': sum(data['need_hours_total'] for data in need_data.values())
            }
        }
    
    def extract_role_name_from_filename(self, filename):
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰è·ç¨®åæŠ½å‡º"""
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: need_per_date_slot_role_è·ç¨®å.parquet
        if 'need_per_date_slot_role_' in filename:
            return filename.replace('need_per_date_slot_role_', '').replace('.parquet', '')
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: need_è·ç¨®å_role_*.parquet
        match = re.search(r'need_([^_]+)_role', filename)
        if match:
            return match.group(1)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: need_è·ç¨®å.parquet
        if filename.startswith('need_'):
            return filename.replace('need_', '').replace('.parquet', '')
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return filename.replace('.parquet', '')
    
    def execute_proportional_abolition_calculation(self, data_package, period_days):
        """æŒ‰åˆ†å»ƒæ­¢è¨ˆç®—å®Ÿè¡Œ"""
        
        operating_data = data_package['operating_data']
        need_data = data_package['need_data']
        
        # è·ç¨®åˆ¥å®Ÿé…ç½®æ™‚é–“è¨ˆç®—
        role_actual_allocation = {}
        for role in operating_data['role'].unique():
            role_data = operating_data[operating_data['role'] == role]
            role_records = len(role_data)
            role_hours_total = role_records * 0.5
            role_hours_daily = role_hours_total / period_days  # å‹•çš„æœŸé–“å¯¾å¿œ
            
            role_actual_allocation[role] = {
                'records': role_records,
                'hours_total': role_hours_total,
                'hours_daily': role_hours_daily,
                'staff_count': role_data['staff'].nunique()
            }
        
        # è·ç¨®åˆ¥éä¸è¶³ç®—å‡º
        role_shortages = {}
        for role_name, need_info in need_data.items():
            need_hours_daily = need_info['need_hours_daily']
            actual_info = role_actual_allocation.get(role_name, {
                'hours_daily': 0, 'staff_count': 0
            })
            actual_hours_daily = actual_info['hours_daily']
            shortage_daily = need_hours_daily - actual_hours_daily
            
            role_shortages[role_name] = {
                'role': role_name,
                'need_hours_daily': need_hours_daily,
                'actual_hours_daily': actual_hours_daily,
                'shortage_daily': shortage_daily,
                'shortage_status': 'SHORTAGE' if shortage_daily > 0 else 'SURPLUS' if shortage_daily < 0 else 'BALANCED',
                'staff_count_current': actual_info['staff_count']
            }
        
        # çµ„ç¹”å…¨ä½“éä¸è¶³ç®—å‡º
        total_need_daily = sum(need_info['need_hours_daily'] for need_info in need_data.values())
        total_actual_daily = sum(actual_info['hours_daily'] for actual_info in role_actual_allocation.values())
        total_shortage_daily = total_need_daily - total_actual_daily
        
        return {
            'role_based_results': {
                'role_shortages': role_shortages,
                'shortage_ranking': sorted(role_shortages.values(), key=lambda x: x['shortage_daily'], reverse=True)
            },
            'organization_wide_results': {
                'total_need_daily': total_need_daily,
                'total_actual_daily': total_actual_daily,
                'total_shortage_daily': total_shortage_daily,
                'organization_status': 'SHORTAGE' if total_shortage_daily > 0 else 'SURPLUS' if total_shortage_daily < 0 else 'BALANCED'
            }
        }
    
    def get_streamlit_display_data(self):
        """Streamlitè¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        
        if not self.calculation_results:
            raise ValueError('è¨ˆç®—çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚execute_integrated_calculation()ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')
        
        results = self.calculation_results['calculation_results']
        
        # è·ç¨®åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        role_df = pd.DataFrame([
            {
                'è·ç¨®': info['role'],
                'Needæ™‚é–“/æ—¥': round(info['need_hours_daily'], 1),
                'å®Ÿé…ç½®æ™‚é–“/æ—¥': round(info['actual_hours_daily'], 1),
                'éä¸è¶³æ™‚é–“/æ—¥': round(info['shortage_daily'], 1),
                'ç¾åœ¨ã‚¹ã‚¿ãƒƒãƒ•æ•°': info['staff_count_current'],
                'çŠ¶æ…‹': info['shortage_status']
            }
            for info in results['role_based_results']['role_shortages'].values()
        ])
        
        # çµ„ç¹”å…¨ä½“ãƒ‡ãƒ¼ã‚¿
        org_data = results['organization_wide_results']
        
        return {
            'role_breakdown_df': role_df,
            'organization_summary': {
                'total_need': round(org_data['total_need_daily'], 1),
                'total_actual': round(org_data['total_actual_daily'], 1),
                'total_shortage': round(org_data['total_shortage_daily'], 1),
                'status': org_data['organization_status']
            },
            'app_parameters': self.calculation_results['app_parameters']
        }


# Streamlitè¡¨ç¤ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

def create_proportional_abolition_dashboard(integration_results):
    """æŒ‰åˆ†å»ƒæ­¢åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ"""
    
    import streamlit as st
    import plotly.express as px
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    
    # ãƒšãƒ¼ã‚¸è¨­å®š
    st.markdown("## æŒ‰åˆ†å»ƒæ­¢ãƒ»è·ç¨®åˆ¥åˆ†æçµæœ")
    
    display_data = integration_results
    org_summary = display_data['organization_summary']
    role_df = display_data['role_breakdown_df']
    app_params = display_data['app_parameters']
    
    # åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¡¨ç¤º
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("åˆ†ææœŸé–“", f"{app_params['period']['period_days']}æ—¥")
    with col2:
        st.metric("æŠ½å‡ºæ–¹æ³•", app_params['period']['extraction_method'])
    with col3:
        st.metric("è·ç¨®æ•°", len(role_df))
    
    # çµ„ç¹”å…¨ä½“ã‚µãƒãƒªãƒ¼
    st.markdown("### çµ„ç¹”å…¨ä½“éä¸è¶³")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Needæ™‚é–“/æ—¥", f"{org_summary['total_need']}h")
    with col2:
        st.metric("å®Ÿé…ç½®æ™‚é–“/æ—¥", f"{org_summary['total_actual']}h")
    with col3:
        color = "normal" if abs(org_summary['total_shortage']) < 5 else "inverse"
        st.metric("éä¸è¶³æ™‚é–“/æ—¥", f"{org_summary['total_shortage']:+.1f}h", delta_color=color)
    with col4:
        status_color = "ğŸ”´" if org_summary['status'] == 'SHORTAGE' else "ğŸŸ¢" if org_summary['status'] == 'SURPLUS' else "ğŸŸ¡"
        st.metric("çµ„ç¹”çŠ¶æ…‹", f"{status_color} {org_summary['status']}")
    
    # è·ç¨®åˆ¥è©³ç´°
    st.markdown("### è·ç¨®åˆ¥éä¸è¶³è©³ç´°")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
    st.dataframe(
        role_df.style.format({
            'Needæ™‚é–“/æ—¥': '{:.1f}',
            'å®Ÿé…ç½®æ™‚é–“/æ—¥': '{:.1f}',
            'éä¸è¶³æ™‚é–“/æ—¥': '{:+.1f}'
        }).applymap(
            lambda x: 'background-color: #ffebee' if isinstance(x, str) and 'SHORTAGE' in x 
                     else 'background-color: #e8f5e8' if isinstance(x, str) and 'SURPLUS' in x 
                     else '', subset=['çŠ¶æ…‹']
        ),
        use_container_width=True
    )
    
    # è·ç¨®åˆ¥éä¸è¶³ã‚°ãƒ©ãƒ•
    st.markdown("### è·ç¨®åˆ¥éä¸è¶³è¦–è¦šåŒ–")
    
    # æ¨ªæ£’ã‚°ãƒ©ãƒ•
    fig = px.bar(
        role_df.sort_values('éä¸è¶³æ™‚é–“/æ—¥', ascending=True),
        x='éä¸è¶³æ™‚é–“/æ—¥',
        y='è·ç¨®',
        orientation='h',
        color='éä¸è¶³æ™‚é–“/æ—¥',
        color_continuous_scale=['red', 'white', 'green'],
        color_continuous_midpoint=0,
        title='è·ç¨®åˆ¥éä¸è¶³æ™‚é–“/æ—¥',
        labels={'éä¸è¶³æ™‚é–“/æ—¥': 'éä¸è¶³æ™‚é–“ (æ™‚é–“/æ—¥)', 'è·ç¨®': 'è·ç¨®'}
    )
    
    fig.update_layout(
        height=max(400, len(role_df) * 30),
        xaxis_title="éä¸è¶³æ™‚é–“ (æ™‚é–“/æ—¥)",
        yaxis_title="è·ç¨®"
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # æ•£å¸ƒå›³: Need vs å®Ÿé…ç½®
    fig_scatter = px.scatter(
        role_df,
        x='Needæ™‚é–“/æ—¥',
        y='å®Ÿé…ç½®æ™‚é–“/æ—¥',
        size='ç¾åœ¨ã‚¹ã‚¿ãƒƒãƒ•æ•°',
        color='çŠ¶æ…‹',
        hover_name='è·ç¨®',
        title='Needæ™‚é–“ vs å®Ÿé…ç½®æ™‚é–“',
        labels={
            'Needæ™‚é–“/æ—¥': 'Needæ™‚é–“ (æ™‚é–“/æ—¥)',
            'å®Ÿé…ç½®æ™‚é–“/æ—¥': 'å®Ÿé…ç½®æ™‚é–“ (æ™‚é–“/æ—¥)'
        }
    )
    
    # ç†æƒ³ç·šï¼ˆNeed = å®Ÿé…ç½®ï¼‰ã‚’è¿½åŠ 
    max_val = max(role_df['Needæ™‚é–“/æ—¥'].max(), role_df['å®Ÿé…ç½®æ™‚é–“/æ—¥'].max())
    fig_scatter.add_trace(go.Scatter(
        x=[0, max_val],
        y=[0, max_val],
        mode='lines',
        line=dict(dash='dash', color='gray'),
        name='ç†æƒ³ç·š (Need = å®Ÿé…ç½®)'
    ))
    
    st.plotly_chart(fig_scatter, use_container_width=True)
    
    return {
        'dashboard_created': True,
        'components_count': 4,
        'visualizations': ['metrics', 'dataframe', 'horizontal_bar', 'scatter_plot']
    }

def create_shortage_priority_matrix(role_df):
    """ä¸è¶³å„ªå…ˆåº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆ"""
    
    import streamlit as st
    import plotly.express as px
    import numpy as np
    
    st.markdown("### æ”¹å–„å„ªå…ˆåº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹")
    
    # å„ªå…ˆåº¦è¨ˆç®—
    role_df_copy = role_df.copy()
    role_df_copy['ä¸è¶³æ™‚é–“çµ¶å¯¾å€¤'] = role_df_copy['éä¸è¶³æ™‚é–“/æ—¥'].abs()
    role_df_copy['å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢'] = (
        role_df_copy['ä¸è¶³æ™‚é–“çµ¶å¯¾å€¤'] * 2 +  # ä¸è¶³æ™‚é–“ã®é‡ã¿
        (role_df_copy['ç¾åœ¨ã‚¹ã‚¿ãƒƒãƒ•æ•°'] == 0) * 10  # æœªé…ç½®ã®å ´åˆã®é‡ã¿
    )
    
    # å„ªå…ˆåº¦åˆ†é¡
    def get_priority_level(row):
        if row['ç¾åœ¨ã‚¹ã‚¿ãƒƒãƒ•æ•°'] == 0 and row['éä¸è¶³æ™‚é–“/æ—¥'] > 0:
            return 'IMMEDIATE'
        elif row['éä¸è¶³æ™‚é–“/æ—¥'] > 5:
            return 'HIGH'
        elif row['éä¸è¶³æ™‚é–“/æ—¥'] > 2:
            return 'MEDIUM'
        elif row['éä¸è¶³æ™‚é–“/æ—¥'] > 0:
            return 'LOW'
        else:
            return 'NONE'
    
    role_df_copy['å„ªå…ˆåº¦ãƒ¬ãƒ™ãƒ«'] = role_df_copy.apply(get_priority_level, axis=1)
    
    # å„ªå…ˆåº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¡¨ç¤º
    priority_colors = {
        'IMMEDIATE': '#d32f2f',
        'HIGH': '#f57c00',
        'MEDIUM': '#fbc02d',
        'LOW': '#689f38',
        'NONE': '#455a64'
    }
    
    fig_matrix = px.scatter(
        role_df_copy[role_df_copy['éä¸è¶³æ™‚é–“/æ—¥'] > 0],  # ä¸è¶³è·ç¨®ã®ã¿
        x='ç¾åœ¨ã‚¹ã‚¿ãƒƒãƒ•æ•°',
        y='éä¸è¶³æ™‚é–“/æ—¥',
        color='å„ªå…ˆåº¦ãƒ¬ãƒ™ãƒ«',
        size='å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢',
        hover_name='è·ç¨®',
        color_discrete_map=priority_colors,
        title='æ”¹å–„å„ªå…ˆåº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ (ä¸è¶³è·ç¨®ã®ã¿)',
        labels={
            'ç¾åœ¨ã‚¹ã‚¿ãƒƒãƒ•æ•°': 'ç¾åœ¨ã‚¹ã‚¿ãƒƒãƒ•æ•° (äºº)',
            'éä¸è¶³æ™‚é–“/æ—¥': 'ä¸è¶³æ™‚é–“ (æ™‚é–“/æ—¥)'
        }
    )
    
    st.plotly_chart(fig_matrix, use_container_width=True)
    
    # å„ªå…ˆåº¦åˆ¥é›†è¨ˆ
    priority_summary = role_df_copy[role_df_copy['å„ªå…ˆåº¦ãƒ¬ãƒ™ãƒ«'] != 'NONE'].groupby('å„ªå…ˆåº¦ãƒ¬ãƒ™ãƒ«').agg({
        'è·ç¨®': 'count',
        'éä¸è¶³æ™‚é–“/æ—¥': 'sum',
        'ç¾åœ¨ã‚¹ã‚¿ãƒƒãƒ•æ•°': 'sum'
    }).rename(columns={'è·ç¨®': 'è·ç¨®æ•°', 'éä¸è¶³æ™‚é–“/æ—¥': 'åˆè¨ˆä¸è¶³æ™‚é–“', 'ç¾åœ¨ã‚¹ã‚¿ãƒƒãƒ•æ•°': 'åˆè¨ˆã‚¹ã‚¿ãƒƒãƒ•æ•°'})
    
    st.markdown("#### å„ªå…ˆåº¦åˆ¥é›†è¨ˆ")
    st.dataframe(priority_summary, use_container_width=True)
    
    return role_df_copy[['è·ç¨®', 'å„ªå…ˆåº¦ãƒ¬ãƒ™ãƒ«', 'å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢']].sort_values('å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢', ascending=False)


# çµ±åˆãƒ†ã‚¹ãƒˆé–¢æ•°

def test_app_integration_complete():
    """å®Œå…¨appçµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    
    print('=' * 60)
    print('å®Œå…¨appçµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ')
    print('=' * 60)
    
    try:
        # 1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡ºãƒ†ã‚¹ãƒˆ
        print('\nã€Test 1: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡ºãƒ†ã‚¹ãƒˆã€‘')
        param_extractor = AppParameterExtractor('app.py')
        app_params = param_extractor.extract_all_parameters()
        
        print(f'æœŸé–“æŠ½å‡º: {app_params["period"]["period_days"]}æ—¥')
        print(f'æŠ½å‡ºæ–¹æ³•: {app_params["period"]["extraction_method"]}')
        print(f'ã‚·ãƒŠãƒªã‚ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {app_params["scenario"]["directory"]}')
        
        # 2. çµ±åˆè¨ˆç®—ãƒ†ã‚¹ãƒˆ
        print('\nã€Test 2: çµ±åˆè¨ˆç®—ãƒ†ã‚¹ãƒˆã€‘')
        integration = DynamicNeedCalculationIntegration('app.py')
        calculation_results = integration.execute_integrated_calculation()
        
        print(f'è¨ˆç®—å®Œäº†: è·ç¨®æ•°{len(calculation_results["calculation_results"]["role_based_results"]["role_shortages"])}')
        print(f'çµ„ç¹”å…¨ä½“çŠ¶æ…‹: {calculation_results["calculation_results"]["organization_wide_results"]["organization_status"]}')
        
        # 3. Streamlitè¡¨ç¤ºãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
        print('\nã€Test 3: Streamlitè¡¨ç¤ºãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆã€‘')
        display_data = integration.get_streamlit_display_data()
        
        print(f'è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {len(display_data["role_breakdown_df"])}è·ç¨®')
        print(f'çµ„ç¹”å…¨ä½“ä¸è¶³: {display_data["organization_summary"]["total_shortage"]:+.1f}æ™‚é–“/æ—¥')
        
        # 4. çµ±åˆæˆåŠŸç¢ºèª
        print('\nã€Test 4: çµ±åˆæˆåŠŸç¢ºèªã€‘')
        success_checks = [
            len(calculation_results) > 0,
            'calculation_results' in calculation_results,
            len(display_data['role_breakdown_df']) > 0,
            display_data['organization_summary']['status'] in ['SHORTAGE', 'SURPLUS', 'BALANCED']
        ]
        
        all_success = all(success_checks)
        print(f'çµ±åˆãƒ†ã‚¹ãƒˆçµæœ: {"SUCCESS" if all_success else "FAILED"}')
        
        return {
            'test_success': all_success,
            'app_params': app_params,
            'calculation_results': calculation_results,
            'display_data': display_data,
            'test_timestamp': datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f'[ERROR] çµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•—: {e}')
        return {'test_success': False, 'error': str(e)}

def test_dynamic_parameter_extraction():
    """å‹•çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡ºãƒ†ã‚¹ãƒˆ"""
    
    print('\nå‹•çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡ºãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...')
    
    try:
        extractor = AppParameterExtractor('app.py')
        
        # æœŸé–“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
        period_params = extractor.extract_period_parameters()
        print(f'æœŸé–“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {period_params}')
        
        # ã‚·ãƒŠãƒªã‚ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ†ã‚¹ãƒˆ
        scenario_info = extractor.extract_scenario_directory()
        print(f'ã‚·ãƒŠãƒªã‚ªæƒ…å ±: {scenario_info}')
        
        # çµ±åˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
        all_params = extractor.extract_all_parameters()
        print(f'çµ±åˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡ºæˆåŠŸ: {len(all_params)}é …ç›®')
        
        return {
            'extraction_success': True,
            'period_params': period_params,
            'scenario_info': scenario_info,
            'all_params': all_params
        }
        
    except Exception as e:
        print(f'[ERROR] ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡ºãƒ†ã‚¹ãƒˆå¤±æ•—: {e}')
        return {'extraction_success': False, 'error': str(e)}

def test_streamlit_dashboard_integration():
    """Streamlitãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    print('\nStreamlitãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...')
    
    try:
        # çµ±åˆè¨ˆç®—å®Ÿè¡Œ
        integration = DynamicNeedCalculationIntegration('app.py')
        calculation_results = integration.execute_integrated_calculation()
        display_data = integration.get_streamlit_display_data()
        
        # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæº–å‚™
        dashboard_ready = True
        components_ready = [
            'role_breakdown_df' in display_data,
            'organization_summary' in display_data,
            len(display_data['role_breakdown_df']) > 0
        ]
        
        dashboard_ready = all(components_ready)
        
        print(f'ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æº–å‚™: {"Ready" if dashboard_ready else "Not Ready"}')
        print(f'è¡¨ç¤ºå¯èƒ½è·ç¨®æ•°: {len(display_data["role_breakdown_df"])}')
        print(f'çµ„ç¹”çŠ¶æ…‹: {display_data["organization_summary"]["status"]}')
        
        return {
            'dashboard_ready': dashboard_ready,
            'display_data': display_data,
            'components_ready': components_ready
        }
        
    except Exception as e:
        print(f'[ERROR] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•—: {e}')
        return {'dashboard_ready': False, 'error': str(e)}


# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
def execute_app_integration():
    """ãƒ¡ã‚¤ãƒ³appçµ±åˆå®Ÿè¡Œ"""
    
    print('=' * 80)
    print('app.pyçµ±åˆNeedç®—å‡ºã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ')
    print('æŒ‰åˆ†å»ƒæ­¢ãƒ»è·ç¨®åˆ¥åˆ†æ - Streamlitçµ±åˆç‰ˆ')
    print('=' * 80)
    
    try:
        # çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        test_result = test_app_integration_complete()
        
        if test_result['test_success']:
            print('\n[SUCCESS] appçµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†')
            print('ã‚·ã‚¹ãƒ†ãƒ ã¯Streamlitãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ä½¿ç”¨å¯èƒ½ã§ã™')
            
            # çµæœä¿å­˜
            result_file = f'appçµ±åˆçµæœ_20250808_091705.json'
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(test_result, f, ensure_ascii=False, indent=2, default=str)
            print(f'çµ±åˆçµæœä¿å­˜: {result_file}')
            
            return test_result
        else:
            print('\n[ERROR] appçµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•—')
            return test_result
            
    except Exception as e:
        print(f'[ERROR] appçµ±åˆå®Ÿè¡Œå¤±æ•—: {e}')
        return {'success': False, 'error': str(e)}

if __name__ == "__main__":
    execute_app_integration()
